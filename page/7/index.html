<!DOCTYPE html>
<html lang="zh" dir="auto">

<head>
	<meta name="generator" content="Hugo 0.122.0"><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Waiting For You</title>

<meta name="description" content="这是一个纯粹的博客......">
<meta name="author" content="WFUing">
<link rel="canonical" href="https://WFUing.github.io/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.078343916625d121842bb25d5797d26510dec739246c5291e7aa1c8bdfed3a34.css" integrity="sha256-B4NDkWYl0SGEK7JdV5fSZRDexzkkbFKR56oci9/tOjQ=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://WFUing.github.io/img/logo.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://WFUing.github.io/img/logo.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://WFUing.github.io/img/logo.gif">
<link rel="apple-touch-icon" href="https://WFUing.github.io/logo.gif">
<link rel="mask-icon" href="https://WFUing.github.io/logo.gif">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://WFUing.github.io/index.xml">
<link rel="alternate" type="application/json" href="https://WFUing.github.io/index.json">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script>
window.MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']],
    displayMath: [['$$', '$$'], ['\[\[', '\]\]']],
    processEscapes: true,
    processEnvironments: true,
    autoload: {
      color: [],
      colorv2: ['color']
    },
    packages: {'[+]': ['noerrors']}
  },
  options: {
    skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    ignoreHtmlClass: 'tex2jax_ignore',
    processHtmlClass: 'tex2jax_process'
  },
  loader: {
    load: ['[tex]/noerrors']
  }
};
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" id="MathJax-script"></script>
<meta property="og:title" content="Waiting For You" />
<meta property="og:description" content="这是一个纯粹的博客......" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://WFUing.github.io/" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Waiting For You"/>
<meta name="twitter:description" content="这是一个纯粹的博客......"/>

<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "Organization",
  "name": "Waiting For You",
  "url": "https://WFUing.github.io/",
  "description": "这是一个纯粹的博客......",
  "thumbnailUrl": "https://WFUing.github.io/img/logo.gif",
  "sameAs": [
      "https://github.com/WFUing", "img/qq.jpg"
  ]
}
</script>
</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>
<header class="header intro-header" style="background-image: url('/img/home-bg-jeep.jpg')"><nav class="nav">
    <div class="logo">
        <a style="color: rgb(218, 218, 219);" href="https://WFUing.github.io/" accesskey="h" title="Waiting For You (Alt + H)">Waiting For You</a>
        <div class="logo-switches">
            <button id="theme-toggle" accesskey="t" title="(Alt + T)" style="color: rgb(218, 218, 219);">
                <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                    fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                    stroke-linejoin="round">
                    <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                </svg>
                <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                    fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                    stroke-linejoin="round">
                    <circle cx="12" cy="12" r="5"></circle>
                    <line x1="12" y1="1" x2="12" y2="3"></line>
                    <line x1="12" y1="21" x2="12" y2="23"></line>
                    <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                    <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                    <line x1="1" y1="12" x2="3" y2="12"></line>
                    <line x1="21" y1="12" x2="23" y2="12"></line>
                    <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                    <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                </svg>
            </button>
        </div>
    </div>
    <ul id="menu">
        <li>
            <a href="https://WFUing.github.io/search" title="SEARCH (Alt &#43; /)" accesskey=/>
                <span style="color: rgb(218, 218, 219);">SEARCH</span>
            </a>
        </li>
        <li>
            <a href="https://WFUing.github.io/" title="HOME">
                <span style="color: rgb(218, 218, 219);" class="active">HOME</span>
            </a>
        </li>
        <li>
            <a href="https://WFUing.github.io/post" title="BLOGS">
                <span style="color: rgb(218, 218, 219);">BLOGS</span>
            </a>
        </li>
        <li>
            <a href="https://WFUing.github.io/archives" title="ARCHIVE">
                <span style="color: rgb(218, 218, 219);">ARCHIVE</span>
            </a>
        </li>
        <li>
            <a href="https://WFUing.github.io/tags" title="TAGS">
                <span style="color: rgb(218, 218, 219);">TAGS</span>
            </a>
        </li>
    </ul>
</nav>

    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1 ">
                <div class="site-heading">
                    <h1 style="color: rgb(218, 218, 219);">Waiting For You </h1>
                    
		    <span class="subheading"></span>
                </div>
            </div>
        </div>
    </div>
</header>


<main class="main">

<div class="profile">
    <script>
        
        const childDiv = document.querySelector('.profile');
        
        const parentDiv = childDiv.parentElement.parentElement;
        parentDiv.setAttribute('name', 'profile-page')
    </script>

    <div class="profile_inner">
        <div data-pagefind-ignore="all" class="container">
            <div class="row">
                
                
                <div class="
                    col-lg-8 col-lg-offset-1
                    col-md-8 col-md-offset-1
                    col-sm-12
                    col-xs-12
                    post-container
                ">
                     
                    <div data-pagefind-ignore="all">
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/architecture/iot/reactive-manifesto/">
                            <h2 class="post-title">
                                响应式宣言(Reactive Manifesto)
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                响应式系统具有响应性、复原性、弹性和消息驱动性。
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Saturday, October 28, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/architecture/iot/akka/">
                            <h2 class="post-title">
                                akka框架
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                Akka 是一个开源项目，基于 Apache 2 License。AKKA框架是用Scala写的，主要用于高并发与分布式应用，目前已经得到广泛地运用，例如Spark、Spray等框架在底层都使用了AKKA进行并发处理。
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Friday, October 27, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/algorithm/ai/li-hongyis-notes/markdown%E5%85%AC%E5%BC%8F%E8%AF%AD%E6%B3%95/">
                            <h2 class="post-title">
                                Markdown公式语法.md
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                一、公式使用参考 1．如何插入公式 $ \LaTeX $ 的数学公式有两种：行中公式和独立公式。行中公式放在文中与其它文字混编，独立公式单独成行。
行中公式可以用如下方法表示： $ 数学公式 $
独立公式可以用如下方法表示： $$ 数学公式 $$
自动编号的公式可以用如下方法表示： 若需要手动编号，参见“大括号和行标的使用”。 \begin{equation} 数学公式 \label{eq:当前公式名} \end{equation}
自动编号后的公式可在全文任意处使用 \eqref{eq:公式名} 语句引用。
例子： 1 $ J_\alpha(x) = \sum_{m=0}^\infty \frac{(-1)^m}{m! \Gamma (m + \alpha + 1)} {\left({ \frac{x}{2} }\right)}^{2m + \alpha} \text {，行内公式示例} $ 显示：$ J_\alpha(x) = \sum_{m=0}^\infty \frac{(-1)^m}{m! \Gamma (m + \alpha + 1)} {\left({ \frac{x}{2} }\right)}^{2m + \alpha} \text {，行内公式示例} $
例子：
1 $$ J_\alpha(x) = \sum_{m=0}^\infty \frac{(-1)^m}{m! \Gamma (m + \alpha + 1)} {\left({ \frac{x}{2} }\right)}^{2m + \alpha} \text {，独立公式示例} $$ 显示：$$ J_\alpha(x) = \sum_{m=0}^\infty \frac{(-1)^m}{m!
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Monday, October 23, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/algorithm/ai/li-hongyis-notes/%E4%BA%8C%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/">
                            <h2 class="post-title">
                                二、回归模型.md
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                二、回归模型 [toc]
2.1 线性回归模型 回归模型应用案例 股票市场预测（Stock Market Forecast）：预测某个公司明天的股票情况 自动驾驶车（Self-Driving Car）：预测方向盘的转动角度 推荐系统（Recommendation）：预测某用户购买某商品的可能性 线性回归模型（Linear Regression Model） 形式如下： $y= f(x) = w \cdot x + b $
y是输出，$\widehat{y}$ 是真实值/标签（label) w是权重（weight） b是偏置（bias） x是输入（input），也可叫做特征（feature）。数据集中一般包含多个object，每个object一般包含多个component。此时，上标是object的索引，下标是component的索引 损失函数（Loss Function）如果不考虑模型的好坏，衡量一个函数的好坏，其实是衡量模型参数的好坏。以线性模型为例，就是衡量参数和的好坏。如 $ L(f) = L(w,b) = \sum_{n=1} ^{10}{ \widehat{y} - (b + w \cdot x_n)} $ ，把所有的样本误差的平方和作为损失函数 输入：一个函数 输出：多么地不好（how bad it is）。损失函数值越大，则这个函数越差、与数据集中内容月不相符 梯度下降（Gradient Descent） 梯度下降可以优化损失函数的值，使其尽量小，即可找到最好（在数据集上模拟效果最好）的模型参数。 现在假设模型$f$中只有一个参数 $w$，则损失函数为$L(f) = L(w)$ ，梯度下降算法如下
初始化参数：随机选取一个 $ w_0 $（并不一定是随机选取），令 $ w = w_0 $ 计算梯度 $\frac{dL(f)}{dw}|_{w=w_0}$ ，如果小于0，此时w增大则L（f）减小，如果大于0，此时w减小则L（w）会减小。如果模型中有多个参数，则计算损失函数在各个参数方向上的偏导数 更新模型参数，$w_1 = w_0 - lr \frac{dL(f)}{dw}|_{w=w_0}$ ，w的变化量取决于梯度和学习率（Learning Rate）的大小：梯度绝对值或学习率越大，则w变化量越大。如果模型有多个参数，则用上一步计算出的偏导数对应更新各参数。 重复第2步和第3步，经过多次参数更新/迭代（iteration），可以使损失函数的值达到局部最小（即局部最优，Local Optimal），但不一定是全局最优。 现在假设模型$f$中只有两个参数 $w$，则损失函数为$L(f) = L(w)$ ，梯度下降算法如下（若模型中有多个参数，按相同方法更新各参数）
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Monday, October 23, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/algorithm/ai/li-hongyis-notes/%E5%85%ADtips-for-training-dnn/">
                            <h2 class="post-title">
                                六、Tips for Training DNN.md
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                Tips for Training DNN [toc]
6.1 神经网络训练问题与解决方案 明确问题类型及其对应方法 在深度学习中，一般有两种问题：
在训练集上性能不好 在测试集上性能不好。 当一个方法被提出时，它往往是针对这两个问题其中之一的，比如dropout方法是用来处理在测试集上性能不好的情况。
处理神经网络在训练集上性能不好的情况和方法 修改神经网络架构，比如换成更好的激活函数： sigmoid函数会导致梯度消失，可以换成ReLU、Leaky ReLU、Parametric ReLU、Maxout 调整学习率： 比如RMSProp、Momentum、Adam 处理神经网络在测试集上性能不好的情况和方法 Early Stopping、Regularization，这两个是比较传统的方法，不只适用于深度学习 Dropout，比较有深度学习的特色 一些性能优化方法的简介 下面3点都是在增加模型的随机性，鼓励模型做更多的exploration。
Shuffling： 输入数据的顺序不要固定，mini-batch每次要重新生成 Dropout： 鼓励每个神经元都学到东西，也可以广义地理解为增加随机性 Gradient noise： 2015年提出，计算完梯度后，加上Gaussian noise。 随着迭代次数增加，noise应该逐渐变小。 下面3点是关于学习率调整的技巧
warm up： 开始时学习率较小，等稳定之后学习率变大 Curriculum learning： 2009年提出，先使用简单的数据训练模型（一方面此时模型比较弱，另一方面在clean data中更容易提取到核心特征），然后再用难的数据训练模型。 这样可以提高模型的鲁棒性。 Fine-tuning 下面3点是关于数据预处理的技巧，避免模型学习到太极端的参数
Normalization： 有Batch Normalization、Instance Normalization、Group Normalization、Layer Normalization、Positional Normalization Regularization 6.2 神经网络精度低不一定是因为过拟合 相比于决策树等方法，神经网络更不容易过拟合：K近邻、决策树等方法在训练集上更容易得到100%等很高的正确率，神经网络一般不能，训练神经网络首先遇到的问题一般是在训练集上的精度不高。 不要总是把精度低归咎于过拟合：如果模型在训练集上精度高，对于K近邻、决策树等方法我们可以直接判断为过拟合，但对于神经网络来说我们还需要检查神经网络在测试集上的精度。如果神经网络在训练集上精度高但在测试集上精度低，这才说明神经网络过拟合了。 如果56层的神经网络和20层的神经网络相比，56层网络在测试集上的精度低于20层网络，这还不能判断为56层网络包含了过多参数导致过拟合。一般来讲，56层网络优于20层网络，但如果我们发现56层网络在训练集上的精度本来就低于20层网络，那原因可能有很多而非过拟合，比如56层网络没训练好导致一个不好的局部最优、虽然56层网络的参数多但结构有问题等等。 感兴趣可以看看ResNet论文**Deep Residual Learning for Image Recognition**，这篇论文可能与该问题有关。 6.3 常用激活函数（训练集） 梯度消失（Vanishing Gradient Problem） 定义：1980年代常用的激活函数是sigmoid函数。以MNIST手写数字识别为例，在使用sigmoid函数时会发现随着神经网络层数增加，识别准确率逐渐下降，这个现象的原因并不是过拟合（原因见上文），而是梯度消失。
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Monday, October 23, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/algorithm/ai/li-hongyis-notes/%E4%B8%83convolutional-neural-network/">
                            <h2 class="post-title">
                                七、Convolutional Neural Network.md
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                七、Convolutional Neural Network [toc]
7.1 CNN入门详解 卷积神经网络（CNN）常常被用来做图像处理，当然也可以用一般的神经网络，那它们各自有什么优缺点呢？
FNN用于图片处理的缺点 使用一般的全连接前馈神经网络（FNN）处理图片时的缺点：
需要很多的参数： 假设有一张尺寸100×100的图片（尺寸已经算很小了），那输入层就有100×100×3=30K个像素，假设第一个隐藏层有1K个神经元（一个神经元包含30K个参数），这就已经需要30M个参数了…… 该架构中每个神经元就是一个分类器，这是没必要的： 第一个隐藏层作为最基础的pattern分类器（比如判断有无绿色、边缘等），第二个隐藏层基于第一个隐藏层继续做pattern分类（比如木头、肉类），以此类推…… 按照人类的直观理解，我们不是像全连接神经网络一样去处理图片的。具体来看，有哪些方面呢？
图片的一些性质 结合全连接前馈神经网络的缺点和人类对图片的直观理解，可以得到下述图片的3个性质。
性质1：Some patterns are much smaller than the whole image. 在识别某个模式（pattern）时，一个神经元并不需要图片的所有像素点。对于一张人类全身照的图片，我们只需要看到头部而非整张图片就可以判断它是一个人脸。所以我们应该是可以用少量参数去识别这些pattern的。
性质2：The same patterns appear in different regions. 比如说人脸可以在图片的中间区域，也可以在图片的某个角落区域。所以识别不同区域中的相同pattern的多个分类器（或detector）应该用同一组参数或者共享参数。
性质3：Subsampling the pixels will not change the object CNN架构说明 2014年在ECCV上提出，针对上述的图片的3个性质，确定了CNN的架构如下。
如上图所示，图片经过卷积层然后进行最大池化（max pooling），这个步骤可以进行多次；然后将数据展开（Flatten），然后将数据传进全连接前馈网络得到最后的图片分类结果。
如上图所示，卷积是针对了图片的性质1和性质2，最大池化是针对了图片的性质3。
卷积(Convolution) ★ 假设有一张6×6的二值图，即一个6×6的矩阵。
卷积核（Filter） 神经元就是一个计算/函数，卷积核其实就是神经元。如下图所示，1个卷积层可以有多个卷积核，矩阵里元素的值就是需要通过学习得到的参数。因为这里的输入是一个矩阵，所以卷积核也是1个矩阵（卷积核的通道数等于输入的通道数）。假设卷积核大小是3×3，这对应了图片的性质1，即用小的卷积核识别一个小的pattern。
怎么做卷积 如下图所示
卷积区域： 根据该卷积核的大小（以3×3为例），选择图片中相同大小的区域进行卷积。 卷积的计算方法： 从图片中扫描得到的3×3矩阵和卷积核的3×3矩阵，这2个矩阵相同位置的元素相乘可以得到9个值并求和（也就是内积）得到1个值，这就是1次卷积操作。 卷积顺序和方向： 卷积核按照从左到右、从上到下的顺序，从图片左上角开始移动，移动步长（stride）可以设置（以1为例）。在扫描到的每个区域中，都进行1次卷积。1个卷积核移动结束后，则得到1个新的矩阵（大小为4×4），即1个卷积核的输出是1个矩阵。 卷积层有多个卷积核，每个卷积核都按照该方式进行卷积得到多个矩阵，这些矩阵合起来就形成了1个卷积层的特征图（Feature Map），这个特征图也就是卷积层的输出。 卷积层特征图的通道数等于该卷积层中卷积核的数量，即某卷积层有多少个卷积核，那该卷积层的特征图就有多少个通道。 
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Monday, October 23, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/algorithm/ai/li-hongyis-notes/%E4%B8%89%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/">
                            <h2 class="post-title">
                                三、梯度下降.md
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                三、梯度下降 [toc]
梯度下降伪代码 梯度下降可以优化损失函数的值，使其尽量小，即可找到最好（在数据集上拟合效果最好）的模型参数。现在假设模型 $f$ 中只有一个参数 $w$ ，则损失函数为 $L(f) = L(w)$ ，梯度下降算法如下（若模型有多个参数，按相同方法更新各方法）
初始化参数：随机选取一个 $w_0$ （$w_0$ 并不一定是随机选取） 计算梯度 $\frac{dL(f)}{dw}$ ，如果小于0，此时 $w$ 增大则 $L(f)$ 会减小；如果大于0，此时 $w$ 增大则 $L(w)$ 会减小。如果模型有多个参数，则计算损失函数在各个参数方向上的偏导数。 更新模型参数 $w_1=w_0-lr\frac{dL(f)}{dw}$ ，$w$ 的变化量取决于梯度和学习率（Learning Rate）的大小：梯度绝对值或学习率越大，则 $w$ 变化量越大。如果模型有多个参数，则用上一步计算出的偏导数对应更新各参数。 重复第2步和第3步。经过多次参数更新/迭代（iteration），可以使损失函数的值达到局部最小（即局部最优，Local Optimal），但不一定是全局最优。 自适应学习率（Adaptive Learning Rate） 梯度下降的过程中，固定学习率并不合理。学习率太大，可能导致loss不减小反而增大；学习率太小，loss会减小得很慢。基本原则是随着参数迭代更新，学习率应该越来越小，比如 $\eta_t = \frac{\eta}{\sqrt{t+1}}$ 。更好的办法是每个参数都有各自的学习率，比如Adagrad。
Adagrad Adaptive Gradient Descent，自适应梯度下降。2011年提出，核心是每个参数（parameter）有不同的学习率。每次迭代中，学习率要除以它对应参数的之前梯度的均方根（RMS），即 $w_{t+1} = w_t-\frac{\eta}{\sqrt{\sum_{i=0}^{t}{(g_t)^2}}}g_t$ ，其中 $t$ 是迭代次数，$w$ 是参数，$g$ 是梯度，$\eta$ 是初始学习率。随着参数迭代，$t$ 越来越大，$\sqrt{\sum_{i=0}^{t}{(g_t)^2}}$ 也越来越大，因此学习率的变化趋势是越来越小。
Adagrad的矛盾（Contradiction） 一般的梯度下降方法中 $w_{t+1}=w_t-\eta_tg_t$ ，其中 $\eta_t$ 是常数，梯度越大时，则参数更新的步幅越大，这是由 $g_t$ 项决定的。在Adagrad中，$\eta$ 是常量，梯度 $g_t$ 越大时，会使得参数更新的步幅越大，但 $\sqrt{\sum_{i=0}^{t}{(g_t)^2}}$ 越大会使得参数更新的步幅越小，这是一个矛盾吗？
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Monday, October 23, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/algorithm/ai/li-hongyis-notes/%E5%9B%9B%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/">
                            <h2 class="post-title">
                                四、分类模型.md
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                四、分类模型 [toc]
4.1 分类简介及其与回归的区别 分类模型应用案例（Classification Cases） 信用评分（Credit Scoring） 输入：收入、储蓄、职业、年龄、信用历史等等 输出：是否贷款 医疗诊断（Medical Diagnosis） 输入：现在症状、年龄、性别、病史 输出：哪种疾病 手写文字识别（Handwritten Character Recognition） 输入：文字图片 输出：是哪一个汉字 人脸识别（Face Recognition） 输入：面部图片 输出：是哪个人 把分类当成回归去做 不行
假设有两个类别，其中类别1的标签为1，类别2的标签为-1，那0就是分界线，大于0就是类别1，小于0就是类别2。但是回归模型会惩罚哪些太正确的样本，如果结果远远大于1，它的分类应该是类别1还是类别2？这时为了降低整体误差，需要调整已经找到的回归函数，就会导致结果的不准确。 假设有多个类别，类别1的标签是1，类别2的标签是2，类别3的标签是3。这样的话，标签间具有2和3相近、3大于2这种本来不存在的数字关系。 理想替代方案（Ideal Alternatives） 模型：模型可以根据特征判断类型，输入是特征，输出是类别 损失函数：预测错误的次数，即$L(f)=\sum_n{\sigma(f(x_n) \neq \hat{y_n} }$ 。这个函数不可微。 如何找到最好的函数，比如感知机（Perceptron）、支持向量机（SVM） 4.2 分类模型指概率生成模型 贝叶斯公式 $P(A \cap B) = P(A)P(B|A) = P(B)P(A|B)$ $P(A|B) = \frac{P(A)P(B|A)}{P(B)}$ 全概率公式 $P(B)=\sum_{i=1}^{n}{P(A_i)P(B|A_i)}$
概率生成模型（Probalitity Genetative Model） 理论与定义 假设有两个类别的$C_1和C_2$，要判断对象$x$属于哪个类别，这样把分类问题变成了概率计算问题。
根据贝叶斯公式（Bayes&rsquo; theorem）和全概率公式（Total Probability Theorem）可以知道，$x$属于类别$C_1$的概率为$P(C_1|x)= \frac{P(x|C_1)P(C_1)}{P(x)}=\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}$ ，如果$P(C_1|x)&gt;0.5$ 则类别为$C_1$ ，否则类别为$C_2$。 概率生成模型的意思就是可以通过这个模型生成一个$$x$$。具体来讲就是，根据$P(x)=P(x|C_1)P(C_1)+P(x|C_2)P(C_2)$ 计算出$P(x)$，就可以知道 $x$ 的分布进而生成 $x$ 。如果想要计算出$P(x)$，就要根据训练集估计出$P(C_1)$、$P(x|C_1)$、$P(C_2)$、$P(x|C_2)$这四个值。更直观一点地讲，每个类别就是一个多元正态分布，其中多元是因为每个样本有多个维度的特征。 可以根据数据集中属于两个类别的对象的数量计算 $P(C_1)$ 和 $P(C_2)$ 这两个先验概率（Prior Probability）。如果有2个样本属于类别$C_1$ ，4个样本属于类别$C_2$ ，那$P(C_1)= \frac{1}{3}$、$P(C_2)= \frac{2}{3}$。 要计算后验概率（Posterior Probability）$P(x|C_1)$ 和 $P(x|C_2)$，可以假设训练集中的各类别样本的特征分别是从某个多元正太分布（多元对应特征的多维）中取样得到的，或者说是假设训练集中各类别样本的特征分别符合某多元正态分布。该正太分布的输入是一个样本的特征 $x$，输出为样本 $x$ 是从这个正太分布取样得到（或者说该样本属于某类别）的概率密度，然后通过积分就可以求得 $P(x|C_1)$ 和 $P(x|C_2)$ 。 正太分布公式为 $f_{\mu,\sum{(x)}}=\frac{1}{(2\pi)^\frac{D}{2}} \frac{1}{|\sum|^\frac{1}{2}} {e^{-\frac{1}{2}(x-\mu)^T\sum^{-1}{x-\mu}}}$ 。正太分布有2个参数，即均值 $\mu$ （代表正太分布的中心位置）和协方差矩阵（Covariance Matrix）$\sum$ （代表正态分布的离散程度），计算出均值 $\mu$ 和协方差 $\sum$ 即可得到该正态分布。公式中的 $D$ 为多维特征的维度。 实际上从任何一个正态分布中取样都有可能得到训练集中的特征，只是概率不同而已。通过极大值似然估计（Maximum Likelihood Estimate，MLE），我们可以找到取样得到训练集特征的概率最大的那个正态分布，假设其均值和协方差矩阵为 $ \mu^* $ 和 $ \sum^* $ 。 根据某正态分布的均值 $\mu$ 和协方差 $\sum$ ，可以计算出从该正态分布取样得到训练集的概率。 $ L(\mu,\sum) = f_{\mu,\sum}{x_1} f_{\mu,\sum}{x_2}f_{\mu,\sum}{x_3}&hellip;f_{\mu,\sum}{x_N} $ ，这就是似然函数（Likelihood Function），其中$N$ 是训练集中某个类别样本的数量。 $\mu^,\sum^=\arg\max_{\mu,\sum}{L(\mu,\sum)}$，当然可以求导。直觉：$\mu^=\frac{1}{N}\sum_{i=1}^{N}{x_i}$，$\sum^ = \frac{1}{N}\sum_{i=1}^{N}(x_i-\mu^*)^2T$ 协方差矩阵共享 每个类别的特征符合一个多元正态分布，每个多元正态分布也有不同的均值和协方差矩阵。让每个类别对应的多元正态分布共享一个协方差矩阵（各个协方差矩阵的加权平均和），公式为 $\sum = \frac{N_1}{N_1+N_2}\sum_1+\frac{N_2}{N_1+N_2}\sum_2$，可以减少模型参数，缓解过拟合
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Monday, October 23, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/algorithm/ai/li-hongyis-notes/%E4%BA%94%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
                            <h2 class="post-title">
                                五、深度学习.md
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                五、深度学习 [toc]
5.1引言 深度学习的历史 1958年：心理学家Rosenblatt提出感知机（Perceptron） 它是一个线性模型。 1969年：有人说感知机是线性模型，具有局限性。 1980年代：多层感知机（Multi-layer Perceptron） 和当今的神经网络是没有本质差别的。 1986年：Hinton提出反向传播算法（Backpropagation） 但是超过3个隐藏层的神经网络，还是训练不出好的结果。 1989年：有人提出一个隐藏层就可以得到任何函数，为什么要多层？ 多层感知机慢慢淡出大家的视野。 2006年：受限玻尔兹曼机初始化（RBM Initialization） Hinton提出用受限玻尔兹曼机做初始化，很多人觉得这是个大突破，但实际上用处并不大。 至少让多层感知机回到大家的视野。 2009年：GPU 2011年：神经网络用于语音识别 2012年：神经网络技术赢得ILSVRC（ImageNet Large Scale Visual Recognition Challenge） 深度学习的三个步骤 和机器学习一样：
确定模型（Model）/函数集（Function Set），在深度学习中就是定义一个神经网络。 不同的连接会构成多样的网络结构。 确定如何评价函数的好坏 如果是多分类，那和Classification一章中一样，计算每个样本预测结果与Ground Truth的交叉熵，然后求和，即为Loss。 确定如何找到最好的函数 还是Gradient Descent。 神经网络模型对应的函数比较复杂，而反向传播算法（Backpropagation）是一个很有效的计算神经网络梯度的方法。 神经网络的结构 输入层（Input Layer）：实际上就是输入，并不是真正的“层”。 隐藏层（Hidden Layers）：输入层和输出层之间的层，Deep指有很多隐藏层，多少层才算Deep并没有统一标准。可以看成特征提取器（Feature Extractor），作用是代替特征工程（Feature Engineering）。 输出层（Output Layer）：最后一层，可以看成分类器 全连接前反馈神经网络 即Fully Connected Feedforward Neural Network，FFN。
全连接是指每个神经元与上一层的所有神经元相连。 前馈神经网络（FNN，Feedforward Neural Network）是指各神经元分层排列，每个神经元只与前一层的神经元相连，接收前一层的输出，并输出给下一层，各层间没有反馈。 一些网络 其中Residual Net并不是一般的全连接前馈神经网络
网络结构 提出年份 层数 ImageNet错误率 AlexNet 2012 8 16.4% 2014 19 7.
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Monday, October 23, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    <div class="post-preview">
                        <a href="https://WFUing.github.io/post/tech/algorithm/ai/li-hongyis-notes/%E4%B8%80%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/">
                            <h2 class="post-title">
                                一、机器学习概论.md
                            </h2>
                        
                            <div class="post-content-preview">
                        
                                李宏毅机器学习笔记 [toc]
一、机器学习概论 机器学习是什么 机器学习就是让机器能自动找到一个函数function
语音识别（Speech Recognition）：输入是音频，输出是音频对应的文字 图像分类：输入是图片，输出是类别（比如猫、狗） AlphaGo下围棋：输入是当前棋盘的状态，输出是下一步落棋的位置 对话/问答系统 机器能够找到哪些函数 为解决不同的问题、完成不同的任务，需要找到不同的函数，那机器学习能找到哪些函数呢？
回归（Regression）：输出是一个连续的数值、标量，比如PM2.5预测 分类（Classification）：输出是一个离散的值。 二分类（Binary Classification）的输出就是0或1、Yes或No、&hellip;，比如文本情感分析的输出可以是正面和负面 多分类（Multi-Category Classification）的输出就是[1,2,3,&hellip;,N]，比如图像分类里判断一张图片是猫还是狗还是杯子 生成（Generation）：很多教科书吧机器学习划分为回归问题和分类问题，但其实不止这两种问题，比如生成（Generation）。生成是指让机器学习如何创造/生成，比如生成文本、图片等。 如何告诉机器我们希望找到什么函数 我们该如何为机器提供学习资料？
有监督学习（Supervised Learning）：可以把有监督学习种的“监督”理解为标签（Label），即数据集种不仅包括特征还包括标签。有了标签，我们就可以评价一个函数的好坏，进而优化这个函数。使用Loss判断函数的好坏，Loss越小，函数越好。 强化学习（Reinforcement Learning）：原始的AlphaGo是先通过有监督学习优化到一定程度，然后用强化学习继续优化。新版本的AlphaGo是完全通过强化学习实现的，优于原始的AlphaGo。 无监督学习（Unsupervised Learning）：只给机器提供数据特征，但不提供数据标签。那机器能学到什么呢？ 下面以让机器学习下围棋为例：有监督学习VS强化学习
有监督学习：函数的输入（数据特征）就是期盼状态，函数的输出（数据标签）就是下一步落棋的位置。此时，我们需要为机器提供的数据就类似棋谱（如果现在棋局是这样，那下一步怎么落棋最好），但其实人类不一定知道怎么落棋最好。 强化学习：让机器跟自己、别人下棋，把结果（赢或输）作为Reward，引导机器学习如何下棋。如果它赢了，那它就知道这一盘里有几步棋下得好，但不知道是哪几步；如果它输了，它就知道这一盘里有几步棋下得不好，但不知道是哪几步。 机器如何找出我们想找到的函数 我们要给定函数形式/范围（模型），比如假定函数是线性模型、神经网络等等。模型就是一个函数集，模型的参数确定以后，才得到一个函数。 找到更好的函数： 使用梯度下降（Gradient Descent），找到更好的函数。 前沿研究 AI的可解释性（Explainable AI）：比如，机器为什么认为这张图片里有一只猫？ 对抗攻击（Adversarial Attack）：对输入故意添加一些人无法察觉的细微的干扰，导致模型以高置信度给出一个错误的输出。 模型压缩（Network Compression）： 把模型压缩以减少模型对计算资源消耗。 异常检测（Anomaly Detection）：使机器知道它遇到了自己不知道的东西。 迁移学习（Transfer Learning/Domain Adversarial Learning）： 一个模型已经学到了一些知识，将这些知识应用到另一个任务中。 元学习（Meta Learning）： 让机器学习如何学习。机器学习是我们教机器学习某种知识，元学习是我们教机器如何学习。 终身学习（Life-Long Learning）：让机器终身学习，学习完任务1、再继续学任务2、…… 机器学习的三个步骤 确定模型（Model）/函数集（Function Set） 确定如何评价函数的好坏 确定如何找到最好的函数 
                        
                            </div>
                        </a>
                        <p class="post-meta">
                        
                            Posted by WFUing on Monday, October 23, 2023
                            
                            
                        
                        </p>

                    </div>
                    <hr>
                    
                    </div>

                    
                    
                    
                    <ul class="pager" data-pagefind-ignore="all">
                        
                        <li class="previous">
                            <a href="/page/6/">&larr; Newer Posts</a>
                        </li>
                        
                        
                        <li class="next">
                            <a href="/page/8/">Older Posts &rarr;</a>
                        </li>
                        
                    </ul>
                    
                </div>

                
                
                <div class="
                    col-lg-3 col-lg-offset-0
                    col-md-3 col-md-offset-0
                    col-sm-12
                    col-xs-12
                    sidebar-container
                ">
                    
                    
                    <section class="visible-md visible-lg">
                    
                        <div class="short-about">
                            
                            
                            
                                <p>Software Developer, Open Source Enthusiast and Life Adventurer</p>
                            
                        
                        <ul class="list-inline">
                            
                            <li>
                                <a href="mailto:youremail@gmail.com">
                                    <span class="fa-stack fa-lg">
                                        <i class="fa fa-circle fa-stack-2x"></i>
                                        <i class="fa fa-envelope fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            
                            
                            
                            
                            
                            
                            <li>
                                <a target="_blank" href="/your%20wechat%20qr%20code%20image">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-weixin fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            
                            
                            <li>
                                <a target="_blank" href="https://github.com/yourgithub">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            
                            
                            
                            
                            <li>
                                <a target="_blank" href="https://www.linkedin.com/in/yourlinkedinid">
                                    <span class="fa-stack fa-lg">
                                        <i class="fas fa-circle fa-stack-2x"></i>
                                        <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                                    </span>
                                </a>
                            </li>
                            
                            
                            
                                    <li>
                                        <a target="_blank" href="https://stackoverflow.com/users/yourstackoverflowid">
                                            <span class="fa-stack fa-lg">
                                                <i class="fas fa-circle fa-stack-2x"></i>
                                                <i class="fab fa-stack-overflow fa-stack-1x fa-inverse"></i>
                                            </span>
                                        </a>
                                    </li>
                            
                            
                            
                            
                            
                            
                            
                                </ul>
                            </div>
                    </section>
                    
                    
                    
                    
                    
                    <section>
                        <hr class="hidden-sm hidden-xs">
                        <h5>FEATURED TAGS</h5>
                        <div class="tags">
                            
                            
                            
                            
                            
                                    <a href="/tags/akka" title="akka">
                                        akka
                                    </a>
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                                    <a href="/tags/code-generation" title="code-generation">
                                        code-generation
                                    </a>
                            
                            
                            
                            
                            
                            
                            
                                    <a href="/tags/data" title="data">
                                        data
                                    </a>
                            
                            
                            
                                    <a href="/tags/dsl" title="dsl">
                                        dsl
                                    </a>
                            
                            
                            
                            
                            
                            
                            
                            
                            
                                    <a href="/tags/git" title="git">
                                        git
                                    </a>
                            
                            
                            
                                    <a href="/tags/http" title="http">
                                        http
                                    </a>
                            
                            
                            
                                    <a href="/tags/https" title="https">
                                        https
                                    </a>
                            
                            
                            
                            
                            
                            
                            
                            
                            
                                    <a href="/tags/interview" title="interview">
                                        interview
                                    </a>
                            
                            
                            
                            
                            
                                    <a href="/tags/java" title="java">
                                        java
                                    </a>
                            
                            
                            
                            
                            
                                    <a href="/tags/kubevela" title="kubevela">
                                        kubevela
                                    </a>
                            
                            
                            
                            
                            
                                    <a href="/tags/langium" title="langium">
                                        langium
                                    </a>
                            
                            
                            
                                    <a href="/tags/language" title="language">
                                        language
                                    </a>
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                                    <a href="/tags/serverless" title="serverless">
                                        serverless
                                    </a>
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                            
                                    <a href="/tags/xtext" title="xtext">
                                        xtext
                                    </a>
                            
                            
                        </div>
                    </section>
                    

                    
                    
                    
                </div>

            </div>
        </div>


    </div>

</div>

    </main>
    
<footer class="footer">
    <span>&copy; 2024 <a href="https://WFUing.github.io/">Waiting For You</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
