[{"content":"下面列出了所有类型的编程语言的完整分类列表。编程语言没有严格的分类方案。因此，我们可以将一种语言视为不止一种编程语言的示例。\n让我们一一理解这些编程语言。由于列表很大，因此不可能详细讨论所有这些内容。在这里，我正在用所有这些各种编程语言的示例编写简短的介绍。\n编译语言 编译语言是一种编程语言，其中我们使用编译器来编译和执行代码。编译器通常是从我们的书面源代码生成机器级代码的翻译器。\nC\nC ++\nC＃\nALGOL\nCobol\nFortran\nJava\nVisual Basic\nSmalltalk\n解释语言 解释语言是一种编程语言，在其中，无需将程序编译为机器语言的指令，我们就可以直接自由地执行指令。解释器逐行执行程序。语言解释为编译后的实现（如平台独立性，动态范围，动态类型等）提供了更多的灵活性。\nPython\nRuby\nPerl\nPascal\nLisp\nBASIC\nAPL\n脚本语言 脚本语言是控制应用程序的编程语言。可以在任何其他应用程序上独立执行的脚本。它们被广泛应用于它们所控制的应用中，并被用于自动化领域。\nPHP\nVBScript\nWindows PowerShell\nF-Script\nBeanShell\nAutoIt\nR\nGame Maker Language\n标记语言 标记语言是一种人工语言，用于对文档进行注释，以便在语法上与文本（可定义文本显示方式的文本）区分开。\nHTML\nXML\nXHTML\nSGML\nCurl\n程序语言 程序（命令式）编程意味着指定程序达到预期状态应采取的步骤。过程不过是一组可以通过过程调用引用的指令。这有助于代码的重用。这种类型的编程使程序结构化并易于跟踪程序流。\nHyperTalk\nGo\nPL/C\nPL/I\nMATLAB\nCurl\nMathematica\nMATLAB\n函数式语言 函数式编程语言将每次计算都定义为数学评估。他们专注于函数的应用。一些函数式编程语言是纯函数式语言，但是许多所谓的函数式语言是不纯净的，包含命令式功能，它们不是纯函数式语言。\nPure Functional\nAgda\nSAC\nSASL\nCuneiform\nCurry\nFuthark\nHaskell\n不纯功能语言 APL\nC++ (since C++11)\nC#\nVB.NET\nCeylon\nKotlin\nLisp\nClojure\nJScript\nPHP\nPython\n基于逻辑的编程语言 逻辑编程是一种编程范例，主要基于形式逻辑。基于逻辑的编程是一组逻辑形式的语句，这些语句表达有关问题域的事实和规则。\nProlog\nROOP\nALF\nAlma-0\nCurry\nFril\nJanus\n面向对象的语言 面向对象的编程（OOP）是基于对象概念的高级编程范例，该对象可能包含字段形式的数据，通常称为属性。在OOP中，计算机程序将相关数据和功能绑定到对象中，并实现对象及其相关过程以创建软件程序。\nScala\nC++\nJava\nPython\nC#\nRuby\nScala\n数据流语言 数据流编程语言依赖于表示数据流。在数据流语言中，数据流从一条指令传递到另一条指令以执行。条件执行会跳转数据，并在过程调用中将数据路由到其他位置。\nAnalytica\nBMDFM\nHartmann pipelines\nLucid\nMax\nOz\nPrograph\nPure Data\n嵌入式语言 主要是动态脚本和编程语言。它也可以用作独立于平台的通用编程语言。嵌入式语言有两种类型：\n服务端 : 服务器端嵌入式语言更加灵活。动态生成附加标记是拥有服务器端代码片段的主要目的。服务该页面时，嵌入在网页中的服务器端是自动丢弃的代码，并由输出替换。 客户端 : 客户端嵌入式语言旨在为网页提供动态特性，从而减少重新连接服务器的开销。 服务器端\nPHP\nVBScript\nSMX\nTcl\nWebDNA\n客户端\nActionScript\nJavaScript\nVBScript\n机器语言 这些语言可由计算中央处理器直接执行。机器语言通常以八进制或十六进制形式的位模式编码。\nARM\nDEC\nx86\nIBM System/360\nMIPS\nSun, Oracle SPARC\n系统语言 这些语言用于内存管理或任务管理中使用的低级语言。与应用软件相比，通常用于系统编程的系统编程语言（例如，用于编写系统软件的语言）通常需要不同的开发方法。\nAda\nNim\nRust\nSwift\nESPOL\n并发语言 这些语言是为了在消息传递语言中并发而构造的。例如，Java显示共享内存并发。\nGo\nJava\nJulia\nclojure\nScala\n范式语言 这些类型的语言支持多种编程语言或编程范式。多范式语言允许使用多种编程风格。没有一种特定的语言能够以最简单或有效的方式解决所有问题，这就是我们使用Multiparadigm语言的原因。\nAda\nAPL\nBETA\nC++\nC#\nCobra\n扩展语言 这些语言用作其他语言的扩展。扩展编程语言嵌入到另一个程序中，并用于在扩展脚本中利用其功能。\nAutoLISP\nBeanShell\nPerl\nPike\nRuby\n迭代语言 这些语言围绕生成器提供或提供生成器。\nAldor\nAlphard\nPHP\nCLU\nCobra\n硬件描述语言 这些编程语言用于电子产品，硬件描述语言或HDL用于描述电子电路或数字逻辑电路的结构，设计和操作。Verilog和VHDL在工业中使用的各种最流行和得到良好支持的HDL品种中。\n模拟电路的HDL：\nVerilog-AMS\nVHDL-AMS\n数字电路的HDL：\nAdvanced Boolean Expression Language(ABEL)\nAltera Hardware Description Language(AHDL)\nBluespec\nLava\nELLA\n视觉语言 在Viual Languages中，用户可以以二维或多种方式指定程序，而不能使用视觉语言中的一维（文本字符串）来指定程序，我们使用图形元素和图形来开发程序。\nAnalytica\nBlockly\nDRAKON\nFabrik\nScratch\nSimulink\nSpreadsheets\n基于列表的语言 列表的语言基于列表数据结构。\n例：\nLisp\nArc\nClojure\nR\nDylan\nJoy\n同步语言 这些编程语言用于对反应系统进行编程。编程反应系统是被中断并立即响应的系统。这些系统中的一些也称为实时系统，并且被广泛使用。\nArgus\nAverest\nEsterel\nLustre\nSignal\n宏语言 这些语言用于将一个源代码文件转换为另一个。宏是一小段文本，可以扩展为更大的文本。宏语言通常用于预处理源代码。预处理程序提供文件包含等功能。\ncpp (the C preprocessor)\nm4\nML/I (general purpose macro processor)\n查询语言 数据库和信息系统中使用这些语言进行查询。\nSQL\nXPath\nAQL\nPQL\nXQuery\n元编程语言 元编程语言是编写程序，该程序编写或操纵其他程序（包括其自身）作为数据，或者完成在编译时在运行时执行的部分工作。\nC++\nCWIC\nCurl\nD\neC\nEmacs Lisp\nElixir\nF#\n基于规则的语言 当被一组数据中的条件激活时，基于规则的语言实例化规则。将选择某些集合，并执行属于那些规则的语句。\nawk\nCLIPS\nConstraint Handling Rules\nDrools\nJess\nOPS5\nProlog\n数值分析语言 在数值分析中，我们分析和实现用于数值解的算法，以解决涉及连续变量的现实数学模型的巨大问题。我们在数值分析中使用以下编程语言。\nMathematica\nMATLAB\nPROSE\nR\n语法处理语言 这些语言可帮助生成词法分析器和解析器以实现上下文无关的语法。\nANTLR\nCoco/R (EBNF with semantics)\nGNU bison (FSF\u0026rsquo;s version of Yacc)\nGNU Flex (FSF version of Lex)\nlex (Lexical Analysis, from Bell Labs)\nParsing expression grammar (PEG)\n非基于英语的语言 有几种编程语言，它们是用英语以外的其他语言开发的。在这种情况下，语言不是障碍。\nChinese BASIC - Chinese\nFjölnir - Icelandic\nLanguage Symbolique d\u0026rsquo;Enseignement - French\nLexico - Spanish\nRapira - Russian\nChaScript-Bengali\nezhil-Tamil\n基于XML的语言 这些语言用于将XML文档转换为人类可读的格式。\nAnt\nC?\nXPath\nXQuery\nXProc\n","permalink":"https://WFUing.github.io/posts/tech/language/programming-language-pool/","summary":"下面列出了所有类型的编程语言的完整分类列表。编程语言没有严格的分类方案。因此，我们可以将一种语言视为不止一种编程语言的示例。\n让我们一一理解这些编程语言。由于列表很大，因此不可能详细讨论所有这些内容。在这里，我正在用所有这些各种编程语言的示例编写简短的介绍。\n编译语言 编译语言是一种编程语言，其中我们使用编译器来编译和执行代码。编译器通常是从我们的书面源代码生成机器级代码的翻译器。\nC\nC ++\nC＃\nALGOL\nCobol\nFortran\nJava\nVisual Basic\nSmalltalk\n解释语言 解释语言是一种编程语言，在其中，无需将程序编译为机器语言的指令，我们就可以直接自由地执行指令。解释器逐行执行程序。语言解释为编译后的实现（如平台独立性，动态范围，动态类型等）提供了更多的灵活性。\nPython\nRuby\nPerl\nPascal\nLisp\nBASIC\nAPL\n脚本语言 脚本语言是控制应用程序的编程语言。可以在任何其他应用程序上独立执行的脚本。它们被广泛应用于它们所控制的应用中，并被用于自动化领域。\nPHP\nVBScript\nWindows PowerShell\nF-Script\nBeanShell\nAutoIt\nR\nGame Maker Language\n标记语言 标记语言是一种人工语言，用于对文档进行注释，以便在语法上与文本（可定义文本显示方式的文本）区分开。\nHTML\nXML\nXHTML\nSGML\nCurl\n程序语言 程序（命令式）编程意味着指定程序达到预期状态应采取的步骤。过程不过是一组可以通过过程调用引用的指令。这有助于代码的重用。这种类型的编程使程序结构化并易于跟踪程序流。\nHyperTalk\nGo\nPL/C\nPL/I\nMATLAB\nCurl\nMathematica\nMATLAB\n函数式语言 函数式编程语言将每次计算都定义为数学评估。他们专注于函数的应用。一些函数式编程语言是纯函数式语言，但是许多所谓的函数式语言是不纯净的，包含命令式功能，它们不是纯函数式语言。\nPure Functional\nAgda\nSAC\nSASL\nCuneiform\nCurry\nFuthark\nHaskell\n不纯功能语言 APL\nC++ (since C++11)","title":"Programming Language List"},{"content":"Resources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 博客 ZooKeeper源码阅读心得分享+源码基本结构+源码环境搭建 手摸手教你阅读和调试大型开源项目 ZooKeeper ","permalink":"https://WFUing.github.io/posts/tech/distributed/zookeeper/zookeeper-code/","summary":"Resources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 博客 ZooKeeper源码阅读心得分享+源码基本结构+源码环境搭建 手摸手教你阅读和调试大型开源项目 ZooKeeper ","title":"Zookeeper Code"},{"content":"ZooKeeper 简介 ZooKeeper 是什么 ZooKeeper 是 Apache 的顶级项目。ZooKeeper 为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名服务、配置管理和分布式锁等分布式的基础服务。在解决分布式数据一致性方面，ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。\nZooKeeper 主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是 ZooKeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控存储数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。\n很多大名鼎鼎的框架都基于 ZooKeeper 来实现分布式高可用，如：Dubbo、Kafka 等。\nZooKeeper 官方支持 Java 和 C 的 Client API。ZooKeeper 社区为大多数语言（.NET，python 等）提供非官方 API。\nZooKeeper 的应用场景 配置管理 集群节点可以通过中心源获取启动配置 更简单的部署 分布式集群管理 节点加入/离开 节点的实时状态 命名服务，如：DNS 分布式同步：如锁、栅栏、队列 分布式系统的选主 中心化和高可靠的数据注册 ZooKeeper 的特性 ZooKeeper 具有以下特性：\n顺序一致性 - 所有客户端看到的服务端数据模型都是一致的。从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。具体的实现可见：原子广播 原子性 - 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 实现方式可见：事务 单一视图 - 无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 高性能 - ZooKeeper 将数据全量存储在内存中，所以其性能很高。需要注意的是：由于 ZooKeeper 的所有更新和删除都是基于事务的，因此 ZooKeeper 在读多写少的应用场景中有性能表现较好，如果写操作频繁，性能会大大下滑。 高可用 - ZooKeeper 的高可用是基于副本机制实现的，此外 ZooKeeper 支持故障恢复，可见：选举 Leader ZooKeeper 的设计目标 简单的数据模型：ZooKeeper 的数据模型是一个树形结构的文件系统，树中的节点被称为 znode。 可以构建集群：ZooKeeper 支持集群模式，可以通过伸缩性，来控制集群的吞吐量。需要注意的是：由于 ZooKeeper 采用一主多从架构，所以其写性能是有上限的，比较适合于读多写少的场景。 顺序访问：对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事务请求的先后顺序。 高性能、高可用：ZooKeeper 将数据存全量储在内存中以保持高性能，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是基于事务的，所以其在读多写少的应用场景中有着很高的性能表现。 ZooKeeper 核心概念 服务 Zookeeper 服务是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。\n客户端只会连接一个 ZooKeeper 服务器节点，并维持 TCP 连接。\n数据模型 ZooKeeper 的数据模型是一个树形结构的文件系统。\n树中的节点被称为 znode，其中根节点为 /，每个节点上都会保存自己的数据和节点信息。znode 可以用于存储数据，并且有一个与之相关联的 ACL（详情可见 ACL）。ZooKeeper 的设计目标是实现协调服务，而不是真的作为一个文件存储，因此 znode 存储数据的大小被限制在 1MB 以内。\n数据模型 ZooKeeper 的数据访问具有原子性。其读写操作都是要么全部成功，要么全部失败。\nznode 通过路径被引用。znode 节点路径必须是绝对路径。\nznode 有两种类型：\n临时的（ EPHEMERAL ） - 户端会话结束时，ZooKeeper 就会删除临时的 znode。不允许有子节点。 持久的（PERSISTENT ） - 除非客户端主动执行删除操作，否则 ZooKeeper 不会删除持久的 znode。 节点信息 znode 上有一个顺序标志（ SEQUENTIAL ）。如果在创建 znode 时，设置了顺序标志（ SEQUENTIAL ），那么 ZooKeeper 会使用计数器为 znode 添加一个单调递增的数值，即 zxid。ZooKeeper 正是利用 zxid 实现了严格的顺序访问控制能力。\n每个 znode 节点在存储数据的同时，都会维护一个叫做 Stat 的数据结构，里面存储了关于该节点的全部状态信息。如下：\n状态属性 说明 czxid 数据节点创建时的事务 ID ctime 数据节点创建时的时间 mzxid 数据节点最后一次更新时的事务 ID mtime 数据节点最后一次更新时的时间 pzxid 数据节点的子节点最后一次被修改时的事务 ID cversion 子节点的更改次数 version 节点数据的更改次数 aversion 节点的 ACL 的更改次数 ephemeralOwner 如果节点是临时节点，则表示创建该节点的会话的 SessionID；如果节点是持久节点，则该属性值为 0 dataLength 数据内容的长度 numChildren 数据节点当前的子节点个数 集群角色 Zookeeper 集群是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。此外，每个服务器节点承担如下三种角色中的一种：\nLeader - 它负责 发起并维护与各 Follwer 及 Observer 间的心跳。所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader。 Follower - 它会响应 Leader 的心跳。Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，并且负责在 Leader 处理写请求时对请求进行投票。一个 Zookeeper 集群可能同时存在多个 Follower。 Observer - 角色与 Follower 类似，但是无投票权。 客户端可以从任意 ZooKeeper 服务器节点读取数据，但只能通过 Leader 服务写数据并需要半数以上 Follower 的 ACK，才算写入成功。记住这个重要的知识点，下文会详细讲述。\nACL ZooKeeper 采用 ACL（Access Control Lists）策略来进行权限控制。\n每个 znode 创建时都会带有一个 ACL 列表，用于决定谁可以对它执行何种操作。\nACL 依赖于 ZooKeeper 的客户端认证机制。ZooKeeper 提供了以下几种认证方式：\ndigest - 用户名和密码 来识别客户端 sasl - 通过 kerberos 来识别客户端 ip - 通过 IP 来识别客户端 ZooKeeper 定义了如下五种权限：\nCREATE - 允许创建子节点； READ - 允许从节点获取数据并列出其子节点； WRITE - 允许为节点设置数据； DELETE - 允许删除子节点； ADMIN - 允许为节点设置权限。 ZooKeeper 工作原理 读操作 Leader/Follower/Observer 都可直接处理读请求，从本地内存中读取数据并返回给客户端即可。\n由于处理读请求不需要服务器之间的交互，Follower/Observer 越多，整体系统的读请求吞吐量越大，也即读性能越好。\n写操作 所有的写请求实际上都要交给 Leader 处理。Leader 将写请求以事务形式发给所有 Follower 并等待 ACK，一旦收到半数以上 Follower 的 ACK，即认为写操作成功。\n写 Leader 由上图可见，通过 Leader 进行写操作，主要分为五步：\n客户端向 Leader 发起写请求 Leader 将写请求以事务 Proposal 的形式发给所有 Follower 并等待 ACK Follower 收到 Leader 的事务 Proposal 后返回 ACK Leader 得到过半数的 ACK（Leader 对自己默认有一个 ACK）后向所有的 Follower 和 Observer 发送 Commmit Leader 将处理结果返回给客户端 注意\nLeader 不需要得到 Observer 的 ACK，即 Observer 无投票权 Leader 不需要得到所有 Follower 的 ACK，只要收到过半的 ACK 即可，同时 Leader 本身对自己有一个 ACK。上图中有 4 个 Follower，只需其中两个返回 ACK 即可，因为 $$\\frac{2+1}{4+1} \u0026gt; \\frac{1}{2}$$ Observer 虽然无投票权，但仍须同步 Leader 的数据从而在处理读请求时可以返回尽可能新的数据 写 Follower/Observer Follower/Observer 均可接受写请求，但不能直接处理，而需要将写请求转发给 Leader 处理。 除了多了一步请求转发，其它流程与直接写 Leader 无任何区别。 事务 对于来自客户端的每个更新请求，ZooKeeper 具备严格的顺序访问控制能力。\n为了保证事务的顺序一致性，ZooKeeper 采用了递增的事务 id 号（zxid）来标识事务。\nLeader 服务会为每一个 Follower 服务器分配一个单独的队列，然后将事务 Proposal 依次放入队列中，并根据 FIFO(先进先出) 的策略进行消息发送。Follower 服务在接收到 Proposal 后，会将其以事务日志的形式写入本地磁盘中，并在写入成功后反馈给 Leader 一个 Ack 响应。当 Leader 接收到超过半数 Follower 的 Ack 响应后，就会广播一个 Commit 消息给所有的 Follower 以通知其进行事务提交，之后 Leader 自身也会完成对事务的提交。而每一个 Follower 则在接收到 Commit 消息后，完成事务的提交。\n所有的提议（proposal）都在被提出的时候加上了 zxid。zxid 是一个 64 位的数字，它的高 32 位是 epoch 用来标识 Leader 关系是否改变，每次一个 Leader 被选出来，它都会有一个新的 epoch，标识当前属于那个 leader 的统治时期。低 32 位用于递增计数。\n详细过程如下：\nLeader 等待 Server 连接； Follower 连接 Leader，将最大的 zxid 发送给 Leader； Leader 根据 Follower 的 zxid 确定同步点； 完成同步后通知 follower 已经成为 uptodate 状态； Follower 收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了。 观察 ZooKeeper 允许客户端监听它关心的 znode，当 znode 状态发生变化（数据变化、子节点增减变化）时，ZooKeeper 服务会通知客户端。\n客户端和服务端保持连接一般有两种形式：\n客户端向服务端不断轮询 服务端向客户端推送状态 Zookeeper 的选择是服务端主动推送状态，也就是观察机制（ Watch ）。\nZooKeeper 的观察机制允许用户在指定节点上针对感兴趣的事件注册监听，当事件发生时，监听器会被触发，并将事件信息推送到客户端。\n监听器实时触发 监听器总是有序的 创建新的 znode 数据前，客户端就能收到监听事件。 客户端使用 getData 等接口获取 znode 状态时传入了一个用于处理节点变更的回调，那么服务端就会主动向客户端推送节点的变更：\n1 public byte[] getData(final String path, Watcher watcher, Stat stat) 从这个方法中传入的 Watcher 对象实现了相应的 process 方法，每次对应节点出现了状态的改变，WatchManager 都会通过以下的方式调用传入 Watcher 的方法：\n1 2 3 4 5 6 7 8 9 10 11 Set\u0026lt;Watcher\u0026gt; triggerWatch(String path, EventType type, Set\u0026lt;Watcher\u0026gt; supress) { WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); Set\u0026lt;Watcher\u0026gt; watchers; synchronized (this) { watchers = watchTable.remove(path); } for (Watcher w : watchers) { w.process(e); } return watchers; } Zookeeper 中的所有数据其实都是由一个名为 DataTree 的数据结构管理的，所有的读写数据的请求最终都会改变这颗树的内容，在发出读请求时可能会传入 Watcher 注册一个回调函数，而写请求就可能会触发相应的回调，由 WatchManager 通知客户端数据的变化。\n通知机制的实现其实还是比较简单的，通过读请求设置 Watcher 监听事件，写请求在触发事件时就能将通知发送给指定的客户端。\n会话 ZooKeeper 客户端通过 TCP 长连接连接到 ZooKeeper 服务集群。会话 (Session) 从第一次连接开始就已经建立，之后通过心跳检测机制来保持有效的会话状态。通过这个连接，客户端可以发送请求并接收响应，同时也可以接收到 Watch 事件的通知。\n每个 ZooKeeper 客户端配置中都配置了 ZooKeeper 服务器集群列表。启动时，客户端会遍历列表去尝试建立连接。如果失败，它会尝试连接下一个服务器，依次类推。\n一旦一台客户端与一台服务器建立连接，这台服务器会为这个客户端创建一个新的会话。每个会话都会有一个超时时间，若服务器在超时时间内没有收到任何请求，则相应会话被视为过期。一旦会话过期，就无法再重新打开，且任何与该会话相关的临时 znode 都会被删除。\n通常来说，会话应该长期存在，而这需要由客户端来保证。客户端可以通过心跳方式（ping）来保持会话不过期。\nZooKeeper 的会话具有四个属性：\nsessionID - 会话 ID，唯一标识一个会话，每次客户端创建新的会话时，Zookeeper 都会为其分配一个全局唯一的 sessionID。 TimeOut - 会话超时时间，客户端在构造 Zookeeper 实例时，会配置 sessionTimeout 参数用于指定会话的超时时间，Zookeeper 客户端向服务端发送这个超时时间后，服务端会根据自己的超时时间限制最终确定会话的超时时间。 TickTime - 下次会话超时时间点，为了便于 Zookeeper 对会话实行分桶策略管理，同时为了高效低耗地实现会话的超时检查与清理，Zookeeper 会为每个会话标记一个下次会话超时时间点，其值大致等于当前时间加上 TimeOut。 isClosing - 标记一个会话是否已经被关闭，当服务端检测到会话已经超时失效时，会将该会话的 isClosing 标记为已关闭，这样就能确保不再处理来自该会话的心情求了。 Zookeeper 的会话管理主要是通过 SessionTracker 来负责，其采用了分桶策略（将类似的会话放在同一区块中进行管理）进行管理，以便 Zookeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。\nZAB 协议 ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。ZAB 协议不是 Paxos 算法，只是比较类似，二者在操作上并不相同。Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。而 ZooKeeper 需要确保操作的顺序性。\nZAB 协议是 Zookeeper 专门设计的一种支持崩溃恢复的原子广播协议。\nZAB 协议是 ZooKeeper 的数据一致性和高可用解决方案。\nZAB 协议定义了两个可以无限循环的流程：\n选举 Leader - 用于故障恢复，从而保证高可用。 原子广播 - 用于主从同步，从而保证数据一致性。 选举 Leader ZooKeeper 的故障恢复\nZooKeeper 集群采用一主（称为 Leader）多从（称为 Follower）模式，主从节点通过副本机制保证数据一致。\n如果 Follower 节点挂了 - ZooKeeper 集群中的每个节点都会单独在内存中维护自身的状态，并且各节点之间都保持着通讯，只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务。 如果 Leader 节点挂了 - 如果 Leader 节点挂了，系统就不能正常工作了。此时，需要通过 ZAB 协议的选举 Leader 机制来进行故障恢复。 ZAB 协议的选举 Leader 机制简单来说，就是：基于过半选举机制产生新的 Leader，之后其他机器将从新的 Leader 上同步状态，当有过半机器完成状态同步后，就退出选举 Leader 模式，进入原子广播模式。\n术语 myid - 每个 Zookeeper 服务器，都需要在数据文件夹下创建一个名为 myid 的文件，该文件包含整个 Zookeeper 集群唯一的 ID（整数）。 zxid - 类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal ID。为了保证顺序性，该 zxid 必须单调递增。因此 Zookeeper 使用一个 64 位的数来表示，高 32 位是 Leader 的 epoch，从 1 开始，每次选出新的 Leader，epoch 加一。低 32 位为该 epoch 内的序号，每次 epoch 变化，都将低 32 位的序号重置。这样保证了 zxid 的全局递增性。 服务器状态 LOOKING - 不确定 Leader 状态。该状态下的服务器认为当前集群中没有 Leader，会发起 Leader 选举 FOLLOWING - 跟随者状态。表明当前服务器角色是 Follower，并且它知道 Leader 是谁 LEADING - 领导者状态。表明当前服务器角色是 Leader，它会维护与 Follower 间的心跳 OBSERVING - 观察者状态。表明当前服务器角色是 Observer，与 Folower 唯一的不同在于不参与选举，也不参与集群写操作时的投票 选票数据结构 每个服务器在进行领导选举时，会发送如下关键信息\nlogicClock - 每个服务器会维护一个自增的整数，名为 logicClock，它表示这是该服务器发起的第多少轮投票 state - 当前服务器的状态 self_id - 当前服务器的 myid self_zxid - 当前服务器上所保存的数据的最大 zxid vote_id - 被推举的服务器的 myid vote_zxid - 被推举的服务器上所保存的数据的最大 zxid 投票流程 自增选举轮次 - Zookeeper 规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作。 初始化选票 - 每个服务器在广播自己的选票前，会将自己的投票箱清空。该投票箱记录了所收到的选票。例：服务器 2 投票给服务器 3，服务器 3 投票给服务器 1，则服务器 1 的投票箱为(2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。 发送初始化选票 - 每个服务器最开始都是通过广播把票投给自己。 接收外部投票 - 服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。 判断选举轮次 - 收到外部投票后，首先会根据投票信息中所包含的 logicClock 来进行不同处理 外部投票的 logicClock 大于自己的 logicClock。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的 logicClock 更新为收到的 logicClock，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。 外部投票的 logicClock 小于自己的 logicClock。当前服务器直接忽略该投票，继续处理下一个投票。 外部投票的 logickClock 与自己的相等。当时进行选票 PK。 选票 PK - 选票 PK 是基于(self_id, self_zxid) 与 (vote_id, vote_zxid) 的对比 外部投票的 logicClock 大于自己的 logicClock，则将自己的 logicClock 及自己的选票的 logicClock 变更为收到的 logicClock 若 logicClock 一致，则对比二者的 vote_zxid，若外部投票的 vote_zxid 比较大，则将自己的票中的 vote_zxid 与 vote_myid 更新为收到的票中的 vote_zxid 与 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖 若二者 vote_zxid 一致，则比较二者的 vote_myid，若外部投票的 vote_myid 比较大，则将自己的票中的 vote_myid 更新为收到的票中的 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱 统计选票 - 如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。 更新服务器状态 - 投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为 LEADING，否则将自己的状态更新为 FOLLOWING 通过以上流程分析，我们不难看出：要使 Leader 获得多数 Server 的支持，则 ZooKeeper 集群节点数必须是奇数。且存活的节点数目不得少于 N + 1 。\n每个 Server 启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。\n原子广播（Atomic Broadcast） ZooKeeper 通过副本机制来实现高可用。\n那么，ZooKeeper 是如何实现副本机制的呢？答案是：ZAB 协议的原子广播。\nZAB 协议的原子广播要求：\n所有的写请求都会被转发给 Leader，Leader 会以原子广播的方式通知 Follow。当半数以上的 Follow 已经更新状态持久化后，Leader 才会提交这个更新，然后客户端才会收到一个更新成功的响应。这有些类似数据库中的两阶段提交协议。\n在整个消息的广播过程中，Leader 服务器会每个事务请求生成对应的 Proposal，并为其分配一个全局唯一的递增的事务 ID(ZXID)，之后再对其进行广播。\nZAB 是通过一切以领导者为准的强领导者模型和严格按照顺序提交日志，来实现操作的顺序性的，这一点和 Raft 是一样的。\nZooKeeper 应用 ZooKeeper 可以用于发布/订阅、负载均衡、命令服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能 。\n命名服务 在分布式系统中，通常需要一个全局唯一的名字，如生成全局唯一的订单号等，ZooKeeper 可以通过顺序节点的特性来生成全局唯一 ID，从而可以对分布式系统提供命名服务。\n配置管理 利用 ZooKeeper 的观察机制，可以将其作为一个高可用的配置存储器，允许分布式应用的参与者检索和更新配置文件。\n分布式锁 可以通过 ZooKeeper 的临时节点和 Watcher 机制来实现分布式排它锁。\n举例来说，有一个分布式系统，有三个节点 A、B、C，试图通过 ZooKeeper 获取分布式锁。\n（1）访问 /lock （这个目录路径由程序自己决定），创建 带序列号的临时节点（EPHEMERAL） 。\n（2）每个节点尝试获取锁时，拿到 /locks节点下的所有子节点（id_0000,id_0001,id_0002），判断自己创建的节点是不是序列号最小的\n如果序列号是最小的，则成功获取到锁。 释放锁：执行完操作后，把创建的节点给删掉。 如果不是，则监听比自己要小 1 的节点变化。 （3）释放锁，即删除自己创建的节点。\n图中，NodeA 删除自己创建的节点 id_0000，NodeB 监听到变化，发现自己的节点已经是最小节点，即可获取到锁。\n集群管理 ZooKeeper 还能解决大多数分布式系统中的问题：\n如可以通过创建临时节点来建立心跳检测机制。如果分布式系统的某个服务节点宕机了，则其持有的会话会超时，此时该临时节点会被删除，相应的监听事件就会被触发。 分布式系统的每个服务节点还可以将自己的节点状态写入临时节点，从而完成状态报告或节点工作进度汇报。 通过数据的订阅和发布功能，ZooKeeper 还能对分布式系统进行模块的解耦和任务的调度。 通过监听机制，还能对分布式系统的服务节点进行动态上下线，从而实现服务的动态扩容。 选举 Leader 节点 分布式系统一个重要的模式就是主从模式 (Master/Salves)，ZooKeeper 可以用于该模式下的 Matser 选举。可以让所有服务节点去竞争性地创建同一个 ZNode，由于 ZooKeeper 不能有路径相同的 ZNode，必然只有一个服务节点能够创建成功，这样该服务节点就可以成为 Master 节点。\n队列管理 ZooKeeper 可以处理两种类型的队列：\n当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队列。 队列按照 FIFO 方式进行入队和出队操作，例如实现生产者和消费者模型。 同步队列用 ZooKeeper 实现的实现思路如下：\n创建一个父目录 /synchronizing，每个成员都监控标志（Set Watch）位目录 /synchronizing/start 是否存在，然后每个成员都加入这个队列，加入队列的方式就是创建 /synchronizing/member_i 的临时目录节点，然后每个成员获取 /synchronizing 目录的所有目录节点，也就是 member_i。判断 i 的值是否已经是成员的个数，如果小于成员个数等待 /synchronizing/start 的出现，如果已经相等就创建 /synchronizing/start。\nZooKeeper 的缺点 ZooKeeper 的监听是一次性的。\nZooKeeper 不是为高可用性设计的 生产环境中常常需要通过多机房部署来容灾。出于成本考虑，一般多机房都是同时提供服务的，即一个机房撑不住所有流量。ZooKeeper 集群只能有一个 Leader，一旦机房之间连接出现故障，那么只有 Leader 所在的机房可以正常工作，其他机房只能停摆。于是所有流量集中到 Leader 所在的机房，由于处理不过来而导致崩溃。\n即使是在同一个机房里面，由于网段的不同，在调整机房交换机的时候偶尔也会发生网段隔离的情况。实际上机房每个月基本上都会发生短暂的网络隔离之类的子网段调整。在那个时刻 ZooKeeper 将处于不可用状态。如果业务系统重度依赖 ZooKeeper（比如用 Dubbo 作为 RPC，且使用 ZooKeeper 作为注册中心），则系统的可用性将非常脆弱。\n由于 ZooKeeper 对于网络隔离的极度敏感，导致 ZooKeeper 对于网络的任何风吹草动都会做出激烈反应。这使得 ZooKeeper 的不可用时间比较多。我们不能让 ZooKeeper 的不可用，变成系统的不可用。\nZooKeeper 的选举过程速度很慢 互联网环境中，网络不稳定几乎是必然的，而 ZooKeeper 网络隔离非常敏感。一旦出现网络隔离，zookeeper 就要发起选举流程。\nZooKeeper 的选举流程通常耗时 30 到 120 秒，期间 ZooKeeper 由于没有 Leader，都是不可用的。\n对于网络里面偶尔出现的，比如半秒一秒的网络隔离，ZooKeeper 会由于选举过程，而把不可用时间放大几十倍。\nZooKeeper 的性能是有限的 典型的 ZooKeeper 的 TPS 大概是一万多，无法支撑每天动辄几十亿次的调用。因此，每次请求都去 ZooKeeper 获取业务系统信息是不可能的。\n为此，ZooKeeper 的 client 必须自己缓存业务系统的信息。这就导致 ZooKeeper 提供的强一致性实际上是做不到的。如果我们需要强一致性，还需要其他机制来进行保障：比如用自动化脚本把业务系统的 old master 给 kill 掉，但是这可能会引发很多其他问题。\nZooKeeper 无法进行有效的权限控制 ZooKeeper 的权限控制非常弱。在大型的复杂系统里面，使用 ZooKeeper 必须自己再额外的开发一套权限控制系统，通过那套权限控制系统再访问 ZooKeeper。\n额外的权限控制系统不但增加了系统复杂性和维护成本，而且降低了系统的总体性能。\n即使有了 ZooKeeper 也很难避免业务系统的数据不一致 由于 ZooKeeper 的性能限制，我们无法让每次系统内部调用都走 ZooKeeper，因此总有某些时刻，业务系统会存在两份数据（业务系统 client 那边缓存的业务系统信息是定时从 ZooKeeper 更新的，因此会有更新不同步的问题）。\n如果要保持数据的强一致性，唯一的方法是先 kill 掉当前 Leader，再在 ZooKeeper 上更新 Leader 信息。是否要 kill 掉当前 Leader 这个问题上，程序是无法完全自动决定的（因为网络隔离的时候 ZooKeeper 已经不可用了，自动脚本没有全局信息，不管怎么做都可能是错的，什么都不做也可能是错的。当网络故障的时候，只有运维人员才有全局信息，程序是无法得知其他机房的情况的）。因此系统无法自动的保障数据一致性，必须要人工介入。而人工介入的典型时间是半个小时以上，我们不能让系统这么长时间不可用。因此我们必须在某个方向上进行妥协，最常见的妥协方式是放弃强一致性，而接受最终一致性。\n如果我们需要人工介入才能保证可靠的强一致性，那么 ZooKeeper 的价值就大打折扣。\nResources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 书籍 《Hadoop 权威指南（第四版）》 《从 Paxos 到 Zookeeper 分布式一致性原理与实践》 文章 分布式服务框架 ZooKeeper \u0026ndash; 管理分布式环境中的数据 ZooKeeper 的功能以及工作原理 ZooKeeper 简介及核心概念 详解分布式协调服务 ZooKeeper 深入浅出 Zookeeper（一） Zookeeper 架构及 FastLeaderElection 机制 Introduction to Apache ZooKeeper Zookeeper 的优缺点 ","permalink":"https://WFUing.github.io/posts/tech/distributed/zookeeper/zookeeper-theory/","summary":"ZooKeeper 简介 ZooKeeper 是什么 ZooKeeper 是 Apache 的顶级项目。ZooKeeper 为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名服务、配置管理和分布式锁等分布式的基础服务。在解决分布式数据一致性方面，ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。\nZooKeeper 主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是 ZooKeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控存储数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。\n很多大名鼎鼎的框架都基于 ZooKeeper 来实现分布式高可用，如：Dubbo、Kafka 等。\nZooKeeper 官方支持 Java 和 C 的 Client API。ZooKeeper 社区为大多数语言（.NET，python 等）提供非官方 API。\nZooKeeper 的应用场景 配置管理 集群节点可以通过中心源获取启动配置 更简单的部署 分布式集群管理 节点加入/离开 节点的实时状态 命名服务，如：DNS 分布式同步：如锁、栅栏、队列 分布式系统的选主 中心化和高可靠的数据注册 ZooKeeper 的特性 ZooKeeper 具有以下特性：\n顺序一致性 - 所有客户端看到的服务端数据模型都是一致的。从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。具体的实现可见：原子广播 原子性 - 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 实现方式可见：事务 单一视图 - 无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 高性能 - ZooKeeper 将数据全量存储在内存中，所以其性能很高。需要注意的是：由于 ZooKeeper 的所有更新和删除都是基于事务的，因此 ZooKeeper 在读多写少的应用场景中有性能表现较好，如果写操作频繁，性能会大大下滑。 高可用 - ZooKeeper 的高可用是基于副本机制实现的，此外 ZooKeeper 支持故障恢复，可见：选举 Leader ZooKeeper 的设计目标 简单的数据模型：ZooKeeper 的数据模型是一个树形结构的文件系统，树中的节点被称为 znode。 可以构建集群：ZooKeeper 支持集群模式，可以通过伸缩性，来控制集群的吞吐量。需要注意的是：由于 ZooKeeper 采用一主多从架构，所以其写性能是有上限的，比较适合于读多写少的场景。 顺序访问：对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事务请求的先后顺序。 高性能、高可用：ZooKeeper 将数据存全量储在内存中以保持高性能，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是基于事务的，所以其在读多写少的应用场景中有着很高的性能表现。 ZooKeeper 核心概念 服务 Zookeeper 服务是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。","title":"Zookeeper 原理"},{"content":"什么是分布式系统 将硬件或软件组件(服务)分布在不同的网络计算机上，并且通过消息传递进行通信和协调。\n特点\n分布性 对等性 平等: 无主从之分 独立: 拥有自己的CPU和内存，独立处理数据 并发性 外部: 承载多个客户端的并发访问 内部: 作业(Job)被分解成多个任务(Task)，并发运行在不同的节点上 故障独立性 部分节点出现故障不影响整个系统的正常使用 split-brain 问题 对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房。正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，但机房之间无法通信。如果不考虑过半机制，那么就会出现每个机房内部都将选出一个Leader。这就相当于原本一个集群，被分成了两个集群，出现了两个大脑，这就是脑裂。\n脑裂 对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。\nCAP定理 C(Consistency，一致性) 含义: 同一时刻，数据在不同节点的多个副本是否具有完全相同的值 类型 强一致性: 数据更新完成后，同一时刻，不同的读操作都能获得最新的值 弱一致性: 数据更新完成后，同一时刻，不同的读操作不一定都能获得最新的值，也无法保证多长时间之后可以获得最新的值 A(Availability，可用性) 含义: 对于每一次请求，系统是否都能在有限(指定)的时间内做出响应 P(Partition Tolerance，分区容错性) 含义: 当发生网络分区时，系统仍能对外提供满足 一致性C 和 可用性A 的服务 CAP定理 分布式系统在同一时间片段内，不可能同时满足一致性C、可用性A和分区容错性P，最多只能满足其中的两项。\n满足意味着100%， 满足C -\u0026gt; 满足强一致性 满足A -\u0026gt; 满足绝对可用性 对分布式系统而言，网络分区无法避免，满足P是前提条件，所以不可能选择CA架构，只能选择CP或AP架构 例如: 发生网络分区时，某个节点正在进行写操作 如果为了保证C，必须禁止其他节点的读写操作，那就与A冲突了 如果为了保证A，其他节点正常读写，那就与C冲突了 选择CP或AP架构，关键在业务场景 例如: 对于必须确保强一致性的银行业务，只能选择CP BASE理论 BA(Basically Availability，基本可用性) 当系统发生故障时，在确保核心功能和指标有效的提前下，允许损失部分可用性，包括响应时间上的损失、非核心功能上的损失等 S(Soft State，软状态) 允许数据存在中间状态(暂时未更新)，且该状态不会影响整体可用性 允许不同节点上的数据副本的同步过程存在一定延时 EC(Eventually Consistency，最终一致性) 分布在不同节点上的数据副本，在经过一定时间的同步后，最终达到一致状态 例如: Zookeeper、HDFS QJM写事务的过半策略 弱一致性的升级版 BASE定理 分布式系统在满足分区容错性P的同时，允许数据软状态S的存在，并实现基本可用性BA和最终一致性EC\n在满足P的前提下，对CAP中的强一致性A和绝对可用性C进行适度妥协 A -\u0026gt; BA ，C -\u0026gt; EC 通过容忍部分数据的暂时不一致(软状态)，即牺牲数据的强一致性(确保最终一致性)，以确保系统的核心功能和指标有效(基本可用) CAP定理的延伸，CAP的 C+P / A+P -\u0026gt; BASE的EC+BA+P 对大规模互联网系统分布式实践的总结 ","permalink":"https://WFUing.github.io/posts/tech/distributed/overview/","summary":"什么是分布式系统 将硬件或软件组件(服务)分布在不同的网络计算机上，并且通过消息传递进行通信和协调。\n特点\n分布性 对等性 平等: 无主从之分 独立: 拥有自己的CPU和内存，独立处理数据 并发性 外部: 承载多个客户端的并发访问 内部: 作业(Job)被分解成多个任务(Task)，并发运行在不同的节点上 故障独立性 部分节点出现故障不影响整个系统的正常使用 split-brain 问题 对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房。正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，但机房之间无法通信。如果不考虑过半机制，那么就会出现每个机房内部都将选出一个Leader。这就相当于原本一个集群，被分成了两个集群，出现了两个大脑，这就是脑裂。\n脑裂 对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。\nCAP定理 C(Consistency，一致性) 含义: 同一时刻，数据在不同节点的多个副本是否具有完全相同的值 类型 强一致性: 数据更新完成后，同一时刻，不同的读操作都能获得最新的值 弱一致性: 数据更新完成后，同一时刻，不同的读操作不一定都能获得最新的值，也无法保证多长时间之后可以获得最新的值 A(Availability，可用性) 含义: 对于每一次请求，系统是否都能在有限(指定)的时间内做出响应 P(Partition Tolerance，分区容错性) 含义: 当发生网络分区时，系统仍能对外提供满足 一致性C 和 可用性A 的服务 CAP定理 分布式系统在同一时间片段内，不可能同时满足一致性C、可用性A和分区容错性P，最多只能满足其中的两项。\n满足意味着100%， 满足C -\u0026gt; 满足强一致性 满足A -\u0026gt; 满足绝对可用性 对分布式系统而言，网络分区无法避免，满足P是前提条件，所以不可能选择CA架构，只能选择CP或AP架构 例如: 发生网络分区时，某个节点正在进行写操作 如果为了保证C，必须禁止其他节点的读写操作，那就与A冲突了 如果为了保证A，其他节点正常读写，那就与C冲突了 选择CP或AP架构，关键在业务场景 例如: 对于必须确保强一致性的银行业务，只能选择CP BASE理论 BA(Basically Availability，基本可用性) 当系统发生故障时，在确保核心功能和指标有效的提前下，允许损失部分可用性，包括响应时间上的损失、非核心功能上的损失等 S(Soft State，软状态) 允许数据存在中间状态(暂时未更新)，且该状态不会影响整体可用性 允许不同节点上的数据副本的同步过程存在一定延时 EC(Eventually Consistency，最终一致性) 分布在不同节点上的数据副本，在经过一定时间的同步后，最终达到一致状态 例如: Zookeeper、HDFS QJM写事务的过半策略 弱一致性的升级版 BASE定理 分布式系统在满足分区容错性P的同时，允许数据软状态S的存在，并实现基本可用性BA和最终一致性EC","title":"分布式系统概述"},{"content":"Background IIoT（工业物联网）架构通常是分布式和异步的，通信由事件驱动，如消息的发布（和相应的订阅）。这些异步架构提高了可扩展性和对变化的耐受性，但也引发了互操作性问题，因为架构各元素之间对消息内部结构及其分类（主题）的明确知识被稀释了。\n事实上，这也是 REST 应用程序接口面临的一个问题，直到业界联合起来，提出了一种定义同步应用程序接口结构和模式的标准方法：OpenAPI（源自 Swagger）。\nIntroduction 对于异步架构，受 OpenAPI 的启发，AsyncAPI 的出现解决了这一问题：\nAsyncAPI 提供了一种规范，允许您以机器可读的格式定义消息驱动的 API。它与协议无关，因此可以用于通过 Kafka、MQTT、AMQP、WebSockets、STOMP 等工作的 API。该规范与 OpenAPI/Swagger 非常相似，所以如果你熟悉它，AsyncAPI 对你来说应该很容易。\n在 AsyncAPI 中，API 的规格可以用 YAML 或 JSON 定义，例如可以指定消息代理、感兴趣的主题或与每个主题相关的不同消息格式等。不过，AsyncAPI 还处于开发的早期阶段，AsyncAPI 工具市场还不发达，主要局限于生成供人类使用的文档。\nAsyncAPI 最初的贡献就是上图中展示的方法。\nAsyncAPI Toolkit 如上图所示，AsyncAPI 团队扩展了这一初始框架。基于 AsyncAPI 规范在 Xtext 中开发 AsyncAPI JSON 语法的，该语法可验证符合 AsyncAPI 规范的消息驱动 API 定义。同样，根据该语法，Xtext 会自动生成相应的 AsyncAPI 元模型和所有工具（带内容辅助功能的编辑器、解析器等），以便轻松创建 AsyncAPI JSON 定义并将其转换为符合 AsyncAPI 元模型的 AsyncAPI 模型。\n有了 AsyncAPI 元模型和作为符合模型的应用程序接口规范，就可以通过执行 M2T 转换（生成内部 DSL）来继续工作流程。目前，AsyncAPI Toolkit 支持 Java 语言，并生成一个库，通过提供流畅的 API 来协助开发人员创建、发布和接收格式良好的消息。\n值得注意的是，由于这些架构都是基于 message 的，因此数据建模起着至关重要的作用。因此，我们在上述工作流程中使用了另一种（图形化）具体语法，重点是对要交换的消息进行建模。这可用于引导 AsyncAPI JSON 定义，随后可对其进行手动完善。\nImporting / Modeling an AsyncAPI 规范 首先，基于 AsyncAPI 规范，我们创建了一个 Xtext 语法。根据该语法，我们自动生成了一个 Ecore metamodel，以及一套编辑器和基于 Eclipse 的工具。这些编辑器允许使用 AsyncAPI 创建基于 JSON 的消息驱动 API 规范。使用这些编辑器创建的规范会被自动解析并重新整合为 AsyncAPI 元模型的实例。\n生成代码，轻松处理 AsyncAPI 规范中的信息 此外，原型还能生成 Java 代码，支持根据建模的 AsyncAPI（包括嵌套 JSON 对象）创建和序列化基于 JSON 的消息有效载荷。但目前还不支持数组。下面的节选显示了原型支持的 AsyncAPI 规范示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 { \u0026#34;asyncapi\u0026#34;: \u0026#34;1.2.0\u0026#34;, \u0026#34;info\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Sample AsyncAPI specification\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, }, \u0026#34;servers\u0026#34;: [ { \u0026#34;url\u0026#34;: \u0026#34;broker.url:{port}\u0026#34;, \u0026#34;scheme\u0026#34;: \u0026#34;mqtt\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;This is an example description\u0026#34;, \u0026#34;variables\u0026#34;: { \u0026#34;port\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;1883\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;1883\u0026#34;, \u0026#34;8883\u0026#34; ] } } } ], \u0026#34;topics\u0026#34;: { \u0026#34;messages/device2controller\u0026#34;: { \u0026#34;publish\u0026#34;: { \u0026#34;$ref\u0026#34; : \u0026#34;#/components/messages/request\u0026#34; } } } }, \u0026#34;components\u0026#34;: { \u0026#34;schemas\u0026#34;: { \u0026#34;protocol_version\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Protocol version\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;, \u0026#34;default\u0026#34;: 2, \u0026#34;x-friendly-name\u0026#34;: \u0026#34;ProtocolVersion\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ID\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;XXXXXX YY ZZZZZZ W\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Status\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;OK\u0026#34;, \u0026#34;ERROR\u0026#34;], \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Status\u0026#34; }, \u0026#34;environment\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Environment\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;DEV\u0026#34;, \u0026#34;STAG\u0026#34;,\u0026#34;PROD\u0026#34; ], \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Environment\u0026#34; } }, \u0026#34;messages\u0026#34; : { \u0026#34;request\u0026#34; : { \u0026#34;summary\u0026#34; : \u0026#34;Request connectivity.\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Request connectivity when status changes\u0026#34;, \u0026#34;payload\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;P\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/protocol_version\u0026#34; }, \u0026#34;ID\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/id\u0026#34; }, \u0026#34;E\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/environment\u0026#34; }, \u0026#34;M\u0026#34;: { \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Message\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;S\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/status\u0026#34; }, \u0026#34;C\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Content\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;x-friendly-name\u0026#34;: \u0026#34;Content\u0026#34; } } } } } } } } 根据上述规范，可以生成如下信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package tests; import messages.device2controller.Request; import messages.device2controller.Request.Payload.Environment; import messages.device2controller.Request.Payload.Message; import messages.device2controller.Request.Payload.PayloadBuilder; import messages.device2controller.Request.Payload.Message.Status; public class Test { public static void main(String[] args) { PayloadBuilder builder = Request.payloadBuilder(); Request.Payload payload = builder .withProtocolVersion(2) .withEnvironment(Environment.DEV) .withID(\u0026#34;id\u0026#34;) .withMessage( Message.newBuilder() .withStatus(Status.OK) .withContent(\u0026#34;Content\u0026#34;) .build() ).build(); System.out.println(payload.toJson(true)); System.out.println(Request.Payload.fromJson(payload.toJson()).toJson(true)); } } 从 Ecore 模型生成新的 AsyncAPI 在此之前，我们假设您要么已经有一个 AsyncAPI 文件要导入，要么您将使用我们的 AsyncAPI 编辑器创建一个文件。事实上，还有第三种选择：使用现有的 Ecore 模型，并从中生成一个骨架 AsyncAPI 规范。\n生成器将为每个领域类创建一个可重复使用的 JSON 模式。通道将由注释过的 EClasses 创建。此外，还可通过 EAnnotations 指定主机信息。\n除了其局限性外，获得基于 JSON 的 Ecore 模型表示法还有几个优点：\n允许开发人员和架构师创建一个可用的 AsyncAPI 定义，而无需深入了解规范， 同时保持建模环境的简单性和可管理性； 以及让不熟悉建模的人也能遵守 AsyncAPI 规范还能让有经验的开发人员和架构师完善和完成无法用 Ecore 轻松捕获的架构细节 为了在建议的开发工作流程中集成数据模型，定义了 Ecore 到 AsyncAPI 的模型到模型（M2M）和 AsyncAPI 到 JSON 的 M2T 转换。\nResources tutorial: https://modeling-languages.com/asyncapi-modeling-editor-code-generator/ A model-based approach for developing event-driven architectures with AsyncAPI Model-driven development of asynchronous message-driven architectures with AsyncAPI Grammar 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 grammar io.github.abelgomez.asyncapi.AsyncApi hidden(WS) generate asyncApi \u0026#34;http://io.github.abelgomez/asyncapi/AsyncApi\u0026#34; import \u0026#34;http://www.eclipse.org/emf/2002/Ecore\u0026#34; as ecore AsyncAPI: {AsyncAPI} \u0026#39;{\u0026#39;\t( ( \u0026#39;\u0026#34;asyncapi\u0026#34;\u0026#39; \u0026#39;:\u0026#39; version=VersionNumber \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;info\u0026#34;\u0026#39; \u0026#39;:\u0026#39; info=Info \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;servers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; servers+=Server (\u0026#39;,\u0026#39; servers+=Server)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;channels\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; channels+=Channel (\u0026#39;,\u0026#39; channels+=Channel)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;components\u0026#34;\u0026#39; \u0026#39;:\u0026#39; components=Components \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-sla\u0026#34;\u0026#39; \u0026#39;:\u0026#39; sla=Sla \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Info: {Info} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;version\u0026#34;\u0026#39; \u0026#39;:\u0026#39; version=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;termsOfService\u0026#34;\u0026#39; \u0026#39;:\u0026#39; termsOfService=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;contact\u0026#34;\u0026#39; \u0026#39;:\u0026#39; contact=Contact \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;license\u0026#34;\u0026#39; \u0026#39;:\u0026#39; license=License \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-basePackage\u0026#34;\u0026#39; \u0026#39;:\u0026#39; basePackage=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Contact: {Contact} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;email\u0026#34;\u0026#39; \u0026#39;:\u0026#39; email=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; License: {License} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Server: {Server} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;protocol\u0026#34;\u0026#39; \u0026#39;:\u0026#39; protocol=Protocol \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;variables\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; variables+=Variable (\u0026#39;,\u0026#39; variables+=Variable)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-isMonitored\u0026#34;\u0026#39; \u0026#39;:\u0026#39; isMonitored=Boolean \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Variable: {Variable} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;default\u0026#34;\u0026#39; \u0026#39;:\u0026#39; default=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; ^enum+=AnyString (\u0026#39;,\u0026#39; ^enum+=AnyString)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Channel: {Channel} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;publish\u0026#34;\u0026#39; \u0026#39;:\u0026#39; publish=Operation \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;subscribe\u0026#34;\u0026#39; \u0026#39;:\u0026#39; subscribe=Operation \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; parameters+=NamedParameter (\u0026#39;,\u0026#39; parameters+=NamedParameter)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Operation: {Operation} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operationId=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;message\u0026#34;\u0026#39; \u0026#39;:\u0026#39; message=AbstractMessage \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; traits+=AbstractOperationTrait ( \u0026#39;,\u0026#39; traits+=AbstractOperationTrait )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; AbstractMessage: Reference | Message; Message: {Message} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; \u0026#39;:\u0026#39; deprecated=Boolean \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; headers=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; tags+=Tag ( \u0026#39;,\u0026#39; tags+=Tag )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;payload\u0026#34;\u0026#39; \u0026#39;:\u0026#39; payload=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; traits+=AbstractMessageTrait ( \u0026#39;,\u0026#39; traits+=AbstractMessageTrait )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-identifier\u0026#34;\u0026#39; \u0026#39;:\u0026#39; identifier=MessageIdentifier )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedMessage: {NamedMessage} name=AnyString \u0026#39;:\u0026#39; message=AbstractMessage; Tag: {Tag} \u0026#39;{\u0026#39; ( (\u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;?)? \u0026amp; (\u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;?)? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; AbstractSchema: Reference | Schema; Schema: {Schema} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;type\u0026#34;\u0026#39; \u0026#39;:\u0026#39; type=JsonType \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;format\u0026#34;\u0026#39; \u0026#39;:\u0026#39; format=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;minimum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; minimum=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;maximum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; maximum=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;minItems\u0026#34;\u0026#39; \u0026#39;:\u0026#39; minItems=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;maxItems\u0026#34;\u0026#39; \u0026#39;:\u0026#39; maxItems=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;default\u0026#34;\u0026#39; \u0026#39;:\u0026#39; default=PrimitiveValue\u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;properties\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; properties+=NamedSchema (\u0026#39;,\u0026#39; properties+=NamedSchema)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; ^enum+=PrimitiveValue (\u0026#39;,\u0026#39; ^enum+=PrimitiveValue)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;items\u0026#34;\u0026#39; \u0026#39;:\u0026#39; items=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;required\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; required+=AnyString (\u0026#39;,\u0026#39; required+=AnyString)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedSchema: {NamedSchema} name=AnyString \u0026#39;:\u0026#39; schema=AbstractSchema; AbstractParameter: Reference | Parameter; Parameter: {Parameter} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;schema\u0026#34;\u0026#39; \u0026#39;:\u0026#39; schema=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;location\u0026#34;\u0026#39; \u0026#39;:\u0026#39; location=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedParameter: {NamedParameter} name=AnyString \u0026#39;:\u0026#39; parameter=AbstractParameter; AbstractOperationTrait: Reference | OperationTrait; OperationTrait: {OperationTrait} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operationId=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedOperationTrait: {NamedOperationTrait} name=AnyString \u0026#39;:\u0026#39; operationTrait=AbstractOperationTrait; AbstractMessageTrait: Reference | MessageTrait; MessageTrait: {MessageTrait} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; \u0026#39;:\u0026#39; deprecated=Boolean \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; headers=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; tags+=Tag ( \u0026#39;,\u0026#39; tags+=Tag )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedMessageTrait: {NamedMessageTrait} name=AnyString \u0026#39;:\u0026#39; messageTrait=AbstractMessageTrait; Components: {Components} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;schemas\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; schemas+=NamedSchema (\u0026#39;,\u0026#39; schemas+=NamedSchema)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; messages+=NamedMessage (\u0026#39;,\u0026#39; messages+=NamedMessage)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; parameters+=NamedParameter (\u0026#39;,\u0026#39; parameters+=NamedParameter)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;operationTraits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; operationTraits+=NamedOperationTrait (\u0026#39;,\u0026#39; operationTraits+=NamedOperationTrait)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;messageTraits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; messageTraits+=NamedMessageTrait (\u0026#39;,\u0026#39; messageTraits+=NamedMessageTrait)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-qosMetrics\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; qosMetrics+=QoSMetric (\u0026#39;,\u0026#39; qosMetrics+=QoSMetric)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Sla: {Sla} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;guaranteeTerm\u0026#34;\u0026#39; \u0026#39;:\u0026#39; guaranteeTerm+=GuaranteeTerm (\u0026#39;,\u0026#39; guaranteeTerm+=GuaranteeTerm)* ) ) \u0026#39;}\u0026#39;; GuaranteeTerm: {GuaranteeTerm} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;scopes\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; scopes+=Scope (\u0026#39;,\u0026#39; scopes+=Scope)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39; ) ( \u0026#39;\u0026#34;qualifyingConditions\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; qualifyingConditions+=QualifyingCondition (\u0026#39;,\u0026#39; qualifyingConditions+=QualifyingCondition)* \u0026#39;}\u0026#39;\u0026#39;,\u0026#39;)? ( \u0026#39;\u0026#34;slos\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; slos+=Slo (\u0026#39;,\u0026#39; slos+=Slo)* \u0026#39;}\u0026#39;)\t) \u0026#39;}\u0026#39;; Scope: {Scope}( name=AnyString \u0026#39;:\u0026#39; reference= [Channel|AnyString] ); QualifyingCondition: {QualifyingCondition} name=AnyString \u0026#39;:\u0026#39; condition=BooleanExpression ; Slo: {Slo} name=AnyString \u0026#39;:\u0026#39; condition=BooleanExpression ;\tAbstractQoSMetric: QoSMetricReference | QoSMetric; QoSMetricReference: metric= [QoSMetric|AnyString]\t; QoSMetric: (\u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )\t\u0026amp; ( \u0026#39;\u0026#34;metricType\u0026#34;\u0026#39; \u0026#39;:\u0026#39; metricType=QoSMetricType \u0026#39;,\u0026#39;? )\t\u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;unit\u0026#34;\u0026#39; \u0026#39;:\u0026#39; unit=QoSMetricUnit \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;groupedByEvent\u0026#34;\u0026#39; \u0026#39;:\u0026#39; groupedByEvent=Boolean \u0026#39;,\u0026#39;? )\t) (DerivedQoSMetric)?\t// Això està al final de tot, pq Xtext es queixa que no pot haver-hi una unasssigned rule dins d\u0026#39;una unordered list.\t\u0026#39;}\u0026#39;); DerivedQoSMetric: {DerivedQoSMetric}( \u0026#39;\u0026#34;derivedQoSMetricDefinition\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( (\u0026#39;\u0026#34;window\u0026#34;\u0026#39; \u0026#39;:\u0026#39; window = AnyString \u0026#39;,\u0026#39;? ) \u0026amp; (\u0026#39;\u0026#34;windowUnit\u0026#34;\u0026#39; \u0026#39;:\u0026#39; windowUnit = WindowUnit \u0026#39;,\u0026#39;? ) \u0026amp; (\u0026#39;\u0026#34;aggregationFunction\u0026#34;\u0026#39; \u0026#39;:\u0026#39; aggregationFunction = AggregationFunction \u0026#39;,\u0026#39;? ) ) \u0026#39;}\u0026#39; ) ; BooleanExpression: AndExpression | OrExpression | ComparisonExpression; AndExpression: {AndExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;AND\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; conditions+=BooleanExpression (\u0026#39;,\u0026#39; conditions+=BooleanExpression)* \u0026#39;]\u0026#39; \u0026#39;}\u0026#39; ; OrExpression: {OrExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;OR\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; conditions+=BooleanExpression (\u0026#39;,\u0026#39; conditions+=BooleanExpression)* \u0026#39;]\u0026#39; \u0026#39;}\u0026#39;; ComparisonExpression: {ComparisonExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;qosMetric\u0026#34;\u0026#39; \u0026#39;:\u0026#39; qosMetric = AbstractQoSMetric \u0026#39;,\u0026#39; \u0026#39;\u0026#34;operator\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operator = Operator \u0026#39;,\u0026#39; \u0026#39;\u0026#34;value\u0026#34;\u0026#39; \u0026#39;:\u0026#39; value = AnyString \u0026#39;}\u0026#39; ; Reference: {Reference} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;$ref\u0026#34;\u0026#39; \u0026#39;:\u0026#39; uri=AnyString \u0026#39;}\u0026#39;; //GenericJsonExpression: //\tPrimitiveValue //\t| GenericJsonObject //\t| GenericJsonArray; // //GenericJsonObject: //\t\u0026#39;{\u0026#39; \u0026#39;}\u0026#39; | \u0026#39;{\u0026#39; GenericJsonTuple (\u0026#39;,\u0026#39; GenericJsonTuple)* \u0026#39;}\u0026#39;; // //GenericJsonArray: //\t\u0026#39;[\u0026#39; \u0026#39;]\u0026#39; | \u0026#39;[\u0026#39; GenericJsonExpression (\u0026#39;,\u0026#39; GenericJsonExpression)* \u0026#39;]\u0026#39;; // //GenericJsonTuple: AnyString \u0026#39;:\u0026#39; GenericJsonExpression; // //GenericJsonTupleButRef: AnyStringButRef \u0026#39;:\u0026#39; GenericJsonExpression; enum WindowUnit: seconds = \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | minutes = \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | hours = \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | days = \u0026#39;\u0026#34;days\u0026#34;\u0026#39; | messages = \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; ; enum AggregationFunction: AVG = \u0026#39;\u0026#34;AVG\u0026#34;\u0026#39; | MEDIAN = \u0026#39;\u0026#34;MEDIAN\u0026#34;\u0026#39; | MAX = \u0026#39;\u0026#34;MAX\u0026#34;\u0026#39; | MIN = \u0026#39;\u0026#34;MIN\u0026#34;\u0026#39; ; enum QoSMetricType: availability = \u0026#39;\u0026#34;availability\u0026#34;\u0026#39; | bandwith = \u0026#39;\u0026#34;bandwith\u0026#34;\u0026#39; | cpu = \u0026#39;\u0026#34;cpu\u0026#34;\u0026#39; | capacity = \u0026#39;\u0026#34;capacity\u0026#34;\u0026#39; | disaster = \u0026#39;\u0026#34;disaster\u0026#34;\u0026#39; | resiliance = \u0026#39;\u0026#34;resiliance\u0026#34;\u0026#39; | discoverability = \u0026#39;\u0026#34;discoverability\u0026#34;\u0026#39; | documentation = \u0026#39;\u0026#34;documentation\u0026#34;\u0026#39; | exception_handling = \u0026#39;\u0026#34;exception_handling\u0026#34;\u0026#39; | expected_failures = \u0026#39;\u0026#34;expected_failures\u0026#34;\u0026#39; | failover = \u0026#39;\u0026#34;failover\u0026#34;\u0026#39; | jitter = \u0026#39;\u0026#34;jitter\u0026#34;\u0026#39; | latency = \u0026#39;\u0026#34;latency\u0026#34;\u0026#39; | load_balancing = \u0026#39;\u0026#34;load_balancing\u0026#34;\u0026#39; | maximum_throughput = \u0026#39;\u0026#34;maximum_throughput\u0026#34;\u0026#39; | memory_aapacity = \u0026#39;\u0026#34;memory_aapacity\u0026#34;\u0026#39; | packet_loss = \u0026#39;\u0026#34;packet_loss\u0026#34;\u0026#39; | precision = \u0026#39;\u0026#34;precision\u0026#34;\u0026#39; | probability_of_correctness = \u0026#39;\u0026#34;probability_of_correctness\u0026#34;\u0026#39; | round_trip_time = \u0026#39;\u0026#34;round_trip_time\u0026#34;\u0026#39; | throughput = \u0026#39;\u0026#34;throughput\u0026#34;\u0026#39; | time_to_tail = \u0026#39;\u0026#34;time_to_tail\u0026#34;\u0026#39; | time_to_tepair = \u0026#39;\u0026#34;time_to_tepair\u0026#34;\u0026#39; | type_consistency = \u0026#39;\u0026#34;type_consistency\u0026#34;\u0026#39; | uptime = \u0026#39;\u0026#34;uptime\u0026#34;\u0026#39; | up_to_dateness = \u0026#39;\u0026#34;up-to-dateness\u0026#34;\u0026#39; ; enum QoSMetricUnit: milliseconds = \u0026#39;\u0026#34;milliseconds\u0026#34;\u0026#39; | seconds = \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | minutes = \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | hours = \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | null = \u0026#39;\u0026#34;null\u0026#34;\u0026#39; ; enum Operator: greater = \u0026#39;\u0026#34;\u0026gt;\u0026#34;\u0026#39; | greater_equal = \u0026#39;\u0026#34;\u0026gt;=\u0026#34;\u0026#39; | equal = \u0026#39;\u0026#34;=\u0026#34;\u0026#39; | less_equal = \u0026#39;\u0026#34;\u0026lt;=\u0026#34;\u0026#39; | less = \u0026#39;\u0026#34;\u0026lt;\u0026#34;\u0026#39;\t; enum JsonType: string = \u0026#39;\u0026#34;string\u0026#34;\u0026#39; | number = \u0026#39;\u0026#34;number\u0026#34;\u0026#39; | integer = \u0026#39;\u0026#34;integer\u0026#34;\u0026#39; | boolean = \u0026#39;\u0026#34;boolean\u0026#34;\u0026#39; | object = \u0026#39;\u0026#34;object\u0026#34;\u0026#39; | array = \u0026#39;\u0026#34;array\u0026#34;\u0026#39; | any = \u0026#39;\u0026#34;any\u0026#34;\u0026#39; | null = \u0026#39;\u0026#34;null\u0026#34;\u0026#39;; enum Boolean: _false = \u0026#34;false\u0026#34; | _true = \u0026#34;true\u0026#34;; enum VersionNumber: _200 = \u0026#39;\u0026#34;2.0.0\u0026#34;\u0026#39;; enum MessageIdentifier: none =\u0026#39;\u0026#34;none\u0026#34;\u0026#39; | generated = \u0026#39;\u0026#34;generated\u0026#34;\u0026#39; | md5 = \u0026#39;\u0026#34;md5\u0026#34;\u0026#39; | sha256 = \u0026#39;\u0026#34;sha-256\u0026#34;\u0026#39;; enum Protocol: amqp = \u0026#39;\u0026#34;amqp\u0026#34;\u0026#39; | amqps = \u0026#39;\u0026#34;amqps\u0026#34;\u0026#39; | http = \u0026#39;\u0026#34;http\u0026#34;\u0026#39; | https = \u0026#39;\u0026#34;https\u0026#34;\u0026#39; | jms = \u0026#39;\u0026#34;jms\u0026#34;\u0026#39; | kafka = \u0026#39;\u0026#34;kafka\u0026#34;\u0026#39; | kafka_secure = \u0026#39;\u0026#34;kafka-secure\u0026#34;\u0026#39; | mqtt = \u0026#39;\u0026#34;mqtt\u0026#34;\u0026#39; | secure_mqtt = \u0026#39;\u0026#34;secure-mqtt\u0026#34;\u0026#39; | ws = \u0026#39;\u0026#34;ws\u0026#34;\u0026#39; | wss = \u0026#39;\u0026#34;wss\u0026#34;\u0026#39; | stomp = \u0026#39;\u0026#34;stomp\u0026#34;\u0026#39; | stomps = \u0026#39;\u0026#34;stomps\u0026#34;\u0026#39;; PrimitiveValue: AnyString | \u0026#34;true\u0026#34; | \u0026#34;false\u0026#34; | INT; AnyStringButRef: STRING | Keyword; AnyString: STRING | \u0026#39;\u0026#34;$ref\u0026#34;\u0026#39; | Keyword; terminal ID: \u0026#39;^\u0026#39;?(\u0026#39;a\u0026#39;..\u0026#39;z\u0026#39;|\u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;|\u0026#39;_\u0026#39;) (\u0026#39;a\u0026#39;..\u0026#39;z\u0026#39;|\u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;|\u0026#39;_\u0026#39;|\u0026#39;0\u0026#39;..\u0026#39;9\u0026#39;)*; terminal INT returns ecore::EInt: (\u0026#39;0\u0026#39;..\u0026#39;9\u0026#39;)+; terminal STRING: \u0026#39;\u0026#34;\u0026#39; ( \u0026#39;\\\\\u0026#39; . | !(\u0026#39;\\\\\u0026#39;|\u0026#39;\u0026#34;\u0026#39;) )* \u0026#39;\u0026#34;\u0026#39; | \u0026#34;\u0026#39;\u0026#34; ( \u0026#39;\\\\\u0026#39; . | !(\u0026#39;\\\\\u0026#39;|\u0026#34;\u0026#39;\u0026#34;) )* \u0026#34;\u0026#39;\u0026#34;; terminal WS: (\u0026#39; \u0026#39;|\u0026#39;\\t\u0026#39;|\u0026#39;\\r\u0026#39;|\u0026#39;\\n\u0026#39;)+; Keyword: \u0026#39;\u0026#34;2.0.0\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026lt;\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026lt;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026gt;\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026gt;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;AND\u0026#34;\u0026#39; | \u0026#39;\u0026#34;AVG\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MAX\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MEDIAN\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MIN\u0026#34;\u0026#39; | \u0026#39;\u0026#34;OR\u0026#34;\u0026#39; | \u0026#39;\u0026#34;aggregationFunction\u0026#34;\u0026#39; | \u0026#39;\u0026#34;amqp\u0026#34;\u0026#39; | \u0026#39;\u0026#34;amqps\u0026#34;\u0026#39; | \u0026#39;\u0026#34;any\u0026#34;\u0026#39; | \u0026#39;\u0026#34;array\u0026#34;\u0026#39; | \u0026#39;\u0026#34;asyncapi\u0026#34;\u0026#39; | \u0026#39;\u0026#34;availability\u0026#34;\u0026#39; | \u0026#39;\u0026#34;bandwith\u0026#34;\u0026#39; | \u0026#39;\u0026#34;boolean\u0026#34;\u0026#39; | \u0026#39;\u0026#34;capacity\u0026#34;\u0026#39; | \u0026#39;\u0026#34;channels\u0026#34;\u0026#39; | \u0026#39;\u0026#34;components\u0026#34;\u0026#39; | \u0026#39;\u0026#34;contact\u0026#34;\u0026#39; | \u0026#39;\u0026#34;cpu\u0026#34;\u0026#39; | \u0026#39;\u0026#34;dataType\u0026#34;\u0026#39; | \u0026#39;\u0026#34;days\u0026#34;\u0026#39; | \u0026#39;\u0026#34;default\u0026#34;\u0026#39; | \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; | \u0026#39;\u0026#34;derivedQoSMetricDefinition\u0026#34;\u0026#39; | \u0026#39;\u0026#34;description\u0026#34;\u0026#39; | \u0026#39;\u0026#34;disaster\u0026#34;\u0026#39; | \u0026#39;\u0026#34;discoverability\u0026#34;\u0026#39; | \u0026#39;\u0026#34;documentation\u0026#34;\u0026#39; | \u0026#39;\u0026#34;email\u0026#34;\u0026#39; | \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;exception_handling\u0026#34;\u0026#39; | \u0026#39;\u0026#34;expected_failures\u0026#34;\u0026#39; | \u0026#39;\u0026#34;failover\u0026#34;\u0026#39; | \u0026#39;\u0026#34;format\u0026#34;\u0026#39; | \u0026#39;\u0026#34;groupedByEvent\u0026#34;\u0026#39; | \u0026#39;\u0026#34;guaranteeTerm\u0026#34;\u0026#39; | \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; | \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | \u0026#39;\u0026#34;http\u0026#34;\u0026#39; | \u0026#39;\u0026#34;https\u0026#34;\u0026#39; | \u0026#39;\u0026#34;info\u0026#34;\u0026#39; | \u0026#39;\u0026#34;integer\u0026#34;\u0026#39; | \u0026#39;\u0026#34;items\u0026#34;\u0026#39; | \u0026#39;\u0026#34;jitter\u0026#34;\u0026#39; | \u0026#39;\u0026#34;jms\u0026#34;\u0026#39; | \u0026#39;\u0026#34;kafka\u0026#34;\u0026#39; | \u0026#39;\u0026#34;kafka-secure\u0026#34;\u0026#39; | \u0026#39;\u0026#34;latency\u0026#34;\u0026#39; | \u0026#39;\u0026#34;license\u0026#34;\u0026#39; | \u0026#39;\u0026#34;load_balancing\u0026#34;\u0026#39; | \u0026#39;\u0026#34;location\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maxItems\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maximum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maximum_throughput\u0026#34;\u0026#39; | \u0026#39;\u0026#34;memory_aapacity\u0026#34;\u0026#39; | \u0026#39;\u0026#34;message\u0026#34;\u0026#39; | \u0026#39;\u0026#34;messageTraits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; | \u0026#39;\u0026#34;metricType\u0026#34;\u0026#39; | \u0026#39;\u0026#34;milliseconds\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minItems\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minimum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | \u0026#39;\u0026#34;mqtt\u0026#34;\u0026#39; | \u0026#39;\u0026#34;mqtts\u0026#34;\u0026#39; | \u0026#39;\u0026#34;name\u0026#34;\u0026#39; | \u0026#39;\u0026#34;null\u0026#34;\u0026#39; | \u0026#39;\u0026#34;number\u0026#34;\u0026#39; | \u0026#39;\u0026#34;object\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operationTraits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operator\u0026#34;\u0026#39; | \u0026#39;\u0026#34;packet_loss\u0026#34;\u0026#39; | \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; | \u0026#39;\u0026#34;payload\u0026#34;\u0026#39; | \u0026#39;\u0026#34;precision\u0026#34;\u0026#39; | \u0026#39;\u0026#34;probability_of_correctness\u0026#34;\u0026#39; | \u0026#39;\u0026#34;properties\u0026#34;\u0026#39; | \u0026#39;\u0026#34;protocol\u0026#34;\u0026#39; | \u0026#39;\u0026#34;publish\u0026#34;\u0026#39; | \u0026#39;\u0026#34;qosMetric\u0026#34;\u0026#39; | \u0026#39;\u0026#34;qualifyingConditions\u0026#34;\u0026#39; | \u0026#39;\u0026#34;required\u0026#34;\u0026#39; | \u0026#39;\u0026#34;resiliance\u0026#34;\u0026#39; | \u0026#39;\u0026#34;round_trip_time\u0026#34;\u0026#39; | \u0026#39;\u0026#34;schema\u0026#34;\u0026#39; | \u0026#39;\u0026#34;schemas\u0026#34;\u0026#39; | \u0026#39;\u0026#34;scopes\u0026#34;\u0026#39; | \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | \u0026#39;\u0026#34;secure-mqtt\u0026#34;\u0026#39; | \u0026#39;\u0026#34;servers\u0026#34;\u0026#39; | \u0026#39;\u0026#34;slos\u0026#34;\u0026#39; | \u0026#39;\u0026#34;stomp\u0026#34;\u0026#39; | \u0026#39;\u0026#34;stomps\u0026#34;\u0026#39; | \u0026#39;\u0026#34;string\u0026#34;\u0026#39; | \u0026#39;\u0026#34;subscribe\u0026#34;\u0026#39; | \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; | \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; | \u0026#39;\u0026#34;termsOfService\u0026#34;\u0026#39; | \u0026#39;\u0026#34;throughput\u0026#34;\u0026#39; | \u0026#39;\u0026#34;time_to_tail\u0026#34;\u0026#39; | \u0026#39;\u0026#34;time_to_tepair\u0026#34;\u0026#39; | \u0026#39;\u0026#34;title\u0026#34;\u0026#39; | \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;type\u0026#34;\u0026#39; | \u0026#39;\u0026#34;type_consistency\u0026#34;\u0026#39; | \u0026#39;\u0026#34;unit\u0026#34;\u0026#39; | \u0026#39;\u0026#34;up-to-dateness\u0026#34;\u0026#39; | \u0026#39;\u0026#34;uptime\u0026#34;\u0026#39; | \u0026#39;\u0026#34;url\u0026#34;\u0026#39; | \u0026#39;\u0026#34;value\u0026#34;\u0026#39; | \u0026#39;\u0026#34;variables\u0026#34;\u0026#39; | \u0026#39;\u0026#34;version\u0026#34;\u0026#39; | \u0026#39;\u0026#34;window\u0026#34;\u0026#39; | \u0026#39;\u0026#34;windowUnit\u0026#34;\u0026#39; | \u0026#39;\u0026#34;ws\u0026#34;\u0026#39; | \u0026#39;\u0026#34;wss\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-basePackage\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-qosMetrics\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-sla\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-title\u0026#34;\u0026#39;; ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/asyncapi-code-generator/","summary":"Background IIoT（工业物联网）架构通常是分布式和异步的，通信由事件驱动，如消息的发布（和相应的订阅）。这些异步架构提高了可扩展性和对变化的耐受性，但也引发了互操作性问题，因为架构各元素之间对消息内部结构及其分类（主题）的明确知识被稀释了。\n事实上，这也是 REST 应用程序接口面临的一个问题，直到业界联合起来，提出了一种定义同步应用程序接口结构和模式的标准方法：OpenAPI（源自 Swagger）。\nIntroduction 对于异步架构，受 OpenAPI 的启发，AsyncAPI 的出现解决了这一问题：\nAsyncAPI 提供了一种规范，允许您以机器可读的格式定义消息驱动的 API。它与协议无关，因此可以用于通过 Kafka、MQTT、AMQP、WebSockets、STOMP 等工作的 API。该规范与 OpenAPI/Swagger 非常相似，所以如果你熟悉它，AsyncAPI 对你来说应该很容易。\n在 AsyncAPI 中，API 的规格可以用 YAML 或 JSON 定义，例如可以指定消息代理、感兴趣的主题或与每个主题相关的不同消息格式等。不过，AsyncAPI 还处于开发的早期阶段，AsyncAPI 工具市场还不发达，主要局限于生成供人类使用的文档。\nAsyncAPI 最初的贡献就是上图中展示的方法。\nAsyncAPI Toolkit 如上图所示，AsyncAPI 团队扩展了这一初始框架。基于 AsyncAPI 规范在 Xtext 中开发 AsyncAPI JSON 语法的，该语法可验证符合 AsyncAPI 规范的消息驱动 API 定义。同样，根据该语法，Xtext 会自动生成相应的 AsyncAPI 元模型和所有工具（带内容辅助功能的编辑器、解析器等），以便轻松创建 AsyncAPI JSON 定义并将其转换为符合 AsyncAPI 元模型的 AsyncAPI 模型。\n有了 AsyncAPI 元模型和作为符合模型的应用程序接口规范，就可以通过执行 M2T 转换（生成内部 DSL）来继续工作流程。目前，AsyncAPI Toolkit 支持 Java 语言，并生成一个库，通过提供流畅的 API 来协助开发人员创建、发布和接收格式良好的消息。\n值得注意的是，由于这些架构都是基于 message 的，因此数据建模起着至关重要的作用。因此，我们在上述工作流程中使用了另一种（图形化）具体语法，重点是对要交换的消息进行建模。这可用于引导 AsyncAPI JSON 定义，随后可对其进行手动完善。","title":"A Modeling Editor and Code Generator for message-driven architectures with AsyncAPI"},{"content":"OpenAPI Generator 可根据 OpenAPI yaml 规范生成代码，并支持多种语言。\n如何使用 OpenAPI 本节介绍如何创建一个基本的 OpenAPI yaml 规范，并用它为 Spring Boot 应用程序生成服务器端代码。\nCreate OpenAPI spec 首先要做的是为您的应用程序设计 OpenAPI 规范。您将设计一个客户 API。该 API 允许您创建一个客户，并根据其 ID 检索该客户。现实生活中的应用程序接口会更加复杂，但我们还是保持简单。\n使用 Swagger 编辑器 是设计 API 的简便方法。它会立即反馈您的规范是否有错误，并即时生成 Swagger 文档。\nOpenAPI 规范的 header 包含一些有关 API 的元数据，如标题、版本、API 运行的服务器等。标签可用于对资源进行分组，从而为您提供更多概览。\n1 2 3 4 5 6 7 8 9 openapi: \u0026#34;3.0.2\u0026#34; info: title: API Customer version: \u0026#34;1.0\u0026#34; servers: - url: https://localhost:8080 tags: - name: Customer description: Customer specific data. paths 部分包含资源规范。您定义的第一个资源是创建 Customer 的资源，将通过包含 JSON 主体的 POST 方式创建。生成器将使用 operationId 为该资源创建方法名称。为简单起见，只考虑成功响应。模式指的是 JSON 主体，将在本节后面介绍。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /customer: post: tags: - Customer summary: Create Customer operationId: createCustomer requestBody: content: application/json: schema: $ref: \u0026#39;#/components/schemas/Customer\u0026#39; responses: \u0026#39;200\u0026#39;: description: OK content: \u0026#39;application/json\u0026#39;: schema: $ref: \u0026#39;#/components/schemas/CustomerFullData\u0026#39; 第二个资源允许您检索客户。该资源也需要一个包含要检索的 customerId 的路径参数。如果 ID 不存在，将返回 NOT FOUND 的响应。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /customer/{customerId}: get: tags: - Customer summary: Retrieve Customer operationId: getCustomer parameters: - name: customerId in: path required: true schema: type: integer format: int64 responses: \u0026#39;200\u0026#39;: description: OK content: \u0026#39;application/json\u0026#39;: schema: $ref: \u0026#39;#/components/schemas/CustomerFullData\u0026#39; \u0026#39;404\u0026#39;: description: NOT FOUND 最后，在组件部分，定义了使用的模式。除了 ID 之外，Customer 模式和 CustomerFullData 模式共享所有属性。为了提高可维护性，可以使用 allOf 属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 components: schemas: Customer: type: object properties: firstName: type: string description: First name of the customer lastName: type: string description: Last name of the customer CustomerFullData: allOf: - $ref: \u0026#39;#/components/schemas/Customer\u0026#39; - type: object properties: customerId: type: integer description: The ID of the customer format: int64 description: Full data of the customer. 该应用程序的 OpenAPI 规范现已完成。\nCreate Spring Boot Application 要创建 Spring Boot 应用程序，请访问 start.spring.io，选择最新稳定的 Spring Boot 版本、Java 17 并添加 Spring Web 依赖关系。下载生成的项目并将其打开到您喜欢的集成开发环境中。在 src/main/resources 目录中添加 OpenAPI 规范，名称为 customer.yml。\n您将使用 Open API Generator Maven 插件，因此请将该插件添加到 pom 文件的构建部分。由于您使用的是 Spring Boot 应用程序，因此使用 spring 作为 generatorName，并使用 inputSpec 属性设置 customer.yml 文件的路径。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.openapitools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;openapi-generator-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;generate\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/customer.yml\u0026lt;/inputSpec\u0026gt; \u0026lt;generatorName\u0026gt;spring\u0026lt;/generatorName\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 执行以下命令生成代码：\n1 $ mvn clean compile 编译失败，出现以下错误：\n1 2 3 4 package io.swagger.annotations does not exist package io.swagger.annotations does not exist package org.openapitools.jackson.nullable does not exist cannot find symbol 为了解决这些问题，需要在 pom 文件中添加以下依赖项：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-annotations\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.validation\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;validation-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openapitools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind-nullable\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 再次运行编译会出现以下错误：\n1 2 3 4 5 6 7 8 9 package springfox.documentation.builders does not exist package springfox.documentation.builders does not exist package springfox.documentation.service does not exist package springfox.documentation.service does not exist package springfox.documentation.spi does not exist package springfox.documentation.spring.web.paths does not exist package springfox.documentation.spring.web.paths does not exist package springfox.documentation.spring.web.plugins does not exist package springfox.documentation.swagger2.annotations does not exist 在 pom 文件中添加以下依赖项可以解决这些错误：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-swagger-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-swagger2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 仔细看看生成了什么。导航至 target/generated-sources/open-api 目录，在该目录中可以找到生成的文件。以下目录包含生成的文件：\nsrc/main/org/openapitools/api : 是 Spring 控制器的一个接口，也是一个实现 src/main/org/openapitools/configuration : 是 Swagger 文档的控制器 src/main/org/openapitools/model : 基于 API 规范的 API 模型 src/main/org/openapitools : OpenAPI2SpringBoot 是一个 SpringBootApplication 当你想运行 Spring Boot 应用程序时，你会遇到一个错误，因为 Spring Boot 无法确定它需要运行哪个 SpringBootApplication :\n1 $ mvn spring-boot:run 由此产生的错误是 :\n1 Unable to find a single main class from the following candidates [org.openapitools.OpenAPI2SpringBoot, com.mydeveloperplanet.myopenapiplanet.MyOpenApiPlanetApplication 默认情况下会生成大量代码，也许比你需要的还要多。下一段将介绍如何调整配置。\nConfigure OpenAPI plugin 除了 OpenAPI 插件的 Maven 部分记录的所有选项外，还有许多额外的选项可在 OpenAPI 插件配置部分的 configOptions 部分进行配置。可通过在配置部分添加 configHelp 属性来显示可用选项。\n1 2 3 4 5 \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/customer.yml\u0026lt;/inputSpec\u0026gt; \u0026lt;generatorName\u0026gt;spring\u0026lt;/generatorName\u0026gt; \u0026lt;configHelp\u0026gt;true\u0026lt;/configHelp\u0026gt; \u0026lt;/configuration\u0026gt; 在此列表中，您将使用 interfaceOnly 属性，它只会为控制器和 API 模型生成接口。\n1 2 3 4 5 6 \u0026lt;configuration\u0026gt; ... \u0026lt;configOptions\u0026gt; \u0026lt;interfaceOnly\u0026gt;true\u0026lt;/interfaceOnly\u0026gt; \u0026lt;/configOptions\u0026gt; \u0026lt;/configuration\u0026gt; 此时，还可以删除之前添加的 Springfox 依赖项。这些都不再需要了。\n从生成的代码中还可以看到，代码是在 org.openapitools 包中生成的。你可能希望这是你自己的软件包名称，这可以通过一些基本属性来配置。通过 packageName 属性，您可以设置默认的软件包名称。不过，还必须设置 apiPackage 和 modelPackage 属性，否则这些属性仍将在 org.openapitools 包中生成。在配置部分添加以下内容。\n1 2 3 4 5 6 7 \u0026lt;configuration\u0026gt; .... \u0026lt;packageName\u0026gt;com.mydeveloperplanet.myopenapiplanet\u0026lt;/packageName\u0026gt; \u0026lt;apiPackage\u0026gt;com.mydeveloperplanet.myopenapiplanet.api\u0026lt;/apiPackage\u0026gt; \u0026lt;modelPackage\u0026gt;com.mydeveloperplanet.myopenapiplanet.model\u0026lt;/modelPackage\u0026gt; .... \u0026lt;/configuration\u0026gt; 生成的控制器界面如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @javax.annotation.Generated(value = \u0026#34;org.openapitools.codegen.languages.SpringCodegen\u0026#34;, date = \u0026#34;2022-01-15T12:51:43.809971036+01:00[Europe/Amsterdam]\u0026#34;) @Validated @Api(value = \u0026#34;customer\u0026#34;, description = \u0026#34;the customer API\u0026#34;) public interface CustomerApi { default Optional\u0026lt;NativeWebRequest\u0026gt; getRequest() { return Optional.empty(); } /** * POST /customer : Create Customer * * @param customer (optional) * @return OK (status code 200) */ @ApiOperation(value = \u0026#34;Create Customer\u0026#34;, nickname = \u0026#34;createCustomer\u0026#34;, notes = \u0026#34;\u0026#34;, response = CustomerFullData.class, tags={ \u0026#34;Customer\u0026#34;, }) @ApiResponses(value = { @ApiResponse(code = 200, message = \u0026#34;OK\u0026#34;, response = CustomerFullData.class) }) @RequestMapping( method = RequestMethod.POST, value = \u0026#34;/customer\u0026#34;, produces = { \u0026#34;application/json\u0026#34; }, consumes = { \u0026#34;application/json\u0026#34; } ) default ResponseEntity\u0026lt;CustomerFullData\u0026gt; createCustomer(@ApiParam(value = \u0026#34;\u0026#34;) @Valid @RequestBody(required = false) Customer customer) { getRequest().ifPresent(request -\u0026gt; { for (MediaType mediaType: MediaType.parseMediaTypes(request.getHeader(\u0026#34;Accept\u0026#34;))) { if (mediaType.isCompatibleWith(MediaType.valueOf(\u0026#34;application/json\u0026#34;))) { String exampleString = \u0026#34;null\u0026#34;; ApiUtil.setExampleResponse(request, \u0026#34;application/json\u0026#34;, exampleString); break; } } }); return new ResponseEntity\u0026lt;\u0026gt;(HttpStatus.NOT_IMPLEMENTED); } ... Use Generated Code 在应用程序中，首先要在包 domain 中创建一个 Customer 类。\n1 2 3 4 5 6 public class Customer { private Long customerId; private String firstName; private String lastName; // Getters and setters } 创建一个 CustomerController，实现生成的 CustomerApi 接口。\n创建 Customer 是一种基本的实现方式，您可以将 Customer 添加到 HashMap 中：计算索引是键，域客户对象是值。在实际应用中，您将把客户保存到数据库中。\n检索客户时，首先要检查所请求的 ID 是否存在于 HashMap 中。找到 ID 后，Customer 域对象将转换为 Customer API 模型对象并返回给请求者。如果未找到 ID，则会返回 NOT FOUND 响应。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @RestController public class CustomerController implements CustomerApi { private final HashMap\u0026lt;Long, com.mydeveloperplanet.myopenapiplanet.domain.Customer\u0026gt; customers = new HashMap\u0026lt;\u0026gt;(); private Long index = 0L; @Override public ResponseEntity\u0026lt;CustomerFullData\u0026gt; createCustomer(Customer apiCustomer) { com.mydeveloperplanet.myopenapiplanet.domain.Customer customer = new com.mydeveloperplanet.myopenapiplanet.domain.Customer(); customer.setCustomerId(index); customer.setFirstName(apiCustomer.getFirstName()); customer.setLastName(apiCustomer.getLastName()); customers.put(index, customer); index++; return ResponseEntity.ok(domainToApi(customer)); } @Override public ResponseEntity\u0026lt;CustomerFullData\u0026gt; getCustomer(Long customerId) { if (customers.containsKey(customerId)) { return ResponseEntity.ok(domainToApi(customers.get(customerId))); } else { return new ResponseEntity\u0026lt;\u0026gt;(HttpStatus.NOT_FOUND); } } private CustomerFullData domainToApi(com.mydeveloperplanet.myopenapiplanet.domain.Customer customer) { CustomerFullData cfd = new CustomerFullData(); cfd.setCustomerId(customer.getCustomerId()); cfd.setFirstName(customer.getFirstName()); cfd.setLastName(customer.getLastName()); return cfd; } } 运行 Spring Boot 应用程序：\n1 $ mvn spring-boot:run 添加 Consumer，并查找\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 $ curl -i -X \u0026#39;POST\u0026#39; \\ \u0026gt; \u0026#39;http://localhost:8080/customer\u0026#39; \\ \u0026gt; -H \u0026#39;accept: application/json\u0026#39; \\ \u0026gt; -H \u0026#39;Content-Type: application/json\u0026#39; \\ \u0026gt; -d \u0026#39;{ \u0026gt; \u0026#34;firstName\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026gt; \u0026#34;lastName\u0026#34;: \u0026#34;Bar\u0026#34; \u0026gt; }\u0026#39; HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:42:47 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;Foo\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Bar\u0026#34;,\u0026#34;customerId\u0026#34;:0} $ curl -i -X \u0026#39;POST\u0026#39; \\ \u0026gt; \u0026#39;http://localhost:8080/customer\u0026#39; \\ \u0026gt; -H \u0026#39;accept: application/json\u0026#39; \\ \u0026gt; -H \u0026#39;Content-Type: application/json\u0026#39; \\ \u0026gt; -d \u0026#39;{ \u0026gt; \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026gt; \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34; \u0026gt; }\u0026#39; HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:43:11 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34;,\u0026#34;customerId\u0026#34;:1} $ curl -i http://localhost:8080/customer/1 HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:45:21 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34;,\u0026#34;customerId\u0026#34;:1} $ curl -i http://localhost:8080/customer/2 HTTP/1.1 404 Content-Length: 0 Date: Sat, 15 Jan 2022 11:46:18 GMT Add OpenAPI Documentation https://springdoc.org/ 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springdoc-openapi-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.12\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在浏览器中导航至 http://localhost:8080/swagger-ui.html，即可显示 OpenAPI 文档，并可在此处下载 OpenAPI yaml 规范。\n当你仔细查看文档时，会发现它与 Swagger 编辑器中显示的文档有所不同。springdoc 依赖项默认会从源代码生成文档，并使用生成的文档。如何配置 springdoc 以使用 customer.yml 文件？\n首先，您需要将 customer.yml 文件移至 src/main/resources/static/customer.yml 目录。这也意味着你需要更改 pom 中的 Open API 生成器配置。\n1 2 3 4 \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/static/customer.yml\u0026lt;/inputSpec\u0026gt; ... \u0026lt;/configuration\u0026gt; 在 application.properties 文件中添加以下属性\n1 springdoc.swagger-ui.url=/customer.yml URL 现在显示的是您创建的 customer.yml 中定义的 API\nResources 官方 OpenAPI Specification v3.1.0 repo Blogs Open API Server Implementation Using OpenAPI Generator Generate Server Code Using OpenAPI Generator ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/openapi-code-generator/","summary":"OpenAPI Generator 可根据 OpenAPI yaml 规范生成代码，并支持多种语言。\n如何使用 OpenAPI 本节介绍如何创建一个基本的 OpenAPI yaml 规范，并用它为 Spring Boot 应用程序生成服务器端代码。\nCreate OpenAPI spec 首先要做的是为您的应用程序设计 OpenAPI 规范。您将设计一个客户 API。该 API 允许您创建一个客户，并根据其 ID 检索该客户。现实生活中的应用程序接口会更加复杂，但我们还是保持简单。\n使用 Swagger 编辑器 是设计 API 的简便方法。它会立即反馈您的规范是否有错误，并即时生成 Swagger 文档。\nOpenAPI 规范的 header 包含一些有关 API 的元数据，如标题、版本、API 运行的服务器等。标签可用于对资源进行分组，从而为您提供更多概览。\n1 2 3 4 5 6 7 8 9 openapi: \u0026#34;3.0.2\u0026#34; info: title: API Customer version: \u0026#34;1.0\u0026#34; servers: - url: https://localhost:8080 tags: - name: Customer description: Customer specific data. paths 部分包含资源规范。您定义的第一个资源是创建 Customer 的资源，将通过包含 JSON 主体的 POST 方式创建。生成器将使用 operationId 为该资源创建方法名称。为简单起见，只考虑成功响应。模式指的是 JSON 主体，将在本节后面介绍。","title":"Openapi Code Generator"},{"content":"REST 全称是 Representational State Transfer（表现层状态转化），更具体的全称是 Resource Representational State Transfer（资源表现层状态转化），具体可以见 Roy Thomas Fielding 的博士论文 https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm 这一章。\nREST 指的是一组架构约束条件和原则：\n为设计一个功能强、性能好、适宜通信的 web 应用 如果一个架构符合 REST 的约束条件和原则，我们就称它为 RESTful 结构 Resources restful petclinic tutorial docter paper bilibili-软件体系结构-2022.7-REST Create REST APIs with JAX-RS 核心概念 资源（Resources） 表现层（Representation） 状态转化（State Transfer） 资源 网络上的一个实体，或者说是网络上的一个具体信息，任何事物，只要有被引用到的必要，它就是一个资源。\n一段文本，一张图片，一首歌曲 数据库中的一行数据 一个手机号码，某用户的个人信息 一种服务 资源标识 要让一个资源可以被识别，需要有个唯一标识，在Web中这个唯一标识就是URI（Uniform Resource Identifier）。例如：\nhttps://www.ex.com/software/releases/latest.tar.gz https://www.ex.com/map/roads/USA/CA/17_mile_drive https://www.ex.com/search/cs578 URI 设计原则\n易读： https://www.oschina.net/news/38119/oschina-translate-reward-plan 表达资源的层级关系： https://github.com/git/git/commit/e3ae056f87e1d675913d08/orders/2012/10 表示资源的同级关系： /git/block-sha1/sha1.h/compare/e3af72cda056f87e;bd63e61bdf38eb264 表达资源的过滤： https://github.com/git/git/pulls?q=is%3Aclosed 统一资源接口\nRESTful 架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的 HTTP 方法如 GET，PUT 和 POST，并遵循这些方法的语义 如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性 GET和HEAD请求是安全的，无论请求多少次，都不改变服务器状态 GET、HEAD、PUT和DELETE请求是幂等的，无论对资源操作多少次，结果总是一样的，后面的请求并不会产生比第一次更多的影响 GET 获取表示，变更时获取表示（缓存）。安全且幂等。\n200: OK，表示已在响应中发出 204: 无内容，资源有空表示 301: Moved Permanently，资源的URI已被更新 303: See Other，其他（如，负载均衡） 304: not modified，资源未更改（缓存） 400: bad request，指代坏请求（如，参数错误） 404: not found，资源不存在 406: not acceptable，服务端不支持所需表示 500: internal server error，通用错误响应 503: Service Unavailable，服务端当前无法处理请求 POST 使用服务端管理的（自动产生）的实例号创建资源，或创建子资源，部分更新资源，如果没有被修改，则不过更新资源（乐观锁）。不安全且不幂等。\n406: not acceptable，服务端不支持所需表示 409: conflict，通用冲突 412: Precondition Failed，前置条件失败（如执行条件更新时的冲突） 415: unsupported media type，接受到的表示不受支持 500: internal server error，通用错误响应 503: Service Unavailable，服务当前无法处理请求 PUT 用客户端管理的实例号创建一个资源，通过替换的方式更新资源，如果未被修改，则更新资源（乐观锁）。不安全但幂等。\n200: OK，如果已存在资源被更改 201: created，如果新资源被创建 301: Moved Permanently，资源的URI已更改 303: See Other，其他（如，负载均衡） 400: bad request，指代坏请求 404: not found，资源不存在 DELETE 删除资源。不安全但幂等。\n200: OK，资源已被删除 301: Moved Permanently，资源的URI已更改 303: See Other，其他，如负载均衡 400: bad request，指代坏请求 404: not found，资源不存在 409: conflict，通用冲突 500: internal server error，通用错误响应 503: Service Unavailable，服务端当前无法处理请求 指导意义 统一资源接口要求使用标准的HTTP方法对资源进行操作，所以URI只应该来表示资源的名称，而不应该包括资源的操作。通俗来说，URI不应该使用动作来描述。例如：\nPOST /getUser?id=1 $\\rightarrow$ GET /Uset/1 GET /newUser $\\rightarrow$ POST /User GET /updateUser $\\rightarrow$ PUT /User/1 GET /deleteUser?id=2 $\\rightarrow$ DELETE /User/2 表现 (Representation) \u0026ldquo;资源\u0026quot;是一种信息实体，它可以有多种外在表现形式。我们把\u0026quot;资源\u0026quot;具体呈现出来的形式，叫做它的\u0026quot;表现层\u0026rdquo;（Representation）\n文本可以用txt格式表现，也可以用HTML格式、XMIL格式、JSON格式表现，甚至可以采用二进制格式 图片可以用JPG格式表现，也可以用PNG格式表示 资源表述 URI只代表资源的实体，不代表它的形式。严格地说，有些网址最后的 .html 后缀名是不必要的，因为这个后缀名表示格式，属于 \u0026ldquo;表现层\u0026rdquo; 范畴，而URI应该只代表 \u0026ldquo;资源\u0026rdquo; 的位置。\n资源的表述包括数据和描述数据的元数据，例如，HTTP头 \u0026ldquo;Content-Type\u0026rdquo; 就是这样一个元数据属性\n客户端可以通过 Accept 头请求一种特定格式的表述，服务端则通过 Content-Type 告诉客户端资源的表述形式\n支持的表达\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ~ » http get https://api.github.com/orgs/github \u0026#39;Accept: application/json\u0026#39; HTTP/1.1 200 OK Content-Type: application/json; charset=utf-8 { \u0026#34;archived_at\u0026#34;: null, \u0026#34;avatar_url\u0026#34;: \u0026#34;https://avatars.githubusercontent.com/u/9919?v=4\u0026#34;, \u0026#34;blog\u0026#34;: \u0026#34;https://github.com/about\u0026#34;, \u0026#34;company\u0026#34;: null, \u0026#34;created_at\u0026#34;: \u0026#34;2008-05-11T04:37:31Z\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;How people build software.\u0026#34;, \u0026#34;email\u0026#34;: null, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/events\u0026#34;, \u0026#34;followers\u0026#34;: 29993, \u0026#34;following\u0026#34;: 0, \u0026#34;has_organization_projects\u0026#34;: true, \u0026#34;has_repository_projects\u0026#34;: true, \u0026#34;hooks_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/hooks\u0026#34;, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github\u0026#34;, \u0026#34;id\u0026#34;: 9919, \u0026#34;is_verified\u0026#34;: true, \u0026#34;issues_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/issues\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;San Francisco, CA\u0026#34;, \u0026#34;login\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;members_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/members{/member}\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;GitHub\u0026#34;, \u0026#34;node_id\u0026#34;: \u0026#34;MDEyOk9yZ2FuaXphdGlvbjk5MTk=\u0026#34;, \u0026#34;public_gists\u0026#34;: 0, \u0026#34;public_members_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/public_members{/member}\u0026#34;, \u0026#34;public_repos\u0026#34;: 477, \u0026#34;repos_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/repos\u0026#34;, \u0026#34;twitter_username\u0026#34;: null, \u0026#34;type\u0026#34;: \u0026#34;Organization\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-11-29T19:44:55Z\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/orgs/github\u0026#34; } 不支持的表达\n1 2 3 4 5 6 7 8 ~ » http get https://api.github.com/orgs/github \u0026#39;Accept: text/xml\u0026#39; HTTP/1.1 415 Unsupported Media Type Content-Type: application/json; charset=utf-8 { \u0026#34;documentation_url\u0026#34;: \u0026#34;https://docs.github.com/v3/media\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Unsupported \u0026#39;Accept\u0026#39; header: \u0026#39;text/xml\u0026#39;. Must accept \u0026#39;application/json\u0026#39;.\u0026#34; } 资源链接 当你浏览Web网页时，从一个连接跳到一个页面，再从另一个连接跳到另外一冬页面，就是利用了超媒体的概念：把一个个把资源链接起来。\n同样，我们在表述格式里边加入链接来引导客户端：\n在Link头告诉客户端怎么访问下一页和最后一页的记录； 在响应体里用url来链接项目所有者和项目地址 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 ~ » http -h get https://api.github.com/orgs/github/repos HTTP/1.1 200 OK Content-Type: application/json; charset=utf-8 Link: \u0026lt;https://api.github.com/organizations/9919/repos?page=2\u0026gt;; rel=\u0026#34;next\u0026#34;, \u0026lt;https://api.github.com/organizations/9919/repos?page=16\u0026gt;; rel=\u0026#34;last\u0026#34; [ { \u0026#34;id\u0026#34;: 3222, \u0026#34;node_id\u0026#34;: \u0026#34;MDEwOlJlcG9zaXRvcnkzMjIy\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;media\u0026#34;, \u0026#34;full_name\u0026#34;: \u0026#34;github/media\u0026#34;, \u0026#34;private\u0026#34;: false, \u0026#34;owner\u0026#34;: { \u0026#34;login\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;id\u0026#34;: 9919, \u0026#34;node_id\u0026#34;: \u0026#34;MDEyOk9yZ2FuaXphdGlvbjk5MTk=\u0026#34;, \u0026#34;avatar_url\u0026#34;: \u0026#34;https://avatars.githubusercontent.com/u/9919?v=4\u0026#34;, \u0026#34;gravatar_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/users/github\u0026#34;, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github\u0026#34;, \u0026#34;followers_url\u0026#34;: \u0026#34;https://api.github.com/users/github/followers\u0026#34;, \u0026#34;following_url\u0026#34;: \u0026#34;https://api.github.com/users/github/following{/other_user}\u0026#34;, \u0026#34;gists_url\u0026#34;: \u0026#34;https://api.github.com/users/github/gists{/gist_id}\u0026#34;, \u0026#34;starred_url\u0026#34;: \u0026#34;https://api.github.com/users/github/starred{/owner}{/repo}\u0026#34;, \u0026#34;subscriptions_url\u0026#34;: \u0026#34;https://api.github.com/users/github/subscriptions\u0026#34;, \u0026#34;organizations_url\u0026#34;: \u0026#34;https://api.github.com/users/github/orgs\u0026#34;, \u0026#34;repos_url\u0026#34;: \u0026#34;https://api.github.com/users/github/repos\u0026#34;, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/users/github/events{/privacy}\u0026#34;, \u0026#34;received_events_url\u0026#34;: \u0026#34;https://api.github.com/users/github/received_events\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Organization\u0026#34;, \u0026#34;site_admin\u0026#34;: false }, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github/media\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Media files for use in your GitHub integration projects\u0026#34;, \u0026#34;fork\u0026#34;: false, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media\u0026#34;, \u0026#34;forks_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/forks\u0026#34;, \u0026#34;keys_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/keys{/key_id}\u0026#34;, \u0026#34;collaborators_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/collaborators{/collaborator}\u0026#34;, \u0026#34;teams_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/teams\u0026#34;, \u0026#34;hooks_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/hooks\u0026#34;, \u0026#34;issue_events_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues/events{/number}\u0026#34;, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/events\u0026#34;, \u0026#34;assignees_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/assignees{/user}\u0026#34;, \u0026#34;branches_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/branches{/branch}\u0026#34;, \u0026#34;tags_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/tags\u0026#34;, \u0026#34;blobs_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/blobs{/sha}\u0026#34;, \u0026#34;git_tags_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/tags{/sha}\u0026#34;, \u0026#34;git_refs_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/refs{/sha}\u0026#34;, \u0026#34;trees_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/trees{/sha}\u0026#34;, \u0026#34;statuses_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/statuses/{sha}\u0026#34;, \u0026#34;languages_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/languages\u0026#34;, \u0026#34;stargazers_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/stargazers\u0026#34;, \u0026#34;contributors_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/contributors\u0026#34;, \u0026#34;subscribers_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/subscribers\u0026#34;, \u0026#34;subscription_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/subscription\u0026#34;, \u0026#34;commits_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/commits{/sha}\u0026#34;, \u0026#34;git_commits_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/commits{/sha}\u0026#34;, \u0026#34;comments_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/comments{/number}\u0026#34;, \u0026#34;issue_comment_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues/comments{/number}\u0026#34;, \u0026#34;contents_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/contents/{+path}\u0026#34;, \u0026#34;compare_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/compare/{base}...{head}\u0026#34;, \u0026#34;merges_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/merges\u0026#34;, \u0026#34;archive_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/{archive_format}{/ref}\u0026#34;, \u0026#34;downloads_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/downloads\u0026#34;, \u0026#34;issues_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues{/number}\u0026#34;, \u0026#34;pulls_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/pulls{/number}\u0026#34;, \u0026#34;milestones_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/milestones{/number}\u0026#34;, \u0026#34;notifications_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/notifications{?since,all,participating}\u0026#34;, \u0026#34;labels_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/labels{/name}\u0026#34;, \u0026#34;releases_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/releases{/id}\u0026#34;, \u0026#34;deployments_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/deployments\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2008-03-09T22:43:49Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-09-23T01:50:37Z\u0026#34;, \u0026#34;pushed_at\u0026#34;: \u0026#34;2015-02-27T17:31:20Z\u0026#34;, \u0026#34;git_url\u0026#34;: \u0026#34;git://github.com/github/media.git\u0026#34;, \u0026#34;ssh_url\u0026#34;: \u0026#34;git@github.com:github/media.git\u0026#34;, \u0026#34;clone_url\u0026#34;: \u0026#34;https://github.com/github/media.git\u0026#34;, \u0026#34;svn_url\u0026#34;: \u0026#34;https://github.com/github/media\u0026#34;, \u0026#34;homepage\u0026#34;: \u0026#34;https://github.com/logos\u0026#34;, \u0026#34;size\u0026#34;: 4484, \u0026#34;stargazers_count\u0026#34;: 293, \u0026#34;watchers_count\u0026#34;: 293, \u0026#34;language\u0026#34;: null, \u0026#34;has_issues\u0026#34;: false, \u0026#34;has_projects\u0026#34;: true, \u0026#34;has_downloads\u0026#34;: true, \u0026#34;has_wiki\u0026#34;: false, \u0026#34;has_pages\u0026#34;: false, \u0026#34;has_discussions\u0026#34;: false, \u0026#34;forks_count\u0026#34;: 69, \u0026#34;mirror_url\u0026#34;: null, \u0026#34;archived\u0026#34;: true, \u0026#34;disabled\u0026#34;: false, \u0026#34;open_issues_count\u0026#34;: 0, \u0026#34;license\u0026#34;: null, \u0026#34;allow_forking\u0026#34;: true, \u0026#34;is_template\u0026#34;: false, \u0026#34;web_commit_signoff_required\u0026#34;: false, \u0026#34;topics\u0026#34;: [], \u0026#34;visibility\u0026#34;: \u0026#34;public\u0026#34;, \u0026#34;forks\u0026#34;: 69, \u0026#34;open_issues\u0026#34;: 0, \u0026#34;watchers\u0026#34;: 293, \u0026#34;default_branch\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;permissions\u0026#34;: { \u0026#34;admin\u0026#34;: false, \u0026#34;maintain\u0026#34;: false, \u0026#34;push\u0026#34;: false, \u0026#34;triage\u0026#34;: false, \u0026#34;pull\u0026#34;: true } }, ... ] 状态转移（State Transfer） 状态应该区分应用状态和资源状态，\n客户端负责维护应用状态， 而服务端维护资源状态。 客户端与服务端的交互必须是无状态的，并在每一次请求中包含处理该请求所需的一切信息。服务端不需要在请求间保留应用状态，只有在接受到实际请求的时候，服务端才会关注应用状态。这种无状态通信原则，使得服务端和中介能够理解独立的请求和响应。在多次请求中，同一客户端也不再需要依赖于同一服务器，方便实现高可扩展和高可用性的服务端。\n客户端应用状态在服务端提供的超媒体的指引下发生变迁。服务端通过超媒体告诉客户端当前状态有哪些后续状态可以进入。\n","permalink":"https://WFUing.github.io/posts/tech/network/restful/","summary":"REST 全称是 Representational State Transfer（表现层状态转化），更具体的全称是 Resource Representational State Transfer（资源表现层状态转化），具体可以见 Roy Thomas Fielding 的博士论文 https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm 这一章。\nREST 指的是一组架构约束条件和原则：\n为设计一个功能强、性能好、适宜通信的 web 应用 如果一个架构符合 REST 的约束条件和原则，我们就称它为 RESTful 结构 Resources restful petclinic tutorial docter paper bilibili-软件体系结构-2022.7-REST Create REST APIs with JAX-RS 核心概念 资源（Resources） 表现层（Representation） 状态转化（State Transfer） 资源 网络上的一个实体，或者说是网络上的一个具体信息，任何事物，只要有被引用到的必要，它就是一个资源。\n一段文本，一张图片，一首歌曲 数据库中的一行数据 一个手机号码，某用户的个人信息 一种服务 资源标识 要让一个资源可以被识别，需要有个唯一标识，在Web中这个唯一标识就是URI（Uniform Resource Identifier）。例如：\nhttps://www.ex.com/software/releases/latest.tar.gz https://www.ex.com/map/roads/USA/CA/17_mile_drive https://www.ex.com/search/cs578 URI 设计原则\n易读： https://www.oschina.net/news/38119/oschina-translate-reward-plan 表达资源的层级关系： https://github.com/git/git/commit/e3ae056f87e1d675913d08/orders/2012/10 表示资源的同级关系： /git/block-sha1/sha1.h/compare/e3af72cda056f87e;bd63e61bdf38eb264 表达资源的过滤： https://github.com/git/git/pulls?q=is%3Aclosed 统一资源接口\nRESTful 架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的 HTTP 方法如 GET，PUT 和 POST，并遵循这些方法的语义 如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性 GET和HEAD请求是安全的，无论请求多少次，都不改变服务器状态 GET、HEAD、PUT和DELETE请求是幂等的，无论对资源操作多少次，结果总是一样的，后面的请求并不会产生比第一次更多的影响 GET 获取表示，变更时获取表示（缓存）。安全且幂等。","title":"Restful API Tutorial"},{"content":"Actor Model CPU 上有多个内核。如果我们想充分利用现有的这些硬件，就需要一种并发运行代码的方法。数十年来无法追踪的错误和开发人员的沮丧都表明，线程并不是解决问题的办法。不过不用担心，我们还有其他很好的选择，今天我要向你展示的就是其中之一：actor model。\nactor model actor model 是一种处理并发计算的概念模型。它为系统组件的行为和交互方式定义了一些通用规则。\nactors actor 是计算的原始单元。它接收 message，并根据 message进行某种计算。\n这种想法与面向对象语言（object-oriented languages）中的想法非常相似：对象接收 message（方法调用），并根据接收到的 message（我们调用的方法）进行操作。\n主要区别在于，actors 之间是完全隔离的，它们永远不会共享内存。值得注意的是，一个 actor 可以保持一个私有状态，其他 actor 永远无法直接改变该状态。\n一个 actor 不是 actor。它们是以系统的形式出现的。在 actor model 中，一切都是 actor，它们需要有地址，这样一个行为者才能向另一个 actor 发送 message。\nmailbox 虽然多个 actor 可以同时运行，但一个 actor 会按顺序处理给定的 message。这意味着，如果你向同一个 actor 发送 3 条 message，它只会一次执行一条。要同时执行这 3 条 message，你需要创建 3 个 actor，每个 actor 发送一条 message。\nmessage 是异步发送给角色的，角色在处理另一条消息时需要将消息存储在某个地方。mailbox 就是存储这些 message 的地方。\nactor 之间通过发送异步消息进行通信。这些 message 会保存在其他 actor 的 mailbox 中，直到它们被处理。\nWhat actors do 当 actor 收到 message 时，它可以做以下三件事中的一件：\nCreate more actors Send messages to other actors Designate what to do with the next message：指定义这个状态在收到下一条信息时的样子，行为体如何改变状态。假设我们有一个行为类似于计算器的行为体，它的初始状态是简单的数字 0。当这个行为体收到 add(1) 消息时，它不会改变自己的原始状态，而是指定在收到下一条消息时，状态将是 1。 Fault tolerance Erlang 引入了 \u0026ldquo;let it crash\u0026rdquo; 的理念。其理念是，你不需要进行防御性编程，试图预测所有可能发生的问题，并找到处理它们的方法，因为根本不可能考虑到每一个故障点。\nErlang 所做的就是简单地让它崩溃，但让这些关键代码由某个人监管，而这个人唯一的责任就是知道当崩溃发生时该做什么（比如将代码单元重置为稳定状态），而使这一切成为可能的就是 actor model。\n每段代码都运行在一个进程中（这也是 Erlang 对其角色的基本称呼）。这个进程是完全孤立的，这意味着它的状态不会影响任何其他进程。我们有一个 \u0026ldquo;监督者\u0026rdquo;，它基本上是另一个进程（所有东西都是行为体，还记得吗？），当被监督的进程崩溃时，它会收到通知，然后可以采取一些措施。\n这就使得创建 \u0026ldquo;self heal\u0026rdquo; 系统成为可能，也就是说，如果一个行为体由于某种原因进入了异常状态并崩溃，那么监管者就可以采取一些措施，尝试将其恢复到一致的状态（有多种策略可以做到这一点，最常见的就是以初始状态重新启动行为体）。\nActor Model For IoT 物联网（IoT）由许多节点组成，通常功能有限。通过互联网协议标准进行通信的小型软件组件通常在机器之间形成高度分布式的工作流程，人与机器之间的互动极少。一般的应用场景包括监控环境条件等数据的传感器。复杂的应用则使用传感器和执行器，例如：家庭自动化和健康数据跟踪。这些系统使机器能够将数据上传到互联网服务器。因此，它们可以随时随地跟踪数据。\n典型 IoT 系统的主要特点之一是涉及大量受管设备，每个设备的内部状态都在不断变化。在许多情况下，这些设备都是在一些简单的网络协议上运行的原始硬件。这种 \u0026ldquo;极简\u0026rdquo; 要求与 actor model 非常吻合，因为 actor model 的基本原则之一就是将业务逻辑分解成最小的任务，由各个 actor 来处理。\nactor 具有 delivery guarantees 和 isolation 特性，非常适合物联网世界，是模拟数百万个并发连接的传感器生成实时数据的绝佳工具。它们设计轻巧，因此可以在不消耗过多计算资源的情况下进行扩展。\n以下是行动者适合物联网的特征属性：\nScalability：物联网带来了许多挑战，如何处理所有同时连接的设备产生的大量数据，并对其进行检索、汇总、分析和推送，同时保持设备的响应速度。面临的挑战包括管理高峰期接收传感器数据的巨大突发流量、批处理和实时处理这些海量数据，以及进行模拟真实世界使用模式的大规模仿真。一些物联网部署还要求后端服务管理设备，而不仅仅是吸收设备发送的数据。管理这一切的后端系统需要能够按需扩展，并具有完全的弹性。这非常适合 reactive architectures ，尤其是 Akka。\nConcurrency：物联网应用网关是系统中将本地传感器和执行器连接到云的点（例如路边站、运输过程中的车载设备或家庭自动化网关）。即使一个应用程序在传感器、执行器和云服务之间 \u0026ldquo;只转发数据\u0026rdquo;，也会有并发事件。物联网应用网关需要处理在其环境中发生的事件流和到达其接口的数据流。环境以自己的速度产生数据并要求输出。Actor model 通过消息传递实现了对来自设备的消息的高性能并发处理，从而解决了上述问题。message-processing models的优势之一是，传统的并发问题（主要是共享状态的同步）不再是问题。行为体可以保留设备内部状态或活动会话等私有状态，并在没有锁的情况下自由更新。Actor model 可确保一次只处理一条消息。\nFault Tolerance：在构建可能被数百万联网设备使用的服务时，您需要一个应对信息流的模型。您需要对设备故障、信息丢失和服务失败时的情况进行抽象。今天，我们常常认为调用堆栈是理所当然的。但是，它们发明的年代，由于多 CPU 系统并不常见，并发编程并不那么重要。调用栈不能跨线程，因此不能模拟异步调用链。 上图显示了一个严重的问题。工作线程如何处理这种情况？它很可能无法解决问题，因为它通常不知道失败任务的目的。调用者 \u0026ldquo;线程需要得到通知，但没有调用栈可以释放异常。失败通知只能通过侧通道完成，例如，在 \u0026ldquo;调用者 \u0026ldquo;线程希望得到结果的地方放置一个错误代码。如果没有这种通知，\u0026ldquo;调用者 \u0026ldquo;就永远不会收到失败通知，任务也就丢失了！这与网络系统的工作原理惊人地相似，在网络系统中，信息/请求可能在没有任何通知的情况下丢失/失败。\n有了 actor，我们可以将 actor 组织成监管层次，因此，单个 actor 的错误不会导致整个系统瘫痪。\nLightWeight：基准测试表明，Akka 模型每千兆字节堆内存可处理 250 万个角色，单机每秒可处理 5000 万条消息。\nNetwork Protocol Decoupling：利用 actor model ，我们可以利用容错功能，将代表设备的角色与底层通信协议分离开来。这样，代表设备和设备状态的角色就可以从代表通信协议的 actor 中分离出来，从而使设备 actor 免受网络错误的影响，并提高各个 actor 的功能一致性。\nNon-blocking communications：物联网应用 \u0026ldquo;必须 \u0026ldquo;具有反应性和异步性。大多数物联网应用程序都应能够处理来自设备的许多连接以及从设备中获取的所有信息。异步消息传递广泛应用于机器对机器通信。异步通信具有灵活性：应用程序可以发送一条信息，然后继续处理其他事情。actor 是唯一可寻址的，拥有自己独立的邮箱或消息队列。它们通过消息传递支持非阻塞通信，因此适合构建非阻塞和分布式计算系统。\nCustomization：所有行为体都有一个定义明确的生命周期，并配有精致的钩子，如用于生命周期逻辑控制的 preStart()、postRestart() 和 postStop()。在模拟物联网设备时，可以轻松地将自定义初始化和终止例程锚定到相应的钩子上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 object Device { def props(deviceType: String, mqttPubSub: ActorRef) = //... } class Device(deviceType: String, mqttPubSub: ActorRef) extends Actor { import Device._ private var opState: OpState = InitialState(deviceType) override def preStart(): Unit = //Initialize device\u0026#39;s op-state... override def postStop(): Unit = //Reset/Shutdown device... def receive = { case ReportOpState =\u0026gt; //Assemble report data with OpState mqttPubSub ! new Publish(Mqtt.topicReport, reportData) case UpdateOpState(newState) =\u0026gt; //Update opState with newState mqttPubSub ! new Publish(Mqtt.topicUpdate, updateResult) case PowerOff =\u0026gt; //Shutdown device... } } view raw 上面的片段展示了如何在 Scala/Akka 中构建一个设备角色，使用行业标准 MQTT（消息队列遥测传输）发布-订阅消息协议向订阅者发布其运行状态信息。这里的目的并不是研究如何用 Scala 或 Akka 编程，而是提供一个简单的示例，说明 Akka 角色易于理解的逻辑流程。\nResources https://www.brianstorti.com/the-actor-model/ http://akshantalpm.github.io/Actor-Model-For-IoT/ https://www.infoworld.com/article/3209728/why-akka-and-the-actor-model-shine-for-iot-applications.html ","permalink":"https://WFUing.github.io/posts/tech/distributed/iot/actor/","summary":"Actor Model CPU 上有多个内核。如果我们想充分利用现有的这些硬件，就需要一种并发运行代码的方法。数十年来无法追踪的错误和开发人员的沮丧都表明，线程并不是解决问题的办法。不过不用担心，我们还有其他很好的选择，今天我要向你展示的就是其中之一：actor model。\nactor model actor model 是一种处理并发计算的概念模型。它为系统组件的行为和交互方式定义了一些通用规则。\nactors actor 是计算的原始单元。它接收 message，并根据 message进行某种计算。\n这种想法与面向对象语言（object-oriented languages）中的想法非常相似：对象接收 message（方法调用），并根据接收到的 message（我们调用的方法）进行操作。\n主要区别在于，actors 之间是完全隔离的，它们永远不会共享内存。值得注意的是，一个 actor 可以保持一个私有状态，其他 actor 永远无法直接改变该状态。\n一个 actor 不是 actor。它们是以系统的形式出现的。在 actor model 中，一切都是 actor，它们需要有地址，这样一个行为者才能向另一个 actor 发送 message。\nmailbox 虽然多个 actor 可以同时运行，但一个 actor 会按顺序处理给定的 message。这意味着，如果你向同一个 actor 发送 3 条 message，它只会一次执行一条。要同时执行这 3 条 message，你需要创建 3 个 actor，每个 actor 发送一条 message。\nmessage 是异步发送给角色的，角色在处理另一条消息时需要将消息存储在某个地方。mailbox 就是存储这些 message 的地方。\nactor 之间通过发送异步消息进行通信。这些 message 会保存在其他 actor 的 mailbox 中，直到它们被处理。","title":"Actor"},{"content":"Resources Demos https://github.com/gofireflyio/aiac https://github.com/JustAIGithub/AI-Code-Convert Blogs 25 Best AI Code Generators ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/ai-code-generators/","summary":"Resources Demos https://github.com/gofireflyio/aiac https://github.com/JustAIGithub/AI-Code-Convert Blogs 25 Best AI Code Generators ","title":"AI Code Generators"},{"content":"Resources git tutorial: https://wyag.thb.lt/ 动图展示10大Git命令: https://zhuanlan.zhihu.com/p/132573100 git intro: https://missing.csail.mit.edu/2020/version-control/ book: https://git-scm.com/book/en/v2 commit convention 规范: https://www.conventionalcommits.org/en/v1.0.0/#summary Write yourself a Git：https://wyag.thb.lt/ 如何编写Git Commit Message? 为了创建一个有用的 revision history ，团队应该首先就 commit message convention 达成一致，至少要定义以下三点：\nStyle：标记语法Markup syntax, 流式布局wrap margins, 语法grammar, 大小写capitalization, 标点符号punctuation。把这些东西写出来，去掉猜测，让一切尽可能简单。 Content：提交消息的正文应该包含什么样的信息？不应该包含什么？ Metadata：如何引用 issue tracking IDs、pull request numbers 等？ 幸运的是，Git提交信息的规范已经有了很好的约定。事实上，很多 Git 命令的功能中就包含了这些约定。您不需要重新发明什么。只要遵循下面的七条规则，您就能像专家一样 commit message 了。\nThe seven rules of a great Git commit message\nSeparate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs. how For example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Summarize changes in around 50 characters or less More detailed explanatory text, if necessary. Wrap it to about 72 characters or so. In some contexts, the first line is treated as the subject of the commit and the rest of the text as the body. The blank line separating the summary from the body is critical (unless you omit the body entirely); various tools like `log`, `shortlog` and `rebase` can get confused if you run the two together. Explain the problem that this commit is solving. Focus on why you are making this change as opposed to how (the code explains that). Are there side effects or other unintuitive consequences of this change? Here\u0026#39;s the place to explain them. Further paragraphs come after blank lines. - Bullet points are okay, too - Typically a hyphen or asterisk is used for the bullet, preceded by a single space, with blank lines in between, but conventions vary here If you use an issue tracker, put references to them at the bottom, like this: Resolves: #123 See also: #456, #789 1. Separate subject from body with a blank line From the git commit manpage:\n1 Though not required, it\u0026#39;s a good idea to begin the commit message with a single short (less than 50 character) line summarizing the change, followed by a blank line and then a more thorough description. The text up to the first blank line in a commit message is treated as the commit title, and that title is used throughout Git. For example, Git-format-patch(1) turns a commit into email, and it uses the title on the Subject line and the rest of the commit in the body. 首先，并非每次提交都需要主题和正文。有时一行就够了，特别是当修改非常简单，不需要更多上下文的时候。\n1 Fix typo in introduction to user guide 如果读者想知道错别字是什么，可以直接查 typo 本身，即使用 git show 或 git diff 或 git log -p。\n如果您在命令行提交类似的内容，使用 git commit 的 -m 选项也很方便\n1 $ git commit -m \u0026#34;Fix typo in introduction to user guide\u0026#34; 然而，当一个提交需要一些解释和上下文时，你需要写一个正文。例如：\n1 2 3 4 5 Derezz the master control program MCP turned out to be evil and had become intent on world domination. This commit throws Tron\u0026#39;s disc into MCP (causing its deresolution) and turns it back into a chess game. 使用 -m 选项编写带正文的提交信息并不容易。最好使用合适的文本编辑器来编写。\n在浏览日志时，主体与主体的分离是有好处的。以下是完整的日志记录：\n1 2 3 4 5 6 7 8 9 10 $ git log commit 42e769bdf4894310333942ffc5a15151222a87be Author: Kevin Flynn \u0026lt;kevin@flynnsarcade.com\u0026gt; Date: Fri Jan 01 00:00:00 1982 -0200 Derezz the master control program MCP turned out to be evil and had become intent on world domination. This commit throws Tron\u0026#39;s disc into MCP (causing its deresolution) and turns it back into a chess game. 现在只打印主题行 git log --oneline ：\n1 2 $ git log --oneline 42e769 Derezz the master control program 或者，按用户分组提交，同样只显示主题行，git shortlog：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ git shortlog Kevin Flynn (1): Derezz the master control program Alan Bradley (1): Introduce security program \u0026#34;Tron\u0026#34; Ed Dillinger (3): Rename chess program to \u0026#34;MCP\u0026#34; Modify chess program Upgrade chess program Walter Gibbs (1): Introduce protoype chess program 在Git中，主题行和正文之间的区别还有很多，但如果中间没有空行，它们都无法正常工作。\n2. Limit the subject line to 50 characters 50个字符不是硬性限制，只是一个经验法则。将主题行保持在这一长度可确保其可读性，并迫使作者思考如何以最简洁的方式说明内容。\n1 Tip: If you\u0026#39;re having a hard time summarizing, you might be committing too many changes at once. Strive for atomic commits (a topic for a separate post). GitHub\u0026rsquo;s UI is fully aware of these conventions. It will warn you if you go past the 50 character limit and will truncate any subject line longer than 72 characters with an ellipsis.\n3. Capitalize the subject line This is as simple as it sounds. Begin all subject lines with a capital letter.\nFor example:\nAccelerate to 88 miles per hour Instead of:\naccelerate to 88 miles per hour 4. Do not end the subject line with a period Trailing punctuation is unnecessary in subject lines. Besides, space is precious when you\u0026rsquo;re trying to keep them to 50 chars or less.\nExample:\nOpen the pod bay doors Instead of:\nOpen the pod bay doors. 5. Use the imperative mood in the subject line Imperative mood just means \u0026ldquo;spoken or written as if giving a command or instruction\u0026rdquo;. A few examples:\nClean your room Close the door Take out the trash Git itself uses the imperative whenever it creates a commit on your behalf.\n例如，使用 git merge 时创建的默认信息如下\n1 Merge branch \u0026#39;myfeature\u0026#39; 当使用 git revert 时，\n1 2 3 Revert \u0026#34;Add the thing with the stuff\u0026#34; This reverts commit cc87791524aedd593cff5a74532befe7ab69ce9d. 或 点击 GitHub 拉取请求上的 Merge 按钮时：\n1 Merge pull request #123 from someuser/somebranch 因此，当您在命令行中编写提交信息时，您遵循的是 Git 自带的约定。例如，\nRefactor subsystem X for readability Update getting started documentation Remove deprecated methods Release version 1.0.0 这样写一开始可能会有点尴尬。我们更习惯于用指示语气说话，而指示语气则是报告事实。这就是为什么提交的信息经常读起来像这样：\nFixed bug with Y Changing behavior of X 有时承诺信息会被写成内容描述：\nMore fixes for broken stuff Sweet new API methods 为了消除任何混淆，这里有一个简单的规则，以便每次都能正确操作。\n一个正确的Git提交主题行应该能够完成以下句子：\nIf applied, this commit will your subject line here For example:\nIf applied, this commit will refactor subsystem X for readability If applied, this commit will update getting started documentation If applied, this commit will remove deprecated methods If applied, this commit will release version 1.0.0 If applied, this commit will merge pull request #123 from user/branch Remember: Use of the imperative is important only in the subject line. You can relax this restriction when you\u0026rsquo;re writing the body.\n6. Wrap the body at 72 characters Git 不会自动换行。当您写提交信息的正文时，必须注意右边距，并手动换行。\n建议在72个字符时进行，这样Git就有足够的空间缩进文本，同时又能将所有内容保持在80个字符以内。\n7. Use the body to explain what and why vs. how Bitcoin Core 的这个 commit 是一个很好的例子，它解释了改变的内容和原因：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 commit eb0b56b19017ab5c16c745e6da39c53126924ed6 Author: Pieter Wuille \u0026lt;pieter.wuille@gmail.com\u0026gt; Date: Fri Aug 1 22:57:55 2014 +0200 Simplify serialize.h\u0026#39;s exception handling Remove the \u0026#39;state\u0026#39; and \u0026#39;exceptmask\u0026#39; from serialize.h\u0026#39;s stream implementations, as well as related methods. As exceptmask always included \u0026#39;failbit\u0026#39;, and setstate was always called with bits = failbit, all it did was immediately raise an exception. Get rid of those variables, and replace the setstate with direct exception throwing (which also removes some dead code). As a result, good() is never reached after a failure (there are only 2 calls, one of which is in tests), and can just be replaced by !eof(). fail(), clear(n) and exceptions() are just never called. Delete them. 看看完整的差异，想想作者花时间在此时此地提供这些上下文，为同事和未来的提交者节省了多少时间。如果他不这样做，这些内容可能会永远丢失。\n在大多数情况下，您可以省略关于如何修改的细节。在这方面，代码通常是不言自明的，如果代码非常复杂，需要用散文来解释，那就是源注释的作用。只需重点说明您首先进行修改的原因\u0026ndash;(修改前的工作方式以及有什么问题)、现在的工作方式，以及您为什么决定以这种方式解决问题。\n未来感谢您的维护者可能就是您自己！\n","permalink":"https://WFUing.github.io/posts/tech/operations/git/how-to-write-a-git-commit-message/","summary":"Resources git tutorial: https://wyag.thb.lt/ 动图展示10大Git命令: https://zhuanlan.zhihu.com/p/132573100 git intro: https://missing.csail.mit.edu/2020/version-control/ book: https://git-scm.com/book/en/v2 commit convention 规范: https://www.conventionalcommits.org/en/v1.0.0/#summary Write yourself a Git：https://wyag.thb.lt/ 如何编写Git Commit Message? 为了创建一个有用的 revision history ，团队应该首先就 commit message convention 达成一致，至少要定义以下三点：\nStyle：标记语法Markup syntax, 流式布局wrap margins, 语法grammar, 大小写capitalization, 标点符号punctuation。把这些东西写出来，去掉猜测，让一切尽可能简单。 Content：提交消息的正文应该包含什么样的信息？不应该包含什么？ Metadata：如何引用 issue tracking IDs、pull request numbers 等？ 幸运的是，Git提交信息的规范已经有了很好的约定。事实上，很多 Git 命令的功能中就包含了这些约定。您不需要重新发明什么。只要遵循下面的七条规则，您就能像专家一样 commit message 了。\nThe seven rules of a great Git commit message\nSeparate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs.","title":"How to Write a Git Commit Message"},{"content":"Linux 的命令确实非常多，然而熟悉 Linux 的人从来不会因为 Linux 的命令太多而烦恼。因为我们仅仅只需要掌握常用命令，就完全可以驾驭 Linux。\n接下来，让我们一起来看看都有那些常用的 Linux 命令吧！\n一、文件目录操作 1.ls 命令 ls 命令不仅可以查看 linux 文件夹包含的文件而且可以查看文件权限（包括目录、文件夹、文件权限）查看目录信息等等。\n命令格式\n1 ls [选项][目录名] 常用参数\n-l ：列出长数据串，包含文件的属性与权限数据等 -a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用） -d ：仅列出目录本身，而不是列出目录的文件数据 -h ：将文件容量以较易读的方式（GB，kB等）列出来 -R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来 使用实例\n1.列出 home 目录下的所有文件和目录的详细资料。\n1 2 ls -a -l /home ls -al /home 2.列出当前目录下所有以\u0026quot;d\u0026quot;开头的文件目录详情内容。\n1 ls -l d* 2.cd命令 最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。用于切换当前目录至dirName。\n命令格式\n1 cd [目录名] 操作案例\n1.从当前目录进入系统根目录。\n1 cd / 2.跳转到 home/Code 目录。\n1 cd /home/Code 3.pwd 命令 查看\u0026quot;当前工作目录\u0026quot;的完整路径。\n命令格式\n1 pwd [选项] 常用参数\n-P :显示实际物理路径，而非使用连接（link）路径 -L :当目录为连接路径时，显示连接路径 操作案例\n1.显示当前所在路径。\n1 pwd 4.mkdir 命令 用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。\n命令格式\n1 mkdir [选项] 目录 常用参数\n-m, \u0026ndash;mode=模式，设定权限\u0026lt;模式\u0026gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p, \u0026ndash;parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v, \u0026ndash;verbose 每次创建新目录都显示信息 \u0026ndash;help 显示此帮助信息并退出 \u0026ndash;version 输出版本信息并退出 使用实例\n1.创建一个空目录。\n1 mkdir test 2.递归创建多个目录。\n1 mkdir test/test1 3.创建权限为777的目录。\n1 mkdir -m 777 test2 4.创建目录都显示信息。\n1 mkdir -v test4 5.rm 命令 删除一个目录中的一个或多个文件或目录，如果没有使用- r选项，则rm不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。\n命令格式\n1 rm [选项] 文件 常用参数\n-f, \u0026ndash;force 忽略不存在的文件，从不给出提示。 -i, \u0026ndash;interactive 进行交互式删除 -r, -R, \u0026ndash;recursive 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v, \u0026ndash;verbose 详细显示进行的步骤 \u0026ndash;help 显示此帮助信息并退出 \u0026ndash;version 输出版本信息并退出 使用实例\n1.删除文件 test.txt,系统会提示是否删除。\n1 rm test.txt 2.强制删除 test.txt，系统不再提示。\n1 rm -f test.txt 3.将 test 子目录及目录中所有档案删除。\n1 rm -r test 6.rmdir 命令 该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。\n命令格式\n1 rmdir [选项] 目录 常用参数\n-p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。 -v, \u0026ndash;verbose 显示指令执行过程 使用实例\n1.删除空目录 test1，非空目录无法删除。\n1 rmdir test1 2.当子目录被删除后使它也成为空目录的话，则顺便一并删除\n1 rmdir -p test2 # test 目录下仅有 test2 7. mv 命令 可以用来移动文件或者将文件改名（move (rename) files）。当第二个参数类型是文件时，mv命令完成文件重命名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。\n命令格式\n1 mv [选项] 源文件或目录 目标文件或目录 常用参数\n-b ：若需覆盖文件，则覆盖前先行备份 -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖 -u ：若目标文件已经存在，且 source 比较新，才会更新(update) -t ： \u0026ndash;target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后 使用实例\n1.将 test1.txt 重命名为 test2.txt。\n1 mv test1.txt test2.txt 2.移动文件 test1.txt 到目录 test2\n1 mv test1.txt test2 3.将文件 test1.txt、test2.txt、test3.txt 移动到目录 test3。\n1 mv test1.txt test2.txt test3.txt test3 8.cp 命令 将源文件复制至目标文件，或将多个源文件复制至目标目录。\n命令格式\n1 cp [选项] 源文件 目录 或 cp [选项] -t 目录 源文件 常用参数\n-t \u0026ndash;target-directory 指定目标目录 -i \u0026ndash;interactive 覆盖前询问（使前面的 -n 选项失效） -n \u0026ndash;no-clobber 不要覆盖已存在的文件（使前面的 -i 选项失效） -f \u0026ndash;force 强行复制文件或目录，不论目的文件或目录是否已经存在 -u \u0026ndash;update 使用这项参数之后，只会在源文件的修改时间较目的文件更新时，或是对应的目的文件并不存在，才复制文件 使用实例\n1.复制文件 test1.txt 到 test1 目录\n1 cp test1.txt test1 # 若文件存在，会提示是否覆盖。若不存在直接完成复制 复制 test1 整个目录到 test2\n1 cp -a test1 test2 9.touch 命令 touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。\n命令格式\n1 touch [选项] 文件 常用参数\n-a 或\u0026ndash;time=atime或\u0026ndash;time=access或\u0026ndash;time=use 只更改存取时间 -c 或\u0026ndash;no-create 不建立任何文档 -d 使用指定的日期时间，而非现在的时间 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题 -m 或\u0026ndash;time=mtime或\u0026ndash;time=modify 只更改变动时间 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同 -t 使用指定的日期时间，而非现在的时间 使用实例\n1.创建不存在的文件test.txt\n1 touch test.txt 2.更新 test.txt 的实践和 test1.txt 时间戳相同\n1 touch -r test.txt test1.txt 10.cat 命令 用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。\n命令格式\n1 cat [选项] [文件] 常用参数\n-A, \u0026ndash;show-all 等价于 -vET -b, \u0026ndash;number-nonblank 对非空输出行编号 -e 等价于 -vE -E, \u0026ndash;show-ends 在每行结束处显示 $ -n, \u0026ndash;number 对输出的所有行编号,由1开始对所有输出的行数编号 -s, \u0026ndash;squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价 -T, \u0026ndash;show-tabs 将跳格字符显示为 ^I -u (被忽略) -v, \u0026ndash;show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 使用实例\n1.把 test.log 的文件内容加上行号后输入 test1.log 这个文件里。\n1 cat -n test.log test1.log 将 test.log 的文件内容反向显示。\n1 tac test.log 11.nl 命令 输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。\n命令格式\n1 nl [选项] [文件] 常用参数\n-b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n) -b t ：如果有空行，空的那一行不要列出行号(默认值) -n ：列出行号表示的方法，主要有三种： -n ln ：行号在萤幕的最左方显示 -n rn ：行号在自己栏位的最右方显示，且不加 0 -n rz ：行号在自己栏位的最右方显示，且加 0 -w ：行号栏位的占用的位数 使用实例\n用 nl 列出 test.log 的内容。\n1 nl test.log 用 nl 列出 test.log 的内容，空本行也加上行号。\n1 nl -b a test.log 12.more 命令 more 命令和 cat 的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。\n命令格式\n1 more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 常用参数\n+n 从笫n行开始显示 -n 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示Press space to continue，'q' to quit（按空格键继续，按q键退出），禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 操作指令\nEnter：向下n行，需要定义。默认为1行 Ctrl+F：向下滚动一屏 空格键：向下滚动一屏 Ctrl+B：返回上一屏 = ：输出当前行的行号 ：f ：输出文件名和当前行的行号 V ：调用vi编辑器 !命令 ：调用Shell，并执行命令 q ：退出more 使用实例\n1.显示文件 test.log 第3行起内容。\n1 more +3 test.log 2.从文件 test.log 查找第一个出现\u0026quot;day3\u0026quot;字符串的行，并从该处前2行开始显示输出。\n1 more +/day3 test.log 设置每屏显示行数\n1 more -5 test.log 13.less 命令 less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。\n命令格式\n1 less [参数] 文件 常用参数\n-b \u0026lt;缓冲区大小\u0026gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o \u0026lt;文件名\u0026gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x \u0026lt;数字\u0026gt; 将\u0026quot;tab\u0026quot;键显示为规定的数字空格 操作命令\n/字符串：向下搜索\u0026quot;字符串\u0026quot;的功能 ?字符串：向上搜索\u0026quot;字符串\u0026quot;的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 使用实例\n1.查看文件 test.log。\n1 less test.log 14.head 命令 head 用来显示档案的开头至标准输出中，默认 head 命令打印其相应文件的开头 10 行。\n命令格式\n1 head [参数] [文件] 常用参数\n-q 隐藏文件名 -v 显示文件名 -c\u0026lt;字节\u0026gt; 显示字节数 -n\u0026lt;行数\u0026gt; 显示的行数 使用实例\n1.显示文件 test.log 的前 5 行\n1 head -n 5 test.log 2.显示文件 test.log 前 20 个字节\n1 head -c 20 test.log 15.tail 命令 显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。\n命令格式\n1 tail [必要参数] [选择参数] [文件] 常用参数\n-f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c\u0026lt;数目\u0026gt; 显示的字节数 -n\u0026lt;行数\u0026gt; 显示行数 \u0026ndash;pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q, \u0026ndash;quiet, \u0026ndash;silent 从不输出给出文件名的首部 -s, \u0026ndash;sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 使用实例\n1.显示文件 test.log 最后 5 行内容。\n1 tail -n 5 test.log 2.循环查看文件内容\n1 tail -f test.log 二、文件查找 16.which 命令 which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。\n命令格式\n1 which 可执行文件名称 常用参数\n-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名 -p 与-n参数相同，但此处的包括了文件的路径 -w 指定输出时栏位的宽度 -V 显示版本信息 使用实例\n1.查找文件、显示命令路径。\n1 which pwd 用 which 去找出 which\n1 which which 17.whereis 命令 whereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。\n命令格式\n1 whereis [-bmsu] [BMS 目录名 -f ] 文件名 常用参数\n-b 定位可执行文件 -m 定位帮助文件 -s 定位源代码文件 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 -B 指定搜索可执行文件的路径 -M 指定搜索帮助文件的路径 -S 指定搜索源代码文件的路径 使用实例\n1.将和 svn 文件相关的文件都查找出来。\n1 whereis svn 2.只将二进制文件查找出来。\n1 whereis -b svn 18.locate 命令 可以很快速的搜寻档案系统内是否有指定的档案。\n命令格式\n1 locate [选择参数] [样式] 常用参数\n-e 将排除在寻找的范围之外。 -1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。 -f 将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中。 -q 安静模式，不会显示任何错误讯息。 -n 至多显示 n个输出。 -r 使用正规运算式 做寻找的条件。 -o 指定资料库存的名称。 -d 指定资料库的路径 使用实例\n1.查找和 pwd 相关的所有文件。\n1 locate pwd 搜索etc 目录下，所有以 m 开头的文件。\n1 bash复制代码locate /etc/m 19.find 命令 主要作用是沿着文件层次结构向下遍历，匹配符合条件的文件，并执行相应的操作。\n命令格式\n1 find [选项] [搜索路径] [表达式] 常用参数\n-print find 命令将匹配的文件输出到标准输出 -exec find 命令对匹配的文件执行该参数所给出的 shell 命令\n-name 按照文件名查找文件 -type 查找某一类型的文件 使用实例\n1.打印当前目录文件目录列表。\n1 find . -print 2.打印当前目录下所有不以.txt 结尾的文件名。\n1 find . ! -name \u0026#34;*.txt\u0026#34; 3.打印当前目录下所有权限为 777 的 php 文件。\n1 find . -type f -name \u0026#34;*.php\u0026#34; -perm 777 4.找到当前目录下所有 php 文件，并显示其详细信息。\n1 find . -name \u0026#34;*.php\u0026#34; -exec ls -l {} \\; 5.查找当前目录下所有 c 代码文件，统计总行数。\n1 find . -type f -name \u0026#34;*.c\u0026#34; | xargs wc -l xargs 命令可以从标准输入接收输入，并把输入转换为一个特定的参数列表。\n命令格式\n1 command | xargs [选项] [command] xargs 命令应该紧跟在管道操作符之后，因为它以标准输入作为主要的源数据流。\n常用参数\n-n 指定每行最大的参数数量 -d 指定分隔符 三、文件打包上传和下载 20.tar 命令 用来压缩和解压文件。tar本身不具有压缩功能。他是调用压缩功能实现的。\n命令格式\n1 tar [必要参数] [选择参数] [文件] 常用参数\n必要参数\n-A 新增压缩文件到已存在的压缩 -B 设置区块大小 -c 建立新的压缩文件 -d 记录文件的差别 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -x 从压缩的文件中提取文件 -t 显示压缩文件的内容 -z 支持gzip解压文件 -j 支持bzip2解压文件 -Z 支持compress解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -W 确认压缩文件的正确性 可选参数\n-b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.将文件打全部打包成tar包。\n1 2 3 4 5 tar -cvf test.tar test.log # 仅打包，不压缩！ tar -zcvf test.tar.gz test.log # 打包后，以 gzip 压缩 tar -zcvf test.tar.bz2 test.log # 打包后，以 bzip2 压缩 2.将 tar 包解压缩\n1 tar -zxvf test.tar.gz 21.gzip 命令 使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出\u0026quot;.gz\u0026quot;的扩展名。\n命令格式\n1 gzip [参数] [文件或者目录] 常用参数\n-a或\u0026ndash;ascii 使用ASCII文字模式。 -c或\u0026ndash;stdout或\u0026ndash;to-stdout 把压缩后的文件输出到标准输出设备，不去更动原始文件。 -d或\u0026ndash;decompress或\u0026mdash;-uncompress 解开压缩文件。 -f或\u0026ndash;force 强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -h或\u0026ndash;help 在线帮助。 使用实例\n1.把 test1 目录下的每个文件压缩成.gz 文件。\n1 gzip * 四、文件权限设置 22.chmod 命令 用于改变linux系统文件或目录的访问权限。\n命令格式\n1 chmod [-cfvR] [--help] [--version] mode file 常用参数\n必要参数\n-c 当发生改变时，报告处理信息 -f 错误信息不输出 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细处理信息 选择参数\n\u0026ndash;reference=\u0026lt;目录或者文件\u0026gt; 设置成具有指定目录或者文件具有相同的权限 \u0026ndash;version 显示版本信息 \u0026lt;权限范围\u0026gt;+\u0026lt;权限设置\u0026gt; 使权限范围内的目录或者文件具有指定的权限 \u0026lt;权限范围\u0026gt;-\u0026lt;权限设置\u0026gt; 删除权限范围的目录或者文件的指定权限 \u0026lt;权限范围\u0026gt;=\u0026lt;权限设置\u0026gt; 设置权限范围内的目录或者文件的权限为指定的值 权限范围\nu ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 权限代号\nr：读权限，用数字4表示 w：写权限，用数字2表示 x：执行权限，用数字1表示 -：删除权限，用数字0表示 使用实例\n1.增加文件所有用户组可执行权限\n1 chmod a+x test.log 删除所有用户的可执行权限\n1 chmod a-x test.log 23.chgrp 命令 可采用群组名称或群组识别码的方式改变文件或目录的所属群组。\n命令格式\n1 chgrp [选项] [组] [文件] 常用参数\n必要参数\n-c 当发生改变时输出调试信息 -f 不显示错误信息 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 \u0026ndash;dereference 作用于符号链接的指向，而不是符号链接本身 \u0026ndash;no-dereference 作用于符号链接本身 选择参数\n\u0026ndash;reference=\u0026lt;文件或者目录\u0026gt; \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.改变文件的群组属性\n1 chgrp -v bin test.log 2.改变文件test1.log 的群组属性，使得文件test1.log的群组属性和参考文件test.log的群组属性相同\n1 chgrp --reference=test.log test1.log 24.chown 命令 通过chown改变文件的拥有者和群组。\n命令格式\n1 chown [选项] [所有者] [:[组]] 文件 常用参数\n必要参数\n-c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 显示详细的处理信息 -deference 作用于符号链接的指向，而不是链接文件本身 选择参数\n\u0026ndash;reference=\u0026lt;目录或文件\u0026gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 \u0026ndash;from=\u0026lt;当前用户：当前群组\u0026gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.改变拥有者和群组\n1 chown mail:mail test.log 五、磁盘存储 25.df 命令 显示指定磁盘文件的可用空间。\n命令格式 1 df [选项] [文件] 常用参数\n必要参数\n-a 全部文件系统列表 -h 方便阅读方式显示 -H 等于\u0026rsquo;-h\u0026rsquo;，但是计算式，1K=1000，而不是1K=1024 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地文件系统 -m 区块为1048576字节 \u0026ndash;no-sync 忽略 sync 命令 -P 输出格式为POSIX \u0026ndash;sync 在取得磁盘信息前，先执行sync命令 -T 文件系统类型 选择参数\n\u0026ndash;block-size=\u0026lt;区块大小\u0026gt; 指定区块大小 -t\u0026lt;文件系统类型\u0026gt; 只显示选定文件系统的磁盘信息 -x\u0026lt;文件系统类型\u0026gt; 不显示选定文件系统的磁盘信息 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.显示指定磁盘使用情况\n1 df -t ext3 du 命令 显示每个文件和目录的磁盘使用空间。\n命令格式\n1 du [选项] [文件] 常用参数\n-a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 \u0026ndash; -c或\u0026ndash;total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或\u0026ndash;kilobytes 以KB(1024bytes)为单位输出。 -m或\u0026ndash;megabytes 以MB为单位输出。 -s或\u0026ndash;summarize 仅显示总计，只列出最后加总的值。 -h或\u0026ndash;human-readable 以K，M，G为单位，提高信息的可读性。 -x或\u0026ndash;one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L\u0026lt;符号链接\u0026gt;或\u0026ndash;dereference\u0026lt;符号链接\u0026gt; 显示选项中所指定符号链接的源文件大小。 -S或\u0026ndash;separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X\u0026lt;文件\u0026gt;或\u0026ndash;exclude-from=\u0026lt;文件\u0026gt; 在\u0026lt;文件\u0026gt;指定目录或文件。 \u0026ndash;exclude=\u0026lt;目录或文件\u0026gt; 略过指定的目录或文件。 -D或\u0026ndash;dereference-args 显示指定符号链接的源文件大小。 -H或\u0026ndash;si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或\u0026ndash;count-links 重复计算硬件链接的文件。 使用实例\n1.显示指定目录或文件所占空间\n1 2 du test # 目录 du test.log # 文件 六、性能监控和优化命令 27.top 命令 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等。\n命令格式\n1 top [参数] 常见参数\n-b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i\u0026lt;时间\u0026gt; 设置间隔时间 -u\u0026lt;用户名\u0026gt; 指定用户名 -p\u0026lt;进程号\u0026gt; 指定进程 -n\u0026lt;次数\u0026gt; 循环显示的次数 使用实例\n显示进程信息\n1 top 28.free 命令 显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。\n命令格式\n1 free [参数] 常见参数\n-b 以Byte为单位显示内存使用情况 -k 以KB为单位显示内存使用情况 -m 以MB为单位显示内存使用情况 -g 以GB为单位显示内存使用情况 -o 不显示缓冲区调节列 -s \u0026lt;间隔秒数\u0026gt; 持续观察内存使用状况 -t 显示内存总和列。 -V 显示版本信息。 使用实例\n1.显示内存情况。\n1 2 3 free free -g #以GB为单位 free -m #以MB为单位 29.vmstat 用来显示虚拟内存的信息。\n命令格式\n1 2 3 4 5 6 7 vmstat [-a] [-n] [-S unit] [delay [ count]] vmstat [-s] [-n] [-S unit] vmstat [-m] [-n] [delay [ count]] vmstat [-d] [-n] [delay [ count]] vmstat [-p disk partition] [-n] [delay [ count]] vmstat [-f] vmstat [-V] 常见参数\n-a：显示活跃和非活跃内存 -f：显示从系统启动至今的fork数量 -m：显示slabinfo -n：只在开始时显示一次各字段名称 -s：显示内存相关统计信息及多种系统活动数量 delay：刷新时间间隔。如果不指定，只显示一条结果 count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷 -d：显示磁盘相关统计信息 -p：显示指定磁盘分区统计信息 -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） 使用实例\n1.显示活跃和非活跃内存。\n1 vmstat -a 5 5 # 5秒时间内进行5次采样 30.lostat 命令 通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况, 负载信息。\n命令格式\n1 iostat [参数] [时间] [次数] 常见参数\n-C 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 使用实例\n1.定时显示所有信息。\n1 iostat 2 3 #每隔 2秒刷新显示，且显示3次 31.lsof 命令 用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。\n命令格式\n1 lsof [参数] [文件] 常见参数\n-a 列出打开文件存在的进程 -c\u0026lt;进程名\u0026gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d\u0026lt;文件号\u0026gt; 列出占用该文件号的进程 +d\u0026lt;目录\u0026gt; 列出目录下被打开的文件 +D\u0026lt;目录\u0026gt; 递归列出目录下被打开的文件 -n\u0026lt;目录\u0026gt; 列出使用NFS的文件 -i\u0026lt;条件\u0026gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p\u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 使用实例\n1.查看谁正在使用bash文件，也就是说查找某个文件相关的进程。\n1 lsof /bin/bash 七、网络命令 32.ifconfig 命令 ifconfig 命令用来查看和配置网络设备。\n命令格式\n1 ifconfig [网络设备] [参数] 常见参数\nup 启动指定网络设备/网卡 down 关闭指定网络设备/网卡。 arp 设置指定网卡是否支持ARP协议 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 使用实例\n1.启动关闭指定网卡\n1 2 ifconfig eth0 up ifconfig eth0 down 2.用ifconfig修改MAC地址\n1 ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE 33.route 命令 Route命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。\n命令格式\n1 route [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]] 常见参数\n-c 显示更多信息 -n 不解析名字 -v 显示详细的处理信息 -F 显示发送信息 -C 显示路由缓存 -f 清除所有网关入口的路由表。 -p 与 add 命令一起使用时使路由具有永久性。 add:添加一条新路由。 del:删除一条路由。 -net:目标地址是一个网络。 -host:目标地址是一个主机。 netmask:当添加一个网络路由时，需要使用网络掩码。 gw:路由数据包通过网关。注意，你指定的网关必须能够达到。 metric：设置路由跳数。 Command 指定您想运行的命令 (Add/Change/Delete/Print)。 Destination 指定该路由的网络目标。 使用实例\n1.显示当前路由\n1 2 route route -n 2.添加网关/设置网关\n1 route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 ping 命令 确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。\n命令格式\n1 ping [参数] [主机名或IP地址] 常见参数\n-d 使用Socket的SO_DEBUG功能 -f 极限检测。大量且快速地送网络封包给一台机器，看它的回应 -n 只输出数值 -q 不显示任何传送封包的信息，只显示最后的结果 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题 -R 记录路由过程 -v 详细显示指令的执行过程 -c 数目：在发送指定数目的包后停止 -i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次 -I 网络界面：使用指定的网络界面送出数据包 -l 前置载入：设置在送出要求信息之前，先行发出的数据包 -p 范本样式：设置填满数据包的范本样式 -s 字节数：指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节 -t 存活数值：设置存活数值TTL的大小 使用实例\nping 网关\n1 ping -b 192.168.120.1 35.traceroute 命令\n让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。\n命令格式\n1 traceroute [参数] [主机] 常见参数\n-d 使用Socket层级的排错功能 -f 设置第一个检测数据包的存活数值TTL的大小 -F 设置勿离断位 -g 设置来源路由网关，最多可设置8个 -i 使用指定的网络界面送出数据包 -I 使用ICMP回应取代UDP资料信息 -m 设置检测数据包的最大存活数值TTL的大小 -n 直接使用IP地址而非主机名称 -p 设置UDP传输协议的通信端口 -r 忽略普通的Routing Table，直接将数据包送到远端主机上 -s 设置本地主机送出数据包的IP地址 -t 设置检测数据包的TOS数值 -v 详细显示指令的执行过程 -w 设置等待远端主机回报的时间 -x 开启或关闭数据包的正确性检验 使用实例\n1.traceroute 用法简单、最常用的用法\n1 traceroute www.baidu.com 跳数设置\n1 traceroute -m 10 www.baidu.com 36.netstat 命令 用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。\n命令格式\n1 netstat [-acCeFghilMnNoprstuvVwx] [-A\u0026lt;网络类型\u0026gt;] [--ip] 常见参数\n-a或-all 显示所有连线中的Socket -A\u0026lt;网络类型\u0026gt;或-\u0026lt;网络类型\u0026gt; 列出该网络类型连线中的相关地址 -c或-continuous 持续列出网络状态 -C或-cache 显示路由器配置的快取信息 -e或-extend 显示网络其他相关信息 -F或-fib 显示FIB -g或-groups 显示多重广播功能群组组员名单 -h或-help 在线帮助 -i或-interfaces 显示网络界面信息表单 -l或-listening 显示监控中的服务器的Socket -M或-masquerade 显示伪装的网络连线 -n或-numeric 直接使用IP地址，而不通过域名服务器 -N或-netlink或-symbolic 显示网络硬件外围设备的符号连接名称 -o或-timers 显示计时器 -p或-programs 显示正在使用Socket的程序识别码和程序名称 -r或-route 显示Routing Table -s或-statistice 显示网络工作信息统计表 -t或-tcp 显示TCP传输协议的连线状况 -u或-udp 显示UDP传输协议的连线状况 -v或-verbose 显示指令执行过程 -V或-version 显示版本信息 -w或-raw 显示RAW传输协议的连线状况 -x或-unix 此参数的效果和指定\u0026quot;-A unix\u0026quot;参数相同 -ip或-inet 此参数的效果和指定\u0026quot;-A inet\u0026quot;参数相同 使用实例\n列出所有端口\n1 netstat -a 37.telnet 命令 执行telnet指令开启终端机阶段作业，并登入远端主机。\n命令格式\n1 telnet [参数] [主机] 常见参数\n-8 允许使用8位字符资料，包括输入与输出 -a 尝试自动登入远端系统 -b\u0026lt;主机别名\u0026gt; 使用别名指定远端主机名称 -c 不读取用户专属目录里的.telnetrc文件 -d 启动排错模式 -e\u0026lt;脱离字符\u0026gt; 设置脱离字符 -E 滤除脱离字符 -f 此参数的效果和指定\u0026quot;-F\u0026quot;参数相同 使用实例\n1.远程服务器无法访问\n1 telnet 192.168.120.206 八、其他命令 38.ln 命令 为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。\n命令格式\n1 ln [参数] [源文件或目录] [目标文件或目录] 常用参数\n必要参数\n-b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 选择参数\n-S -S\u0026lt;字尾备份字符串\u0026gt; 或 --suffix=\u0026lt;字尾备份字符串\u0026gt; -V -V\u0026lt;备份方式\u0026gt; 或 --version-control=\u0026lt;备份方式\u0026gt;\n使用实例\n1.为 test.log文件创建软链接linktest\n1 ln -s test.log linktest 2.为 test.log创建硬链接lntest。\n1 ln test.log lntest 39.diff 命令 比较单个文件或者目录内容。\n命令格式\n1 diff [参数] [文件1或目录1] [文件2或目录2] 常用参数\n-c 上下文模式，显示全部内文，并标出不同之处 -u 统一模式，以合并的方式来显示文件内容的不同 -a 只会逐行比较文本文件 -N 在比较目录时，若文件 A 仅出现在某个目录中，预设会显示：Only in 目录。若使用 -N 参数，则 diff 会将文件 A 与一个空白的文件比较 -r 递归比较目录下的文件 使用实例\n1.显示 test1.txt 和 test2.txt 两个文件差异。\n1 diff test1.txt test2.txt 40.grep 命令 一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。\n命令格式\n1 grep [option] pattern file 常用参数\n-c 计算找到\u0026rsquo;搜寻字符串\u0026rsquo;（即 pattern）的次数 -i 忽略大小写的不同，所以大小写视为相同 -n 输出行号 -v 反向选择，打印不匹配的行 -r 递归搜索 \u0026ndash;color=auto 将找到的关键词部分加上颜色显示 使用实例\n1.将 /etc/passwd 文件中出现 root 的行取出来，关键词部分加上颜色显示。\n1 2 grep \u0026#34;root\u0026#34; /etc/passwd --color=auto cat /etc/passwd | grep \u0026#34;root\u0026#34; --color=auto 2.将 /etc/passwd 文件中没有出现 root 和 nologin 的行取出来。\n1 grep -v \u0026#34;root\u0026#34; /etc/passwd | grep -v \u0026#34;nologin\u0026#34; 41.wc 命令 用来显示文件所包含的行、字和字节数。\n命令格式\n1 wc [选项] [文件] 常用参数\n-c 统计字节数 -l 统计行数 -m 统计字符数，这个标志不能与 -c 标志一起使用 -w 统计字数，一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度 使用实例\n1.统计文件的字节数、行数和字符数。\n1 2 3 wc -c test.txt wc -l test.txt wc -m test.txt 2.统计文件的字节数、行数和字符数，只打印数字，不打印文件名。\n1 2 3 cat test.txt | wc -c cat test.txt | wc -l cat test.txt | wc -m 42.ps 命令 用来显示当前进程的状态。\n命令格式\n1 ps[参数] 常用参数\na 显示所有进程 -a 显示同一终端下的所有程序 -A 显示所有进程 c 显示进程的真实名称 -N 反向选择 -e 等于-A e 显示环境变量 f 显示程序间的关系 -H 显示树状结构 r 显示当前终端的进程 T 显示当前终端的所有程序 u 指定用户的所有进程 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -C\u0026lt;命令\u0026gt; 列出指定命令的状况 \u0026ndash;lines\u0026lt;行数\u0026gt; 每页显示的行数 \u0026ndash;width\u0026lt;字符数\u0026gt; 每页显示的字符数 使用实例\n1.显示所有进程信息。\n1 ps -A 显示指定用户信息。\n1 ps -u root 显示所有进程信息，连同命令行。\n1 ps -ef 43.watch 命令\n可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令。\n命令格式\n1 watch [参数] [命令] 常用参数\n-n或\u0026ndash;interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d或\u0026ndash;differences 用-d或\u0026ndash;differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 -h, \u0026ndash;help 查看帮助文档 使用实例\n1.每隔一秒高亮显示网络链接数的变化情况\n1 watch -n 1 -d netstat -ant 2.每隔一秒高亮显示http链接数的变化情况\n1 watch -n 1 -d \u0026#39;pstree|grep http\u0026#39; 44.at 命令 在一个指定的时间执行一个指定任务，只能执行一次。（需开启atd进程）\n命令格式\n1 at [参数] [时间] 常用参数\n-m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出 -I atq的别名 -d atrm的别名 -v 显示任务将被执行的时间 -c 打印任务的内容到标准输出 -V 显示版本信息 -q\u0026lt;列队\u0026gt; 使用指定的列队 -f\u0026lt;文件\u0026gt; 从指定文件读入任务而不是从标准输入读入 -t\u0026lt;时间参数\u0026gt; 以时间参数的形式提交要运行的任务 使用实例\n1.3天后的下午5点执行/bin/ls\n1 2 3 at 5pm+3 days at\u0026gt; /bin/ls at\u0026gt; \u0026lt;EOT\u0026gt; 45.crontab 命令 在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。(需开启crond服务)\n命令格式\n1 2 crontab [-u user] file 或 crontab [-u user] [ -e | -l | -r ] 常用参数\n-u user：用来设定某个用户的crontab服务，例如，-u ixdba表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。 file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i：在删除用户的crontab文件时给确认提示。 使用实例\n1.列出 crontab 文件。\n1 crontab -l 2.编辑crontab 文件。\n1 crontab -e Crontab 任务实例\n1.每1分钟执行一次command\n1 * * * * * command 2.每小时的第3和第15分钟执行\n1 3,15 * * * * command 3.在上午8点到11点的第3和第15分钟执行\n1 3,15 8-11 * * * command ","permalink":"https://WFUing.github.io/posts/tech/os/linux-instructions/","summary":"Linux 的命令确实非常多，然而熟悉 Linux 的人从来不会因为 Linux 的命令太多而烦恼。因为我们仅仅只需要掌握常用命令，就完全可以驾驭 Linux。\n接下来，让我们一起来看看都有那些常用的 Linux 命令吧！\n一、文件目录操作 1.ls 命令 ls 命令不仅可以查看 linux 文件夹包含的文件而且可以查看文件权限（包括目录、文件夹、文件权限）查看目录信息等等。\n命令格式\n1 ls [选项][目录名] 常用参数\n-l ：列出长数据串，包含文件的属性与权限数据等 -a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用） -d ：仅列出目录本身，而不是列出目录的文件数据 -h ：将文件容量以较易读的方式（GB，kB等）列出来 -R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来 使用实例\n1.列出 home 目录下的所有文件和目录的详细资料。\n1 2 ls -a -l /home ls -al /home 2.列出当前目录下所有以\u0026quot;d\u0026quot;开头的文件目录详情内容。\n1 ls -l d* 2.cd命令 最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。用于切换当前目录至dirName。\n命令格式\n1 cd [目录名] 操作案例\n1.从当前目录进入系统根目录。\n1 cd / 2.跳转到 home/Code 目录。\n1 cd /home/Code 3.pwd 命令 查看\u0026quot;当前工作目录\u0026quot;的完整路径。","title":"45 个常用Linux 命令，让你轻松玩转Linux！"},{"content":"Six strategies for getting better results Write clear instructions GPT 无法读懂你的心思。如果产出太长，请要求简短回复。如果结果太简单，要求专家级的写作。如果您不喜欢格式，请演示您希望看到的格式。GPT 越少需要猜测你想要什么，你就越有可能得到它。\n在您的询问中包含详细信息，以获得更多相关答案：为了得到高度相关的回复，请确保请求提供了任何重要的细节或上下文。否则，您就只能让模型来猜测您的意思了。 要求模特采用一个角色：系统信息可用于指定模型在回复中使用的角色。 使用分隔符清楚标明输入内容的不同部分：三引号、XML 标记、章节标题等分隔符可以帮助划分需要区别对待的文本部分。 指定完成任务所需的步骤：有些任务最好以一连串的步骤来指定。明确写出这些步骤可以让模型更容易地遵循它们。 举例说明：提供适用于所有示例的一般说明通常比通过示例演示任务的所有排列组合更有效，但在某些情况下，提供示例可能更容易。例如，如果您打算让模型复制一种难以明确描述的回应用户询问的特定风格，这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。 指定所需的输出长度：您可以要求模型生成具有给定目标长度的输出。可以用字数、句数、段落数、要点数等来指定目标输出长度。但请注意，指示模型生成特定字数的精确度并不高。模型可以更可靠地生成具有特定段落数或要点数的输出结果。 Provide reference text GPT 可以自信地编造虚假答案，尤其是在被问及深奥的话题或引用和 URL 时。就像一张笔记能帮助学生在考试中取得更好的成绩一样，为 GPT 提供参考文本也能帮助他们在作答时减少无中生有的情况。\n指导模型使用参考文本作答：如果我们能为模型提供与当前查询相关的可信信息，那么我们就可以指示模型使用所提供的信息来撰写答案。 指导范例引用参考文献回答问题：如果输入内容中已经补充了相关知识，那么就可以直接要求模型通过引用所提供文档中的段落来为其答案添加引文。请注意，输出中的引用可以通过所提供文档中的字符串匹配进行编程验证。 Split complex tasks into simpler subtasks 在软件工程中，将一个复杂的系统分解成一系列模块化组件是一种很好的做法，提交给 GPT 的任务也是如此。复杂任务的错误率往往高于简单任务。此外，复杂任务通常可以重新定义为较简单任务的工作流程，其中前期任务的输出被用于构建后期任务的输入。\n使用意图分类来确定与用户查询最相关的指令：对于需要大量独立指令集来处理不同情况的任务，首先对查询类型进行分类，并利用该分类来确定需要哪些指令，可能会有所帮助。这可以通过定义固定类别和硬编码与处理特定类别任务相关的指令来实现。这一过程也可以递归应用，将任务分解为一系列阶段。这种方法的优势在于，每次查询只包含执行任务下一阶段所需的指令，与使用单次查询执行整个任务相比，错误率更低。这还可以降低成本，因为运行较大的提示需要花费更多的成本。 对于需要冗长对话的对话应用程序，总结或过滤之前的对话：由于 GPT 的上下文长度是固定的，因此用户和助手之间的对话（整个对话都包含在上下文窗口中）不可能无限期地进行下去。解决这个问题有多种变通方法，其中之一就是总结对话中的前几轮对话。一旦输入的大小达到预定的阈值长度，就会触发一个对部分对话进行总结的查询，而之前对话的总结可以作为系统消息的一部分。或者，也可以在整个对话过程中在后台异步总结之前的对话。 对长文档进行分块摘要，并递归构建完整摘要：由于 GPT 有固定的上下文长度，因此在单次查询中，GPT 无法用于摘要长度超过上下文长度减去生成摘要长度的文本。 Give GPTs time to \u0026ldquo;think\u0026rdquo; 如果要求你用 17 乘以 28，你可能不会马上知道，但花点时间还是能算出来的。同样，GPT 学生在试图立即回答而不是花时间推理出答案时，会犯更多的推理错误。在回答问题之前，要求学生进行一连串的推理，可以帮助 GPT 学生更可靠地推理出正确答案。\n在匆忙得出结论之前，指示模型自己找出解决方案：如果我们明确指示模型在得出结论之前先从第一性原理进行推理，会得到更好的结果。例如，假设我们想要一个模型来评估学生对数学问题的解答。最明显的方法是简单地问模型学生的解法是否正确。 使用内心独白或一系列查询来隐藏模型的推理过程：前面的策略表明，在回答具体问题之前，模型有时必须对问题进行详细推理。对于某些应用，模型得出最终答案的推理过程不宜与用户共享。例如，在辅导应用中，我们可能希望鼓励学生自己找出答案，但模型对学生解决方案的推理过程可能会向学生透露答案。内心独白是一种可以用来缓解这种情况的策略。内心独白的原理是指示模型将输出结果中不对用户公开的部分转化为结构化格式，以便于解析。然后，在向用户展示输出结果之前，先对输出结果进行解析，只让部分输出结果可见。 Use external tools 向 GPT 提供其他工具的输出结果，弥补 GPT 的不足。例如，文本检索系统可以告诉 GPT 相关文档的信息。代码执行引擎可以帮助 GPT 进行数学运算和运行代码。如果某项任务可以通过工具而不是 GPT 更可靠或更高效地完成，那么就将其卸载，以获得两者的最佳效果。\n利用嵌入式搜索实现高效知识检索：如果将外部信息源作为输入的一部分，模型可以利用外部信息源。这可以帮助模型生成更多信息和最新回复。例如，如果用户询问有关特定电影的问题，那么在模型输入中添加有关电影的高质量信息（如演员、导演等\u0026hellip;\u0026hellip;）可能会很有用。嵌入可用于实现高效的知识检索，以便在运行时将相关信息动态添加到模型输入中。文本嵌入是一个可以衡量文本字符串之间相关性的向量。相似或相关的字符串会比不相关的字符串靠得更近。这一事实以及快速向量搜索算法的存在，意味着嵌入可以用来实现高效的知识检索。特别是，文本语料库可以分割成若干块，每个块都可以嵌入和存储。然后，可以嵌入给定的查询，并执行矢量搜索，从语料库中找到与查询最相关的嵌入文本块（即在嵌入空间中最接近的文本块）。 使用代码执行来执行更精确的计算或调用外部应用程序接口：不能依靠 GPT 自行准确执行算术运算或长时间计算。在需要的情况下，可以指示模型编写和运行代码，而不是自己进行计算。特别是，可以指示模型将需要运行的代码放入指定格式（如三重回溯）中。产生输出后，可提取并运行代码。最后，如有必要，可将代码执行引擎（即 Python 解释器）的输出作为下一次查询的模型输入。 让模型访问特定功能：聊天完成 API 允许在请求中传递函数描述列表。这样，模型就能根据提供的模式生成函数参数。生成的函数参数由 API 以 JSON 格式返回，可用于执行函数调用。然后，函数调用提供的输出可以在下一个请求中反馈到模型中，以结束循环。这是使用 GPT 模型调用外部函数的推荐方式。 Test changes systematically 如果能对性能进行测量，提高性能就会变得更容易。在某些情况下，对提示符的修改会在一些孤立的示例上取得更好的性能，但在更具代表性的示例集上却会导致整体性能下降。因此，为了确保修改对性能的净积极影响，可能有必要定义一个综合测试套件（也称为 \u0026ldquo;评估\u0026rdquo;）。\nResources https://platform.openai.com/docs/guides/gpt-best-practices https://github.com/mattnigh/ChatGPT3-Free-Prompt-List https://style.mla.org/citing-generative-ai/ ","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/chatgpt-guide/","summary":"Six strategies for getting better results Write clear instructions GPT 无法读懂你的心思。如果产出太长，请要求简短回复。如果结果太简单，要求专家级的写作。如果您不喜欢格式，请演示您希望看到的格式。GPT 越少需要猜测你想要什么，你就越有可能得到它。\n在您的询问中包含详细信息，以获得更多相关答案：为了得到高度相关的回复，请确保请求提供了任何重要的细节或上下文。否则，您就只能让模型来猜测您的意思了。 要求模特采用一个角色：系统信息可用于指定模型在回复中使用的角色。 使用分隔符清楚标明输入内容的不同部分：三引号、XML 标记、章节标题等分隔符可以帮助划分需要区别对待的文本部分。 指定完成任务所需的步骤：有些任务最好以一连串的步骤来指定。明确写出这些步骤可以让模型更容易地遵循它们。 举例说明：提供适用于所有示例的一般说明通常比通过示例演示任务的所有排列组合更有效，但在某些情况下，提供示例可能更容易。例如，如果您打算让模型复制一种难以明确描述的回应用户询问的特定风格，这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。 指定所需的输出长度：您可以要求模型生成具有给定目标长度的输出。可以用字数、句数、段落数、要点数等来指定目标输出长度。但请注意，指示模型生成特定字数的精确度并不高。模型可以更可靠地生成具有特定段落数或要点数的输出结果。 Provide reference text GPT 可以自信地编造虚假答案，尤其是在被问及深奥的话题或引用和 URL 时。就像一张笔记能帮助学生在考试中取得更好的成绩一样，为 GPT 提供参考文本也能帮助他们在作答时减少无中生有的情况。\n指导模型使用参考文本作答：如果我们能为模型提供与当前查询相关的可信信息，那么我们就可以指示模型使用所提供的信息来撰写答案。 指导范例引用参考文献回答问题：如果输入内容中已经补充了相关知识，那么就可以直接要求模型通过引用所提供文档中的段落来为其答案添加引文。请注意，输出中的引用可以通过所提供文档中的字符串匹配进行编程验证。 Split complex tasks into simpler subtasks 在软件工程中，将一个复杂的系统分解成一系列模块化组件是一种很好的做法，提交给 GPT 的任务也是如此。复杂任务的错误率往往高于简单任务。此外，复杂任务通常可以重新定义为较简单任务的工作流程，其中前期任务的输出被用于构建后期任务的输入。\n使用意图分类来确定与用户查询最相关的指令：对于需要大量独立指令集来处理不同情况的任务，首先对查询类型进行分类，并利用该分类来确定需要哪些指令，可能会有所帮助。这可以通过定义固定类别和硬编码与处理特定类别任务相关的指令来实现。这一过程也可以递归应用，将任务分解为一系列阶段。这种方法的优势在于，每次查询只包含执行任务下一阶段所需的指令，与使用单次查询执行整个任务相比，错误率更低。这还可以降低成本，因为运行较大的提示需要花费更多的成本。 对于需要冗长对话的对话应用程序，总结或过滤之前的对话：由于 GPT 的上下文长度是固定的，因此用户和助手之间的对话（整个对话都包含在上下文窗口中）不可能无限期地进行下去。解决这个问题有多种变通方法，其中之一就是总结对话中的前几轮对话。一旦输入的大小达到预定的阈值长度，就会触发一个对部分对话进行总结的查询，而之前对话的总结可以作为系统消息的一部分。或者，也可以在整个对话过程中在后台异步总结之前的对话。 对长文档进行分块摘要，并递归构建完整摘要：由于 GPT 有固定的上下文长度，因此在单次查询中，GPT 无法用于摘要长度超过上下文长度减去生成摘要长度的文本。 Give GPTs time to \u0026ldquo;think\u0026rdquo; 如果要求你用 17 乘以 28，你可能不会马上知道，但花点时间还是能算出来的。同样，GPT 学生在试图立即回答而不是花时间推理出答案时，会犯更多的推理错误。在回答问题之前，要求学生进行一连串的推理，可以帮助 GPT 学生更可靠地推理出正确答案。\n在匆忙得出结论之前，指示模型自己找出解决方案：如果我们明确指示模型在得出结论之前先从第一性原理进行推理，会得到更好的结果。例如，假设我们想要一个模型来评估学生对数学问题的解答。最明显的方法是简单地问模型学生的解法是否正确。 使用内心独白或一系列查询来隐藏模型的推理过程：前面的策略表明，在回答具体问题之前，模型有时必须对问题进行详细推理。对于某些应用，模型得出最终答案的推理过程不宜与用户共享。例如，在辅导应用中，我们可能希望鼓励学生自己找出答案，但模型对学生解决方案的推理过程可能会向学生透露答案。内心独白是一种可以用来缓解这种情况的策略。内心独白的原理是指示模型将输出结果中不对用户公开的部分转化为结构化格式，以便于解析。然后，在向用户展示输出结果之前，先对输出结果进行解析，只让部分输出结果可见。 Use external tools 向 GPT 提供其他工具的输出结果，弥补 GPT 的不足。例如，文本检索系统可以告诉 GPT 相关文档的信息。代码执行引擎可以帮助 GPT 进行数学运算和运行代码。如果某项任务可以通过工具而不是 GPT 更可靠或更高效地完成，那么就将其卸载，以获得两者的最佳效果。","title":"chatGPT 使用指南"},{"content":"Resources github：https://github.com/fatedier/frp document：https://gofrp.org/docs/ finalshell：https://sourceforge.net/projects/finalshell/ vscode remote ssh：https://code.visualstudio.com/docs/remote/ssh 下面给出一些blog，都详细写了如何使用frp搭建内网穿透，在本文中就不再赘述。\n使用frp进行内网穿透：https://sspai.com/post/52523 基于frp docker 进行内网穿透：https://izhaong.com/pages/b387de/ CentOS7下通过frp做内网穿透：https://blog.fengdis.com/2019/12/25/CentOS%E4%B8%8B%E9%80%9A%E8%BF%87frp%E5%81%9A%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/ 这一篇blog的05节写了遇到的常见问题，这也是本文关心的。\n常见问题：https://www.derrors.cn/index.php/it-tech/frp.html Questions 大部分都是网络端口上的问题，下面先给出一张frp的原理图。\nssh: connect to host xx.xx.xx.xx port xx: Operation timed out\n使用ssh连接时，连接超时 原因：服务器防火墙未开放frp配置中对应的remote_port端口； 解决：在服务器的防火墙中开放相应端口。 ssh: connect to host xx.xx.xx.xx port xx: Connection refused\n连接被拒绝 原因：服务器防火墙未开放frp配置中对应的server_port端口； 解决：在服务器的防火墙中开放相应端口。 当然云服务器端，也会有安全组或者防火墙，需要把相应的都开起来\n1 2 3 4 5 6 7 8 9 #开放端口 firewall-cmd --zone=public --add-port=7000/tcp --permanent firewall-cmd --zone=public --add-port=6000/tcp --permanent #查看开放端口列表 firewall-cmd --permanent --zone=public --list-ports #防火墙reload firewall-cmd --reload firewalld 拓展 这边很多的问题都跟防火墙有关系，这边给出 firewalld 的相关指令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 source: 根据源地址过滤（优先级最高） interface: 根据网卡过滤（优先级次高） service: 根据服务名过滤 port: 根据端口过滤 icmp-block: icmp 报文过滤，按照 icmp 类型配置 masquerade: ip 地址伪装 forward-port: 端口转发 rule: 自定义规则 # 查看是否开启 systemctl status firewalld.service # 打开防火墙 systemctl start firewalld.service # 停用防火墙 systemctl disable firewalld # 禁用防火墙 systemctl stop firewalld.service # 开机启动 systemctl enable firewalld # 取消开机启动 systemctl disable firewalld # 查看运行状态 firewall-cmd --state # 查看接口信息 firewall-cmd --list-all # 更新防火墙规则方法1:无需断开连接，动态更改规则 firewall-cmd --reload # 更新防火墙规则方法2:断开连接，以重启的方式更改规则 firewall-cmd --complete-reload # 查看帮助 firewall-cmd --help --zone=NAME # 指定 Zone --permanent # 为永久生效 --timeout=seconds # 持续一段时间，到期后自动移除，经常用于调试，且不能与 --permanent 同时使用 # 追加一个8181端口，永久有效 firewall-cmd --add-port=8181/tcp --permanent # 追加一段端口范围 firewall-cmd --add-port=6000-6600/tcp # 开放 ftp 服务 firewall-cmd --add-service=ftp # 添加eth0 接口至 public 信任等级，永久有效 firewall-cmd --zone=public --add-interface=eth0 --permanent # 关闭防火墙 sudo systemctl stop firewalld # 关闭端口 sudo firewall-cmd --remove-port=3000/tcp --permanent # 配置 public zone 的端口转发 firewall-cmd --zone=public --add-masquerade # 然后转发 tcp 22 端口至 9527 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=9527 # 转发 22 端口数据至另一个 ip 的相同端口上 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toaddr=192.168.1.123 # 转发 22 端口数据至另一 ip 的 9527 端口上 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=9527:toaddr=192.168.1.100 # IP 封禁 firewall-cmd --permanent --add-rich-rule=\u0026#34;rule family=\u0026#39;ipv4\u0026#39; source address=\u0026#39;192.168.1.123\u0026#39; reject\u0026#34; # 通过 ipset 来封禁 ip firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:ip firewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=192.168.1.123 # 封禁网段 firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:net firewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=192.168.1.0/24 # 倒入 ipset 规则 blacklist，然后封禁 blacklist firewall-cmd --permanent --zone=public --new-ipset-from-file=/path/blacklist.xml firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#39;rule source ipset=blacklist drop\u0026#39; ","permalink":"https://WFUing.github.io/posts/tech/network/frp-nat-traversal/","summary":"Resources github：https://github.com/fatedier/frp document：https://gofrp.org/docs/ finalshell：https://sourceforge.net/projects/finalshell/ vscode remote ssh：https://code.visualstudio.com/docs/remote/ssh 下面给出一些blog，都详细写了如何使用frp搭建内网穿透，在本文中就不再赘述。\n使用frp进行内网穿透：https://sspai.com/post/52523 基于frp docker 进行内网穿透：https://izhaong.com/pages/b387de/ CentOS7下通过frp做内网穿透：https://blog.fengdis.com/2019/12/25/CentOS%E4%B8%8B%E9%80%9A%E8%BF%87frp%E5%81%9A%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/ 这一篇blog的05节写了遇到的常见问题，这也是本文关心的。\n常见问题：https://www.derrors.cn/index.php/it-tech/frp.html Questions 大部分都是网络端口上的问题，下面先给出一张frp的原理图。\nssh: connect to host xx.xx.xx.xx port xx: Operation timed out\n使用ssh连接时，连接超时 原因：服务器防火墙未开放frp配置中对应的remote_port端口； 解决：在服务器的防火墙中开放相应端口。 ssh: connect to host xx.xx.xx.xx port xx: Connection refused\n连接被拒绝 原因：服务器防火墙未开放frp配置中对应的server_port端口； 解决：在服务器的防火墙中开放相应端口。 当然云服务器端，也会有安全组或者防火墙，需要把相应的都开起来\n1 2 3 4 5 6 7 8 9 #开放端口 firewall-cmd --zone=public --add-port=7000/tcp --permanent firewall-cmd --zone=public --add-port=6000/tcp --permanent #查看开放端口列表 firewall-cmd --permanent --zone=public --list-ports #防火墙reload firewall-cmd --reload firewalld 拓展 这边很多的问题都跟防火墙有关系，这边给出 firewalld 的相关指令。","title":"Frp Nat Traversal"},{"content":"Resources url: https://www.telosys.org/ tutorial: https://tomassetti.me/telosys-code-generation-tool/ ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/telosys-code-generation-tool/","summary":"Resources url: https://www.telosys.org/ tutorial: https://tomassetti.me/telosys-code-generation-tool/ ","title":"Telosys: a Code Generation Tool by Laurent Guerin"},{"content":"一、书名和作者 书名：《人月神话》 作者：布鲁克斯(FrederickP.Brooks.Jr.) 二、书籍概览 主要论点和结构 《人月神话》是一本旨在深入探讨软件工程中的管理和工程问题的经典著作。本书强调了软件开发过程中的复杂性和挑战，尤其是在大规模项目中。书中还探讨了许多经典观点，如\u0026quot;人月神话\u0026quot;、\u0026ldquo;二八定律\u0026quot;和\u0026quot;沟通成本\u0026rdquo;，为软件行业的专业人员提供了宝贵的见解和管理原则，使他们能够更好地理解和应对软件项目的挑战。\n目标读者和应用场景 该书的目标读者包括软件工程师、项目经理、团队领导和决策者，以及任何对软件开发过程感兴趣的人。对于软件开发工程师来说，这本书提供了宝贵的洞察，帮助他们更好地理解项目管理和团队协作的挑战；对于项目经理来说，本书提供了管理大型软件项目所需的关键原则和策略；领导小型或大型软件团队的人员可以从本书中获得关于如何优化团队协作、提高效率和管理项目的方法；即使不是专业人员，任何对软件开发过程感兴趣的人都可以从本书中获得对软件工程领域的深入了解，从而更好地理解和评估不同软件项目。总的来说，《人月神话》适用于各种软件项目，无论是大规模的企业级项目还是小规模的个人项目。\n三、核心观点与主题 1. 人月神话\n人月神话的产生 《人月神话》的核心观点之一是关于\u0026quot;人月神话\u0026quot;本身的产生。这一概念源自于普遍存在的一种误解，即认为增加项目开发的人员数量会自动缩短项目完成时间。作者布鲁克斯解释了这种误解的根源，即对软件工程的特殊性和复杂性的不理解。这种误解在早期的计算机领域中非常普遍，导致了一些项目的失败和项目时间的延长。\n后果和启发 项目增加人员后出现的管理问题和沟通成本的急剧上升，最后导致了项目的失败，包括延期、成本超支和低质量交付等。这些后果为软件开发的实践带来了极大的挑战，但也激发了对更好方法的追求。软件工程领域需要更多的规划、需求管理和团队协作，以避免人员增加引发的问题。\n实例或案例 一个鲜明的案例是IBM的OS/360项目，该项目是为了开发一种崭新的操作系统。初期，这个项目规模宏大，聚集了大量人员资源，充满了雄心壮志，然而，很快就陷入了严重的延期和质量问题的泥淖。在这个项目中，管理层采取了一种常见的措施，即试图通过增加项目开发的人员数量来加快进度。然而，结果却截然不同于期望。\n2. 二八定律\n二八定律的阐述 本书的第二个重要主题是\u0026quot;二八定律\u0026quot;，它强调了在软件开发中常见的现象，即80%的工作通常需要80%的时间，而剩下的20%工作同样需要80%的时间。这一定律揭示了工作任务的不均衡性，以及为什么某些部分的工作似乎总是比预期需要更多的时间。作者详细探讨了这一定律的背后原因，以及它在软件工程中的应用。\n重要任务的优先性 项目中的关键任务和非关键任务应当被明智地区分开来。关键任务往往占据大部分时间和资源，因此它们的规划和执行至关重要。这个观点呼吁项目管理者和团队要明智地设置优先级，确保关键任务首先得到充分关注，以确保项目能够按计划顺利进行。\n实例或案例 一个生动的例子是在软件开发项目中的功能开发和测试。根据二八定律，80%的开发工作可能会占用80%的时间，但剩下的20%的时间可能都被用于测试和调试。这种情况表明，关键任务（测试）常常被放在项目的后期，从而导致项目延期和问题的累积。通过理解这一现象，团队可以更好地规划项目，提前考虑到测试和质量保证，从而避免在后期因紧急问题而忙乱无序。这个案例强调了二八定律的实际应用，以提高项目的效率和成功率。\n3. 沟通成本\n沟通成本的重要性 这本书的第三个主题关注了\u0026quot;沟通成本\u0026quot;的概念。沟通在软件开发项目中是至关重要的，因为团队成员需要共同合作、协调工作和共享信息。然而，随着团队规模的增大，沟通的复杂性也随之增加。所以为了有效地合作，必须投入时间和精力来解决沟通问题。\n沟通成本的增加 随着团队规模的增加，沟通成本的急剧上升。当团队规模庞大时，需要花更多的时间来协调、汇报和共享信息。这不仅仅是人员增加导致的问题，还包括了更多的管理层次、更多的会议和文档。这会消耗时间和资源，导致项目时间表的延迟。\n实例或案例 在大型软件开发项目中，特别是在跨地理位置分布的全球团队中，沟通成本的急剧上升。团队成员分布在不同的时区，可能使用不同的语言和文化，这会增加沟通的困难。管理层必须花更多的时间来协调跨团队合作，编写文档以确保信息传递清晰，以及组织跨地域的会议。这些额外的沟通成本不仅会影响项目进度，还可能导致误解和沟通失败。通过理解沟通成本的重要性和增加，团队可以采取更有效的沟通策略，包括利用技术工具、清晰的沟通计划和团队培训，以减轻这一问题带来的负面影响。这个案例强调了如何通过降低沟通成本来提高项目的成功机会。\n4. 团队工作\n团队工作的重要性 软件开发项目往往需要多个团队成员之间的有效合作，包括程序员、测试人员、设计师和管理者，团队协作的不可或缺，才能保证项目成功完成。\n团队协作所面临的挑战 随着团队规模的扩大，不同成员之间的协调和沟通变得更加困难。这可能导致沟通失误、工作分配的混乱和项目的延期。有效的团队协作不仅涉及技术层面，还需要关注人际关系和沟通技巧。\n实例或案例 考虑一个涉及多个团队的复杂项目，每个团队负责不同的模块或组件。如果团队之间的协调和沟通不顺畅，可能会导致不同部分之间的不一致，甚至出现集成问题。\n四、亮点与启发 最有影响的观点或实例 在《人月神话》中，最有影响的观点之一是关于\u0026quot;人月神话\u0026quot;本身。这一观点深刻地揭示了在软件开发项目中的一个普遍误解，即增加项目开发的人员数量会缩短项目时间。通过生动的IBM的OS/360项目的案例，作者清晰地展示了增加人员数量并不总是解决方案，反而可能导致更多的管理和沟通成本，从而延长项目时间表。这个观点对软件工程领域产生了深远的影响，提醒我们要谨慎处理人员规模的增长，强调了规划、管理和沟通的重要性。\n另一个关键观点是\u0026quot;二八定律\u0026quot;，它解释了为什么80%的工作通常需要80%的时间，而剩下的20%同样需要80%的时间。这一定律强调了项目中关键任务的优先性和规划的必要性。通过理解这一观点，团队可以更好地分配资源和精力，确保项目关键任务的顺利执行，从而避免时间表的延迟和资源浪费。\n对个人或专业发展的启示 它提醒我们要对软件工程项目的复杂性和挑战有充分的认识。软件开发不同于传统工程，它涉及到人、技术和管理的多层次交互。因此，我们需要谨慎规划、有效沟通和管理，以确保项目的成功。此外，书中的案例和观点强调了团队协作的不可或缺性。无论是在大型企业项目还是小型团队中，团队成员之间的合作和协调至关重要。这启示我们要发展良好的团队协作技能，倾听他人的意见，学会解决冲突，以实现共同的目标。通过《人月神话》，我们能够深入理解软件工程的本质，从中汲取宝贵的经验教训，不仅提高专业素养，还能应用于各种项目和团队，推动软件工程领域的不断进步。\n五、批评与局限性 任何有争议、模糊或过时的信息 尽管《人月神话》包含了许多宝贵的观点和经验教训，但也存在一些有争议、模糊或过时的信息。首先，书中的一些案例和观点可能仅适用于特定的历史背景，因为软件工程领域在书写时已经发生了巨大的变化。例如，书中提到的硬件和软件环境可能与现代技术和工具有很大不同，因此某些观点可能已经过时。此外，一些观点可能在不同背景下产生争议。例如，在某些敏捷开发项目中，强调小团队、快速迭代和自组织可能与书中的一些建议相悖。因此，读者需要谨慎评估书中的观点，以确保其适用于其具体的项目和环境。\n可能的不足或缺陷 一个潜在的不足是书中强调的某些问题可能过于简化了复杂的软件工程现实。例如，书中提到的\u0026quot;人月神话\u0026quot;观点虽然有其价值，但它可能过于一概而论。在实际项目中，项目规模、团队结构和技术要求各不相同，因此不同项目可能会有不同的最佳实践。这种简化可能导致读者忽视了项目的特定需求。此外，书中强调的一些建议和技巧可能需要更多的上下文和实际操作指南。读者可能需要额外的资源来理解如何具体应用这些原则。因此，书中的一些内容可能缺乏具体的实施细节，这可能对一些读者而言是不足之处。\n六、实际应用和拓展 在实际工作 / 学习中如何应用这些概念 《人月神话》中的概念对实际工作和学习有重要意义。首先，对于软件工程领域的专业人士，书中的观点提供了宝贵的指导，如如何有效地管理项目、规划资源、协调团队和降低沟通成本。对于项目经理、团队领导和决策者，这些观点有助于更好地理解软件项目的特殊性和复杂性，从而提高项目的成功机会。\n其次，这些概念也适用于其他领域，特别是项目管理领域。无论是在制造业、医疗保健、建筑业还是任何需要团队合作和资源管理的领域，书中的原则都具有通用性。学习如何应对复杂性、规划和协调资源以及降低沟通成本对于任何项目的成功都是至关重要的。\n对未来研究或实践的建议 随着技术的不断发展，需要考虑新兴技术对软件工程和项目管理的影响。例如，人工智能、云计算和大数据等新技术如何改变项目的性质和需求。\n其次，可以深入研究如何应对全球化和跨文化团队合作的挑战。随着全球化趋势的加强，团队成员可能分布在不同国家和文化中，如何有效协作和沟通将成为一个重要的研究领域。\n七、总结与评价 对书籍的整体评价 《人月神话》是一本经典的软件工程管理著作，提供了深刻的洞察和宝贵的经验教训。它以清晰、易懂的语言讨论了软件开发中的复杂性和挑战，强调了管理和工程方面的重要性。这本书的长期影响力可见一斑，许多软件专业人士将其视为必读之作。\n书籍的长处和短处 长处：\n经典观点： 书中的观点，如\u0026quot;人月神话\u0026quot;和\u0026quot;二八定律\u0026quot;，具有深远的影响，为软件工程管理提供了宝贵的指导。 实际建议： 书中提供了许多实际的管理建议和案例，读者可以在实际项目中应用。 通俗易懂： 作者以平易近人的语言阐释了复杂的概念，使其对广大读者更容易理解。 跨学科性： 书中的原则和观点不仅适用于软件工程领域，还适用于其他项目管理领域。 短处：\n部分过时观点： 由于书写时间较早，某些观点和案例已经过时，需要根据现代技术和实践进行审慎评估。 不足的实际操作指南： 有些观点可能需要更多的实际操作指南，以帮助读者更好地应用。 ","permalink":"https://WFUing.github.io/posts/read/the-mythical-man-month-thoughts/","summary":"一、书名和作者 书名：《人月神话》 作者：布鲁克斯(FrederickP.Brooks.Jr.) 二、书籍概览 主要论点和结构 《人月神话》是一本旨在深入探讨软件工程中的管理和工程问题的经典著作。本书强调了软件开发过程中的复杂性和挑战，尤其是在大规模项目中。书中还探讨了许多经典观点，如\u0026quot;人月神话\u0026quot;、\u0026ldquo;二八定律\u0026quot;和\u0026quot;沟通成本\u0026rdquo;，为软件行业的专业人员提供了宝贵的见解和管理原则，使他们能够更好地理解和应对软件项目的挑战。\n目标读者和应用场景 该书的目标读者包括软件工程师、项目经理、团队领导和决策者，以及任何对软件开发过程感兴趣的人。对于软件开发工程师来说，这本书提供了宝贵的洞察，帮助他们更好地理解项目管理和团队协作的挑战；对于项目经理来说，本书提供了管理大型软件项目所需的关键原则和策略；领导小型或大型软件团队的人员可以从本书中获得关于如何优化团队协作、提高效率和管理项目的方法；即使不是专业人员，任何对软件开发过程感兴趣的人都可以从本书中获得对软件工程领域的深入了解，从而更好地理解和评估不同软件项目。总的来说，《人月神话》适用于各种软件项目，无论是大规模的企业级项目还是小规模的个人项目。\n三、核心观点与主题 1. 人月神话\n人月神话的产生 《人月神话》的核心观点之一是关于\u0026quot;人月神话\u0026quot;本身的产生。这一概念源自于普遍存在的一种误解，即认为增加项目开发的人员数量会自动缩短项目完成时间。作者布鲁克斯解释了这种误解的根源，即对软件工程的特殊性和复杂性的不理解。这种误解在早期的计算机领域中非常普遍，导致了一些项目的失败和项目时间的延长。\n后果和启发 项目增加人员后出现的管理问题和沟通成本的急剧上升，最后导致了项目的失败，包括延期、成本超支和低质量交付等。这些后果为软件开发的实践带来了极大的挑战，但也激发了对更好方法的追求。软件工程领域需要更多的规划、需求管理和团队协作，以避免人员增加引发的问题。\n实例或案例 一个鲜明的案例是IBM的OS/360项目，该项目是为了开发一种崭新的操作系统。初期，这个项目规模宏大，聚集了大量人员资源，充满了雄心壮志，然而，很快就陷入了严重的延期和质量问题的泥淖。在这个项目中，管理层采取了一种常见的措施，即试图通过增加项目开发的人员数量来加快进度。然而，结果却截然不同于期望。\n2. 二八定律\n二八定律的阐述 本书的第二个重要主题是\u0026quot;二八定律\u0026quot;，它强调了在软件开发中常见的现象，即80%的工作通常需要80%的时间，而剩下的20%工作同样需要80%的时间。这一定律揭示了工作任务的不均衡性，以及为什么某些部分的工作似乎总是比预期需要更多的时间。作者详细探讨了这一定律的背后原因，以及它在软件工程中的应用。\n重要任务的优先性 项目中的关键任务和非关键任务应当被明智地区分开来。关键任务往往占据大部分时间和资源，因此它们的规划和执行至关重要。这个观点呼吁项目管理者和团队要明智地设置优先级，确保关键任务首先得到充分关注，以确保项目能够按计划顺利进行。\n实例或案例 一个生动的例子是在软件开发项目中的功能开发和测试。根据二八定律，80%的开发工作可能会占用80%的时间，但剩下的20%的时间可能都被用于测试和调试。这种情况表明，关键任务（测试）常常被放在项目的后期，从而导致项目延期和问题的累积。通过理解这一现象，团队可以更好地规划项目，提前考虑到测试和质量保证，从而避免在后期因紧急问题而忙乱无序。这个案例强调了二八定律的实际应用，以提高项目的效率和成功率。\n3. 沟通成本\n沟通成本的重要性 这本书的第三个主题关注了\u0026quot;沟通成本\u0026quot;的概念。沟通在软件开发项目中是至关重要的，因为团队成员需要共同合作、协调工作和共享信息。然而，随着团队规模的增大，沟通的复杂性也随之增加。所以为了有效地合作，必须投入时间和精力来解决沟通问题。\n沟通成本的增加 随着团队规模的增加，沟通成本的急剧上升。当团队规模庞大时，需要花更多的时间来协调、汇报和共享信息。这不仅仅是人员增加导致的问题，还包括了更多的管理层次、更多的会议和文档。这会消耗时间和资源，导致项目时间表的延迟。\n实例或案例 在大型软件开发项目中，特别是在跨地理位置分布的全球团队中，沟通成本的急剧上升。团队成员分布在不同的时区，可能使用不同的语言和文化，这会增加沟通的困难。管理层必须花更多的时间来协调跨团队合作，编写文档以确保信息传递清晰，以及组织跨地域的会议。这些额外的沟通成本不仅会影响项目进度，还可能导致误解和沟通失败。通过理解沟通成本的重要性和增加，团队可以采取更有效的沟通策略，包括利用技术工具、清晰的沟通计划和团队培训，以减轻这一问题带来的负面影响。这个案例强调了如何通过降低沟通成本来提高项目的成功机会。\n4. 团队工作\n团队工作的重要性 软件开发项目往往需要多个团队成员之间的有效合作，包括程序员、测试人员、设计师和管理者，团队协作的不可或缺，才能保证项目成功完成。\n团队协作所面临的挑战 随着团队规模的扩大，不同成员之间的协调和沟通变得更加困难。这可能导致沟通失误、工作分配的混乱和项目的延期。有效的团队协作不仅涉及技术层面，还需要关注人际关系和沟通技巧。\n实例或案例 考虑一个涉及多个团队的复杂项目，每个团队负责不同的模块或组件。如果团队之间的协调和沟通不顺畅，可能会导致不同部分之间的不一致，甚至出现集成问题。\n四、亮点与启发 最有影响的观点或实例 在《人月神话》中，最有影响的观点之一是关于\u0026quot;人月神话\u0026quot;本身。这一观点深刻地揭示了在软件开发项目中的一个普遍误解，即增加项目开发的人员数量会缩短项目时间。通过生动的IBM的OS/360项目的案例，作者清晰地展示了增加人员数量并不总是解决方案，反而可能导致更多的管理和沟通成本，从而延长项目时间表。这个观点对软件工程领域产生了深远的影响，提醒我们要谨慎处理人员规模的增长，强调了规划、管理和沟通的重要性。\n另一个关键观点是\u0026quot;二八定律\u0026quot;，它解释了为什么80%的工作通常需要80%的时间，而剩下的20%同样需要80%的时间。这一定律强调了项目中关键任务的优先性和规划的必要性。通过理解这一观点，团队可以更好地分配资源和精力，确保项目关键任务的顺利执行，从而避免时间表的延迟和资源浪费。\n对个人或专业发展的启示 它提醒我们要对软件工程项目的复杂性和挑战有充分的认识。软件开发不同于传统工程，它涉及到人、技术和管理的多层次交互。因此，我们需要谨慎规划、有效沟通和管理，以确保项目的成功。此外，书中的案例和观点强调了团队协作的不可或缺性。无论是在大型企业项目还是小型团队中，团队成员之间的合作和协调至关重要。这启示我们要发展良好的团队协作技能，倾听他人的意见，学会解决冲突，以实现共同的目标。通过《人月神话》，我们能够深入理解软件工程的本质，从中汲取宝贵的经验教训，不仅提高专业素养，还能应用于各种项目和团队，推动软件工程领域的不断进步。\n五、批评与局限性 任何有争议、模糊或过时的信息 尽管《人月神话》包含了许多宝贵的观点和经验教训，但也存在一些有争议、模糊或过时的信息。首先，书中的一些案例和观点可能仅适用于特定的历史背景，因为软件工程领域在书写时已经发生了巨大的变化。例如，书中提到的硬件和软件环境可能与现代技术和工具有很大不同，因此某些观点可能已经过时。此外，一些观点可能在不同背景下产生争议。例如，在某些敏捷开发项目中，强调小团队、快速迭代和自组织可能与书中的一些建议相悖。因此，读者需要谨慎评估书中的观点，以确保其适用于其具体的项目和环境。\n可能的不足或缺陷 一个潜在的不足是书中强调的某些问题可能过于简化了复杂的软件工程现实。例如，书中提到的\u0026quot;人月神话\u0026quot;观点虽然有其价值，但它可能过于一概而论。在实际项目中，项目规模、团队结构和技术要求各不相同，因此不同项目可能会有不同的最佳实践。这种简化可能导致读者忽视了项目的特定需求。此外，书中强调的一些建议和技巧可能需要更多的上下文和实际操作指南。读者可能需要额外的资源来理解如何具体应用这些原则。因此，书中的一些内容可能缺乏具体的实施细节，这可能对一些读者而言是不足之处。\n六、实际应用和拓展 在实际工作 / 学习中如何应用这些概念 《人月神话》中的概念对实际工作和学习有重要意义。首先，对于软件工程领域的专业人士，书中的观点提供了宝贵的指导，如如何有效地管理项目、规划资源、协调团队和降低沟通成本。对于项目经理、团队领导和决策者，这些观点有助于更好地理解软件项目的特殊性和复杂性，从而提高项目的成功机会。\n其次，这些概念也适用于其他领域，特别是项目管理领域。无论是在制造业、医疗保健、建筑业还是任何需要团队合作和资源管理的领域，书中的原则都具有通用性。学习如何应对复杂性、规划和协调资源以及降低沟通成本对于任何项目的成功都是至关重要的。\n对未来研究或实践的建议 随着技术的不断发展，需要考虑新兴技术对软件工程和项目管理的影响。例如，人工智能、云计算和大数据等新技术如何改变项目的性质和需求。\n其次，可以深入研究如何应对全球化和跨文化团队合作的挑战。随着全球化趋势的加强，团队成员可能分布在不同国家和文化中，如何有效协作和沟通将成为一个重要的研究领域。\n七、总结与评价 对书籍的整体评价 《人月神话》是一本经典的软件工程管理著作，提供了深刻的洞察和宝贵的经验教训。它以清晰、易懂的语言讨论了软件开发中的复杂性和挑战，强调了管理和工程方面的重要性。这本书的长期影响力可见一斑，许多软件专业人士将其视为必读之作。\n书籍的长处和短处 长处：\n经典观点： 书中的观点，如\u0026quot;人月神话\u0026quot;和\u0026quot;二八定律\u0026quot;，具有深远的影响，为软件工程管理提供了宝贵的指导。 实际建议： 书中提供了许多实际的管理建议和案例，读者可以在实际项目中应用。 通俗易懂： 作者以平易近人的语言阐释了复杂的概念，使其对广大读者更容易理解。 跨学科性： 书中的原则和观点不仅适用于软件工程领域，还适用于其他项目管理领域。 短处：","title":"The Mythical Man Month Thoughts"},{"content":"动态规划 【LeetCode 55】跳跃游戏 【LeetCode 72】编辑距离 【LeetCode 115】不同的子序列 【LeetCode 124】二叉树中的最大路径和 【LeetCode 174】地下城游戏 【LeetCode 188】买卖股票的最佳时机IV 【LeetCode 198】打家劫舍 【LeetCode 213】打家劫舍II 【LeetCode 233】数字1的个数 【LeetCode 300】最长递增子序列 【LeetCode 309】最佳买卖股票时机含冷冻期 【LeetCode 312】戳气球 【LeetCode 337】打家劫舍III 【LeetCode 354】俄罗斯套娃信封问题 【LeetCode 376】摆动序列 【LeetCode 390】消除游戏 【LeetCode 689】三个无重叠子数组的最大和 【LeetCode 714】买卖股票的最佳时机含手续费 【LeetCode 907】子数组的最小值之和 【LeetCode 943】最短超级串 【LeetCode 1031】两个非重叠子数组的最大和 【LeetCode 1039】多边形三角剖分的最低得分 【LeetCode 1186】删除一次得到子数组最大和 【LeetCode 系列】买卖股票的最佳时机 【LeetCode 面试题 08.11】硬币 贪心算法 【LeetCode 55】跳跃游戏 【LeetCode 121】买卖股票的最佳时机 【LeetCode 122】买卖股票的最佳时机II 【LeetCode 123】买卖股票的最佳时机III 【LeetCode 42】接雨水 【LeetCode 135】分发糖果 ","permalink":"https://WFUing.github.io/posts/tech/algorithm/leetcode/","summary":"动态规划 【LeetCode 55】跳跃游戏 【LeetCode 72】编辑距离 【LeetCode 115】不同的子序列 【LeetCode 124】二叉树中的最大路径和 【LeetCode 174】地下城游戏 【LeetCode 188】买卖股票的最佳时机IV 【LeetCode 198】打家劫舍 【LeetCode 213】打家劫舍II 【LeetCode 233】数字1的个数 【LeetCode 300】最长递增子序列 【LeetCode 309】最佳买卖股票时机含冷冻期 【LeetCode 312】戳气球 【LeetCode 337】打家劫舍III 【LeetCode 354】俄罗斯套娃信封问题 【LeetCode 376】摆动序列 【LeetCode 390】消除游戏 【LeetCode 689】三个无重叠子数组的最大和 【LeetCode 714】买卖股票的最佳时机含手续费 【LeetCode 907】子数组的最小值之和 【LeetCode 943】最短超级串 【LeetCode 1031】两个非重叠子数组的最大和 【LeetCode 1039】多边形三角剖分的最低得分 【LeetCode 1186】删除一次得到子数组最大和 【LeetCode 系列】买卖股票的最佳时机 【LeetCode 面试题 08.11】硬币 贪心算法 【LeetCode 55】跳跃游戏 【LeetCode 121】买卖股票的最佳时机 【LeetCode 122】买卖股票的最佳时机II 【LeetCode 123】买卖股票的最佳时机III 【LeetCode 42】接雨水 【LeetCode 135】分发糖果 ","title":"Leetcode"},{"content":"DSL 和 DSL 工具的一个重要方面是代码生成。DSL 本身在形式化、指定和交流内容方面具有优势，因为它们具有特定领域的性质。但是，如果能从指定的内容中推导出实现代码，就能大大提高工作效率。\nResources blogs https://www.typefox.io/blog/code-generation-for-langium-based-dsls/ https://www.typefox.io/blog/code-generation-for-langium-based-dsls-2 https://www.typefox.io/blog/code-generation-for-langium-based-dsls-3/ github repo: https://github.com/TypeFox/langium-in-browser-codegen-example/tree/main https://github.com/eclipse-langium/langium/blob/main/examples/arithmetics 运行示例 本帖中的运行示例使用 Langium 的 Arithmetics 示例实现。Arithmetics 的 grammar 见 arithmetics.langium\n代码生成器的输入示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 MODULE priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; DEF costPerUnit: materialPerUnit + laborPerUnit; DEF expectedNoOfSales: 200; DEF costOfGoodsSold: expectedNoOfSales * costPerUnit; DEF generalExpensesAndSales: 10000; DEF desiredProfitPerUnit: 50; DEF netPrice: (costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales + desiredProfitPerUnit; DEF vat: 0.15; DEF calcGrossListPrice(net, tax): net / (1 - tax); calcGrossListPrice(netPrice, vat); 本模块介绍一种非常简单的产品价格计算方法。它包括给变量分配常量值和计算值。最后，一个名为 calcGrossListPrice 的函数被调用，参数是之前定义的 netPrice 和 tax。下图展示了 Langium 在解析输入时创建的抽象语法树（AST）。\n现在，让我们将其转化为纯 JavaScript 代码。为了合成所需的代码段，生成器需要访问 AST 并检查相应的部分。让我们通过一个纯 JavaScript 模板来定义生成器的入口函数，如下所示，它会贡献一些静态框架代码：\n1 2 3 4 5 6 7 8 function generateModule(root: Module): string { return ` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 让我们也定义 generateModuleContent(Module) 并按如下方式实现它，由于需要循环，所以这次使用经典的字符串连接：\n1 2 3 4 5 6 7 8 9 function generateModuleContent(module: Module): string { let result = `let ${lastComputableExpressionValueVarName};\\n`; for (const s of module.statements) { result += generateStatement(s) + \u0026#39;\\n\u0026#39;; } result += `\\n` result += `return ${lastComputableExpressionValueVarName};`; return result; } 问题 1：对于多行模板文字，生成的代码将包含由 ········ 在 generateModule() 中指示的空白。我添加了空白，以使生成器符合我们的格式规则。\n缺点：会使生成结果变得混乱。\n问题 2：访问列表时，我们必须在每个语句的生成片段后插入换行符。此外，我们还必须注意 for 循环前后的换行符。最后，还有 \\n 与 \\r\\n 的问题。\n虽然这个问题在这里很简单，但如果出现有条件附加的代码段或者连续多个循环，就会变得相当困难。\n问题 3：generateModuleContent() 中的字符串连接没有注意 generateModule() 中调用该函数之前的缩进。\n生成的代码将如下所示，具体取决于 generateStatement() 的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; . . . return lastComputableExpressionValue; ········}) .... 这个示例很好地说明了生成代码中的缩进是如何出错的。周围的静态代码缩进了，但不应该缩进，而括弧中的语句没有缩进，但应该缩进。\nSolution A: Smart tagged templates Solution A：Langium 提供了一个名为 expandToString 的标签函数，可智能处理空白。\n在 generateModule(Module) 第 2 行的开头回车之前直接插入 expandToString 引用，可将后续模板转换为标记模板，请参见 generateModule2(Module)：\n1 2 3 4 5 6 7 8 9 10 import { expandToString } from \u0026#39;langium\u0026#39;; function generateModule2(root: Module): string { return expandToString` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 这样就得到了下面的生成结果：\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;use strict\u0026#34;; (() =\u0026gt; { let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; . . . return lastComputableExpressionValue; }) expandToString 实现以下这些功能：\n在模板的所有非空行中识别和修剪共同的前导空格 确定用 ${} 包装的表达式的偏移量 修剪 single leading and trailing line breaks 合并模板内的换行符 因此，\n功能 1 删除了生成模块 2(Module) 中由 ········ 表示的空白，这使得静态代码从偏移量 0 开始，即生成时没有任何缩进。 功能 2 将 ${generateModuleContent(root)} 行内的额外缩进 (␣␣) 应用到替换字符串中的每一行。在我们的示例中，这将产生正确缩进的语句实现片段，而缩进只需指定一次。 功能 3 丢弃了紧随开头回车符之后的初始换行符，以及包括结尾回车符缩进在内的尾部换行符。这与生成器入口函数（如 generateModule2(Module)）关系不大，但与从其他标记模板（如 generateModuleContent(Module)）中调用的生成器函数（如 generateModuleContent(Module)）非常相关，因为周围的换行符将由调用模板决定。最后但并非最不重要的一点是， 功能 4 使所有换行符都与系统换行符一致。这一点非常可取，因为生成的代码通常会被持久化到磁盘上，并希望与平台保持一致。 现在，让我们再来看看 generateModuleContent(Module) 模块：\n1 2 3 4 5 6 7 8 9 function generateModuleContent(module: Module): string { let result = `let ${lastComputableExpressionValueVarName};\\n`; for (const s of module.statements) { result += generateStatement(s) + \u0026#39;\\n\u0026#39;; } result += `\\n` result += `return ${lastComputableExpressionValueVarName};`; return result; } 将循环重写为 map;join 表达式后，我们就可以使用标记模板和 expandToString 来实现字符串连接，如下所示：\n1 2 3 4 5 6 7 8 function generateModuleContent2(module: Module): string { return expandToString` let ${lastComputableExpressionValueVarName}; ${ module.statements.map(generateStatement).join(\u0026#39;\\n\u0026#39;) } return ${lastComputableExpressionValueVarName}; `; } 连接操作中的分隔符会被功能 4 expandToString 处理，如果在 MS Windows 机器上执行，它会用 \\r\\n 替换单个 \\n。\n我们上面的价格计算示例的整个输出结果可能如下，我在这里跳过了缺失的生成器部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026#34;use strict\u0026#34;; (() =\u0026gt; { let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; const expectedNoOfSales = lastComputableExpressionValue = 200; const costPerUnit = lastComputableExpressionValue = materialPerUnit + laborPerUnit; const costOfGoodsSold = lastComputableExpressionValue = expectedNoOfSales * costPerUnit; const generalExpensesAndSales = lastComputableExpressionValue = 10000; const desiredProfitPerUnit = lastComputableExpressionValue = 50; const netPrice = lastComputableExpressionValue = ((costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales) + desiredProfitPerUnit; const vat = lastComputableExpressionValue = 0.15; const calcGrossListPrice = (net, tax) =\u0026gt; net / (1 - tax); lastComputableExpressionValue = calcGrossListPrice( netPrice, vat ); return lastComputableExpressionValue; }) 除了普通关键字、标识符和运算符的连接外，我的生成器还插入了典型的括号复合表达式，比如在计算 netPrice 的值时。此外，像 calcGrossListPrice 这样的函数调用会在多行中生成，从而使参数更易于阅读。\n结论：如果我们想使用 JavaScript 模板表达式而不是普通的字符串连接来实现代码生成器，如果我们想获得正确格式化的生成代码以及正确格式化的模板，那么 expandToString 将为我们提供极大的帮助。\n备注：重要的是要保持模板行缩进一致，特别是不要混合使用制表符和空格！VS 代码提供了一个显示空白字符的便捷选项，名为 Toggle Render Whitespace。\nSolution B: two stage code generation 试想一下，如果某些行后没有添加内容，您希望跳过这些行的换行符。试想一下，您需要对代码片段的缩进进行配置，或者需要对生成的代码进行后处理和调整，以满足特定条件。在生成 Java 或 JavaScript 等语言时，可以考虑添加导入子句，同时在代码中添加符号引用。生成丰富的表达式语法也可能需要比纯字符串更多的抽象。最后但并非最不重要的一点是，我们可能希望将生成的代码段与它们在文本中代表的源定义区域关联起来。这样的要求需要一种不同的方法。\n在本部分中，将重点介绍两阶段代码生成方法，并展示如何将其与 Solution A 中使用的 Tagged Templates 整合在一起。\nGeneration tree 要满足上述要求，一种可行的方法是将生成任务一分为二，并使用比字符串更具表现力的数据结构来捕获中间结果。任务 1 建立待生成代码的描述，任务 2 则渲染所需的输出结果。\n在我们的日常实践中，事实证明树状数据结构非常有用。我们定义了以下数据类型的联盟，并将其称为 Generated 类型：\n1 2 type Generated = string | GeneratorNode | undefined; type GeneratorNode = CompositeGeneratorNode | IndentNode | NewLineNode; 生成任务 1 的结果可能已经是字符串类型，例如，如果结果非常短。通常，它的类型是 GeneratorNode。此外，它还可能是 undefined 的。这在顶层没有太大意义，但在将模板的部分内容转移到子例程时却非常有用。未定义的可能结果允许这些函数向其调用者发出信号，表明该函数不会生成任何东西，这与空字符串等其他东西不同。\nCompositeGeneratorNode 实现了复合设计模式。该类型的实例是容器，可容纳一系列其他字符串和生成器节点。IndentNode 是 CompositeGeneratorNode 的特化，提供缩进信息。NewLineNode 的实例用于描述换行，它们的严格程度是可参数化的。\n在早期的 Langium 中，我们通过以编程方式合成生成器描述来构建代码生成器，例如 Langium CLI 中包含的描述。这样一来，代码生成器的实现就会被大量的 node.append(...) 或 node.children.push(...) 指令所支配，而所需生成的代码结构很快就会被混淆。\n通过 tagged templates 在 Langium v1.0 中，发布了另一个名为 expandToNode 的标签函数，也就是我们的解决方案 B。请回顾算术语言示例中的 generateModule2 示例：\n1 2 3 4 5 6 7 8 function generateModule2(root: Module): string { return expandToString` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 将标签函数替换为 expandToNode 并将返回类型更改为 Generated，就可以轻松将其转换为两阶段生成。\n1 2 3 4 5 6 7 8 function generateModule3(root: Module): Generated { return expandToNode` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent2(root)} ········}) `; } 与 expandToString 一样，模板中会自动删除 ········ 所指示的缩进。此外，还省略了开头 \\n 后的初始换行，以及结尾 \\n 前的换行和随后的空白。\n然后，必须将 generateModule3(Module) 的结果转换为字符串，这就是我上文提到的生成任务 2。为此，Langium 提供了名为 toString(unknown) 的函数。如果调用 toString 时使用了 GeneratorNode 类型的参数，它就会将该参数转换为字符串，否则就会委托 JavaScript 的默认字符串构造函数来处理。\n现在让我们看看 generateModuleContent2(Module) 的实现，这也是上次的内容：\n1 2 3 4 5 6 7 8 function generateModuleContent2(module: Module): string { return expandToString` let ${lastComputableExpressionValueVarName}; ${ module.statements.map(generateStatement).join(\u0026#39;\\n\u0026#39;) } return ${lastComputableExpressionValueVarName}; `; } 同样，我替换了上面的标记函数和返回类型。不过，我们并不想立即将语句元素的生成结果连接成一个字符串。相反，我们想为每个元素创建生成描述，并将其包含在该模板的结果中。为此，Langium 提供了 joinToNode() 函数。该函数的使用方法将在 generateModuleContent3(Module) 中进行说明：\n1 2 3 4 5 6 7 8 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; ${ joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } joinToNode 的第一个参数是一个要访问的元素集合、一个为每个元素创建生成描述的函数，以及一个可选的配置对象，用于确定分隔符或注册其他回调（如 element filter 和 prefix/suffix 提供程序）。如果输入集合为空，或者所有元素都没有生成，joinToNode 也不会返回任何结果，实际上用 undefined 来表示。\n为什么要区分 undefined ？ tl;dr：expandToNode 可以将换行符配置为可省略。如果某行的最后一个替换是未定义的或 GeneratorNode 类型的对象，它就会这样做。如果该行的剩余部分只包含空白字符，则整行将被省略，同时呈现所需的输出结果。\n1 2 3 let lastComputableExpressionValueVarName return lastComputableExpressionValueVarName; 调用 joinToNode(\u0026hellip;) 没有任何结果。不过，它的尾部换行符会被附加到生成的代码中，并产生第一个空行。然后，我们在模板中请求的空行也会被附加到生成的代码中，这样就连续生成了两行空行。不过，我个人（也许你也一样）更倾向于省略包含 joinToNode(\u0026hellip;) 调用的整行，即忽略替换后的换行。为了实现这一首选行为，expandToNode 会检查每一行是否有占位符/替换。如果包含替换，则按以下方式评估最后一个替换的值：\n如果替换值未定义或属于 GeneratorNode 类型，则配置该行的终端 NewLineNode，使其仅在前一行为非空时才显示为换行符。否则，配置 NewLineNode 为无条件换行。\n在我们的例子中，generateModuleContent3(Module) 的语句列表为空，这意味着我们将在第 1 行末尾得到一个换行符，因为该行至少包含静态字符串 let，即非空字符串。准确地说，无论其配置如何，添加到生成描述中的 NewLineNode 都会导致换行。第 2 行的占位符将解析为 undefined 的 \u0026ldquo;值\u0026rdquo;。因此，随后代表第 2 行末尾换行符的 NewLineNode 将被标记为 ifNotEmpty，如上所述。在稍后的字符串呈现过程中（任务 2），第 2 行将被评估为空，从而使结束符 NewLineNode 呈现为空。\n第 3 行仅包含一个换行符（不包含任何替换），并导致在生成描述中无条件添加一个 NewLineNode。第 4 行要求在生成说明中添加 return- 以及 lastComputableExpressionValueVarName 内容的字符串值。由于模板将在下一行关闭，因此结束符将被忽略。\n这种方法还允许对仅包含空白和可能导致 undefined 的替换的行强制执行无条件换行。只需将 ??'' 到（最后一个）替换内容中，或者在行尾再添加一个类似 ${''} 的替换。expandToNode 就会插入一个无条件的 NewLineNode。顺便说一下：后一个选项也适用于包含可能为空的 CompositeGeneratorNodes 的替换。\nBenefits 函数 expandToNode 返回 CompositeGeneratorNode 的一个实例，代表某段文本的生成描述。此类对象可任意组合，也可随意操作。元素可以添加、删除或改变顺序。此外，由于复合生成器节点（CompositeGeneratorNode）所描述的某些文本片段的具体缩进最终是在其跨容器（任务 2）的文本渲染时确定的，因此父节点和某些子节点的创建和组合可能完全独立于彼此。一个子节点甚至可能包含在同一生成描述中不同缩进级别的不同位置。此外，在要连接的字符串模板或表达式中，不再需要硬编码的换行符。\n此外，生成器实现可以在基于标记模板的实现风格和基于普通方法调用的风格之间来回切换，这取决于哪种风格最适合。由于 CompositeGeneratorNode 定义了更多的方便方法，因此这两者之间的界限并不明显。下面将提到其中一些方法，有关它们的精确定义，请参阅 Langium 代码库：\nappend(\u0026hellip;Generated[]) appendNewLine() appendNewLineIfNotEmpty() appendIf(boolean, \u0026hellip;Generated[]) appendTemplate\u0026lt;template content\u0026gt; appendTemplateIf(boolean)\u0026lt;template content\u0026gt; indent(Generated[]) … 在某些情况下，这种方式可能更好。\n1 2 3 4 5 6 7 8 9 10 11 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; `.appendNewLine() .appendIf(module.statements.length !== 0, joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) ).appendTemplate` return ${lastComputableExpressionValueVarName}; `; } The avigation between DSL source and generated code 在 Solution A 和 Solution B 中，已经使 TypeScript 和 JavaScript 中的代码生成变得简单且可扩展，现在是时候来讨论一些实际问题了，即如何处理生成的代码，而不是纯粹的字符串段连接。\n这包括在集成开发环境中导航生成的工件及其相应的源代码（例如，用于手动审查），以及在调试生成的代码时自动切换到基于 DSL 的源代码。为了在基于 DSL 的开发工具中启用这些功能，代码生成器需要收集数据，了解哪些源定义生成了哪些代码。\n用下面的截图来说明 DSL 源代码和生成代码之间的来回导航。DSL 工具的用户可能想了解代码生成器为某个专用语句生成了什么代码。DSL 开发工具可能会提供这样的审查工具，例如通过选择敏感的上下文菜单项，如第一张截图所示。当然，也可以进行其他集成：在生成的工件中，可能有多个地方会受到某个语句或定义的影响。\n另一方面，用户可能希望或需要调查为什么生成器会将某些语句放入生成的工件中，即源代码中的哪些定义。如第二张截图所示，如果有机会让开发工具说明生成代码中某些语句的原因或来源，可能会简化此类任务。\n除了这类静态代码分析外，还希望运行生成的代码，在某个入口点设置断点，并通过逐步浏览 DSL 编写的源代码来逐步实现，如下图所示。\n在这里，一个装有 Langium Arithmetics 示例语言的 Monaco editor 被添加到了一个普通网站上，并输入了在 Solution A 中介绍的正在运行的示例脚本。基于 Langium 的语言服务器已经处理了输入，确定没有验证错误，并调用了生成器。然后对获得的 JavaScript 代码和相应的源映射进行评估。源映射是根据 JavaScript 代码生成过程中捕获的跟踪数据创建的。\n获取追踪数据 为了实现上述功能，我们需要捕获跟踪数据，将源数据中的相关文本区域与 generated artifacts 中的相应文本区域关联起来。在此，我们假定源数据是以人类可读文本的形式（通常是根据某种 DSL）编制的，并保存在 disc 上的文件中（至少与某个 URI 相关联），而 generated artifacts 则假定由 a stream of characters 组成。\n回顾本系列的第二部分，我们将代码生成任务分为两项：\nthe composition of a generation description the rendering of the description into the desired text 引入了一种树形数据结构来捕获描述，它由几种不同的数据类型组成，这些数据类型都归属于联合类型 GeneratorNode。既然已经引入了这样一种专用数据结构，就可以根据自己的喜好为这些数据添加额外的信息。还记得上次的模板标签函数 expandToNode，它在任务（1）中为给定的 JavaScript 模板文字建立了 GeneratorNode 实例，以及生成器函数 generateModuleContent3(Module)：\n1 2 3 4 5 6 7 8 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; ${ joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } 无论所提供的模块中定义了哪些语句，所包含的模板都会生成静态代码，而生成的输出则代表模块所包含的语句。这些语句的生成由函数 generateStatement(Statement) 完成，该函数提供给第 4 行的 joinToNode(\u0026hellip;) 调用。因此，模板第 3 行、第 5 行和第 6 行的内容只能与 module 相关联，因为这是它们被添加到输出中的原因。与此相反，generateStatement(Statement) 产生的输出可以与 module 关联，因为这些语句包含在 module 中，但更具体地说，它们应该与 module.statements 中包含的相应 Statement 实例关联。为了实现这两个目的，Langium 提供了以下函数：\nexpandTracedToNode\u0026lt;T extends AstNode\u0026gt;(T, Properties\u0026lt;T\u0026gt;?, number?) joinTracedToNode\u0026lt;T extends AstNode\u0026gt;(T, Properties\u0026lt;T\u0026gt;?) 我们可以使用这些函数捕获所需的跟踪数据，并重写 generateModuleContent3 如下：\n1 2 3 4 5 6 7 8 function generateModuleContent4(module: Module): Generated { return expandTracedToNode(module)` let ${lastComputableExpressionValueVarName}; ${ joinTracedToNode(module, \u0026#39;statements\u0026#39;)(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } 请注意，这两个函数都会再次返回函数。返回函数的签名与 expandToNode 和 joinToNode 的签名完全一致。因此，expandTracedToNode(module) 的结果是一个将模板字面意义转换为标记模板的标记函数。它在内部委托给 expandToNode，并在组成的 GeneratorNode 中注释了模块是相应源对象的信息。\n同样的原理也适用于 joinTracedToNode(模块, \u0026lsquo;语句\u0026rsquo;)。它返回一个与 joinToNode(\u0026hellip;) 接口相同的函数。第 4 行中对 generateModuleContent4(Module) 的调用是指：对 module.statements 中的每个元素应用 generateStatement(Statement)，为生成的每个 GeneratorNode 注释跟踪信息，说明生成的部分代表父对象模块中名为 statements 的属性（集合）的第 i 个元素，将所有这些生成器节点添加到一个容器 GeneratorNode 中，并为该容器注释信息，说明生成的部分代表源对象模块中 statements 属性的全部内容。\n追踪数据剖析 Langium 会在生成任务（2）中对跟踪数据进行评估和计算。在这种情况下，函数 toStringAndTrace(GeneratorNode) 将取代 Langium 的 toString(unknown)。它返回一个形状为 { text: string, trace：traceRegion }，其中 text 是希望生成的文本，trace 是描述嵌套跟踪区域的复合结构，将生成文本中的区域与源文件中的区域关联起来。数据类型 TraceRegion 的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 interface TraceRegion { sourceRegion?: TextRegion; targetRegion: TextRegion; children?: TraceRegion[]; } interface TextRegion { fileURI?: string; offset: number; end: number; length?: number; range?: Range; } 假定源数据是 Langium 通过解析 DSL 语法表述的文本而创建的有效 AST 元素，AstNode 实例就会被注释为代表相应具体语法节点的对象。后者反过来又提供了其 DSL 文档中的起始和结束位置以及文档的文件 URI。通过这些信息，toStringAndTrace(GeneratorNode) 计算出生成器节点的源区域。在文本渲染过程中，通过记录生成器节点生成文本的开始和结束位置，计算出相应的目标区域。此时，目标 TextRegion 的 fileURI 属性永远不会被设置，因为此时还不知道生成的文本是否会被写入某个文件，如果是，文件的 URI 可能是什么。\n让我们来看看以下输入和相应输出的简化示例：\n1 2 3 4 Module priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; 1 2 3 4 5 let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; return lastComputableExpressionValue; 下面的截图中展示了所得到的轨迹区域：\n玫瑰色背景所限定的区域代表跟踪所描述的根跟踪区域，该区域来自 generateModuleContent4(module) 所返回的生成器节点。 淡黄色矩形表示的区域来自 generateModuleContent4(Module) 。第 4 行中调用 joinTracedToNode(\u0026hellip;)(\u0026hellip;) 生成器节点生成的区域。源区域等于对象模块属性 \u0026ldquo;语句 \u0026ldquo;中所有元素定义的 \u0026ldquo;边界框\u0026rdquo;，目标区域等于第 4 行中 joinTracedToNode(\u0026hellip;)(\u0026hellip;) 调用 generateStatement(Statement) 的结果所描述的所有文本片段的 \u0026ldquo;边界框\u0026rdquo;，加上 { appendNewLineIfNotEmpty: true } 所要求的插入分隔线。包含这些源文本区域和目标文本区域描述的 TraceRegion 实例可通过根跟踪对象的子属性（即 trace.children[0]）访问。 蓝色背景区域表示跟踪区域，包括对象模块属性 \u0026ldquo;statements \u0026ldquo;条目 0 定义所涉及的源文本区域，以及执行 generateStatement(module.statements[0])后返回的生成器节点所描述的目标区域。跟踪区域描述对象可通过 trace.children[0].children[0] 访问。同样的情况也适用于绿色背景区域，但它们表示 module.statements 的条目 1 的定义和生成文本。该跟踪区域描述可通过 trace.children[0].children[1] 访问。 实际上，这种深度的跟踪数据捕获并不是终点。如果我们继续将 expandTracedToNode(\u0026hellip;) 应用于在 generateStatement(Module) 中要区分的所有特殊情况，我们就会得到完全深度解析和细粒度的跟踪区域，直至每个标识符、运算符和数字字面。\n将跟踪数据转换为 JavaScript 源映射 如今的浏览器和 VS Code 都支持源映射的概念，以便于调试已编译、转译或最小化的代码。源映射可以作为单独文件附加到生产的 JavaScript 代码中，甚至可以内联到生产的代码中（这通常会大大增加要传输的代码）。因此，为了实现能够调试用算术 DSL 编写的脚本这一目标，我们不仅需要捕获跟踪信息，还需要使用它们来合成符合源映射格式的数据。好消息是我们不需要完全靠自己。https://npmjs.com 上发布的 source-map 软件包可以帮我们完成大部分工作。\n在 langium-in-browser-codegen-example GitHub 代码库中，我实现了源地图数据的组合，并将其内联到生成的 JavaScript 代码中。如果内联，源地图数据必须进行 base64 编码\u0026ndash;这意味着我们基本上没有机会审查我们实际生成的内容。不过，sokra 和其他一些好心人建立了一个工具 https://sokra.github.io/source-map-visualization/。它允许我们上传生成的代码，包括源地图数据（或将源地图数据作为单独文件上传）。下面，我添加了一张所提供的可视化截图。原始页面甚至允许通过将鼠标悬停在某个区域上，观察其对应区域的高亮度（如果有的话），以交互方式查看源区域和目标区域。\n","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/code-generation-for-langium-based-dsls/","summary":"DSL 和 DSL 工具的一个重要方面是代码生成。DSL 本身在形式化、指定和交流内容方面具有优势，因为它们具有特定领域的性质。但是，如果能从指定的内容中推导出实现代码，就能大大提高工作效率。\nResources blogs https://www.typefox.io/blog/code-generation-for-langium-based-dsls/ https://www.typefox.io/blog/code-generation-for-langium-based-dsls-2 https://www.typefox.io/blog/code-generation-for-langium-based-dsls-3/ github repo: https://github.com/TypeFox/langium-in-browser-codegen-example/tree/main https://github.com/eclipse-langium/langium/blob/main/examples/arithmetics 运行示例 本帖中的运行示例使用 Langium 的 Arithmetics 示例实现。Arithmetics 的 grammar 见 arithmetics.langium\n代码生成器的输入示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 MODULE priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; DEF costPerUnit: materialPerUnit + laborPerUnit; DEF expectedNoOfSales: 200; DEF costOfGoodsSold: expectedNoOfSales * costPerUnit; DEF generalExpensesAndSales: 10000; DEF desiredProfitPerUnit: 50; DEF netPrice: (costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales + desiredProfitPerUnit; DEF vat: 0.","title":"Code generation for Langium-based DSLs"},{"content":"模板引擎 模板引擎（也称为模板处理器或模板解析器）是设计用于将模板与数据模型结合起来以生成结果文档的软件，编写模板所用的语言称为模板语言或模板语言。模板引擎通常作为 Web 模板系统或应用程序框架的一部分，也可以用作预处理器或过滤器。流行的模板引擎包括 Ejs、Jade、Pug、Mustache、HandlebarsJS、Jinja2 和 Blade。\n模板引擎如何工作 上图说明了模板引擎的所有基本元素和处理流程。\n使用模板引擎构建服务器端应用程序时，模板引擎会将模板文件中的变量替换为实际值，并将此值显示给客户端。这样，我们就能更轻松地快速构建应用程序。\n使用 expressJS 和 ejs 模板引擎的示例 对于使用 NodeJS 运行时编写的服务器端应用程序，可以使用模板引擎。\n以下步骤演示了模板引擎如何使用 expressJs 和 ejs 模板引擎工作。下面的示例在网页上渲染用户数据。\n步骤 1：安装 express 和 ejs 模板引擎\n安装 ejs 模板引擎和 express 框架，\n1 npm install express ejs 步骤 2：设置视图引擎\n1 2 3 4 5 6 7 8 const express = require(\u0026#34;express\u0026#34;) const app = express(); // Set the View Engine or Template Engine app.set(\u0026#39;view engine\u0026#39;, \u0026#39;ejs\u0026#39;); app.listen(3000) 在上面的代码中，我们创建了 express 应用程序。该应用程序通过 3000 端口监听。\napp.set('view engine', 'ejs'); 告诉我们的 express 应用程序，我们要使用 EJS 作为模板引擎。\n步骤 3：设置视图文件夹\n创建一个名为 view 的文件夹。视图文件夹应包含我们的模板。其中一个模板是 index.ejs，它将生成我们的首页。第二个模板是 user.ejs，用于从服务器端传递用户数据，并立即在网页上呈现。\n1 2 3 4 index.js \u0026gt;view index.ejs user.ejs 步骤 4：设置 routes\n让我们为主页和用户页面创建routes。\n请注意下面的 res.render() 方法。这就是在 expressJS 中渲染模板的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 app.get(\u0026#39;/\u0026#39;, function (req, res) { res.render(\u0026#34;index\u0026#34;); }) app.get(\u0026#34;/user\u0026#34;, function(req,res){ const user = { name: \u0026#34;Theodore Kelechukwu O.\u0026#34;, stack: \u0026#34;MERN\u0026#34;, email: \u0026#34;theodoreonyejiaku@gmail.com\u0026#34;, hubby: [\u0026#34;singing\u0026#34;, \u0026#34;playing guitar\u0026#34;, \u0026#34;reading\u0026#34;, \u0026#34;philosoph\u0026#34;] } res.render(\u0026#34;user\u0026#34;, {user}); }) 正如我们所见，访问默认路由\u0026quot;\u0026quot;时，会显示或渲染 index.ejs 页面。同时，\u0026quot;\\user \u0026ldquo;会显示 user.ejs 页面。\n我们将用户对象传递给 render 对象，以便将用户属性传递给网页并进行渲染。\n步骤 5：模板化我们的视图文件\n现在，我们已经从服务器端传递了用户数据，我们需要立即在前端或网页上显示这些数据。\nindex.ejs\n1 2 3 4 5 6 7 8 9 10 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;This is the title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Welcome to Template Engines\u0026lt;/p\u0026gt; \u0026lt;a href=\u0026#34;/user\u0026#34;\u0026gt;View User\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; user.ejs\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;This is the title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to User Details\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Name:\u0026lt;/b\u0026gt; \u0026lt;%= user.name %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Email:\u0026lt;/b\u0026gt; \u0026lt;%= user.email %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Stack:\u0026lt;/b\u0026gt; \u0026lt;%= user.stack %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;u\u0026gt;\u0026lt;b\u0026gt;Hubbies\u0026lt;/b\u0026gt;\u0026lt;/u\u0026gt; \u0026lt;% user.hubby.forEach(hubby =\u0026gt;{ %\u0026gt; \u0026lt;li\u0026gt;\u0026lt;%= hubby %\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;% })%\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 注意显示值的 \u0026lt;%= variable %\u0026gt; 模式。这是在 ejs 中使用的方式。还要注意 user.forEach(); 这是为了显示模板引擎有多么强大。\nResources https://en.wikipedia.org/wiki/Template_processor https://www.educative.io/answers/what-are-template-engines ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/template-engine/","summary":"模板引擎 模板引擎（也称为模板处理器或模板解析器）是设计用于将模板与数据模型结合起来以生成结果文档的软件，编写模板所用的语言称为模板语言或模板语言。模板引擎通常作为 Web 模板系统或应用程序框架的一部分，也可以用作预处理器或过滤器。流行的模板引擎包括 Ejs、Jade、Pug、Mustache、HandlebarsJS、Jinja2 和 Blade。\n模板引擎如何工作 上图说明了模板引擎的所有基本元素和处理流程。\n使用模板引擎构建服务器端应用程序时，模板引擎会将模板文件中的变量替换为实际值，并将此值显示给客户端。这样，我们就能更轻松地快速构建应用程序。\n使用 expressJS 和 ejs 模板引擎的示例 对于使用 NodeJS 运行时编写的服务器端应用程序，可以使用模板引擎。\n以下步骤演示了模板引擎如何使用 expressJs 和 ejs 模板引擎工作。下面的示例在网页上渲染用户数据。\n步骤 1：安装 express 和 ejs 模板引擎\n安装 ejs 模板引擎和 express 框架，\n1 npm install express ejs 步骤 2：设置视图引擎\n1 2 3 4 5 6 7 8 const express = require(\u0026#34;express\u0026#34;) const app = express(); // Set the View Engine or Template Engine app.set(\u0026#39;view engine\u0026#39;, \u0026#39;ejs\u0026#39;); app.listen(3000) 在上面的代码中，我们创建了 express 应用程序。该应用程序通过 3000 端口监听。","title":"Template Engine"},{"content":"今天花了一点时间搭建了自己的GitHub的博客，当然咯，试验阶段总会发生很多乱七八糟的问题，记录下处理问题过程中几个比较 nice 的 blog\nResources 系列文章，用hugo的PaperMod Theme 建站: https://www.sulvblog.cn/posts/blog/ Hugo + GitHub Action，搭建你的博客自动发布系统: https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ PaperMod主题优化： https://kdjlyy.cn/posts/site/hugo-papermod-optimization https://dvel.me/posts/hugo-papermod-config/ ","permalink":"https://WFUing.github.io/posts/tech/operations/git/how-to-build-github-blog-with-hugo/","summary":"今天花了一点时间搭建了自己的GitHub的博客，当然咯，试验阶段总会发生很多乱七八糟的问题，记录下处理问题过程中几个比较 nice 的 blog\nResources 系列文章，用hugo的PaperMod Theme 建站: https://www.sulvblog.cn/posts/blog/ Hugo + GitHub Action，搭建你的博客自动发布系统: https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ PaperMod主题优化： https://kdjlyy.cn/posts/site/hugo-papermod-optimization https://dvel.me/posts/hugo-papermod-config/ ","title":"How to Build Github Blog With Hugo"},{"content":"为什么要用代码生成 productivity：使用代码生成，只需编写一次 generator ，就可以根据需要多次重复使用。向 generator 提供特定输入并调用它比手动编写代码要快得多，因此代码生成可以节省时间。 Simplification：通过代码生成，你可以从一些抽象的描述中生成代码。需要维护的部分变成了 generator 的输入部分，该部分通常是代码的描述，而不是代码本身，与整个生成的代码相比，该描述通常更容易分析和检查。 Portability：一旦你有了为某种语言或框架生成代码的程序，你就可以简单地更改 generator ，并以不同的语言或框架为目标。您还可以同时针对多个平台。 例如，使用解析器生成器，您可以获得 C#、Java 和 C++ 的 parser。 另一个例子：您可能会编写一个 UML 图表，然后使用代码生成器用 C# 创建一个骨架类，并用 SQL 代码为 MySQL 创建一个数据库。因此，相同的抽象描述可用于生成不同类型的工件。 Consistency：有了代码生成，你总能得到你所期望的代码。生成的代码是根据相同的原则设计的，命名规则等也是一致的。当然，除了生成器中的 bug 之外，代码总是能按照你所期望的方式运行，代码质量始终如一。如果用手工编写代码，不同的开发人员可能会使用不同的风格，即使是最重复的代码也会偶尔出现错误。 为什么不要用代码生成 Maintenance：当您使用代码生成工具时，您的代码就会依赖于它。代码生成工具必须得到维护。如果你创建了它，你就必须不断更新它；如果你只是使用现有的工具，你就必须希望有人继续维护它，或者你必须自己接手。因此，代码生成的优势并不是免费的。如果你没有或找不到合适的能力来维护代码生成器，风险就会更大。 Complexity：自动生成的代码往往比手工编写的代码更复杂。有时，这与将不同部分连接在一起所需的胶水代码有关，或者与生成器支持的用例多于您所需的用例有关。在第二种情况下，生成的代码可以做比你想要的更多的事情，但这并不一定是一种优势。生成代码的优化程度肯定也不如手工编写的代码。有时这种差异很小，并不明显，但如果您的应用程序需要尽可能地提高性能，那么生成的代码对您来说可能并不是最佳选择。 如何使用代码生成? 根据具体情况，代码生成既可以提高工作效率，也可以成为开发过程中的重要组成部分。许多现代集成开发环境就是一个有用的例子：只需点击一个按钮，就能创建一个骨架类来实现接口或类似功能。你完全可以自己编写这样的代码，只不过会浪费一些时间来完成琐碎的任务。\n设计代码生成流水线的方法有很多种。基本上，我们需要定义两个要素：\nInput：用于生成代码的信息来自何处。 Output：如何获得生成的代码。 您也可以在输入和输出之间设置转换步骤。这些步骤可以简化输出层，并使输入和输出更加独立。\nPossible Inputs\nA DSL：例如，我们可以使用 ANTLR 来描述一种语言的语法。由此，我们可以生成一个解析器。 code in other formats：数据库模式。根据数据库模式，我们可以生成 DAO。 wizards：它们允许向用户询问信息。 reverse engineering：可通过处理复杂的代码工件获得信息。 data sources：比如一个DB，一个csv文件或者一个电子表格。 Possible Outputs\ntemplate engine：大多数网络程序员都知道模板引擎，它用于在 HTML UI 中填充数据。 code building APIs：例如，Javaparser 可用于以编程方式创建 Java 文件。 Some Pipelines\n现在让我们来检查一些 pipelines：\nparser generation：本网站的读者一定很熟悉 ANTLR 和其他此类从形式语法自动生成解析器的工具。在这种情况下，输入是一个 DSL，输出则是使用 template engine 生成的。 model driven design：集成开发环境或独立集成开发环境的插件，可以描述应用程序的模型，有时还提供图形界面，并据此生成整个应用程序或仅生成其骨架。 database-related code：这种用法可视为模型驱动设计和模板引擎的产物。通常，程序员会定义一个数据库模式，并据此生成整个 CRUD 应用程序或处理数据库的代码。也有一些工具可以执行相反的过程：根据现有数据库创建数据库模式或处理数据库的代码。 meta-programming languages：这些语言组包括可对程序代码进行近乎完全操作的语言，源代码只是另一种可操作的数据结构。 ad hoc applications：这一类包括所有内容：从为处理一件事情而设计的工具到企业环境中使用的临时系统，这些系统可以根据正式的自定义描述生成整个应用程序。这些应用程序通常是特定工作流程的一部分。例如，客户使用图形界面描述一个应用程序，一个临时系统会生成支持该应用程序的数据库模式，另一个系统会生成 CRUD 界面等。 IDE generated code：许多静态类型语言需要编写大量的模板代码，而集成开发环境通常可以生成其中的一部分：为要实现的方法提供存根的类、标准的等值、hashCode 和 toString 方法、所有现有属性的获取器和设置器。 代码生成工具 模板引擎 模板引擎组 (Template Engine) 可能是最著名和最常用的。模板引擎基本上就是一个能理解简单模板语言的迷你编译器。模板文件包含可由模板引擎解释的特殊符号。它能做的最简单的事情就是用运行时给出的适当数据替换这些特殊符号。大多数模板引擎还支持简单的流程控制命令（如 for 循环、if-else 语句），允许用户描述简单的结构。\n有很多例子，让我们来看两个代表大多数模板引擎行为方式的例子。\nJinja2 Jinja2 是一个广泛使用的 Python 模板引擎。它能做所有模板引擎都能做的事情：根据提供的数据创建独一无二的文档。 它支持模块化模板、控制流、变量等。不过，它也有强大的安全措施：HTML 转义系统和沙箱环境，可以控制对危险属性的访问。\n1 2 3 4 5 6 \u0026lt;title\u0026gt;{% block title %}{% endblock %}\u0026lt;/title\u0026gt; \u0026lt;ul\u0026gt; {% for user in users %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{ user.url }}\u0026#34;\u0026gt;{{ user.username }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; Jinja2 特别支持生成 HTML 页面，这也是最常用的功能。不过，它也可用于创建其他类型的文件。\nPug Pug 是一个深受 Haml 影响的高性能模板引擎，使用 JavaScript 实现，适用于 Node.js 和浏览器。在许多方面，Pug 与许多其他模板引擎一样：它支持模块化模板、控制流等。不同的是，Pug 看起来像 DSL，而且只适用于 HTML。因此，Pug 模板看起来非常简洁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 doctype html html(lang=\u0026#34;en\u0026#34;) head title= pageTitle script(type=\u0026#39;text/javascript\u0026#39;). if (foo) bar(1 + 5) body h1 Pug - node template engine #container.col if youAreUsingPug p You are amazing else p Get on it! p. Pug is a terse and simple templating language with a strong focus on performance and powerful features. 解析器生成器 解析器生成器 (Parser Generation) 是一种自动快速创建语言解析器的工具。它们非常成功且富有成效，因为人们已经对语言解析问题进行了广泛的研究。因此，有一些解决方案可以保证解析人们需要解析的大多数语言。\nANTLR ANTLR 可能是使用最多的解析器生成器。这意味着有很多示例。然而，庞大社区的真正附加价值在于大量可用的语法。\nANTLR 的输入是语法：对语言的正式描述。解析器的输出是一棵解析树：一种包含源代码的结构，其转换方式便于程序的其他部分使用。ANTLR 还提供了两种走解析树的方法：访问者和监听者。第一种适用于需要对解析树中的元素进行操作或交互的情况，而第二种则适用于只需要在规则匹配时做一些事情的情况。\n1 2 3 4 5 6 7 grammar simple; basic : NAME \u0026#39;:\u0026#39; NAME ; NAME : [a-zA-Z]* ; COMMENT : \u0026#39;/*\u0026#39; .*? \u0026#39;*/\u0026#39; -\u0026gt; skip ; 模型驱动设计 这些通常是集成开发环境的插件或独立的集成开发环境，可以通过图形界面描述应用程序的模型，并由此生成应用程序的骨架。之所以会出现这种情况，是因为模型驱动设计的基础是抽象模型，可以用 UML 图表或 DSL 来定义。一旦程序的主要特征可以根据模型进行描述，那么就有可能自动生成该程序的表示法。这种代码中的模型表示法会自动生成结构，但行为通常必须由开发人员自己直接实现。\nAcceleo Acceleo 3 是一款实现 OMG 模型到文本规范的代码生成器。它为开发人员提供了高质量代码生成集成开发环境所应具备的大部分功能：简单的语法、高效的代码生成、先进的工具以及与 JDT 不相上下的功能。Acceleo 可帮助开发人员处理代码生成器的生命周期。得益于基于原型的方法，您可以从现有原型的源代码中快速、轻松地创建第一个生成器，然后利用 Acceleo 工具的所有功能（如重构工具），您可以轻松地改进生成器，实现完整的代码生成器。\nAcceleo 的工作：实施模型驱动设计原则。但缺少的是对 Acceleo 工作体验的描述。Acceleo 基本上是一个 Eclipse 插件，它为您提供了一个工具，可以根据您指定的模板，从 EMF 模型开始创建 Java 代码。EMF 模型可以通过不同方式定义：UML 图表或自定义 DSL。\nUmple Umple 是一种建模工具和编程语言系列，可实现作者所说的面向模型的编程。它在面向对象编程语言（如 Java、C++、PHP 和 Ruby）中添加了关联、属性和状态机等抽象概念，这些抽象概念源自 UML。Umple 还可用于以文本方式创建 UML 类图和状态图。\nUmple 是一种将 UML 模式与传统编程语言结构化结合的工具。它的诞生是为了简化模型驱动开发的过程，而传统的模型驱动开发需要特定而复杂的工具。它本质上是一种编程语言，支持 UML（类和状态）图定义模型的功能。然后，Umple 代码会被其编译器转换为 Java 或 PHP 等传统语言。\nUmple 可以有多种用法：\n可用于以文本方式描述 UML 图表 可与传统语言结合使用，作为该目标语言的预处理器或扩展程序。Umple 编译器在目标语言中转换 Umple 代码，并保持现有目标语言不变。 由于其对 UML 状态机的大量支持，它可以作为状态机生成器使用。根据 Umple 对状态机的描述，可以生成许多目标语言的实现。 1 2 3 4 5 6 7 8 9 10 class Student {} class CourseSection {} class Registration { String grade; * -- 1 Student; * -- 1 CourseSection; } 下面的 Umple 代码描述的是一个状态机。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class GarageDoor { status { Open { buttonOrObstacle -\u0026gt; Closing; } Closing { buttonOrObstacle -\u0026gt; Opening; reachBottom -\u0026gt; Closed; } Closed { buttonOrObstacle -\u0026gt; Opening; } Opening { buttonOrObstacle -\u0026gt; HalfOpen; reachTop -\u0026gt; Open; } HalfOpen { buttonOrObstacle -\u0026gt; Opening; } } } Telosys Telosys 设计用于生成所有管道和重复代码。它不需要使用 UML，但允许用户从起始数据库或使用 DSL 生成模型。它是一个有趣且易于使用的解决方案，还以 Eclipse 插件的形式提供 IDE 支持。\nurl：https://tomassetti.me/telosys-code-generation-tool/ 数据库相关代码 这一切都围绕着一个数据库模式展开，而代码就是从这个模式中生成的，或者是从一个数据库中生成一个模式。之所以可以使用这些生成器，有两个原因：\n关系数据库支持与之交互的标准语言（SQL） 编程语言中存在与数据库交互的广泛模式和库 这两个原因保证了在编程语言和包含程序所需数据的数据库之间创建标准胶合代码成为可能。在实践中，数据库模式可以作为一个简单的模型，用来生成代码。\n许多框架或集成开发环境都包含从类生成数据库模式的基本工具，反之亦然，生成与数据库表交互的类。在本节中，我们将看到一个可以做更多事情的工具示例。\nCelerio Celerio 是面向数据应用程序的代码生成工具。\nCelerio 是一款 Java 工具，其中包括一个数据库提取器，用于从现有数据库中获取数据库模式。然后，它将生成的模式与配置文件结合起来，然后启动模板引擎，以创建整个应用程序。提取的数据库模式为 XML 格式。\nDomain Specific Language（DSL） DSL 是以正规化方式捕捉业务逻辑的好方法。之后，需要以某种方式执行这些逻辑。虽然有时会使用解释器和编译器来执行 DSL，但代码生成器却经常被使用。通过这种方式，DSL 可以被翻译成已经存在编译器的语言，如 Java 或 C#。\n现在，可以使用语言工作台来构建 DSL，语言工作台是专门为设计和实现 DSL 而设计的集成开发环境。语言工作台之所以有用，是因为它们还能以较低的成本为 DSL 定义编辑器和其他支持工具。这一点非常重要，因为非开发人员也可以使用 DSL，他们需要定制的编辑器来利用语言的功能，或者根本无法使用普通的文本编辑器。除其他功能外，语言工作台通常还集成了代码生成功能。让我们来看几个例子。\nJetBrains MPS\nJetBrains MPS 是基于项目编辑器的语言工作台。您可以用它创建一个或多个 DSL。它还可用于扩展现有语言。例如，mbeddr 就是基于 JetBrains MPS 的 C 语言扩展，用于改进嵌入式编程。\n所谓投影式编辑器，是指 MPS 会保留数据的基本结构，并以易于编辑的形式显示出来。这个概念可能有点难以理解。想想传统的编程：你写出源代码，然后编译器将源代码转换为逻辑表示，即解析树。编译器使用这种表示法来执行一些操作，如优化或将其转换为机器代码来执行。使用项目编辑器，您可以直接处理逻辑表示：解析树。不过，您只能按照编辑器（MPS）允许的方式对其进行修改。\n这样做的主要后果是，当使用 JetBrains MPS 创建 DSL 时，您需要整个集成开发环境及其所有功能和功能。您可以获得语法高亮、代码自动补全、项目管理等功能。\n不过，这种方法的优势在于，您可以创建一个使用任何形式的输入来修改代码的 DSL，因此您可以创建一个图形编辑器、一个表格输入，甚至是普通文本。这一优势使得创建非程序员也能使用的 DSL 特别有用。\nXtext Xtext 是一种语言工作台，构建于 Eclipse 和 Eclipse Modeling Framework 之上。它可用于设计文本 DSL 并为其获取编辑器。 从功能上讲，Xtext 是不同工具（如用于解析的 ANTLR、用于用户界面的 Eclipse 等）的组合，用于生成 DSL。\nJulia 让我们看看 Julia 中宏的示例，Julia 是一种受 Lisp 启发的语言，它的语法更易于理解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 julia\u0026gt; macro twostep(arg) println(\u0026#34;I execute at parse time. The argument is: \u0026#34;, arg) return :(println(\u0026#34;I execute at runtime. The argument is: \u0026#34;, $arg)) end @twostep (macro with 1 method) julia\u0026gt; ex = macroexpand( :(@twostep :(1, 2, 3)) ); julia\u0026gt; ex # the macro itself :((println)(\u0026#34;I execute at runtime. The argument is: \u0026#34;, $(Expr(:copyast, :($(QuoteNode(:((1, 2, 3))))))))) julia\u0026gt; eval(ex) # execution of the macro I execute at runtime. The argument is: (1, 2, 3) 可以看出，执行宏和执行宏返回的表达式是两码事。\n这个非常强大的功能可以用于代码生成：你不需要外部工具来创建模板代码，你可以从内部创建。在下面摘自 Julia 文档的示例中，你可以看到它是如何定义一系列新的三元运算符的。\n1 2 3 for op = (:+, :*, :\u0026amp;, :|, :$) eval(:(($op)(a,b,c) = ($op)(($op)(a,b),c))) end 代码利用已定义的二元运算符定义了这些新的三元运算符：\n在前两个元素之间进行基本的二进制运算 然后在第一个运算结果和第三个元素之间再次进行运算 请注意，Julia 的标准语法与传统语言类似：没有奇怪的括号，表达式正常等。然而，当您使用元编程功能时，您将使用类似 Lisp 的内部语法。\n这只是冰山一角，你可以查阅 Julia 手册，进一步了解元编程的强大功能。\nRacket 如果你想在元编程方面做得更多，可以使用 Racket，这是一种受 Lisp 和 Scheme（另一种受 Lisp 影响的语言）启发的语言。\nRacket 同时是一种语言和一个平台，它被设计成一种可以定义其他语言的语言。因此，它甚至可以使用比宏更强大的元编程功能。Racket 可以定义全新的语言，改变基本语言的语法。它之所以能做到这一点，基本上是因为它允许你改变解析本身。\nRacket 的传统语法类似 Lisp。\n1 2 3 (define (four p) (define two-p (hc-append p p)) (vc-append two-p two-p)) 你可以改变它，例如，你可以创建一种语言来定义文档：Scribble\n1 2 3 4 5 6 #lang scribble/base @title{On the Cookie-Eating Habits of Mice} If you give a mouse a cookie, he\u0026#39;s going to ask for a glass of milk. 该语言允许您创建 HTML、PDF 等文件。您可以在语言中定义结构，然后生成所需的任何输出。\n这是一个与元编程和 DSL 相匹配的全新层次：您可以使用类似 DSL 的易用界面轻松创建自定义生成器。当目标受众是其他开发人员时，可以采用这种方法。这是因为您虽然获得了一种功能强大的语言，但它仅仅是一种语言而已。如果使用语言工作台，您就可以拥有一整套强大的编辑工具，帮助普通用户使用语言。\nAd-Hoc Applications 这一类包括所有内容：从为处理一件事情而设计的工具到在企业环境中使用的临时系统，这些系统可以根据正式的自定义描述生成整个应用程序。这些应用程序通常是特定工作流程的一部分。例如，客户使用图形界面描述一个应用程序，一个临时系统会生成支持该应用程序的数据库模式，另一个系统会生成 CRUD 界面等。\n这不是一个正确定义的类别，而是一个总括类别，包括不属于特定组别的所有内容。这意味着这组程序没有标准结构。这也证明了代码生成的多功能性：如果你能创建一个问题模型或描述，那么你就能用代码生成来解决问题。当然，你还必须了解解决一般问题和创建代码生成工具是否有意义，还是直接解决问题更好。\n在本节中，我们将讨论两种工具：CMake 是一款开发工具，而 Yeoman 则是一款脚手架工具。前者主要是生成配置文件：为其他软件提供支持的软件。第二种工具简化了开发人员的工作，提供了一种创建即用项目的方法，可针对特定软件平台、库或需求进行优化。\nCMake CMake 是一个开源、跨平台的工具系列，用于构建、测试和打包软件。\nCMake 包括三个开发工具，用于帮助开发 C 和 C++。主要工具旨在为不同平台和工具链生成构建文件（即 makefile 和项目文件）。例如，它可以生成 Linux 的 makefile 和 Visual Studio 项目文件。\nCMake 不是编译器。用户以 CMake 格式定义项目结构，然后该工具会生成传统构建过程中使用的普通构建文件。\nCMake 文件看起来像一系列命令/宏，用于为编译器设置选项/标志、链接库、执行自定义命令等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 cmake_minimum_required(VERSION 2.8) project(\u0026#34;Antlr-cpp-tutorial\u0026#34;) [..] if (NOT WIN32) set(CMAKE_CXX_FLAGS \u0026#34;-Wdeprecated -Wno-attributes\u0026#34; ) endif() [..] if(APPLE) add_custom_command(TARGET antlr4-tutorial POST_BUILD COMMAND ${CMAKE_COMMAND} -E copy_if_different \u0026#34;${PROJECT_SOURCE_DIR}/libs/antlr4-runtime.dylib\u0026#34; $\u0026lt;TARGET_FILE_DIR:antlr4-tutorial\u0026gt;) endif() Yeoman Yeoman 是一个通用的脚手架系统，可以创建任何类型的应用程序。\n如今，要成为一名优秀的程序员，意味着不仅仅要知道如何编码。你需要了解你所使用的每种工具的最佳实践，并记住每次都要执行它们。编写代码本身就已经很困难了，如果还需要正确编写配置文件和使用正确的项目结构，那就更难了。这就是像 Yeoman 这样的工具的用武之地：它是一款脚手架工具，只需一条命令就能生成一个新项目，并立即实施所有最佳实践。\nYeoman 的核心是一个生成器生态系统，开发人员可以在此基础上构建自己的模板。该工具非常受欢迎，已有数千个模板可供使用。\nYeoman 是一款 JavaScript 应用程序，因此编写生成器只需编写 JavaScript 代码并使用提供的 API 即可。工作流程也非常简单：向用户询问项目信息（如名称），收集配置信息，然后生成项目。\n以下代码展示了生成器的部分示例，用于创建 Yeoman 模板。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 function makeGeneratorName(name) { name = _.kebabCase(name); name = name.indexOf(\u0026#39;generator-\u0026#39;) === 0 ? name : \u0026#39;generator-\u0026#39; + name; return name; } module.exports = class extends Generator { initializing() { this.props = {}; } prompting() { return askName( { name: \u0026#39;name\u0026#39;, message: \u0026#39;Your generator name\u0026#39;, default: makeGeneratorName(path.basename(process.cwd())), filter: makeGeneratorName, validate: str =\u0026gt; { return str.length \u0026gt; \u0026#39;generator-\u0026#39;.length; } }, this ).then(props =\u0026gt; { this.props.name = props.name; }); } [..] writing() { const pkg = this.fs.readJSON(this.destinationPath(\u0026#39;package.json\u0026#39;), {}); const generatorGeneratorPkg = require(\u0026#39;../package.json\u0026#39;); [..] this.fs.writeJSON(this.destinationPath(\u0026#39;package.json\u0026#39;), pkg); } conflicts() { this.fs.append(this.destinationPath(\u0026#39;.eslintignore\u0026#39;), \u0026#39;**/templatesn\u0026#39;); } install() { this.installDependencies({ bower: false }); } }; Resources https://tomassetti.me/code-generation/ ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/a-guide-to-code-generation/","summary":"为什么要用代码生成 productivity：使用代码生成，只需编写一次 generator ，就可以根据需要多次重复使用。向 generator 提供特定输入并调用它比手动编写代码要快得多，因此代码生成可以节省时间。 Simplification：通过代码生成，你可以从一些抽象的描述中生成代码。需要维护的部分变成了 generator 的输入部分，该部分通常是代码的描述，而不是代码本身，与整个生成的代码相比，该描述通常更容易分析和检查。 Portability：一旦你有了为某种语言或框架生成代码的程序，你就可以简单地更改 generator ，并以不同的语言或框架为目标。您还可以同时针对多个平台。 例如，使用解析器生成器，您可以获得 C#、Java 和 C++ 的 parser。 另一个例子：您可能会编写一个 UML 图表，然后使用代码生成器用 C# 创建一个骨架类，并用 SQL 代码为 MySQL 创建一个数据库。因此，相同的抽象描述可用于生成不同类型的工件。 Consistency：有了代码生成，你总能得到你所期望的代码。生成的代码是根据相同的原则设计的，命名规则等也是一致的。当然，除了生成器中的 bug 之外，代码总是能按照你所期望的方式运行，代码质量始终如一。如果用手工编写代码，不同的开发人员可能会使用不同的风格，即使是最重复的代码也会偶尔出现错误。 为什么不要用代码生成 Maintenance：当您使用代码生成工具时，您的代码就会依赖于它。代码生成工具必须得到维护。如果你创建了它，你就必须不断更新它；如果你只是使用现有的工具，你就必须希望有人继续维护它，或者你必须自己接手。因此，代码生成的优势并不是免费的。如果你没有或找不到合适的能力来维护代码生成器，风险就会更大。 Complexity：自动生成的代码往往比手工编写的代码更复杂。有时，这与将不同部分连接在一起所需的胶水代码有关，或者与生成器支持的用例多于您所需的用例有关。在第二种情况下，生成的代码可以做比你想要的更多的事情，但这并不一定是一种优势。生成代码的优化程度肯定也不如手工编写的代码。有时这种差异很小，并不明显，但如果您的应用程序需要尽可能地提高性能，那么生成的代码对您来说可能并不是最佳选择。 如何使用代码生成? 根据具体情况，代码生成既可以提高工作效率，也可以成为开发过程中的重要组成部分。许多现代集成开发环境就是一个有用的例子：只需点击一个按钮，就能创建一个骨架类来实现接口或类似功能。你完全可以自己编写这样的代码，只不过会浪费一些时间来完成琐碎的任务。\n设计代码生成流水线的方法有很多种。基本上，我们需要定义两个要素：\nInput：用于生成代码的信息来自何处。 Output：如何获得生成的代码。 您也可以在输入和输出之间设置转换步骤。这些步骤可以简化输出层，并使输入和输出更加独立。\nPossible Inputs\nA DSL：例如，我们可以使用 ANTLR 来描述一种语言的语法。由此，我们可以生成一个解析器。 code in other formats：数据库模式。根据数据库模式，我们可以生成 DAO。 wizards：它们允许向用户询问信息。 reverse engineering：可通过处理复杂的代码工件获得信息。 data sources：比如一个DB，一个csv文件或者一个电子表格。 Possible Outputs\ntemplate engine：大多数网络程序员都知道模板引擎，它用于在 HTML UI 中填充数据。 code building APIs：例如，Javaparser 可用于以编程方式创建 Java 文件。 Some Pipelines","title":"A Guide to Code Generation"},{"content":"案例驱动 通过几个简单的例子来解释和总结什么是交叉熵（Cross Entropy）以及机器学习分类问题中为什么使用交叉熵。\n第一个例子 假设随机从一个口袋里取硬币，口袋里有一个蓝色的，一个红色的，一个绿色的，一个橘色的。取出一个硬币之后，每次问一个问题，然后做出判断，目标是，问最少的问题，得到正确答案。其中一个最好的设计问题的策略如下：\n每一个硬币有 $\\frac{1}{4}$ 的概率被选中，$\\frac{1}{4}机率 * 2道题目 * 4颗球 = 2$，平均需要问两道题目才能找出不同颜色的球，也就是说期望值为 $2$，就是熵（entropy）。\n第二个例子 例子变了，变成了袋子中 $\\frac{1}{8}$ 的硬币是绿色的，$\\frac{1}{8}$ 的是橘色的，$\\frac{1}{4}$ 是红色的，$\\frac{1}{2}$ 是蓝色的，这时最优的问题的策略如下:\n$\\frac{1}{2}$ 的概率是蓝色，只需要 $1$ 个问题就可以知道是或者不是，$\\frac{1}{4}$ 的概率是红色，需要2个问题，按照这个逻辑，猜中硬币需要的问题的期望是\n$$ \\frac{1}{2}*1+\\frac{1}{4}*2+\\frac{1}{8}*3+\\frac{1}{8}*3=1.75 $$\n第三个例子 假设袋子中全部是蓝色的硬币，那么这时候需要 $0$ 个问题就可以猜到硬币，即 $\\log_{2}{1}=0$。 需要注意的是，只有当知道袋子中全部是蓝色的硬币的时候需要的问题是 $0$ 个。\n总结上面的例子，假设一种硬币出现的概率是 $p$，那么猜中该硬币的所需要的问题数是 $\\log_2{\\frac1{P_i}}$。例如 $p=\\frac{1}{4}，\\log_{2}{4}$ 。\n在这个问题中，问题个数的期望是\n$$ \\sum_i{p_i}*log_2{\\frac{1}{p_i}} $$\n这个式子就是熵的表达式 。简单来说，其意义就是在最优化策略下，猜到颜色所需要的问题的个数。熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。\n现在已经了解了熵是什么，那么，下面解释交叉熵（cross entropy） 的含义.对于第二个例子，如果仍然使用第一个例子中的策略，如下图:\n$\\frac{1}{8}$ 的概率，硬币是橘色，需要两个问题，$\\frac{1}{2}$ 的概率是蓝色，仍然需要两个问题，也就是说，认为小球的分布为 $(\\frac{1}{4},\\frac{1}{4},\\frac{1}{4},\\frac{1}{4})$ ，这个分布就是非真实分布。平均来说，需要的问题数是 $\\frac{1}{8}*2+\\frac{1}{8}*2+\\frac{1}{4}*2+\\frac{1}{2}*2=2$ 。\n因此，在例子二中使用例子一的策略是一个比较差的策略。其中 $2$ 是这个方案中的交叉熵，而最优方案的交叉熵是 $1.75$。\n给定一个策略，交叉熵就是在该策略下猜中颜色所需要的问题的期望值。更普遍的说，交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出成本的大小。交叉的字面意思在于：真实分布与非真实分布的交叉。给定一个方案，越优的策略，最终的交叉熵越低。具有最低的交叉熵的策略就是最优化策略，也就是上面定义的熵。因此，在机器学习中，我们需要最小化交叉熵。\n数学上来讲 其中，$p$ 是真正的概率，例如例子二中，橘色和绿色是 $\\frac{1}{8}$，红色是 $\\frac{1}{4}$，蓝色是 $\\frac{1}{2}$。$\\hat p$ 是错误地假设了的概率，例如，在例子二中我们错误地假设了所有的颜色的概率都是 $\\frac{1}{4}$。$p$ 和 $\\hat p$ 可能有点容易混淆。记住一点，$log$ 是用来计算在你的策略下猜中所需要的问题数，因此，$log$ 中需要的是你的预测概率 $\\hat p$ 。在决策树中，如果建立的树不是最优的，结果就是对于输出的概率分布的假设是错误地，导致的直接结果就是交叉熵很高。交叉熵不仅仅应用在决策树中，在其他的分类问题中也有应用。\n分类问题 在二分类问题中，标签 $y$ 是 $1$ 的似然是对于标签 $y$ 的预测 $\\hat y$ ，同样的，标签是 $0$ 的似然是 $1-\\hat y$ 。我们需要最大化似然函数，而且，由于二分类问题的特殊性，根据伯努力分布 (Bernoulli distribution)，可以把似然函数写成\n当 $y=1$ 的时候，第二项为 $1$，因此，优化的是 $\\hat y$ 当 $y=0$ 的时候，第一项为 $1$，优化的是 $1-\\hat y$ 。 对上面的似然函数取对数，结果是最大化似然函数，就是对上面表达式取负然后最小化。也是交叉熵的表达式。\n交叉熵有时候也被称为对数损失函数。注意与上边例子区别是多了个负号，上边例子是消除不确定性需要付出的成本；而现在这个加了负号的交叉熵，则是最终的目标函数。\n举例来说，假设我有 $3$ 枚硬币，正正反，记为 $(1,1,0)$ 。预测结果是 $(0.8,0.9,0.3)$，那么，交叉熵的均值是:\n$$ \\frac13(1×\\log_20.8+1×log_20.9+(1-0)×log_2(1-0.3)) $$\n假设有一个完美的算法，直接预测出了 $(1,1,0)$，那么交叉熵的结果就是 $0$。\n","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/cross-entropy/","summary":"案例驱动 通过几个简单的例子来解释和总结什么是交叉熵（Cross Entropy）以及机器学习分类问题中为什么使用交叉熵。\n第一个例子 假设随机从一个口袋里取硬币，口袋里有一个蓝色的，一个红色的，一个绿色的，一个橘色的。取出一个硬币之后，每次问一个问题，然后做出判断，目标是，问最少的问题，得到正确答案。其中一个最好的设计问题的策略如下：\n每一个硬币有 $\\frac{1}{4}$ 的概率被选中，$\\frac{1}{4}机率 * 2道题目 * 4颗球 = 2$，平均需要问两道题目才能找出不同颜色的球，也就是说期望值为 $2$，就是熵（entropy）。\n第二个例子 例子变了，变成了袋子中 $\\frac{1}{8}$ 的硬币是绿色的，$\\frac{1}{8}$ 的是橘色的，$\\frac{1}{4}$ 是红色的，$\\frac{1}{2}$ 是蓝色的，这时最优的问题的策略如下:\n$\\frac{1}{2}$ 的概率是蓝色，只需要 $1$ 个问题就可以知道是或者不是，$\\frac{1}{4}$ 的概率是红色，需要2个问题，按照这个逻辑，猜中硬币需要的问题的期望是\n$$ \\frac{1}{2}*1+\\frac{1}{4}*2+\\frac{1}{8}*3+\\frac{1}{8}*3=1.75 $$\n第三个例子 假设袋子中全部是蓝色的硬币，那么这时候需要 $0$ 个问题就可以猜到硬币，即 $\\log_{2}{1}=0$。 需要注意的是，只有当知道袋子中全部是蓝色的硬币的时候需要的问题是 $0$ 个。\n总结上面的例子，假设一种硬币出现的概率是 $p$，那么猜中该硬币的所需要的问题数是 $\\log_2{\\frac1{P_i}}$。例如 $p=\\frac{1}{4}，\\log_{2}{4}$ 。\n在这个问题中，问题个数的期望是\n$$ \\sum_i{p_i}*log_2{\\frac{1}{p_i}} $$\n这个式子就是熵的表达式 。简单来说，其意义就是在最优化策略下，猜到颜色所需要的问题的个数。熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。\n现在已经了解了熵是什么，那么，下面解释交叉熵（cross entropy） 的含义.对于第二个例子，如果仍然使用第一个例子中的策略，如下图:\n$\\frac{1}{8}$ 的概率，硬币是橘色，需要两个问题，$\\frac{1}{2}$ 的概率是蓝色，仍然需要两个问题，也就是说，认为小球的分布为 $(\\frac{1}{4},\\frac{1}{4},\\frac{1}{4},\\frac{1}{4})$ ，这个分布就是非真实分布。平均来说，需要的问题数是 $\\frac{1}{8}*2+\\frac{1}{8}*2+\\frac{1}{4}*2+\\frac{1}{2}*2=2$ 。\n因此，在例子二中使用例子一的策略是一个比较差的策略。其中 $2$ 是这个方案中的交叉熵，而最优方案的交叉熵是 $1.75$。\n给定一个策略，交叉熵就是在该策略下猜中颜色所需要的问题的期望值。更普遍的说，交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出成本的大小。交叉的字面意思在于：真实分布与非真实分布的交叉。给定一个方案，越优的策略，最终的交叉熵越低。具有最低的交叉熵的策略就是最优化策略，也就是上面定义的熵。因此，在机器学习中，我们需要最小化交叉熵。\n数学上来讲 其中，$p$ 是真正的概率，例如例子二中，橘色和绿色是 $\\frac{1}{8}$，红色是 $\\frac{1}{4}$，蓝色是 $\\frac{1}{2}$。$\\hat p$ 是错误地假设了的概率，例如，在例子二中我们错误地假设了所有的颜色的概率都是 $\\frac{1}{4}$。$p$ 和 $\\hat p$ 可能有点容易混淆。记住一点，$log$ 是用来计算在你的策略下猜中所需要的问题数，因此，$log$ 中需要的是你的预测概率 $\\hat p$ 。在决策树中，如果建立的树不是最优的，结果就是对于输出的概率分布的假设是错误地，导致的直接结果就是交叉熵很高。交叉熵不仅仅应用在决策树中，在其他的分类问题中也有应用。","title":"交叉熵"},{"content":" 英文名: WDS 职业: 程序员 运动: 跑步、乒乓球、爬山 ","permalink":"https://WFUing.github.io/about/","summary":" 英文名: WDS 职业: 程序员 运动: 跑步、乒乓球、爬山 ","title":"🙋🏻‍♂️"}]