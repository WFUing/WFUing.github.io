[{"content":"Netty 基础 Netty 是什么 Netty 是 JBoss 开源项目，是异步的、基于事件驱动的网络应用框架，它以高性能、高并发著称。所谓基于事件驱动，说得简单点就是 Netty 会根据客户端事件（连接、读、写等）做出响应，关于这点，随着文章的论述的展开，读者自然会明白。 Netty 主要用于开发基于 TCP 协议的网络 IO 程序（TCP/IP 是网络通信的基石，当然也是 Netty 的基石，Netty 并没有去改变这些底层的网络基础设施，而是在这之上提供更高层的网络基础设施），例如高性能服务器段/客户端、P2P 程序等。 Netty 是基于 Java NIO 构建出来的，Java NIO 又是基于 Linux 提供的高性能 IO 接口/系统调用构建出来的。关于 Netty 在网络中的地位，下图可以很好地表达出来： Netty 的应用场景 在互联网领域，Netty 作为异步高并发的网络组件，常常用于构建高性能 RPC 框架，以提升分布式服务群之间调用或者数据传输的并发度和速度。例如 Dubbo 的网络层就可以（但并非一定）使用 Netty。 一些大数据基础设施，比如 Hadoop，在处理海量数据的时候，数据在多个计算节点之中传输，为了提高传输性能，也采用 Netty 构建性能更高的网络 IO 层。 在游戏行业，Netty 被用于构建高性能的游戏交互服务器，Netty 提供了 TCP/UDP、HTTP 协议栈，方便开发者基于 Netty 进行私有协议的开发。 …… Netty 作为成熟的高性能异步通信框架，无论是应用在互联网分布式应用开发中，还是在大数据基础设施构建中，亦或是用于实现应用层基于公私协议的服务器等等，都有出色的表现，是一个极好的轮子。\nJava 中的网络 IO 模型 Java 中的网络 IO 模型有三种：BIO、NIO、AIO。\nBIO：同步的、阻塞式 IO。在这种模型中，服务器上一个线程处理一次连接，即客户端每发起一个请求，服务端都要开启一个线程专门处理该请求。这种模型对线程量的耗费极大，且线程利用率低，难以承受请求的高并发。BIO 虽然可以使用线程池+等待队列进行优化，避免使用过多的线程，但是依然无法解决线程利用率低的问题。 使用 BIO 构建 C/S 系统的 Java 编程组件是 ServerSocket 和 Socket。服务端示例代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public static void main(String[] args) throws IOException { ExecutorService threadPool = Executors.newCachedThreadPool(); ServerSocket serverSocket = new ServerSocket(8080); while (true) { Socket socket = serverSocket.accept(); threadPool.execute(() -\u0026gt; { handler(socket); }); } } /** * 处理客户端请求 */ private static void handler(Socket socket) throws IOException { byte[] bytes = new byte[1024]; InputStream inputStream = socket.getInputStream(); socket.close(); while (true) { int read = inputStream.read(bytes); if (read != -1) { System.out.println(\u0026#34;msg from client: \u0026#34; + new String(bytes, 0, read)); } else { break; } } } NIO：同步的、非阻塞式 IO。在这种模型中，服务器上一个线程处理多个连接，即多个客户端请求都会被注册到多路复用器（后文要讲的 Selector）上，多路复用器会轮训这些连接，轮训到连接上有 IO 活动就进行处理。NIO 降低了线程的需求量，提高了线程的利用率。Netty 就是基于 NIO 的（这里有一个问题：前文大力宣扬 Netty 是一个异步高性能网络应用框架，为何这里又说 Netty 是基于同步的 NIO 的？请读者跟着文章的描述找寻答案）。 NIO 是面向缓冲区编程的，从缓冲区读取数据的时候游标在缓冲区中是可以前后移动的，这就增加了数据处理的灵活性。这和面向流的 BIO 只能顺序读取流中数据有很大的不同。\nJava NIO 的非阻塞模式，使得一个线程从某个通道读取数据的时候，若当前有可用数据，则该线程进行处理，若当前无可用数据，则该线程不会保持阻塞等待状态，而是可以去处理其他工作（比如处理其他通道的读写）；同样，一个线程向某个通道写入数据的时候，一旦开始写入，该线程无需等待写完即可去处理其他工作（比如处理其他通道的读写）。这种特性使得一个线程能够处理多个客户端请求，而不是像 BIO 那样，一个线程只能处理一个请求。\n使用 NIO 构建 C/S 系统的 Java 编程组件是 Channel、Buffer、Selector。服务端示例代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 public static void main(String[] args) throws IOException { ServerSocketChannel serverSocketChannel = ServerSocketChannel.open(); Selector selector = Selector.open(); // 绑定端口 serverSocketChannel.socket().bind(new InetSocketAddress(8080)); // 设置 serverSocketChannel 为非阻塞模式 serverSocketChannel.configureBlocking(false); // 注册 serverSocketChannel 到 selector，关注 OP_ACCEPT 事件 serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT); while (true) { // 没有事件发生 if (selector.select(1000) == 0) { continue; } // 有事件发生，找到发生事件的 Channel 对应的 SelectionKey 的集合 Set\u0026lt;SelectionKey\u0026gt; selectionKeys = selector.selectedKeys(); Iterator\u0026lt;SelectionKey\u0026gt; iterator = selectionKeys.iterator(); while (iterator.hasNext()) { SelectionKey selectionKey = iterator.next(); // 发生 OP_ACCEPT 事件，处理连接请求 if (selectionKey.isAcceptable()) { SocketChannel socketChannel = serverSocketChannel.accept(); // 将 socketChannel 也注册到 selector，关注 OP_READ // 事件，并给 socketChannel 关联 Buffer socketChannel.register(selector, SelectionKey.OP_READ, ByteBuffer.allocate(1024)); } // 发生 OP_READ 事件，读客户端数据 if (selectionKey.isReadable()) { SocketChannel channel = (SocketChannel) selectionKey.channel(); ByteBuffer buffer = (ByteBuffer) selectionKey.attachment(); channel.read(buffer); System.out.println(\u0026#34;msg form client: \u0026#34; + new String(buffer.array())); } // 手动从集合中移除当前的 selectionKey，防止重复处理事件 iterator.remove(); } } } AIO：异步非阻塞式 IO。在这种模型中，由操作系统完成与客户端之间的 read/write，之后再由操作系统主动通知服务器线程去处理后面的工作，在这个过程中服务器线程不必同步等待 read/write 完成。由于不同的操作系统对 AIO 的支持程度不同，AIO 目前未得到广泛应用。因此本文对 AIO 不做过多描述。 使用 Java NIO 构建的 IO 程序，它的工作模式是：主动轮训 IO 事件，IO 事件发生后程序的线程主动处理 IO 工作，这种模式也叫做 Reactor 模式。使用 Java AIO 构建的 IO 程序，它的工作模式是：将 IO 事件的处理托管给操作系统，操作系统完成 IO 工作之后会通知程序的线程去处理后面的工作，这种模式也叫做 Proactor 模式。\n网路 IO 中阻塞、非阻塞、异步、同步这几个术语的含义和关系：\n阻塞：如果线程调用 read/write 过程，但 read/write 过程没有就绪或没有完成，则调用 read/write 过程的线程会一直等待，这个过程叫做阻塞式读写。 非阻塞：如果线程调用 read/write 过程，但 read/write 过程没有就绪或没有完成，调用 read/write 过程的线程并不会一直等待，而是去处理其他工作，等到 read/write 过程就绪或完成后再回来处理，这个过程叫做阻塞式读写。 异步：read/write 过程托管给操作系统来完成，完成后操作系统会通知（通过回调或者事件）应用网络 IO 程序（其中的线程）来进行后续的处理。 同步：read/write 过程由网络 IO 程序（其中的线程）来完成。 基于以上含义，可以看出：异步 IO 一定是非阻塞 IO；同步 IO 既可以是阻塞 IO、也可以是非阻塞 IO。\nJava NIO API 简单回顾 BIO 以流的方式处理数据，而 NIO 以缓冲区（也被叫做块）的方式处理数据，块 IO 效率比流 IO 效率高很多。BIO 基于字符流或者字节流进行操作，而 NIO 基于 Channel 和 Buffer 进行操作，数据总是从通道读取到缓冲区或者从缓冲区写入到通道。Selector 用于监听多个通道上的事件（比如收到连接请求、数据达到等等），因此使用单个线程就可以监听多个客户端通道。如下图所示：\n关于上图，再进行几点说明：\n一个 Selector 对应一个处理线程 一个 Selector 上可以注册多个 Channel 每个 Channel 都会对应一个 Buffer（有时候一个 Channel 可以使用多个 Buffer，这时候程序要进行多个 Buffer 的分散和聚集操作），Buffer 的本质是一个内存块，底层是一个数组 Selector 会根据不同的事件在各个 Channel 上切换 Buffer 是双向的，既可以读也可以写，切换读写方向要调用 Buffer 的 flip()方法 同样，Channel 也是双向的，数据既可以流入也可以流出 缓冲区（Buffer） 缓冲区（Buffer）本质上是一个可读可写的内存块，可以理解成一个容器对象，Channel 读写文件或者网络都要经由 Buffer。在 Java NIO 中，Buffer 是一个顶层抽象类，它的常用子类有（前缀表示该 Buffer 可以存储哪种类型的数据）：\nByteBuffer CharBuffer ShortBuffer IntBuffer LongBuffer DoubleBuffer FloatBuffer 涵盖了 Java 中除 boolean 之外的所有的基本数据类型。其中 ByteBuffer 支持类型化的数据存取，即可以往 ByteBuffer 中放 byte 类型数据、也可以放 char、int、long、double 等类型的数据，但读取的时候要做好类型匹配处理，否则会抛出 BufferUnderflowException。\n另外，Buffer 体系中还有一个重要的 MappedByteBuffer（ByteBuffer 的子类），可以让文件内容直接在堆外内存中被修改，而如何同步到文件由 NIO 来完成。本文重点不在于此，有兴趣的可以去探究一下 MappedByteBuffer 的底层原理。\n通道（Channel） 通道（Channel）是双向的，可读可写。在 Java NIO 中，Buffer 是一个顶层接口，它的常用子类有：\nFileChannel：用于文件读写 DatagramChannel：用于 UDP 数据包收发 ServerSocketChannel：用于服务端 TCP 数据包收发 SocketChannel：用于客户端 TCP 数据包收发 选择器（Selector） 选择器（Selector）是实现 IO 多路复用的关键，多个 Channel 注册到某个 Selector 上，当 Channel 上有事件发生时，Selector 就会取得事件然后调用线程去处理事件。也就是说只有当连接上真正有读写等事件发生时，线程才会去进行读写等操作，这就不必为每个连接都创建一个线程，一个线程可以应对多个连接。这就是 IO 多路复用的要义。\nNetty 的 IO 线程 NioEventLoop 聚合了 Selector，可以同时并发处理成百上千的客户端连接，后文会展开描述。\n在 Java NIO 中，Selector 是一个抽象类，它的常用方法有：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 public abstract class Selector implements Closeable { ...... /** * 得到一个选择器对象 */ public static Selector open() throws IOException { return SelectorProvider.provider().openSelector(); } ...... /** * 返回所有发生事件的 Channel 对应的 SelectionKey 的集合，通过 * SelectionKey 可以找到对应的 Channel */ public abstract Set\u0026lt;SelectionKey\u0026gt; selectedKeys(); ...... /** * 返回所有 Channel 对应的 SelectionKey 的集合，通过 SelectionKey * 可以找到对应的 Channel */ public abstract Set\u0026lt;SelectionKey\u0026gt; keys(); ...... /** * 监控所有注册的 Channel，当其中的 Channel 有 IO 操作可以进行时， * 将这些 Channel 对应的 SelectionKey 找到。参数用于设置超时时间 */ public abstract int select(long timeout) throws IOException; /** * 无超时时间的 select 过程，一直等待，直到发现有 Channel 可以进行 * IO 操作 */ public abstract int select() throws IOException; /** * 立即返回的 select 过程 */ public abstract int selectNow() throws IOException; ...... /** * 唤醒 Selector，对无超时时间的 select 过程起作用，终止其等待 */ public abstract Selector wakeup(); ...... } 在上文的使用 Java NIO 编写的服务端示例代码中，服务端的工作流程为：\n当客户端发起连接时，会通过 ServerSocketChannel 创建对应的 SocketChannel。 调用 SocketChannel 的注册方法将 SocketChannel 注册到 Selector 上，注册方法返回一个 SelectionKey，该 SelectionKey 会被放入 Selector 内部的 SelectionKey 集合中。该 SelectionKey 和 Selector 关联（即通过 SelectionKey 可以找到对应的 Selector），也和 SocketChannel 关联（即通过 SelectionKey 可以找到对应的 SocketChannel）。 Selector 会调用 select()/select(timeout)/selectNow()方法对内部的 SelectionKey 集合关联的 SocketChannel 集合进行监听，找到有事件发生的 SocketChannel 对应的 SelectionKey。 通过 SelectionKey 找到有事件发生的 SocketChannel，完成数据处理。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 /** * SocketChannel 继承 AbstractSelectableChannel */ public abstract class SocketChannel extends AbstractSelectableChannel implements ByteChannel, ScatteringByteChannel, GatheringByteChannel, NetworkChannel { ...... } public abstract class AbstractSelectableChannel extends SelectableChannel { ...... /** * AbstractSelectableChannel 中包含注册方法，SocketChannel 实例 * 借助该注册方法注册到 Selector 实例上去，该方法返回 SelectionKey */ public final SelectionKey register( // 指明注册到哪个 Selector 实例 Selector sel, // ops 是事件代码，告诉 Selector 应该关注该通道的什么事件 int ops, // 附加信息 attachment Object att) throws ClosedChannelException { ...... } ...... } public abstract class SelectionKey { ...... /** * 获取该 SelectionKey 对应的 Channel */ public abstract SelectableChannel channel(); /** * 获取该 SelectionKey 对应的 Selector */ public abstract Selector selector(); ...... /** * 事件代码，上面的 ops 参数取这里的值 */ public static final int OP_READ = 1 \u0026lt;\u0026lt; 0; public static final int OP_WRITE = 1 \u0026lt;\u0026lt; 2; public static final int OP_CONNECT = 1 \u0026lt;\u0026lt; 3; public static final int OP_ACCEPT = 1 \u0026lt;\u0026lt; 4; ...... /** * 检查该 SelectionKey 对应的 Channel 是否可读 */ public final boolean isReadable() { return (readyOps() \u0026amp; OP_READ) != 0; } /** * 检查该 SelectionKey 对应的 Channel 是否可写 */ public final boolean isWritable() { return (readyOps() \u0026amp; OP_WRITE) != 0; } /** * 检查该 SelectionKey 对应的 Channel 是否已经建立起 socket 连接 */ public final boolean isConnectable() { return (readyOps() \u0026amp; OP_CONNECT) != 0; } /** * 检查该 SelectionKey 对应的 Channel 是否准备好接受一个新的 socket 连接 */ public final boolean isAcceptable() { return (readyOps() \u0026amp; OP_ACCEPT) != 0; } /** * 添加附件（例如 Buffer） */ public final Object attach(Object ob) { return attachmentUpdater.getAndSet(this, ob); } /** * 获取附件 */ public final Object attachment() { return attachment; } ...... } 下图用于辅助读者理解上面的过程和源码：\n首先说明，本文以 Linux 系统为对象来研究文件 IO 模型和网络 IO 模型。\n零拷贝技术 注：本节讨论的是 Linux 系统下的 IO 过程。并且对于零拷贝技术的讲解采用了一种浅显易懂但能触及其本质的方式，因为这个话题，展开来讲实在是有太多的细节要关注。\n在\u0026quot;将本地磁盘中文件发送到网络中\u0026quot;这一场景中，零拷贝技术是提升 IO 效率的一个利器，为了对比出零拷贝技术的优越性，下面依次给出使用直接 IO 技术、内存映射文件技术、零拷贝技术实现将本地磁盘文件发送到网络中的过程。\n直接 IO 技术 使用直接 IO 技术实现文件传输的过程如下图所示。\n上图中，内核缓冲区是 Linux 系统的 Page Cahe。为了加快磁盘的 IO，Linux 系统会把磁盘上的数据以 Page 为单位缓存在操作系统的内存里，这里的 Page 是 Linux 系统定义的一个逻辑概念，一个 Page 一般为 4K。\n可以看出，整个过程有四次数据拷贝，读进来两次，写回去又两次：磁盘\u0026ndash;\u0026gt;内核缓冲区\u0026ndash;\u0026gt;Socket 缓冲区\u0026ndash;\u0026gt;网络。\n直接 IO 过程使用的 Linux 系统 API 为：\n1 2 ssize_t read(int filedes, void *buf, size_t nbytes); ssize_t write(int filedes, void *buf, size_t nbytes); 等函数。\n内存映射文件技术 使用内存映射文件技术实现文件传输的过程如下图所示。\n可以看出，整个过程有三次数据拷贝，不再经过应用程序内存，直接在内核空间中从内核缓冲区拷贝到 Socket 缓冲区。\n内存映射文件过程使用的 Linux 系统 API 为：\n1 void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); 零拷贝技术 使用零拷贝技术，连内核缓冲区到 Socket 缓冲区的拷贝也省略了，如下图所示：\n内核缓冲区到 Socket 缓冲区之间并没有做数据的拷贝，只是一个地址的映射。底层的网卡驱动程序要读取数据并发送到网络上的时候，看似读取的是 Socket 的缓冲区中的数据，其实直接读的是内核缓冲区中的数据。\n零拷贝中所谓的零指的是内存中数据拷贝的次数为 0。\n零拷贝过程使用的 Linux 系统 API 为：\n1 ssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count); 在 JDK 中，提供的：\n1 FileChannel.transderTo(long position, long count, WritableByteChannel target); 方法实现了零拷贝过程，其中的第三个参数可以传入 SocketChannel 实例。例如客户端使用以上的零拷贝接口向服务器传输文件的代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 public static void main(String[] args) throws IOException { SocketChannel socketChannel = SocketChannel.open(); socketChannel.connect(new InetSocketAddress(\u0026#34;127.0.0.1\u0026#34;, 8080)); String fileName = \u0026#34;test.zip\u0026#34;; // 得到一个文件 channel FileChannel fileChannel = new FileInputStream(fileName).getChannel(); // 使用零拷贝 IO 技术发送 long transferSize = fileChannel.transferTo(0, fileChannel.size(), socketChannel); System.out.println(\u0026#34;file transfer done, size: \u0026#34; + transferSize); fileChannel.close(); } Netty 的架构与原理 为什么要制造 Netty 既然 Java 提供了 NIO，为什么还要制造一个 Netty，主要原因是 Java NIO 有以下几个缺点：\nJava NIO 的类库和 API 庞大繁杂，使用起来很麻烦，开发工作量大。 使用 Java NIO，程序员需要具备高超的 Java 多线程编码技能，以及非常熟悉网络编程，比如要处理断连重连、网络闪断、半包读写、失败缓存、网络拥塞和异常流处理等一系列棘手的工作。 Java NIO 存在 Bug，例如 Epoll Bug 会导致 Selector 空轮训，极大耗费 CPU 资源。 Netty 对于 JDK 自带的 NIO 的 API 进行了封装，解决了上述问题，提高了 IO 程序的开发效率和可靠性，同时 Netty：\n设计优雅，提供阻塞和非阻塞的 Socket；提供灵活可拓展的事件模型；提供高度可定制的线程模型。 具备更高的性能和更大的吞吐量，使用零拷贝技术最小化不必要的内存复制，减少资源的消耗。 提供安全传输特性。 支持多种主流协议。预置多种编解码功能，支持用户开发私有协议。 所谓支持 TCP、UDP、HTTP、WebSocket 等协议，就是说 Netty 提供了相关的编程类和接口，因此本文后面主要对基于 Netty 的 TCP Server/Client 开发案例进行讲解，以展示 Netty 的核心原理。\n我们从其中的几个关键词就能看出 Netty 的强大之处：\n零拷贝、可拓展事件模型； 支持 TCP、UDP、HTTP、WebSocket 等协议； 提供安全传输、压缩、大文件传输、编解码支持等等。 几种 Reactor 线程模式 传统的 BIO 服务端编程采用\u0026quot;每线程每连接\u0026quot;的处理模型，弊端很明显，就是面对大量的客户端并发连接时，服务端的资源压力很大；并且线程的利用率很低，如果当前线程没有数据可读，它会阻塞在 read 操作上。这个模型的基本形态如下图所示（图片来源于网络）。\nBIO 服务端编程采用的是 Reactor 模式（也叫做 Dispatcher 模式，分派模式），Reactor 模式有两个要义：\n基于 IO 多路复用技术，多个连接共用一个多路复用器，应用程序的线程无需阻塞等待所有连接，只需阻塞等待多路复用器即可。当某个连接上有新数据可以处理时，应用程序的线程从阻塞状态返回，开始处理这个连接上的业务。 基于线程池技术复用线程资源，不必为每个连接创建专用的线程，应用程序将连接上的业务处理任务分配给线程池中的线程进行处理，一个线程可以处理多个连接的业务。 下图反应了 Reactor 模式的基本形态（图片来源于网络）：\nReactor 模式有两个核心组成部分：\nReactor（图中的 ServiceHandler）：Reactor 在一个单独的线程中运行，负责监听和分发事件，分发给适当的处理线程来对 IO 事件做出反应。 Handlers（图中的 EventHandler）：处理线程执行处理方法来响应 I/O 事件，处理线程执行的是非阻塞操作。 Reactor 模式就是实现网络 IO 程序高并发特性的关键。它又可以分为单 Reactor 单线程模式、单 Reactor 多线程模式、主从 Reactor 多线程模式。\n单 Reactor 单线程模式 单 Reactor 单线程模式的基本形态如下（图片来源于网络）：\n这种模式的基本工作流程为：\nReactor 通过 select 监听客户端请求事件，收到事件之后通过 dispatch 进行分发 如果事件是建立连接的请求事件，则由 Acceptor 通过 accept 处理连接请求，然后创建一个 Handler 对象处理连接建立后的后续业务处理。 如果事件不是建立连接的请求事件，则由 Reactor 对象分发给连接对应的 Handler 处理。 Handler 会完成 read\u0026ndash;\u0026gt;业务处理\u0026ndash;\u0026gt;send 的完整处理流程。 这种模式的优点是：模型简单，没有多线程、进程通信、竞争的问题，一个线程完成所有的事件响应和业务处理。当然缺点也很明显：\n存在性能问题，只有一个线程，无法完全发挥多核 CPU 的性能。Handler 在处理某个连接上的业务时，整个进程无法处理其他连接事件，很容易导致性能瓶颈。 存在可靠性问题，若线程意外终止，或者进入死循环，会导致整个系统通信模块不可用，不能接收和处理外部消息，造成节点故障。 单 Reactor 单线程模式使用场景为：客户端的数量有限，业务处理非常快速，比如 Redis 在业务处理的时间复杂度为 O(1)的情况。\n单 Reactor 多线程模式 单 Reactor 单线程模式的基本形态如下（图片来源于网络）：\n这种模式的基本工作流程为：\nReactor 对象通过 select 监听客户端请求事件，收到事件后通过 dispatch 进行分发。 如果事件是建立连接的请求事件，则由 Acceptor 通过 accept 处理连接请求，然后创建一个 Handler 对象处理连接建立后的后续业务处理。 如果事件不是建立连接的请求事件，则由 Reactor 对象分发给连接对应的 Handler 处理。Handler 只负责响应事件，不做具体的业务处理，Handler 通过 read 读取到请求数据后，会分发给后面的 Worker 线程池来处理业务请求。 Worker 线程池会分配独立线程来完成真正的业务处理，并将处理结果返回给 Handler。Handler 通过 send 向客户端发送响应数据。 这种模式的优点是可以充分的利用多核 cpu 的处理能力，缺点是多线程数据共享和控制比较复杂，Reactor 处理所有的事件的监听和响应，在单线程中运行，面对高并发场景还是容易出现性能瓶颈。\n主从 Reactor 多线程模式 单 Reactor 单线程模式的基本形态如下（图片来源于网络）：\n主从 Reactor 多线程模式的基本形态如下（第一章图片来源于网络，第二章图片是 JUC 作者 Doug Lea 老师在《Scalable IO in Java》中给出的示意图，两张图表达的含义一样）：\n针对单 Reactor 多线程模型中，Reactor 在单个线程中运行，面对高并发的场景易成为性能瓶颈的缺陷，主从 Reactor 多线程模式让 Reactor 在多个线程中运行（分成 MainReactor 线程与 SubReactor 线程）。这种模式的基本工作流程为：\nReactor 主线程 MainReactor 对象通过 select 监听客户端连接事件，收到事件后，通过 Acceptor 处理客户端连接事件。 当 Acceptor 处理完客户端连接事件之后（与客户端建立好 Socket 连接），MainReactor 将连接分配给 SubReactor。（即：MainReactor 只负责监听客户端连接请求，和客户端建立连接之后将连接交由 SubReactor 监听后面的 IO 事件。） SubReactor 将连接加入到自己的连接队列进行监听，并创建 Handler 对各种事件进行处理。 当连接上有新事件发生的时候，SubReactor 就会调用对应的 Handler 处理。 Handler 通过 read 从连接上读取请求数据，将请求数据分发给 Worker 线程池进行业务处理。 Worker 线程池会分配独立线程来完成真正的业务处理，并将处理结果返回给 Handler。Handler 通过 send 向客户端发送响应数据。 一个 MainReactor 可以对应多个 SubReactor，即一个 MainReactor 线程可以对应多个 SubReactor 线程。 这种模式的优点是：\nMainReactor 线程与 SubReactor 线程的数据交互简单职责明确，MainReactor 线程只需要接收新连接，SubReactor 线程完成后续的业务处理。 MainReactor 线程与 SubReactor 线程的数据交互简单， MainReactor 线程只需要把新连接传给 SubReactor 线程，SubReactor 线程无需返回数据。 多个 SubReactor 线程能够应对更高的并发请求。 这种模式的缺点是编程复杂度较高。但是由于其优点明显，在许多项目中被广泛使用，包括 Nginx、Memcached、Netty 等。 这种模式也被叫做服务器的 1+M+N 线程模式，即使用该模式开发的服务器包含一个（或多个，1 只是表示相对较少）连接建立线程+M 个 IO 线程+N 个业务处理线程。这是业界成熟的服务器程序设计模式。\nNetty 的模样 Netty 的设计主要基于主从 Reactor 多线程模式，并做了一定的改进。本节将使用一种渐进式的描述方式展示 Netty 的模样，即先给出 Netty 的简单版本，然后逐渐丰富其细节，直至展示出 Netty 的全貌。\n简单版本的 Netty 的模样如下：\n关于这张图，作以下几点说明：\nBossGroup 线程维护 Selector，ServerSocketChannel 注册到这个 Selector 上，只关注连接建立请求事件（相当于主 Reactor）。 当接收到来自客户端的连接建立请求事件的时候，通过 ServerSocketChannel.accept 方法获得对应的 SocketChannel，并封装成 NioSocketChannel 注册到 WorkerGroup 线程中的 Selector，每个 Selector 运行在一个线程中（相当于从 Reactor）。 当 WorkerGroup 线程中的 Selector 监听到自己感兴趣的 IO 事件后，就调用 Handler 进行处理。 我们给这简单版的 Netty 添加一些细节：\n关于这张图，作以下几点说明：\n有两组线程池：BossGroup 和 WorkerGroup，BossGroup 中的线程（可以有多个，图中只画了一个）专门负责和客户端建立连接，WorkerGroup 中的线程专门负责处理连接上的读写。 BossGroup 和 WorkerGroup 含有多个不断循环的执行事件处理的线程，每个线程都包含一个 Selector，用于监听注册在其上的 Channel。 每个 BossGroup 中的线程循环执行以下三个步骤： 轮训注册在其上的 ServerSocketChannel 的 accept 事件（OP_ACCEPT 事件） 处理 accept 事件，与客户端建立连接，生成一个 NioSocketChannel，并将其注册到 WorkerGroup 中某个线程上的 Selector 上 再去以此循环处理任务队列中的下一个事件 每个 WorkerGroup 中的线程循环执行以下三个步骤： 轮训注册在其上的 NioSocketChannel 的 read/write 事件（OP_READ/OP_WRITE 事件） 在对应的 NioSocketChannel 上处理 read/write 事件 再去以此循环处理任务队列中的下一个事件 我们再来看下终极版的 Netty 的模样，如下图所示（图片来源于网络）：\n关于这张图，作以下几点说明：\nNetty 抽象出两组线程池：BossGroup 和 WorkerGroup，也可以叫做 BossNioEventLoopGroup 和 WorkerNioEventLoopGroup。每个线程池中都有 NioEventLoop 线程。BossGroup 中的线程专门负责和客户端建立连接，WorkerGroup 中的线程专门负责处理连接上的读写。BossGroup 和 WorkerGroup 的类型都是 NioEventLoopGroup。 NioEventLoopGroup 相当于一个事件循环组，这个组中含有多个事件循环，每个事件循环就是一个 NioEventLoop。 NioEventLoop 表示一个不断循环的执行事件处理的线程，每个 NioEventLoop 都包含一个 Selector，用于监听注册在其上的 Socket 网络连接（Channel）。 NioEventLoopGroup 可以含有多个线程，即可以含有多个 NioEventLoop。 每个 BossNioEventLoop 中循环执行以下三个步骤： select：轮训注册在其上的 ServerSocketChannel 的 accept 事件（OP_ACCEPT 事件） processSelectedKeys：处理 accept 事件，与客户端建立连接，生成一个 NioSocketChannel，并将其注册到某个 WorkerNioEventLoop 上的 Selector 上 runAllTasks：再去以此循环处理任务队列中的其他任务 每个 WorkerNioEventLoop 中循环执行以下三个步骤： select：轮训注册在其上的 NioSocketChannel 的 read/write 事件（OP_READ/OP_WRITE 事件） processSelectedKeys：在对应的 NioSocketChannel 上处理 read/write 事件 runAllTasks：再去以此循环处理任务队列中的其他任务 在以上两个processSelectedKeys步骤中，会使用 Pipeline（管道），Pipeline 中引用了 Channel，即通过 Pipeline 可以获取到对应的 Channel，Pipeline 中维护了很多的处理器（拦截处理器、过滤处理器、自定义处理器等）。这里暂时不详细展开讲解 Pipeline。 基于 Netty 的 TCP Server/Client 案例 下面我们写点代码来加深理解 Netty 的模样。下面两段代码分别是基于 Netty 的 TCP Server 和 TCP Client。\n服务端代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 /** * 需要的依赖： * \u0026lt;dependency\u0026gt; * \u0026lt;groupId\u0026gt;io.netty\u0026lt;/groupId\u0026gt; * \u0026lt;artifactId\u0026gt;netty-all\u0026lt;/artifactId\u0026gt; * \u0026lt;version\u0026gt;4.1.52.Final\u0026lt;/version\u0026gt; * \u0026lt;/dependency\u0026gt; */ public static void main(String[] args) throws InterruptedException { // 创建 BossGroup 和 WorkerGroup // 1. bossGroup 只处理连接请求 // 2. 业务处理由 workerGroup 来完成 EventLoopGroup bossGroup = new NioEventLoopGroup(); EventLoopGroup workerGroup = new NioEventLoopGroup(); try { // 创建服务器端的启动对象 ServerBootstrap bootstrap = new ServerBootstrap(); // 配置参数 bootstrap // 设置线程组 .group(bossGroup, workerGroup) // 说明服务器端通道的实现类（便于 Netty 做反射处理） .channel(NioServerSocketChannel.class) // 设置等待连接的队列的容量（当客户端连接请求速率大于 // NioServerSocketChannel 接收速率的时候，会使用该队列做缓冲） // option()方法用于给服务端的 ServerSocketChannel添加配置 .option(ChannelOption.SO_BACKLOG, 128) // 设置连接保活 // childOption()方法用于给服务端 ServerSocketChannel // 接收到的 SocketChannel 添加配置 .childOption(ChannelOption.SO_KEEPALIVE, true) // handler()方法用于给 BossGroup 设置业务处理器 // childHandler()方法用于给 WorkerGroup 设置业务处理器 .childHandler( // 创建一个通道初始化对象 new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { // 向 Pipeline 添加业务处理器 @Override protected void initChannel( SocketChannel socketChannel ) throws Exception { socketChannel.pipeline().addLast( new NettyServerHandler() ); // 可以继续调用 socketChannel.pipeline().addLast() // 添加更多 Handler } } ); System.out.println(\u0026#34;server is ready...\u0026#34;); // 绑定端口，启动服务器，生成一个 channelFuture 对象， // ChannelFuture 涉及到 Netty 的异步模型，后面展开讲 ChannelFuture channelFuture = bootstrap.bind(8080).sync(); // 对通道关闭进行监听 channelFuture.channel().closeFuture().sync(); } finally { bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); } } /** * 自定义一个 Handler，需要继承 Netty 规定好的某个 HandlerAdapter（规范） * InboundHandler 用于处理数据流入本端（服务端）的 IO 事件 * InboundHandler 用于处理数据流出本端（服务端）的 IO 事件 */ static class NettyServerHandler extends ChannelInboundHandlerAdapter { /** * 当通道有数据可读时执行 * * @param ctx 上下文对象，可以从中取得相关联的 Pipeline、Channel、客户端地址等 * @param msg 客户端发送的数据 * @throws Exception */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { // 接收客户端发来的数据 System.out.println(\u0026#34;client address: \u0026#34; + ctx.channel().remoteAddress()); // ByteBuf 是 Netty 提供的类，比 NIO 的 ByteBuffer 性能更高 ByteBuf byteBuf = (ByteBuf) msg; System.out.println(\u0026#34;data from client: \u0026#34; + byteBuf.toString(CharsetUtil.UTF_8)); } /** * 数据读取完毕后执行 * * @param ctx 上下文对象 * @throws Exception */ @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception { // 发送响应给客户端 ctx.writeAndFlush( // Unpooled 类是 Netty 提供的专门操作缓冲区的工具 // 类，copiedBuffer 方法返回的 ByteBuf 对象类似于 // NIO 中的 ByteBuffer，但性能更高 Unpooled.copiedBuffer( \u0026#34;hello client! i have got your data.\u0026#34;, CharsetUtil.UTF_8 ) ); } /** * 发生异常时执行 * * @param ctx 上下文对象 * @param cause 异常对象 * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { // 关闭与客户端的 Socket 连接 ctx.channel().close(); } } 客户端端代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 /** * 需要的依赖： * \u0026lt;dependency\u0026gt; * \u0026lt;groupId\u0026gt;io.netty\u0026lt;/groupId\u0026gt; * \u0026lt;artifactId\u0026gt;netty-all\u0026lt;/artifactId\u0026gt; * \u0026lt;version\u0026gt;4.1.52.Final\u0026lt;/version\u0026gt; * \u0026lt;/dependency\u0026gt; */ public static void main(String[] args) throws InterruptedException { // 客户端只需要一个事件循环组，可以看做 BossGroup EventLoopGroup eventLoopGroup = new NioEventLoopGroup(); try { // 创建客户端的启动对象 Bootstrap bootstrap = new Bootstrap(); // 配置参数 bootstrap // 设置线程组 .group(eventLoopGroup) // 说明客户端通道的实现类（便于 Netty 做反射处理） .channel(NioSocketChannel.class) // handler()方法用于给 BossGroup 设置业务处理器 .handler( // 创建一个通道初始化对象 new ChannelInitializer\u0026lt;SocketChannel\u0026gt;() { // 向 Pipeline 添加业务处理器 @Override protected void initChannel( SocketChannel socketChannel ) throws Exception { socketChannel.pipeline().addLast( new NettyClientHandler() ); // 可以继续调用 socketChannel.pipeline().addLast() // 添加更多 Handler } } ); System.out.println(\u0026#34;client is ready...\u0026#34;); // 启动客户端去连接服务器端，ChannelFuture 涉及到 Netty 的异步模型，后面展开讲 ChannelFuture channelFuture = bootstrap.connect(\u0026#34;127.0.0.1\u0026#34;, 8080).sync(); // 对通道关闭进行监听 channelFuture.channel().closeFuture().sync(); } finally { eventLoopGroup.shutdownGracefully(); } } /** * 自定义一个 Handler，需要继承 Netty 规定好的某个 HandlerAdapter（规范） * InboundHandler 用于处理数据流入本端（客户端）的 IO 事件 * InboundHandler 用于处理数据流出本端（客户端）的 IO 事件 */ static class NettyClientHandler extends ChannelInboundHandlerAdapter { /** * 通道就绪时执行 * * @param ctx 上下文对象 * @throws Exception */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception { // 向服务器发送数据 ctx.writeAndFlush( // Unpooled 类是 Netty 提供的专门操作缓冲区的工具 // 类，copiedBuffer 方法返回的 ByteBuf 对象类似于 // NIO 中的 ByteBuffer，但性能更高 Unpooled.copiedBuffer( \u0026#34;hello server!\u0026#34;, CharsetUtil.UTF_8 ) ); } /** * 当通道有数据可读时执行 * * @param ctx 上下文对象 * @param msg 服务器端发送的数据 * @throws Exception */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { // 接收服务器端发来的数据 System.out.println(\u0026#34;server address: \u0026#34; + ctx.channel().remoteAddress()); // ByteBuf 是 Netty 提供的类，比 NIO 的 ByteBuffer 性能更高 ByteBuf byteBuf = (ByteBuf) msg; System.out.println(\u0026#34;data from server: \u0026#34; + byteBuf.toString(CharsetUtil.UTF_8)); } /** * 发生异常时执行 * * @param ctx 上下文对象 * @param cause 异常对象 * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception { // 关闭与服务器端的 Socket 连接 ctx.channel().close(); } } 什么？你觉得使用 Netty 编程难度和工作量更大了？不会吧不会吧，你要知道，你通过这么两段简短的代码得到了一个基于主从 Reactor 多线程模式的服务器，一个高吞吐量和并发量的服务器，一个异步处理服务器……你还要怎样？\n对上面的两段代码，作以下简单说明：\nBootstrap 和 ServerBootstrap 分别是客户端和服务器端的引导类，一个 Netty 应用程序通常由一个引导类开始，主要是用来配置整个 Netty 程序、设置业务处理类（Handler）、绑定端口、发起连接等。 客户端创建一个 NioSocketChannel 作为客户端通道，去连接服务器。 服务端首先创建一个 NioServerSocketChannel 作为服务器端通道，每当接收一个客户端连接就产生一个 NioSocketChannel 应对该客户端。 使用 Channel 构建网络 IO 程序的时候，不同的协议、不同的阻塞类型和 Netty 中不同的 Channel 对应，常用的 Channel 有： NioSocketChannel：非阻塞的 TCP 客户端 Channel（本案例的客户端使用的 Channel） NioServerSocketChannel：非阻塞的 TCP 服务器端 Channel（本案例的服务器端使用的 Channel） NioDatagramChannel：非阻塞的 UDP Channel NioSctpChannel：非阻塞的 SCTP 客户端 Channel NioSctpServerChannel：非阻塞的 SCTP 服务器端 Channel \u0026hellip;\u0026hellip; 启动服务端和客户端代码，调试以上的服务端代码，发现：\n默认情况下 BossGroup 和 WorkerGroup 都包含 16 个线程（NioEventLoop），这是因为我的 PC 是 8 核的 NioEventLoop 的数量=coreNum*2。这 16 个线程相当于主 Reactor。 其实创建 BossGroup 和 WorkerGroup 的时候可以指定 NioEventLoop 数量，如下：\n1 2 EventLoopGroup bossGroup = new NioEventLoopGroup(1); EventLoopGroup workerGroup = new NioEventLoopGroup(16); 这样就能更好地分配线程资源。\n每一个 NioEventLoop 包含如下的属性（比如自己的 Selector、任务队列、执行器等）： 将代码断在服务端的 NettyServerHandler.channelRead 上： 可以看到 ctx 中包含的属性如下：\n可以看到：\n当前 ChannelHandlerContext ctx 是位于 ChannelHandlerContext 责任链中的一环，可以看到其 next、prev 属性 当前 ChannelHandlerContext ctx 包含一个 Handler 当前 ChannelHandlerContext ctx 包含一个 Pipeline Pipeline 本质上是一个双向循环列表，可以看到其 tail、head 属性 Pipeline 中包含一个 Channel，Channel 中又包含了该 Pipeline，两者互相引用 …… 从下一节开始，我将深入剖析以上两段代码，向读者展示 Netty 的更多细节。\nNetty 的 Handler 组件 无论是服务端代码中自定义的 NettyServerHandler 还是客户端代码中自定义的 NettyClientHandler，都继承于 ChannelInboundHandlerAdapter，ChannelInboundHandlerAdapter 又继承于 ChannelHandlerAdapter，ChannelHandlerAdapter 又实现了 ChannelHandler：\n1 2 3 4 public class ChannelInboundHandlerAdapter extends ChannelHandlerAdapter implements ChannelInboundHandler { ...... 1 2 3 public abstract class ChannelHandlerAdapter implements ChannelHandler { ...... 因此无论是服务端代码中自定义的 NettyServerHandler 还是客户端代码中自定义的 NettyClientHandler，都可以统称为 ChannelHandler。\nNetty 中的 ChannelHandler 的作用是，在当前 ChannelHandler 中处理 IO 事件，并将其传递给 ChannelPipeline 中下一个 ChannelHandler 处理，因此多个 ChannelHandler 形成一个责任链，责任链位于 ChannelPipeline 中。\n数据在基于 Netty 的服务器或客户端中的处理流程是：读取数据\u0026ndash;\u0026gt;解码数据\u0026ndash;\u0026gt;处理数据\u0026ndash;\u0026gt;编码数据\u0026ndash;\u0026gt;发送数据。其中的每个过程都用得到 ChannelHandler 责任链。\nNetty 中的 ChannelHandler 体系如下（第一张图来源于网络）：\n其中：\nChannelInboundHandler 用于处理入站 IO 事件 ChannelOutboundHandler 用于处理出站 IO 事件 ChannelInboundHandlerAdapter 用于处理入站 IO 事件 ChannelOutboundHandlerAdapter 用于处理出站 IO 事件 ChannelPipeline 提供了 ChannelHandler 链的容器。以客户端应用程序为例，如果事件的方向是从客户端到服务器的，我们称事件是出站的，那么客户端发送给服务器的数据会通过 Pipeline 中的一系列 ChannelOutboundHandler 进行处理；如果事件的方向是从服务器到客户端的，我们称事件是入站的，那么服务器发送给客户端的数据会通过 Pipeline 中的一系列 ChannelInboundHandler 进行处理。\n无论是服务端代码中自定义的 NettyServerHandler 还是客户端代码中自定义的 NettyClientHandler，都继承于 ChannelInboundHandlerAdapter，ChannelInboundHandlerAdapter 提供的方法如下：\n从方法名字可以看出，它们在不同的事件发生后被触发，例如注册 Channel 时执行 channelRegistred()、添加 ChannelHandler 时执行 handlerAdded()、收到入站数据时执行 channelRead()、入站数据读取完毕后执行 channelReadComplete()等等。\nNetty 的 Pipeline 组件 上一节说到，Netty 的 ChannelPipeline，它维护了一个 ChannelHandler 责任链，负责拦截或者处理 inbound（入站）和 outbound（出站）的事件和操作。这一节给出更深层次的描述。\nChannelPipeline 实现了一种高级形式的拦截过滤器模式，使用户可以完全控制事件的处理方式，以及 Channel 中各个 ChannelHandler 如何相互交互。\n每个 Netty Channel 包含了一个 ChannelPipeline（其实 Channel 和 ChannelPipeline 互相引用），而 ChannelPipeline 又维护了一个由 ChannelHandlerContext 构成的双向循环列表，其中的每一个 ChannelHandlerContext 都包含一个 ChannelHandler。（前文描述的时候为了简便，直接说 ChannelPipeline 包含了一个 ChannelHandler 责任链，这里给出完整的细节。）\n如下图所示（图片来源于网络）：\n还记得下面这张图吗？这是上文中基于 Netty 的 Server 程序的调试截图，可以从中看到 ChannelHandlerContext 中包含了哪些成分：\nChannelHandlerContext 除了包含 ChannelHandler 之外，还关联了对应的 Channel 和 Pipeline。可以这么来讲：ChannelHandlerContext、ChannelHandler、Channel、ChannelPipeline 这几个组件之间互相引用，互为各自的属性，你中有我、我中有你。\n在处理入站事件的时候，入站事件及数据会从 Pipeline 中的双向链表的头 ChannelHandlerContext 流向尾 ChannelHandlerContext，并依次在其中每个 ChannelInboundHandler（例如解码 Handler）中得到处理；出站事件及数据会从 Pipeline 中的双向链表的尾 ChannelHandlerContext 流向头 ChannelHandlerContext，并依次在其中每个 ChannelOutboundHandler（例如编码 Handler）中得到处理。\nNetty 的 EventLoopGroup 组件 在基于 Netty 的 TCP Server 代码中，包含了两个 EventLoopGroup——bossGroup 和 workerGroup，EventLoopGroup 是一组 EventLoop 的抽象。\n追踪 Netty 的 EventLoop 的继承链，可以发现 EventLoop 最终继承于 JUC Executor，因此 EventLoop 本质就是一个 JUC Executor，即线程，JUC Executor 的源码为：\n1 2 3 4 5 6 public interface Executor { /** * Executes the given command at some time in the future. */ void execute(Runnable command); } Netty 为了更好地利用多核 CPU 的性能，一般会有多个 EventLoop 同时工作，每个 EventLoop 维护着一个 Selector 实例，Selector 实例监听注册其上的 Channel 的 IO 事件。\nEventLoopGroup 含有一个 next 方法，它的作用是按照一定规则从 Group 中选取一个 EventLoop 处理 IO 事件。\n在服务端，通常 Boss EventLoopGroup 只包含一个 Boss EventLoop（单线程），该 EventLoop 维护者一个注册了 ServerSocketChannel 的 Selector 实例。该 EventLoop 不断轮询 Selector 得到 OP_ACCEPT 事件（客户端连接事件），然后将接收到的 SocketChannel 交给 Worker EventLoopGroup，Worker EventLoopGroup 会通过 next()方法选取一个 Worker EventLoop 并将这个 SocketChannel 注册到其中的 Selector 上，由这个 Worker EventLoop 负责该 SocketChannel 上后续的 IO 事件处理。整个过程如下图所示：\nNetty 的 TaskQueue 在 Netty 的每一个 NioEventLoop 中都有一个 TaskQueue，设计它的目的是在任务提交的速度大于线程的处理速度的时候起到缓冲作用。或者用于异步地处理 Selector 监听到的 IO 事件。\nNetty 中的任务队列有三种使用场景：\n处理用户程序的自定义普通任务的时候 处理用户程序的自定义定时任务的时候 非当前 Reactor 线程调用当前 Channel 的各种方法的时候。 对于第一种场景，举个例子，2.4 节的基于 Netty 编写的服务端的 Handler 中，假如 channelRead 方法中执行的过程很耗时，那么以下的阻塞式处理方式无疑会降低当前 NioEventLoop 的并发度：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /** * 当通道有数据可读时执行 * * @param ctx 上下文对象 * @param msg 客户端发送的数据 * @throws Exception */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { // 借助休眠模拟耗时操作 Thread.sleep(LONG_TIME); ByteBuf byteBuf = (ByteBuf) msg; System.out.println(\u0026#34;data from client: \u0026#34; + byteBuf.toString(CharsetUtil.UTF_8)); } 改进方法就是借助任务队列，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 /** * 当通道有数据可读时执行 * * @param ctx 上下文对象 * @param msg 客户端发送的数据 * @throws Exception */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { // 假如这里的处理非常耗时，那么就需要借助任务队列异步执行 final Object finalMsg = msg; // 通过 ctx.channel().eventLoop().execute()将耗时 // 操作放入任务队列异步执行 ctx.channel().eventLoop().execute(new Runnable() { public void run() { // 借助休眠模拟耗时操作 try { Thread.sleep(LONG_TIME); } catch (InterruptedException e) { e.printStackTrace(); } ByteBuf byteBuf = (ByteBuf) finalMsg; System.out.println(\u0026#34;data from client: \u0026#34; + byteBuf.toString(CharsetUtil.UTF_8)); } }); // 可以继续调用 ctx.channel().eventLoop().execute() // 将更多操作放入队列 System.out.println(\u0026#34;return right now.\u0026#34;); } 断点跟踪这个函数的执行，可以发现该耗时任务确实被放入的当前 NioEventLoop 的 taskQueue 中了。\n对于第二种场景，举个例子，2.4 节的基于 Netty 编写的服务端的 Handler 中，假如 channelRead 方法中执行的过程并不需要立即执行，而是要定时执行，那么代码可以这样写：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 /** * 当通道有数据可读时执行 * * @param ctx 上下文对象 * @param msg 客户端发送的数据 * @throws Exception */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception { final Object finalMsg = msg; // 通过 ctx.channel().eventLoop().schedule()将操作 // 放入任务队列定时执行（5min 之后才进行处理） ctx.channel().eventLoop().schedule(new Runnable() { public void run() { ByteBuf byteBuf = (ByteBuf) finalMsg; System.out.println(\u0026#34;data from client: \u0026#34; + byteBuf.toString(CharsetUtil.UTF_8)); } }, 5, TimeUnit.MINUTES); // 可以继续调用 ctx.channel().eventLoop().schedule() // 将更多操作放入队列 System.out.println(\u0026#34;return right now.\u0026#34;); } 断点跟踪这个函数的执行，可以发现该定时任务确实被放入的当前 NioEventLoop 的 scheduleTasjQueue 中了。\n对于第三种场景，举个例子，比如在基于 Netty 构建的推送系统的业务线程中，要根据用户标识，找到对应的 SocketChannel 引用，然后调用 write 方法向该用户推送消息，这时候就会将这一 write 任务放在任务队列中，write 任务最终被异步消费。这种情形是对前两种情形的应用，且涉及的业务内容太多，不再给出示例代码，读者有兴趣可以自行完成，这里给出以下提示：\nNetty 的 Future 和 Promise Netty**对使用者提供的多数 IO 接口（即 Netty Channel 中的 IO 方法）**是异步的（即都立即返回一个 Netty Future，而 IO 过程异步进行），因此，调用者调用 IO 操作后是不能直接拿到调用结果的。要想得到 IO 操作结果，可以借助 Netty 的 Future（上面代码中的 ChannelFuture 就继承了 Netty Future，Netty Future 又继承了 JUC Future）查询执行状态、等待执行结果、获取执行结果等，使用过 JUC Future 接口的同学会非常熟悉这个机制，这里不再展开描述了。也可以通过 Netty Future 的 addListener()添加一个回调方法来异步处理 IO 结果，如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // 启动客户端去连接服务器端 // 由于 bootstrap.connect()是一个异步操作，因此用.sync()等待 // 这个异步操作完成 final ChannelFuture channelFuture = bootstrap.connect( \u0026#34;127.0.0.1\u0026#34;, 8080).sync(); channelFuture.addListener(new ChannelFutureListener() { /** * 回调方法，上面的 bootstrap.connect()操作执行完之后触发 */ public void operationComplete(ChannelFuture future) throws Exception { if (channelFuture.isSuccess()) { System.out.println(\u0026#34;client has connected to server!\u0026#34;); // TODO 其他处理 } else { System.out.println(\u0026#34;connect to serverfail!\u0026#34;); // TODO 其他处理 } } }); Netty Future 提供的接口有：\n注：会有一些资料给出这样的描述：“Netty 中所有的 IO 操作都是异步的”，这显然是错误的。Netty 基于 Java NIO，Java NIO 是同步非阻塞 IO。Netty 基于 Java NIO 做了封装，向使用者提供了异步特性的接口，因此本文说 Netty**对使用者提供的多数 IO 接口（即 Netty Channel 中的 IO 方法）**是异步的。例如在 io.netty.channel.ChannelOutboundInvoker（Netty Channel 的 IO 方法多继承于此）提供的多数 IO 接口都返回 Netty Future：\nPromise 是可写的 Future，Future 自身并没有写操作相关的接口，Netty 通过 Promise 对 Future 进行扩展，用于设置 IO 操作的结果。Future 继承了 Future，相关的接口定义如下图所示，相比于上图 Future 的接口，它多出了一些 setXXX 方法：\nNetty 发起 IO 写操作的时候，会创建一个新的 Promise 对象，例如调用 ChannelHandlerContext 的 write(Object object)方法时，会创建一个新的 ChannelPromise，相关代码如下：\n1 2 3 4 5 6 7 8 9 10 @Override public ChannelFuture write(Object msg) { return write(msg, newPromise()); } ...... @Override public ChannelPromise newPromise() { return new DefaultChannelPromise(channel(), executor()); } ...... 当 IO 操作发生异常或者完成时，通过 Promise.setSuccess()或者 Promise.setFailure()设置结果，并通知所有 Listener。\n","permalink":"https://WFUing.github.io/posts/tech/network/netty/","summary":"Netty 是 JBoss 开源项目，是异步的、基于事件驱动的网络应用框架，以高性能、高并发著称。Netty 是基于 Java NIO 构建出来的，主要用于开发基于 TCP 协议的网络 IO 程序。","title":"Netty"},{"content":"","permalink":"https://WFUing.github.io/posts/tech/network/https-rsa/","summary":"","title":"HTTPS RSA 握手解析"},{"content":"HTTP HTTP 基本概念 HTTP 是什么？ HTTP 是超文本传输协议，也就是HyperText Transfer Protocol。\n能否详细解释「超文本传输协议」？\nHTTP 的名字「超文本协议传输」，它可以拆成三个部分：\n超文本 传输 协议 1. 「协议」\n在生活中，我们也能随处可见「协议」，例如：\n刚毕业时会签一个「三方协议」； 找房子时会签一个「租房协议」； 生活中的协议，本质上与计算机中的协议是相同的，协议的特点：\n「协」字，代表的意思是必须有两个以上的参与者。例如三方协议里的参与者有三个：你、公司、学校三个；租房协议里的参与者有两个：你和房东。 「议」字，代表的意思是对参与者的一种行为约定和规范。例如三方协议里规定试用期期限、毁约金等；租房协议里规定租期期限、每月租金金额、违约如何处理等。 针对 HTTP 协议，我们可以这么理解。\nHTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。\n2. 「传输」\n所谓的「传输」，很好理解，就是把一堆东西从 A 点搬到 B 点，或者从 B 点 搬到 A 点。\n别轻视了这个简单的动作，它至少包含两项重要的信息。\nHTTP 协议是一个双向协议。\n我们在上网冲浪时，浏览器是请求方 A，百度网站就是应答方 B。双方约定用 HTTP 协议来通信，于是浏览器把请求数据发送给网站，网站再把一些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图片、视频了。\n数据虽然是在 A 和 B 之间传输，但允许中间有中转或接力。\n就好像第一排的同学想传递纸条给最后一排的同学，那么传递的过程中就需要经过好多个同学（中间人），这样的传输方式就从「A \u0026lt; \u0026mdash; \u0026gt; B」，变成了「A \u0026lt;-\u0026gt; N \u0026lt;-\u0026gt; M \u0026lt;-\u0026gt; B」。\n而在 HTTP 里，需要中间人遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东西。\n针对传输，我们可以进一步理解了 HTTP。\nHTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。\n3. 「超文本」\nHTTP 传输的内容是「超文本」。\n我们先来理解「文本」，在互联网早期的时候只是简单的字符文字，但现在「文本」的涵义已经可以扩展为图片、视频、压缩包等，在 HTTP 眼里这些都算作「文本」。\n再来理解「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。\nHTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。\nOK，经过了对 HTTP 里这三个名词的详细解释，就可以给出比「超文本传输协议」这七个字更准确更有技术含量的答案：\nHTTP 是一个在计算机世界里专门在「两点」之间「传输」文字、图片、音频、视频等「超文本」数据的「约定和规范」。\n那「HTTP 是用于从互联网服务器传输超文本到本地浏览器的协议」，这种说法正确吗？\n这种说法是不正确的。因为也可以是「服务器\u0026lt; \u0026ndash; \u0026gt;服务器」，所以采用两点之间的描述会更准确。\nHTTP 常见的状态码有哪些？ 1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。\n「101 Switching Protocols」协议切换，服务器已经理解了客户端的请求，并将通过 Upgrade 消息头通知客户端采用不同的协议来完成这个请求。比如切换到一个实时且同步的协议（如 WebSocket）以传送利用此类特性的资源。 2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。\n「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。\n「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。\n「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。\n3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。\n「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。\n「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。\n301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。\n「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。 4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。\n「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。\n「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。\n「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。\n5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。\n「500 Internal Server Error」与 400 类似，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。\n「501 Not Implemented」表示客户端请求的功能还不支持，类似\u0026quot;即将开业，敬请期待\u0026quot;的意思。\n「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。\n「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似\u0026quot;网络服务正忙，请稍后重试\u0026quot;的意思。\nHTTP 常见字段有哪些？ Host 字段\n客户端发送请求时，用来指定服务器的域名。\n1 Host: www.A.com 有了 Host 字段，就可以将请求发往「同一台」服务器上的不同网站。\nContent-Length 字段\n服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。\n1 Content-Length: 1000 如上面则是告诉浏览器，本次服务器回应的数据长度是 1000 个字节，后面的字节就属于下一个回应了。\n大家应该都知道 HTTP 是基于 TCP 传输协议进行通信的，而使用了 TCP 传输协议，就会存在一个\u0026quot;粘包\u0026quot;的问题，HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决\u0026quot;粘包\u0026quot;的问题。\nConnection 字段\nConnection 字段最常用于客户端要求服务器使用「HTTP 长连接」机制，以便其他请求复用。\nHTTP 长连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。\nHTTP/1.1 版本的默认连接都是长连接，但为了兼容老版本的 HTTP，需要指定 Connection 首部字段的值为 Keep-Alive。\n1 Connection: Keep-Alive 开启了 HTTP Keep-Alive 机制后，连接就不会中断，而是保持连接。当客户端发送另一个请求时，它会使用同一个连接，一直持续到客户端或服务器端提出断开连接。\nPS：大家不要把 HTTP Keep-Alive 和 TCP Keepalive 搞混了，这两个虽然长的像，但是不是一个东西。\nContent-Type 字段\nContent-Type 字段用于服务器回应时，告诉客户端，本次数据是什么格式。\n1 Content-Type: text/html; Charset=utf-8 上面的类型表明，发送的是网页，而且编码是 UTF-8。\n客户端请求的时候，可以使用 Accept 字段声明自己可以接受哪些数据格式。\n1 Accept: */* 上面代码中，客户端声明自己可以接受任何格式的数据。\nContent-Encoding 字段\nContent-Encoding 字段说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式\n1 Content-Encoding: gzip 上面表示服务器返回的数据采用了 gzip 方式压缩，告知客户端需要用此方式解压。\n客户端在请求时，用 Accept-Encoding 字段说明自己可以接受哪些压缩方法。\n1 Accept-Encoding: gzip, deflate GET 与 POST GET 和 POST 有什么区别？ 可见 一次完整的HTTP请求过程\nGET 和 POST 方法都是安全和幂等的吗？ 先说明下安全和幂等的概念：\n在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。 所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。 如果从 RFC 规范定义的语义来看：\nGET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如 nginx），而且在浏览器中 GET 请求可以保存为书签。 POST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。所以，浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。 做个简要的小结。\nGET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。\nPOST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。\n注意，上面是从 RFC 规范定义的语义来分析的。\n但是实际过程中，开发者不一定会按照 RFC 规范定义的语义来实现 GET 和 POST 方法。比如：\n可以用 GET 方法实现新增或删除数据的请求，这样实现的 GET 方法自然就不是安全和幂等。 可以用 POST 方法实现查询数据的请求，这样实现的 POST 方法自然就是安全和幂等。 曾经有个笑话，有人写了个博客，删除博客用的是 GET 请求，他觉得没人访问就连鉴权都没做。然后 Google 服务器爬虫爬了一遍，他所有博文就没了。。。\n如果「安全」放入概念是指信息是否会被泄漏的话，虽然 POST 用 body 传输数据，而 GET 用 URL 传输，这样数据会在浏览器地址拦容易看到，但是并不能说 GET 不如 POST 安全的。\n因为 HTTP 传输的内容都是明文的，虽然在浏览器地址拦看不到 POST 提交的 body 数据，但是只要抓个包就都能看到了。\n所以，要避免传输过程中数据被窃取，就要使用 HTTPS 协议，这样所有 HTTP 的数据都会被加密传输。\nGET 请求可以带 body 吗？\nRFC 规范并没有规定 GET 请求不能带 body 的。理论上，任何请求都可以带 body 的。只是因为 RFC 规范定义的 GET 请求是获取资源，所以根据这个语义不需要用到 body。\n另外，URL 中的查询参数也不是 GET 所独有的，POST 请求的 URL 中也可以有参数的。\nHTTP 缓存技术 HTTP 缓存有哪些实现方式？ 对于一些具有重复性的 HTTP 请求，比如每次请求得到的数据都一样的，我们可以把这对「请求 - 响应」的数据都缓存在本地，那么下次就直接读取本地的数据，不必在通过网络获取服务器的响应了，这样的话 HTTP/1.1 的性能肯定肉眼可见的提升。\n所以，避免发送 HTTP 请求的方法就是通过缓存技术，HTTP 设计者早在之前就考虑到了这点，因此 HTTP 协议的头部有不少是针对缓存的字段。\nHTTP 缓存有两种实现方式，分别是强制缓存和协商缓存。\n什么是强制缓存？ 强缓存指的是只要浏览器判断缓存没有过期，则直接使用浏览器的本地缓存，决定是否使用缓存的主动性在于浏览器这边。\n如下图中，返回的是 200 状态码，但在 size 项中标识的是 from disk cache，就是使用了强制缓存。\n强缓存是利用下面这两个 HTTP 响应头部（Response Header）字段实现的，它们都用来表示资源在客户端缓存的有效期：\nCache-Control，是一个相对时间； Expires，是一个绝对时间； 如果 HTTP 响应头部同时有 Cache-Control 和 Expires 字段的话，Cache-Control 的优先级高于 Expires 。\nCache-control 选项更多一些，设置更加精细，所以建议使用 Cache-Control 来实现强缓存。具体的实现流程如下：\n当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 Cache-Control，Cache-Control 中设置了过期时间大小； 浏览器再次请求访问服务器中的该资源时，会先通过请求资源的时间与 Cache-Control 中设置的过期时间大小，来计算出该资源是否过期，如果没有，则使用该缓存，否则重新请求服务器； 服务器再次收到请求后，会再次更新 Response 头部的 Cache-Control。 什么是协商缓存？ 当我们在浏览器使用开发者工具的时候，你可能会看到过某些请求的响应码是 304，这个是告诉浏览器可以使用本地缓存的资源，通常这种通过服务端告知客户端是否可以使用缓存的方式被称为协商缓存。\n上图就是一个协商缓存的过程，所以协商缓存就是与服务端协商之后，通过协商结果来判断是否使用本地缓存。\n协商缓存可以基于两种头部来实现。\n第一种：请求头部中的 If-Modified-Since 字段与响应头部中的 Last-Modified 字段实现，这两个字段的意思是：\n响应头部中的 Last-Modified：标示这个响应资源的最后修改时间； 请求头部中的 If-Modified-Since：当资源过期了，发现响应头中具有 Last-Modified 声明，则再次发起请求的时候带上 Last-Modified 的时间，服务器收到请求后发现有 If-Modified-Since 则与被请求资源的最后修改时间进行对比（Last-Modified），如果最后修改时间较新（大），说明资源又被改过，则返回最新资源，HTTP 200 OK；如果最后修改时间较旧（小），说明资源无新修改，响应 HTTP 304 走缓存。 第二种：请求头部中的 If-None-Match 字段与响应头部中的 ETag 字段，这两个字段的意思是：\n响应头部中 Etag：唯一标识响应资源； 请求头部中的 If-None-Match：当资源过期时，浏览器发现响应头里有 Etag，则再次向服务器发起请求时，会将请求头 If-None-Match 值设置为 Etag 的值。服务器收到请求后进行比对，如果资源没有变化返回 304，如果资源变化了返回 200。 第一种实现方式是基于时间实现的，第二种实现方式是基于一个唯一标识实现的，相对来说后者可以更加准确地判断文件内容是否被修改，避免由于时间篡改导致的不可靠问题。\n如果在第一次请求资源的时候，服务端返回的 HTTP 响应头部同时有 Etag 和 Last-Modified 字段，那么客户端再下一次请求的时候，如果带上了 ETag 和 Last-Modified 字段信息给服务端，这时 Etag 的优先级更高，也就是服务端先会判断 Etag 是否变化了，如果 Etag 有变化就不用在判断 Last-Modified 了，如果 Etag 没有变化，然后再看 Last-Modified。\n为什么 ETag 的优先级更高？ 这是因为 ETag 主要能解决 Last-Modified 几个比较难以解决的问题：\n在没有修改文件内容情况下文件的最后修改时间可能也会改变，这会导致客户端认为这文件被改动了，从而重新请求； 可能有些文件是在秒级以内修改的，If-Modified-Since 能检查到的粒度是秒级的，使用 Etag 就能够保证这种需求下客户端在 1 秒内能刷新多次； 有些服务器不能精确获取文件的最后修改时间。 注意，协商缓存这两个字段都需要配合强制缓存中 Cache-Control 字段来使用，只有在未能命中强制缓存的时候，才能发起带有协商缓存字段的请求。\n下图是强制缓存和协商缓存的工作流程：\n当使用 ETag 字段实现的协商缓存的过程：\n当浏览器第一次请求访问服务器资源时，服务器会在返回这个资源的同时，在 Response 头部加上 ETag 唯一标识，这个唯一标识的值是根据当前请求的资源生成的； 当浏览器再次请求访问服务器中的该资源时，首先会先检查强制缓存是否过期： 如果没有过期，则直接使用本地缓存； 如果缓存过期了，会在 Request 头部加上 If-None-Match 字段，该字段的值就是 ETag 唯一标识； 服务器再次收到请求后，会根据请求中的 If-None-Match 值与当前请求的资源生成的唯一标识进行比较： 如果值相等，则返回 304 Not Modified，不会返回资源； 如果不相等，则返回 200 状态码和返回资源，并在 Response 头部加上新的 ETag 唯一标识； 如果浏览器收到 304 的请求响应状态码，则会从本地缓存中加载资源，否则更新资源。 HTTP 特性 到目前为止，HTTP 常见到版本有 HTTP/1.1，HTTP/2.0，HTTP/3.0，不同版本的 HTTP 特性是不一样的。\n这里先用 HTTP/1.1 版本给大家介绍，其他版本的后续也会介绍。\nHTTP/1.1 的优点有哪些？ HTTP 最突出的优点是「简单、灵活和易于扩展、应用广泛和跨平台」。\n1. 简单\nHTTP 基本的报文格式就是 header + body，头部信息也是 key-value 简单文本的形式，易于理解，降低了学习和使用的门槛。\n2. 灵活和易于扩展\nHTTP 协议里的各类请求方法、URI/URL、状态码、头字段等每个组成要求都没有被固定死，都允许开发人员自定义和扩充。\n同时 HTTP 由于是工作在应用层（ OSI 第七层），则它下层可以随意变化，比如：\nHTTPS 就是在 HTTP 与 TCP 层之间增加了 SSL/TLS 安全传输层； HTTP/1.1 和 HTTP/2.0 传输协议使用的是 TCP 协议，而到了 HTTP/3.0 传输协议改用了 UDP 协议。 3. 应用广泛和跨平台\n互联网发展至今，HTTP 的应用范围非常的广泛，从台式机的浏览器到手机上的各种 APP，从看新闻、刷贴吧到购物、理财、吃鸡，HTTP 的应用遍地开花，同时天然具有跨平台的优越性。\nHTTP/1.1 的缺点有哪些？ HTTP 协议里有优缺点一体的双刃剑，分别是「无状态、明文传输」，同时还有一大缺点「不安全」。\n1. 无状态双刃剑\n无状态的好处，因为服务器不会去记忆 HTTP 的状态，所以不需要额外的资源来记录状态信息，这能减轻服务器的负担，能够把更多的 CPU 和内存用来对外提供服务。\n无状态的坏处，既然服务器没有记忆能力，它在完成有关联性的操作时会非常麻烦。\n例如登录-\u0026gt;添加购物车-\u0026gt;下单-\u0026gt;结算-\u0026gt;支付，这系列操作都要知道用户的身份才行。但服务器不知道这些请求是有关联的，每次都要问一遍身份信息。\n这样每操作一次，都要验证信息，这样的购物体验还能愉快吗？别问，问就是酸爽！\n对于无状态的问题，解法方案有很多种，其中比较简单的方式用 Cookie 技术。\nCookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。\n相当于，在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了，\n2. 明文传输双刃剑\n明文意味着在传输过程中的信息，是可方便阅读的，比如 Wireshark 抓包都可以直接肉眼查看，为我们调试工作带了极大的便利性。\n但是这正是这样，HTTP 的所有信息都暴露在了光天化日下，相当于信息裸奔。在传输的漫长的过程中，信息的内容都毫无隐私可言，很容易就能被窃取，如果里面有你的账号密码信息，那你号没了。\n3. 不安全\nHTTP 比较严重的缺点就是不安全：\n通信使用明文（不加密），内容可能会被窃听。比如，账号信息容易泄漏，那你号没了。 不验证通信方的身份，因此有可能遭遇伪装。比如，访问假的淘宝、拼多多，那你钱没了。 无法证明报文的完整性，所以有可能已遭篡改。比如，网页上植入垃圾广告，视觉污染，眼没了。 HTTP 的安全问题，可以用 HTTPS 的方式解决，也就是通过引入 SSL/TLS 层，使得在安全上达到了极致。\nHTTP/1.1 的性能如何？ HTTP 协议是基于 TCP/IP，并且使用了「请求 - 应答」的通信模式，所以性能的关键就在这两点里。\n1. 长连接\n早期 HTTP/1.0 性能上的一个很大的问题，那就是每发起一个请求，都要新建一次 TCP 连接（三次握手），而且是串行请求，做了无谓的 TCP 连接建立和断开，增加了通信开销。\n为了解决上述 TCP 连接问题，HTTP/1.1 提出了长连接的通信方式，也叫持久连接。这种方式的好处在于减少了 TCP 连接的重复建立和断开所造成的额外开销，减轻了服务器端的负载。\n持久连接的特点是，只要任意一端没有明确提出断开连接，则保持 TCP 连接状态。\n当然，如果某个 HTTP 长连接超过一定时间没有任何数据交互，服务端就会主动断开这个连接。\n2. 管道网络传输\nHTTP/1.1 采用了长连接的方式，这使得管道（pipeline）网络传输成为了可能。\n即可在同一个 TCP 连接里面，客户端可以发起多个请求，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。\n举例来说，客户端需要请求两个资源。以前的做法是，在同一个 TCP 连接里面，先发送 A 请求，然后等待服务器做出回应，收到后再发出 B 请求。那么，管道机制则是允许浏览器同时发出 A 请求和 B 请求，如下图：\n但是服务器必须按照接收请求的顺序发送对这些管道化请求的响应。\n如果服务端在处理 A 请求时耗时比较长，那么后续的请求的处理都会被阻塞住，这称为「队头堵塞」。\n所以，HTTP/1.1 管道解决了请求的队头阻塞，但是没有解决响应的队头阻塞。\n注意!!!\n实际上 HTTP/1.1 管道化技术不是默认开启，而且浏览器基本都没有支持，所以后面所有文章讨论 HTTP/1.1 都是建立在没有使用管道化的前提。大家知道有这个功能，但是没有被使用就行了。\n3. 队头阻塞\n「请求 - 应答」的模式加剧了 HTTP 的性能问题。\n因为当顺序发送的请求序列中的一个请求因为某种原因被阻塞时，在后面排队的所有请求也一同被阻塞了，会招致客户端一直请求不到数据，这也就是「队头阻塞」，好比上班的路上塞车。\n总之 HTTP/1.1 的性能一般般，后续的 HTTP/2 和 HTTP/3 就是在优化 HTTP 的性能。\nHTTP 与 HTTPS HTTP 与 HTTPS 有哪些区别？ HTTP 是超文本传输协议，信息是明文传输，存在安全风险的问题。HTTPS 则解决 HTTP 不安全的缺陷，在 TCP 和 HTTP 网络层之间加入了 SSL/TLS 安全协议，使得报文能够加密传输。\nHTTP 连接建立相对简单，TCP 三次握手之后便可进行 HTTP 的报文传输。而 HTTPS 在 TCP 三次握手之后，还需进行 SSL/TLS 的握手过程，才可进入加密报文传输。\n两者的默认端口不一样，HTTP 默认端口号是 80，HTTPS 默认端口号是 443。\nHTTPS 协议需要向 CA（证书权威机构）申请数字证书，来保证服务器的身份是可信的。\nHTTPS 解决了 HTTP 的哪些问题？ HTTP 由于是明文传输，所以安全上存在以下三个风险：\n窃听风险，比如通信链路上可以获取通信内容，用户号容易没。 篡改风险，比如强制植入垃圾广告，视觉污染，用户眼容易瞎。 冒充风险，比如冒充淘宝网站，用户钱容易没。 HTTPS 在 HTTP 与 TCP 层之间加入了 SSL/TLS 协议，可以很好的解决了上述的风险：\n信息加密：交互信息无法被窃取，但你的号会因为「自身忘记」账号而没。 校验机制：无法篡改通信内容，篡改了就不能正常显示，但百度「竞价排名」依然可以搜索垃圾广告。 身份证书：证明淘宝是真的淘宝网，但你的钱还是会因为「剁手」而没。 可见，只要自身不做「恶」，SSL/TLS 协议是能保证通信是安全的。\nHTTPS 是如何解决上面的三个风险的？\n混合加密的方式实现信息的机密性，解决了窃听的风险。 摘要算法的方式来实现完整性，它能够为数据生成独一无二的「指纹」，指纹用于校验数据的完整性，解决了篡改的风险。 将服务器公钥放入到数字证书中，解决了冒充的风险。 1. 混合加密\n通过混合加密的方式可以保证信息的机密性，解决了窃听的风险。\nHTTPS 采用的是对称加密和非对称加密结合的「混合加密」方式：\n在通信建立前采用非对称加密的方式交换「会话秘钥」，后续就不再使用非对称加密。 在通信过程中全部使用对称加密的「会话秘钥」的方式加密明文数据。 采用「混合加密」的方式的原因：\n对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换。 非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题但速度慢。 2. 摘要算法 + 数字签名\n为了保证传输的内容不被篡改，我们需要对内容计算出一个「指纹」，然后同内容一起传输给对方。\n对方收到后，先是对内容也计算出一个「指纹」，然后跟发送方发送的「指纹」做一个比较，如果「指纹」相同，说明内容没有被篡改，否则就可以判断出内容被篡改了。\n那么，在计算机里会用摘要算法（哈希函数）来计算出内容的哈希值，也就是内容的「指纹」，这个哈希值是唯一的，且无法通过哈希值推导出内容。\n通过哈希算法可以确保内容不会被篡改，但是并不能保证「内容 + 哈希值」不会被中间人替换，因为这里缺少对客户端收到的消息是否来源于服务端的证明。\n举个例子，你想向老师请假，一般来说是要求由家长写一份请假理由并签名，老师才能允许你请假。\n但是你有模仿你爸爸字迹的能力，你用你爸爸的字迹写了一份请假理由然后签上你爸爸的名字，老师一看到这个请假条，查看字迹和签名，就误以为是你爸爸写的，就会允许你请假。\n那作为老师，要如何避免这种情况发生呢？现实生活中的，可以通过电话或视频来确认是否是由父母发出的请假，但是计算机里可没有这种操作。\n那为了避免这种情况，计算机里会用非对称加密算法来解决，共有两个密钥：\n一个是公钥，这个是可以公开给所有人的； 一个是私钥，这个必须由本人管理，不可泄露。 这两个密钥可以双向加解密的，比如可以用公钥加密内容，然后用私钥解密，也可以用私钥加密内容，公钥解密内容。\n流程的不同，意味着目的也不相同：\n公钥加密，私钥解密。这个目的是为了保证内容传输的安全，因为被公钥加密的内容，其他人是无法解密的，只有持有私钥的人，才能解密出实际的内容； 私钥加密，公钥解密。这个目的是为了保证消息不会被冒充，因为私钥是不可泄露的，如果公钥能正常解密出私钥加密的内容，就能证明这个消息是来源于持有私钥身份的人发送的。 一般我们不会用非对称加密来加密实际的传输内容，因为非对称加密的计算比较耗费性能的。\n所以非对称加密的用途主要在于通过「私钥加密，公钥解密」的方式，来确认消息的身份，我们常说的数字签名算法，就是用的是这种方式，不过私钥加密内容不是内容本身，而是对内容的哈希值加密。\n私钥是由服务端保管，然后服务端会向客户端颁发对应的公钥。如果客户端收到的信息，能被公钥解密，就说明该消息是由服务器发送的。\n引入了数字签名算法后，你就无法模仿你爸爸的字迹来请假了，你爸爸手上持有着私钥，你老师持有着公钥。\n这样只有用你爸爸手上的私钥才对请假条进行「签名」，老师通过公钥看能不能解出这个「签名」，如果能解出并且确认内容的完整性，就能证明是由你爸爸发起的请假条，这样老师才允许你请假，否则老师就不认。\n3. 数字证书\n前面我们知道：\n可以通过哈希算法来保证消息的完整性； 可以通过数字签名来保证消息的来源可靠性（能确认消息是由持有私钥的一方发送的）； 但是这还远远不够，还缺少身份验证的环节，万一公钥是被伪造的呢？\n还是拿请假的例子，虽然你爸爸持有私钥，老师通过是否能用公钥解密来确认这个请假条是不是来源你父亲的。\n但是我们还可以自己伪造出一对公私钥啊！\n你找了个夜晚，偷偷把老师桌面上和你爸爸配对的公钥，换成了你的公钥，那么下次你在请假的时候，你继续模仿你爸爸的字迹写了个请假条，然后用你的私钥做个了「数字签名」。\n但是老师并不知道自己的公钥被你替换过了，所以他还是按照往常一样用公钥解密，由于这个公钥和你的私钥是配对的，老师当然能用这个被替换的公钥解密出来，并且确认了内容的完整性，于是老师就会以为是你父亲写的请假条，又允许你请假了。\n好家伙，为了一个请假，真的是斗智斗勇。\n后面你的老师和父亲发现了你伪造公私钥的事情后，决定重新商量一个对策来应对你这个臭家伙。\n正所谓魔高一丈，道高一尺。\n既然伪造公私钥那么随意，所以你爸把他的公钥注册到警察局，警察局用他们自己的私钥对你父亲的公钥做了个数字签名，然后把你爸爸的「个人信息 + 公钥 + 数字签名」打包成一个数字证书，也就是说这个数字证书包含你爸爸的公钥。\n这样，你爸爸如果因为家里确实有事要向老师帮你请假的时候，不仅会用自己的私钥对内容进行签名，还会把数字证书给到老师。\n老师拿到了数字证书后，首先会去警察局验证这个数字证书是否合法，因为数字证书里有警察局的数字签名，警察局要验证证书合法性的时候，用自己的公钥解密，如果能解密成功，就说明这个数字证书是在警察局注册过的，就认为该数字证书是合法的，然后就会把数字证书里头的公钥（你爸爸的）给到老师。\n由于通过警察局验证了数字证书是合法的，那么就能证明这个公钥就是你父亲的，于是老师就可以安心的用这个公钥解密出清教条，如果能解密出，就证明是你爸爸写的请假条。\n正是通过了一个权威的机构来证明你爸爸的身份，所以你的伪造公私钥这个小伎俩就没用了。\n在计算机里，这个权威的机构就是 CA（数字证书认证机构），将服务器公钥放在数字证书（由数字证书认证机构颁发）中，只要证书是可信的，公钥就是可信的。\n数字证书的工作流程，我也画了一张图，方便大家理解：\n通过数字证书的方式保证服务器公钥的身份，解决冒充的风险。\nHTTPS 是如何建立连接的？其间交互了什么？ SSL/TLS 协议基本流程：\n客户端向服务器索要并验证服务器的公钥。 双方协商生产「会话秘钥」。 双方采用「会话秘钥」进行加密通信。 前两步也就是 SSL/TLS 的建立过程，也就是 TLS 握手阶段。\nTLS 的「握手阶段」涉及四次通信，使用不同的密钥交换算法，TLS 握手流程也会不一样的，现在常用的密钥交换算法有两种：RSA 算法 和 ECDHE 算法。\n基于 RSA 算法的 TLS 握手过程比较容易理解，所以这里先用这个给大家展示 TLS 握手过程，如下图：\nTLS 协议建立的详细流程：\n1. ClientHello\n首先，由客户端向服务器发起加密通信请求，也就是 ClientHello 请求。\n在这一步，客户端主要向服务器发送以下信息：\n（1）客户端支持的 TLS 协议版本，如 TLS 1.2 版本。\n（2）客户端生产的随机数（Client Random），后面用于生成「会话秘钥」条件之一。\n（3）客户端支持的密码套件列表，如 RSA 加密算法。\n2. SeverHello\n服务器收到客户端请求后，向客户端发出响应，也就是 ServerHello。服务器回应的内容有如下内容：\n（1）确认 TLS 协议版本，如果浏览器不支持，则关闭加密通信。\n（2）服务器生产的随机数（Server Random），也是后面用于生产「会话秘钥」条件之一。\n（3）确认的密码套件列表，如 RSA 加密算法。\n（4）服务器的数字证书。\n3.客户端回应\n客户端收到服务器的回应之后，首先通过浏览器或者操作系统中的 CA 公钥，确认服务器的数字证书的真实性。\n如果证书没有问题，客户端会从数字证书中取出服务器的公钥，然后使用它加密报文，向服务器发送如下信息：\n（1）一个随机数（pre-master key）。该随机数会被服务器公钥加密。\n（2）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。\n（3）客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供服务端校验。\n上面第一项的随机数是整个握手阶段的第三个随机数，会发给服务端，所以这个随机数客户端和服务端都是一样的。\n服务器和客户端有了这三个随机数（Client Random、Server Random、pre-master key），接着就用双方协商的加密算法，各自生成本次通信的「会话秘钥」。\n4. 服务器的最后回应\n服务器收到客户端的第三个随机数（pre-master key）之后，通过协商的加密算法，计算出本次通信的「会话秘钥」。\n然后，向客户端发送最后的信息：\n（1）加密通信算法改变通知，表示随后的信息都将用「会话秘钥」加密通信。\n（2）服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时把之前所有内容的发生的数据做个摘要，用来供客户端校验。\n至此，整个 TLS 的握手阶段全部结束。接下来，客户端与服务器进入加密通信，就完全是使用普通的 HTTP 协议，只不过用「会话秘钥」加密内容。\n客户端校验数字证书的流程是怎样的？\n接下来，详细说一下实际中数字证书签发和验证流程。\n如下图图所示，为数字证书签发和验证流程：\nCA 签发证书的过程，如上图左边部分：\n首先 CA 会把持有者的公钥、用途、颁发者、有效时间等信息打成一个包，然后对这些信息进行 Hash 计算，得到一个 Hash 值； 然后 CA 会使用自己的私钥将该 Hash 值加密，生成 Certificate Signature，也就是 CA 对证书做了签名； 最后将 Certificate Signature 添加在文件证书上，形成数字证书； 客户端校验服务端的数字证书的过程，如上图右边部分：\n首先客户端会使用同样的 Hash 算法获取该证书的 Hash 值 H1； 通常浏览器和操作系统中集成了 CA 的公钥信息，浏览器收到证书后可以使用 CA 的公钥解密 Certificate Signature 内容，得到一个 Hash 值 H2； 最后比较 H1 和 H2，如果值相同，则为可信赖的证书，否则则认为证书不可信。 但事实上，证书的验证过程中还存在一个证书信任链的问题，因为我们向 CA 申请的证书一般不是根证书签发的，而是由中间证书签发的，比如百度的证书，从下图你可以看到，证书的层级有三级：\n对于这种三级层级关系的证书的验证过程如下：\n客户端收到 baidu.com 的证书后，发现这个证书的签发者不是根证书，就无法根据本地已有的根证书中的公钥去验证 baidu.com 证书是否可信。于是，客户端根据 baidu.com 证书中的签发者，找到该证书的颁发机构是\u0026quot;GlobalSign Organization Validation CA - SHA256 - G2\u0026quot;，然后向 CA 请求该中间证书。 请求到证书后发现\u0026quot;GlobalSign Organization Validation CA - SHA256 - G2\u0026quot;证书是由\u0026quot;GlobalSign Root CA\u0026quot;签发的，由于\u0026quot;GlobalSign Root CA\u0026quot;没有再上级签发机构，说明它是根证书，也就是自签证书。应用软件会检查此证书有否已预载于根证书清单上，如果有，则可以利用根证书中的公钥去验证\u0026quot;GlobalSign Organization Validation CA - SHA256 - G2\u0026quot;证书，如果发现验证通过，就认为该中间证书是可信的。 \u0026ldquo;GlobalSign Organization Validation CA - SHA256 - G2\u0026quot;证书被信任后，可以使用\u0026quot;GlobalSign Organization Validation CA - SHA256 - G2\u0026quot;证书中的公钥去验证 baidu.com 证书的可信性，如果验证通过，就可以信任 baidu.com 证书。 在这四个步骤中，最开始客户端只信任根证书 GlobalSign Root CA 证书的，然后\u0026quot;GlobalSign Root CA\u0026quot;证书信任\u0026quot;GlobalSign Organization Validation CA - SHA256 - G2\u0026quot;证书，而\u0026quot;GlobalSign Organization Validation CA - SHA256 - G2\u0026quot;证书又信任 baidu.com 证书，于是客户端也信任 baidu.com 证书。\n总括来说，由于用户信任 GlobalSign，所以由 GlobalSign 所担保的 baidu.com 可以被信任，另外由于用户信任操作系统或浏览器的软件商，所以由软件商预载了根证书的 GlobalSign 都可被信任。\n操作系统里一般都会内置一些根证书，比如我的 MAC 电脑里内置的根证书有这么多：\n这样的一层层地验证就构成了一条信任链路，整个证书信任链验证流程如下图所示：\n最后一个问题，为什么需要证书链这么麻烦的流程？Root CA 为什么不直接颁发证书，而是要搞那么多中间层级呢？\n这是为了确保根证书的绝对安全性，将根证书隔离地越严格越好，不然根证书如果失守了，那么整个信任链都会有问题。\nHTTPS 的应用数据是如何保证完整性的？ TLS 在实现上分为握手协议和记录协议两层：\nTLS 握手协议就是我们前面说的 TLS 四次握手的过程，负责协商加密算法和生成对称密钥，后续用此密钥来保护应用程序数据（即 HTTP 数据）； TLS 记录协议负责保护应用程序数据并验证其完整性和来源，所以对 HTTP 数据加密是使用记录协议； TLS 记录协议主要负责消息（HTTP 数据）的压缩，加密及数据的认证，过程如下图：\n具体过程如下：\n首先，消息被分割成多个较短的片段，然后分别对每个片段进行压缩。\n接下来，经过压缩的片段会被加上消息认证码（MAC 值，这个是通过哈希算法生成的），这是为了保证完整性，并进行数据的认证。通过附加消息认证码的 MAC 值，可以识别出篡改。与此同时，为了防止重放攻击，在计算消息认证码时，还加上了片段的编码。\n再接下来，经过压缩的片段再加上消息认证码会一起通过对称密码进行加密。\n最后，上述经过加密的数据再加上由数据类型、版本号、压缩后的长度组成的报头就是最终的报文数据。\n记录协议完成后，最终的报文数据将传递到传输控制协议 (TCP) 层进行传输。\n如果你想详细了解记录协议是如何分片、压缩、计算 MAC 值、分组加密，可以看这篇：理解 SSL/TLS 系列 (四) 记录协议\nHTTPS 一定安全可靠吗？ 之前有读者在字节面试的时候，被问到：HTTPS 一定安全可靠吗？\n前两天字节一面时，面试官问我https一定安全可靠吗，如果有假基站起了转发全部信息的作用，这样是不是假基站就获取到全部信息了，从而造成信息泄露。这个该怎么回答呀？\n这个问题的场景是这样的：客户端通过浏览器向服务端发起 HTTPS 请求时，被「假基站」转发到了一个「中间人服务器」，于是客户端是和「中间人服务器」完成了 TLS 握手，然后这个「中间人服务器」再与真正的服务端完成 TLS 握手。\n具体过程如下：\n客户端向服务端发起 HTTPS 建立连接请求时，然后被「假基站」转发到了一个「中间人服务器」，接着中间人向服务端发起 HTTPS 建立连接请求，此时客户端与中间人进行 TLS 握手，中间人与服务端进行 TLS 握手； 在客户端与中间人进行 TLS 握手过程中，中间人会发送自己的公钥证书给客户端，客户端验证证书的真伪，然后从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给中间人，中间人使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（A），后续客户端与中间人通信就用这个对称加密密钥来加密数据了。 在中间人与服务端进行 TLS 握手过程中，服务端会发送从 CA 机构签发的公钥证书给中间人，从证书拿到公钥，并生成一个随机数，用公钥加密随机数发送给服务端，服务端使用私钥解密，得到随机数，此时双方都有随机数，然后通过算法生成对称加密密钥（B），后续中间人与服务端通信就用这个对称加密密钥来加密数据了。 后续的通信过程中，中间人用对称加密密钥（A）解密客户端的 HTTPS 请求的数据，然后用对称加密密钥（B）加密 HTTPS 请求后，转发给服务端，接着服务端发送 HTTPS 响应数据给中间人，中间人用对称加密密钥（B）解密 HTTPS 响应数据，然后再用对称加密密钥（A）加密后，转发给客户端。 从客户端的角度看，其实并不知道网络中存在中间人服务器这个角色。那么中间人就可以解开浏览器发起的 HTTPS 请求里的数据，也可以解开服务端响应给浏览器的 HTTPS 响应数据。相当于，中间人能够\u0026quot;偷看\u0026quot;浏览器与服务端之间的 HTTPS 请求和响应的数据。\n但是要发生这种场景是有前提的，前提是用户点击接受了中间人服务器的证书。\n中间人服务器与客户端在 TLS 握手过程中，实际上发送了自己伪造的证书给浏览器，而这个伪造的证书是能被浏览器（客户端）识别出是非法的，于是就会提醒用户该证书存在问题。\n如果用户执意点击「继续浏览此网站」，相当于用户接受了中间人伪造的证书，那么后续整个 HTTPS 通信都能被中间人监听了。\n所以，这其实并不能说 HTTPS 不够安全，毕竟浏览器都已经提示证书有问题了，如果用户坚决要访问，那不能怪 HTTPS，得怪自己手贱。\n另外，如果你的电脑中毒了，被恶意导入了中间人的根证书，那么在验证中间人的证书的时候，由于你操作系统信任了中间人的根证书，那么等同于中间人的证书是合法的，这种情况下，浏览器是不会弹出证书存在问题的风险提醒的。\n这其实也不关 HTTPS 的事情，是你电脑中毒了才导致 HTTPS 数据被中间人劫持的。\n所以，HTTPS 协议本身到目前为止还是没有任何漏洞的，即使你成功进行中间人攻击，本质上是利用了客户端的漏洞（用户点击继续访问或者被恶意导入伪造的根证书），并不是 HTTPS 不够安全。\n为什么抓包工具能截取 HTTPS 数据？\n很多抓包工具 之所以可以明文看到 HTTPS 数据，工作原理与中间人一致的。\n对于 HTTPS 连接来说，中间人要满足以下两点，才能实现真正的明文代理：\n中间人，作为客户端与真实服务端建立连接这一步不会有问题，因为服务端不会校验客户端的身份； 中间人，作为服务端与真实客户端建立连接，这里会有客户端信任服务端的问题，也就是服务端必须有对应域名的私钥； 中间人要拿到私钥只能通过如下方式：\n去网站服务端拿到私钥； 去 CA 处拿域名签发私钥； 自己签发受浏览器信任的证书； 不用解释，抓包工具只能使用第三种方式取得中间人的身份。\n因此使用抓包工具进行 HTTPS 抓包的时候，抓包工具会生成根证书，导入到客户端系统的 受信任的根证书列表 中，这里的根证书实际上起认证中心（CA）的作用。\n随后抓包工具使用该根证书签发域名的证书，因为根证书受信任，域名的证书同样会被浏览器信任。也就是抓包工具给自己创建了一个认证中心 CA，客户端拿着中间人（抓包工具）签发的证书去中间人（抓包工具）自己的 CA 做认证，这个证书当然被认为是有效的。\n如何避免被中间人抓取数据？\n我们要保证自己电脑的安全，不要被病毒乘虚而入，而且也不要点击任何证书非法的网站，这样 HTTPS 数据就不会被中间人截取到了。\n当然，我们还可以通过 HTTPS 双向认证来避免这种问题。\n一般我们的 HTTPS 是单向认证，客户端只会验证了服务端的身份，但是服务端并不会验证客户端的身份。\n如果用了双向认证方式，不仅客户端会验证服务端的身份，而且服务端也会验证客户端的身份。服务端一旦验证到请求自己的客户端为不可信任的，服务端就拒绝继续通信，客户端如果发现服务端为不可信任的，那么也中止通信。\nHTTP/1.1、HTTP/2、HTTP/3 演变 HTTP/1.1 相比 HTTP/1.0 提高了什么性能？ HTTP/1.1 相比 HTTP/1.0 性能上的改进：\n使用长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。 支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。 但 HTTP/1.1 还是有性能瓶颈：\n请求 / 响应头部（Header）未经压缩就发送，首部信息越多延迟越大。只能压缩 Body 的部分； 发送冗长的首部。每次互相发送相同的首部造成的浪费较多； 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端一直请求不到数据，也就是队头阻塞； 没有请求优先级控制； 请求只能从客户端开始，服务器只能被动响应。 HTTP/2 做了什么优化？ HTTP/2 协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。\n那 HTTP/2 相比 HTTP/1.1 性能上的改进：\n头部压缩 二进制格式 并发传输 服务器主动推送资源 1. 头部压缩\nHTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是一样的或是相似的，那么，协议会帮你消除重复的部分。\n这就是所谓的 HPACK 算法：在客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。\n2. 二进制格式\nHTTP/2 不再像 HTTP/1.1 里的纯文本形式的报文，而是全面采用了二进制格式，头信息和数据体都是二进制，并且统称为帧（frame）：头信息帧（Headers Frame）和数据帧（Data Frame）。\n这样虽然对人不友好，但是对计算机非常友好，因为计算机只懂二进制，那么收到报文后，无需再将明文的报文转成二进制，而是直接解析二进制报文，这增加了数据传输的效率。\n比如状态码 200，在 HTTP/1.1 是用 \u0026lsquo;2\u0026rsquo;\u0026lsquo;0\u0026rsquo;\u0026lsquo;0\u0026rsquo; 三个字符来表示（二进制：00110010 00110000 00110000），共用了 3 个字节，如下图\n在 HTTP/2 对于状态码 200 的二进制编码是 10001000，只用了 1 字节就能表示，相比于 HTTP/1.1 节省了 2 个字节，如下图：\nHeader: :status: 200 OK 的编码内容为：1000 1000，那么表达的含义是什么呢？\n最前面的 1 标识该 Header 是静态表中已经存在的 KV。 在静态表理，\u0026quot;:status: 200 ok\u0026quot;静态表编码是 8，二进制即是 1000。 因此，整体加起来就是 1000 1000。\n3. 并发传输\n我们都知道 HTTP/1.1 的实现是基于请求 - 响应模型的。同一个连接中，HTTP 完成一个事务（请求与响应），才能处理下一个事务，也就是说在发出请求等待响应的过程中，是没办法做其他事情的，如果响应迟迟不来，那么后续的请求是无法发送的，也造成了队头阻塞的问题。\n而 HTTP/2 就很牛逼了，引出了 Stream 概念，多个 Stream 复用在一条 TCP 连接。\n从上图可以看到，1 个 TCP 连接包含多个 Stream，Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成。Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容（头部和包体）。\n针对不同的 HTTP 请求用独一无二的 Stream ID 来区分，接收端可以通过 Stream ID 有序组装成 HTTP 消息，不同 Stream 的帧是可以乱序发送的，因此可以并发不同的 Stream，也就是 HTTP/2 可以并行交错地发送请求和响应。\n比如下图，服务端并行交错地发送了两个响应：Stream 1 和 Stream 3，这两个 Stream 都是跑在一个 TCP 连接上，客户端收到后，会根据相同的 Stream ID 有序组装成 HTTP 消息。\n4、服务器推送\nHTTP/2 还在一定程度上改善了传统的「请求 - 应答」工作模式，服务端不再是被动地响应，可以主动向客户端发送消息。\n客户端和服务器双方都可以建立 Stream，Stream ID 也是有区别的，客户端建立的 Stream 必须是奇数号，而服务器建立的 Stream 必须是偶数号。\n比如下图，Stream 1 是客户端向服务端请求的资源，属于客户端建立的 Stream，所以该 Stream 的 ID 是奇数（数字 1）；Stream 2 和 4 都是服务端主动向客户端推送的资源，属于服务端建立的 Stream，所以这两个 Stream 的 ID 是偶数（数字 2 和 4）。\n再比如，客户端通过 HTTP/1.1 请求从服务器那获取到了 HTML 文件，而 HTML 可能还需要依赖 CSS 来渲染页面，这时客户端还要再发起获取 CSS 文件的请求，需要两次消息往返，如下图左边部分：\n如上图右边部分，在 HTTP/2 中，客户端在访问 HTML 时，服务器可以直接主动推送 CSS 文件，减少了消息传递的次数。\nHTTP/2 有什么缺陷？\nHTTP/2 通过 Stream 的并发能力，解决了 HTTP/1 队头阻塞的问题，看似很完美了，但是 HTTP/2 还是存在\u0026quot;队头阻塞\u0026quot;的问题，只不过问题不是在 HTTP 这一层面，而是在 TCP 这一层。\nHTTP/2 是基于 TCP 协议来传输数据的，TCP 是字节流协议，TCP 层必须保证收到的字节数据是完整且连续的，这样内核才会将缓冲区里的数据返回给 HTTP 应用，那么当「前 1 个字节数据」没有到达时，后收到的字节数据只能存放在内核缓冲区里，只有等到这 1 个字节数据到达时，HTTP/2 应用层才能从内核中拿到数据，这就是 HTTP/2 队头阻塞问题。\n举个例子，如下图：\n图中发送方发送了很多个 packet，每个 packet 都有自己的序号，你可以认为是 TCP 的序列号，其中 packet 3 在网络中丢失了，即使 packet 4-6 被接收方收到后，由于内核中的 TCP 数据不是连续的，于是接收方的应用层就无法从内核中读取到，只有等到 packet 3 重传后，接收方的应用层才可以从内核中读取到数据，这就是 HTTP/2 的队头阻塞问题，是在 TCP 层面发生的。\n所以，一旦发生了丢包现象，就会触发 TCP 的重传机制，这样在一个 TCP 连接中的所有的 HTTP 请求都必须等待这个丢了的包被重传回来。\nHTTP/3 做了哪些优化？ 前面我们知道了 HTTP/1.1 和 HTTP/2 都有队头阻塞的问题：\nHTTP/1.1 中的管道（pipeline）虽然解决了请求的队头阻塞，但是没有解决响应的队头阻塞，因为服务端需要按顺序响应收到的请求，如果服务端处理某个请求消耗的时间比较长，那么只能等响应完这个请求后，才能处理下一个请求，这属于 HTTP 层队头阻塞。 HTTP/2 虽然通过多个请求复用一个 TCP 连接解决了 HTTP 的队头阻塞，但是一旦发生丢包，就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞。 HTTP/2 队头阻塞的问题是因为 TCP，所以 HTTP/3 把 HTTP 下层的 TCP 协议改成了 UDP！\nUDP 发送是不管顺序，也不管丢包的，所以不会出现像 HTTP/2 队头阻塞的问题。大家都知道 UDP 是不可靠传输的，但基于 UDP 的 QUIC 协议 可以实现类似 TCP 的可靠性传输。\nQUIC 有以下 3 个特点。\n无队头阻塞 更快的连接建立 连接迁移 1、无队头阻塞\nQUIC 协议也有类似 HTTP/2 Stream 与多路复用的概念，也是可以在同一条连接上并发传输多个 Stream，Stream 可以认为就是一条 HTTP 请求。\nQUIC 有自己的一套机制可以保证传输的可靠性的。当某个流发生丢包时，只会阻塞这个流，其他流不会受到影响，因此不存在队头阻塞问题。这与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。\n所以，QUIC 连接上的多个 Stream 之间并没有依赖，都是独立的，某个流发生丢包了，只会影响该流，其他流不受影响。\n2、更快的连接建立\n对于 HTTP/1 和 HTTP/2 协议，TCP 和 TLS 是分层的，分别属于内核实现的传输层、openssl 库实现的表示层，因此它们难以合并在一起，需要分批次来握手，先 TCP 握手，再 TLS 握手。\nHTTP/3 在传输数据前虽然需要 QUIC 协议握手，但这个握手过程只需要 1 RTT，握手的目的是为确认双方的「连接 ID」，连接迁移就是基于连接 ID 实现的。\n但是 HTTP/3 的 QUIC 协议并不是与 TLS 分层，而是 QUIC 内部包含了 TLS，它在自己的帧会携带 TLS 里的\u0026quot;记录\u0026rdquo;，再加上 QUIC 使用的是 TLS/1.3，因此仅需 1 个 RTT 就可以「同时」完成建立连接与密钥协商，如下图：\n甚至，在第二次连接的时候，应用数据包可以和 QUIC 握手信息（连接信息 + TLS 信息）一起发送，达到 0-RTT 的效果。\n如下图右边部分，HTTP/3 当会话恢复时，有效负载数据与第一个数据包一起发送，可以做到 0-RTT（下图的右下角）：\n3、连接迁移\n基于 TCP 传输协议的 HTTP 协议，由于是通过四元组（源 IP、源端口、目的 IP、目的端口）确定一条 TCP 连接。\n那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立连接。而建立连接的过程包含 TCP 三次握手和 TLS 四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。\n而 QUIC 协议没有用四元组的方式来\u0026quot;绑定\u0026quot;连接，而是通过连接 ID 来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息（比如连接 ID、TLS 密钥等），就可以\u0026quot;无缝\u0026quot;地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。\n所以，QUIC 是一个在 UDP 之上的伪 TCP + TLS + HTTP/2 的多路复用的协议。\nQUIC 是新协议，对于很多网络设备，根本不知道什么是 QUIC，只会当做 UDP，这样会出现新的问题，因为有的网络设备是会丢掉 UDP 包的，而 QUIC 是基于 UDP 实现的，那么如果网络设备无法识别这个是 QUIC 包，那么就会当作 UDP 包，然后被丢弃。\nHTTP/3 现在普及的进度非常的缓慢，不知道未来 UDP 是否能够逆袭 TCP。\n参考资料：\n[1] 上野 宣。图解 HTTP.人民邮电出版社。\n[2] 罗剑锋。透视 HTTP 协议。极客时间。\n[3] 陈皓.HTTP 的前世今。酷壳 CoolShell.https://coolshell.cn/articles/19840.html\n[4] 阮一峰.HTTP 协议入门。阮一峰的网络日志.http://www.ruanyifeng.com/blog/2016/08/http.html\n[5] 小林coding。\n","permalink":"https://WFUing.github.io/posts/tech/network/http123-https/","summary":"HTTP HTTP 基本概念 HTTP 是什么？ HTTP 是超文本传输协议，也就是HyperText Transfer Protocol。\n能否详细解释「超文本传输协议」？\nHTTP 的名字「超文本协议传输」，它可以拆成三个部分：\n超文本 传输 协议 1. 「协议」\n在生活中，我们也能随处可见「协议」，例如：\n刚毕业时会签一个「三方协议」； 找房子时会签一个「租房协议」； 生活中的协议，本质上与计算机中的协议是相同的，协议的特点：\n「协」字，代表的意思是必须有两个以上的参与者。例如三方协议里的参与者有三个：你、公司、学校三个；租房协议里的参与者有两个：你和房东。 「议」字，代表的意思是对参与者的一种行为约定和规范。例如三方协议里规定试用期期限、毁约金等；租房协议里规定租期期限、每月租金金额、违约如何处理等。 针对 HTTP 协议，我们可以这么理解。\nHTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。\n2. 「传输」\n所谓的「传输」，很好理解，就是把一堆东西从 A 点搬到 B 点，或者从 B 点 搬到 A 点。\n别轻视了这个简单的动作，它至少包含两项重要的信息。\nHTTP 协议是一个双向协议。\n我们在上网冲浪时，浏览器是请求方 A，百度网站就是应答方 B。双方约定用 HTTP 协议来通信，于是浏览器把请求数据发送给网站，网站再把一些数据返回给浏览器，最后由浏览器渲染在屏幕，就可以看到图片、视频了。\n数据虽然是在 A 和 B 之间传输，但允许中间有中转或接力。\n就好像第一排的同学想传递纸条给最后一排的同学，那么传递的过程中就需要经过好多个同学（中间人），这样的传输方式就从「A \u0026lt; \u0026mdash; \u0026gt; B」，变成了「A \u0026lt;-\u0026gt; N \u0026lt;-\u0026gt; M \u0026lt;-\u0026gt; B」。\n而在 HTTP 里，需要中间人遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东西。\n针对传输，我们可以进一步理解了 HTTP。","title":"HTTP-1 HTTPS HTTP-2 HTTP-3"},{"content":"Usage 1 Langium download https://www.npmjs.com/package/langium demo: https://langium.org/docs/getting-started/ note1：第一次按以上流程创建 DSL，HELLO-WORLD 项目在/Users/{用户名}/目录下 note2: VScode 下安装 code 指令。 Shift+Command+P调起命令窗口，输入shell Command，下方出现 Install 'code' command in PATH 选项，点击以安装 vscode extension: langium 2 Langium Concepts 1. The Grammar Language\ndocument: https://langium.org/docs/grammar-language/ Language Declaration: Langium 语法文件以声明语言名称的标题开头 Terminal Rules: Langium 解析器内置流基于Javascript Regular Expressions的 lexer，也允许使用EBNF表达式。但是建议使用 javascript 正则表达式，因为在 langium 内部将 EBNF 转换成了正则表达式 Parser Rules: Parser Rules 向 parser 指示哪些令牌序列是有效的 The Entry Rule: 解析步骤起点的 Parser Rules，从关键字 entry 开始，并匹配其他 Parser Rules 2. 目录结构\n以 https://langium.org/docs/getting-started/的demo为例：\nsrc/language-server/hello-world.langium: 语法规则文件 document: https://langium.org/tutorials/writing_a_grammar/ src/language-server/hello-world-validator.ts: 合法性检验，当用户输入相同函数名、关键字输入错误\u0026hellip;等一系列不符合语法规则时，编辑器能给出相应的错误提醒 document: https://langium.org/tutorials/validation/ src/cli/index.ts: 语言的命令行界面的一般布局，并允许注册特定命令 document: https://langium.org/tutorials/customizing_cli/ src/language-server/main-browser.ts: 为的语言服务器创建一个新的入口点等 document: https://langium.org/tutorials/langium_and_monaco/ src/static/index.html,src/static/styles.css: 静态页面，在与 Monaco Editor 集成，在 web 上运行会用到。 document: https://langium.org/tutorials/langium_and_monaco/ src/web/index.ts: 网络的生成器端点 document: https://langium.org/tutorials/generation_in_the_web/ 3. Extension\n基于 Langium 的语言构建 VSIX 扩展（VSCode 扩展）\ndocument: https://langium.org/tutorials/building_an_extension/ 4. running Langium in the web\n在网络中将 Langium 与 Monaco Editor 集成，无需后端\ndocument: https://langium.org/tutorials/generation_in_the_web/ Resource document：https://langium.org/docs/ github：https://github.com/langium/langium VS Code extension API：https://code.visualstudio.com/api/language-extensions/overview Typescript document：https://typescript.bootcss.com/basic-types.html ","permalink":"https://WFUing.github.io/posts/tech/language/dsl/langium/","summary":"Usage 1 Langium download https://www.npmjs.com/package/langium demo: https://langium.org/docs/getting-started/ note1：第一次按以上流程创建 DSL，HELLO-WORLD 项目在/Users/{用户名}/目录下 note2: VScode 下安装 code 指令。 Shift+Command+P调起命令窗口，输入shell Command，下方出现 Install 'code' command in PATH 选项，点击以安装 vscode extension: langium 2 Langium Concepts 1. The Grammar Language\ndocument: https://langium.org/docs/grammar-language/ Language Declaration: Langium 语法文件以声明语言名称的标题开头 Terminal Rules: Langium 解析器内置流基于Javascript Regular Expressions的 lexer，也允许使用EBNF表达式。但是建议使用 javascript 正则表达式，因为在 langium 内部将 EBNF 转换成了正则表达式 Parser Rules: Parser Rules 向 parser 指示哪些令牌序列是有效的 The Entry Rule: 解析步骤起点的 Parser Rules，从关键字 entry 开始，并匹配其他 Parser Rules 2. 目录结构","title":"langium简介"},{"content":"Resource Protocol specification https://microsoft.github.io/language-server-protocol/ Syntax highlight guide https://code.visualstudio.com/api/language-extensions/syntax-highlight-guide Language Server Tools https://langserver.org/ Language Server Protocol https://microsoft.github.io/language-server-protocol/ VSCode Syntax Highlight Guide https://code.visualstudio.com/api/language-extensions/syntax-highlight-guide Scope Lists https://macromates.com/manual/en/language_grammars https://www.apeth.com/nonblog/stories/textmatebundle.html ","permalink":"https://WFUing.github.io/posts/tech/language/dsl/vscode-language-server/","summary":"Resource Protocol specification https://microsoft.github.io/language-server-protocol/ Syntax highlight guide https://code.visualstudio.com/api/language-extensions/syntax-highlight-guide Language Server Tools https://langserver.org/ Language Server Protocol https://microsoft.github.io/language-server-protocol/ VSCode Syntax Highlight Guide https://code.visualstudio.com/api/language-extensions/syntax-highlight-guide Scope Lists https://macromates.com/manual/en/language_grammars https://www.apeth.com/nonblog/stories/textmatebundle.html ","title":"vscode-language-server"},{"content":"Usage 项目创建 XText 开发一个新的语言\n定义 xtext 文件 dsl.xtext 包括语法定义，语义（Cross-Reference）定义 生成模型代码 XText 根据 dsl.xtext 在 src-gen 目录下，生成 AST 节点模型类 parser，semantic analysis 等阶段需要的 类，如 GrammarAccess，Scope 等 定义 GenerateDsl.mwe2 定义生成流程 generateXtendStub = false 禁用 xtend 模板文件生成 编写 Language Implementation 编写 IDE Features 项目初始化\n使用 Eclipse 开发 Xtext 应用能够得到最大化的支持，包括 xtext，xtext 语言支持，Editor 支持，自动生成 Artifact 等 由于 Eclipse 一些使用上的原因，建议将 Xtext 当做一个纯 Java 框架进行使用，通过 Gradle 自动根据 xtext 生成源代码，这样能够使用 IDEA 进行开发。 目录结构\nxxx.dsl 定义 DSL 的核心处理类，包括 Format，Scope，Validation，Code Generation xxx.dsl.ide 定义与 IDE 相关的处理类，包括 Hover，QuickFix 等 与 Language Server 相关的业务逻辑 xxx.dsl.tests 测试类 Concepts Xtend 一种类似 Java 的语言，包含一些语法糖，如在 Code Generation 使用模板语言定义代码生成过程 Xtext 文档和教程中大量使用该语言，但由于 xtent 在 IDEA 中没有支持，建议只使用 Java 进行开发 Inject Xtext 框架使用 com.google.inject 库进行依赖注入，注册不同的语言服务（如 GrammarAccess，Formatter） Grammar Language https://www.eclipse.org/Xtext/documentation/301_grammarlanguage.html 名为 xtext 的 DSL，用于定义语言语法，以及与语义对象的映射关系 语法对象：抽象语法树的节点，与源代码对应，Parsing 过程将字符串转换为多个语法对象构造的树 语义对象：语义分析处理的对象，比如类型对象，模块对象等 Xtext 框架设计原则是，用 xtext 定义语法以及语义对象，在解析过程中，同时构造出语义对象。其他的语言服务将处理这些语义对象 语义对象使用 EMF Ecore 模型作为规范，见 https://www.eclipse.org/Xtext/documentation/308_emf_integration.html#model-metamodel Module https://www.eclipse.org/Xtext/documentation/302_configuration.html 如 DslRuntimeModule 类似于 依赖注入中的 Module，提供当前 DSL 各种语言服务的类 要使用 DSL 的语言功能（如编译器或 Language Server），通过 Injector 获取 Module，然后调用对应的方法使用 Language Implementation https://www.eclipse.org/Xtext/documentation/303_runtime_concepts.html\n实现语言的各种功能\nCodeGeneration\n用于将 AST 解释执行，或翻译为其他代码 如 Model -\u0026gt; Java, YAML 等 实现 IGenerator2 接口 关注对象 当前待生成的资源（语法树子树根节点） 输出管理（输出的内容，输出的文件路径） 引用其他的对象 Validation\n静态分析实现 Lint，检测模型是否满足约束 静态分析输出 Errors 与 Warnings，通过 Resource.getErrors() 与 Resource.getWarnings() 获取 类别 Automatic Validation Lexer/Parser: 语法校验 Linker：交叉引用校验 利用 Scope（符号表）等信息，执行校验 可能会跨多个模块 Serializer：Concrete Syntax Validation collapsed:: true 具体的语法验证，当验证通过，说明模型可以被正确序列化 TODO: 使用场景 用于模型序列化后，再反序列化回来？ Custom Validation 实现 AbstractDslValidator Linking\n实现交叉引用 需要完成两步 在 xtext grammar 文件中，定义交叉引用 通过 Scoping API 声明 Linking 的语义 Lazy Link Xtext 建议使用 Lazy Link 通过创建 Proxy 对象实现，当实际访问该 Proxy 对象时，才进行 resolve Scoping 通过 Scoping API 定义如何通过引用找到引用的对象 Tips 安装过程可以记录的点\n安装 Eclipse \u0026amp; XText 下载 Eclipse https://www.eclipse.org/Xtext/download.html 选择 Eclipse IDE for Java Developer 安装 在 Installer 中，右上角设置 - Adavanced Mode - 连接图标 - 设置代理 - 切换回 Easy Mode 代理选择全局模式 安装完成后，可设置 Eclipse HTTP 代理 (似乎没用) 在 Eclipse 中添加 Xtext update URL Help -\u0026gt; Install New Software \u0026hellip; -\u0026gt; 复制下面链接 -\u0026gt; Add \u0026hellip; https://download.eclipse.org/modeling/tmf/xtext/updates/composite/releases/ Or https://mirrors.tuna.tsinghua.edu.cn/eclipse/modeling/tmf/xtext/updates/composite/releases/ 添加完成后，选择 xtext，拉取 metadata，拉取完成后，Software sites 出现多个 URL，同样替换源 添加下列 URL https://mirrors.ustc.edu.cn/eclipse/modeling/tmf/xtext/updates/releases/ 替换源 Help -\u0026gt; Install New Software.. -\u0026gt; Available Software sites 将 https://download.eclipse.org 全部替换为 https://mirrors.tuna.tsinghua.edu.cn/eclipse 需要全部替换，否则每次 fetching children 都可能从某个 eclipse.org 中拉取，影响速度 Eclipse 设置代理 需要使用 http 代理，socks5 代理有些问题 Window -\u0026gt; Preference -\u0026gt; Network 设置 http 代理，选择 Active Provider 为 manual 另一个方法是，修改 eclipse.ini 位于 ~/eclipse\\java-2023-03\\eclipse VSCode 插件 grammarcraft.xtend-lang grammarcraft.xtext-lang Resource Document https://www.eclipse.org/Xtext/documentation/301_grammarlanguage.html Runtime concepts https://www.eclipse.org/Xtext/documentation/303_runtime_concepts.html Book https://github.com/varmaprr/books/blob/master/Implementing%20Domain%20Specific%20Languages%20with%20Xtext%20and%20Xtend%20-%20Second%20Edition.pdf ","permalink":"https://WFUing.github.io/posts/tech/language/dsl/xtext/","summary":"Usage 项目创建 XText 开发一个新的语言\n定义 xtext 文件 dsl.xtext 包括语法定义，语义（Cross-Reference）定义 生成模型代码 XText 根据 dsl.xtext 在 src-gen 目录下，生成 AST 节点模型类 parser，semantic analysis 等阶段需要的 类，如 GrammarAccess，Scope 等 定义 GenerateDsl.mwe2 定义生成流程 generateXtendStub = false 禁用 xtend 模板文件生成 编写 Language Implementation 编写 IDE Features 项目初始化\n使用 Eclipse 开发 Xtext 应用能够得到最大化的支持，包括 xtext，xtext 语言支持，Editor 支持，自动生成 Artifact 等 由于 Eclipse 一些使用上的原因，建议将 Xtext 当做一个纯 Java 框架进行使用，通过 Gradle 自动根据 xtext 生成源代码，这样能够使用 IDEA 进行开发。 目录结构\nxxx.dsl 定义 DSL 的核心处理类，包括 Format，Scope，Validation，Code Generation xxx.","title":"xtext简介"},{"content":"Resources 小林coding 3.1 HTTP 常见面试题 一次完整的HTTP请求过程 当我们在web浏览器的地址栏中输入：www.baidu.com，具体发生了什么？\n对www.baidu.com这个网址进行DNS域名解析，得到对应的IP地址 根据这个IP，找到对应的服务器，发起TCP的三次握手 建立TCP连接后发起HTTP请求 服务器响应HTTP请求，浏览器得到html代码 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）（先得到html代码，才能去找这些资源） 浏览器对页面进行渲染呈现给用户 服务器关闭关闭TCP连接 1.DNS怎么找到域名的？\nDNS域名解析采用的是递归查询的方式，过程是，先去找DNS缓存-\u0026gt;缓存找不到就去找根域名服务器-\u0026gt;根域名又会去找下一级，这样递归查找之后，找到了，给我们的web浏览器\n2.为什么HTTP协议要基于TCP来实现？\nTCP是一个端到端的可靠的面相连接的协议，HTTP基于传输层TCP协议不用担心数据传输的各种问题（当发生错误时，会重传）\n3.最后一步浏览器是如何对页面进行渲染的？\na）解析html文件构成 DOM树 b）解析CSS文件构成渲染树 c）边解析，边渲染 d）JS 单线程运行，JS有可能修改DOM结构，意味着JS执行完成前，后续所有资源的下载是没有必要的，所以JS是单线程，会阻塞后续资源下载\nDNS解析（域名解析服务器） 首先会搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存）\n如果浏览器自身的缓存里面没有找到，那么浏览器会搜索系统自身的DNS缓存\n如果还没有找到，那么尝试从 hosts文件 里面去找\n在前面三个过程都没获取到的情况下，就递归地去域名服务器去查找，具体过程如下\nDNS优化两个方面：DNS缓存、DNS负载均衡\nTCP连接建立（三次握手） 拿到域名对应的IP地址之后，User-Agent（一般指浏览器）会以一个随机端口（1024\u0026lt;端口\u0026lt;65535）向服务器的WEB程序（常用的有httpd，nginx）等的80端口。这个连接请求（原始的http请求经过 TCP/IP 4层模型的层层封包）到达服务器端后（这中间有各种路由设备，局域网内除外），进入到网卡，然后是进入到内核的TCP/IP协议栈（用于识别连接请求，解封包，一层一层的剥开），还有可能要经过Netfilter防火墙（属于内核的模块）的过滤，最终达到WEB程序，最终建立了 TCP/IP 的连接。\nTCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的。三次握手的过程如下图：\n发起HTTP请求(建立连接后) HTTP请求报文由四部分组成：请求行、请求头、空格、请求正文\n请求行：用于描述客户端的请求方式（GET/POST等），请求的资源名称(URL)以及使用的HTTP协议的版本号 请求头：用于描述客户端请求哪台主机及其端口，以及客户端的一些环境信息等 空行：空行就是\\r\\n (POST请求时候有) 请求正文：当使用POST等方法时，通常需要客户端向服务器传递数据。这些数据就储存在请求正文中（GET方式是保存在url地址后面，不会放到这里） GET请求\n下面是浏览器对 http://localhost:8081/test?name=XXG\u0026amp;age=23的GET 请求时发送给服务器的数据：\n可以看出请求包含请求行和请求头两部分。其中请求行中包含 method（例如 GET、POST）、URI（通一资源标志符）和协议版本三部分，三个部分之间以空格分开。请求行和每个请求头各占一行，以换行符 CRLF（即 \\r\\n）分割。\nPOST请求\n下面是浏览器对 http://localhost:8081/test 的 POST 请求时发送给服务器的数据，消息体中带上参数 name=XXG\u0026amp;age=23\n可以看出，上面的请求包含四个部分：请求行、请求头、空格、消息体，比之前的 GET 请求多了一个请求消息，其中 请求头和消息体之间用一个空行分割。POST 请求的参数不在 URL 中，而是在消息体中，请求头中多了一项 Content-Length 用于表示消息体的字节数，这样服务器才能知道请求是否发送结束。这也就是 GET 请求和 POST 请求的主要区别。\n那么起始行中的请求方法有哪些种呢？ GET: 完整请求一个资源 （常用） HEAD: 仅请求响应首部 POST：提交表单（常用） PUT: (webdav) 上传文件（但是浏览器不支持该方法） DELETE：(webdav) 删除 OPTIONS：返回请求的资源所支持的方法的方法 TRACE: 追求一个资源请求中间所经过的代理（该方法不能由浏览器发出）\n那什么是URL、URI、URN？ URI Uniform Resource Identifier 统一资源标识符 URL Uniform Resource Locator 统一资源定位符 URN Uniform Resource Name 统一资源名称 URL和URN 都属于 URI，为了方便就把URL和URI暂时都通指一个东西\n服务器响应http请求，浏览器得到html代码 HTTP响应也由四部分组成：状态行，响应头，空格，消息体\n状态行包括：协议版本、状态码、状态码描述 状态码：状态码用于表示服务器对请求的处理结果 1xx：指示信息——表示请求已经接受，继续处理 2xx：成功——表示请求已经被成功接收、理解、接受。 3xx：重定向——要完成请求必须进行更进一步的操作 4xx：客户端错误——请求有语法错误或请求无法实现 5xx：服务器端错误——服务器未能实现合法的请求。 200（没有问题） 302（要你去找别人） 304（要你去拿缓存） 307（要你去拿缓存） 403（有这个资源，但是没有访问权限） 404（服务器没有这个资源） 500（服务器这边有问题）\n响应头：响应头用于描述服务器的基本信息，以及客户端如何处理数据 空格：CRLF（即 \\r\\n）分割 消息体：服务器返回给客户端的数据 响应格式如下图\n上面的 HTTP 响应中，响应头中的 Content-Length 同样用于表示消息体的字节数。Content-Type 表示消息体的类型，通常浏览网页其类型是HTML，当然还会有其他类型，比如图片、视频等。\n浏览器解析html代码，并请求html代码中的资源 浏览器拿到html文件后，就开始解析其中的html代码，遇到js/css/image等静态资源时，就向服务器端去请求下载（会使用多线程下载，每个浏览器的线程数不一样），这是时候就用上 keep-alive特性了，建立一次HTTP连接，可以请求多个资源，下载资源的顺序就是按照代码里面的顺序，但是由于每个资源大小不一样，而浏览器又是多线程请求请求资源，所以这里显示的顺序并不一定是代码里面的顺序。\n浏览器对页面进行渲染呈现给用户 最后，浏览器利用自己内部的工作机制，把请求的静态资源和html代码进行渲染，渲染之后呈现给用户，浏览器是一个边解析边渲染的过程。首先浏览器解析HTML文件构建DOM树，然后解析CSS文件构建渲染树，等到渲染树构建完成后，浏览器开始布局渲染树并将其绘制到屏幕上。这个过程比较复杂，涉及到两个概念: reflow(回流)和repain(重绘)。\nDOM节点中的各个元素都是以盒模型的形式存在，这些都需要浏览器去计算其位置和大小等，这个过程称为relow； 当盒模型的位置,大小以及其他属性，如颜色,字体,等确定下来之后，浏览器便开始绘制内容，这个过程称为repain。 页面在首次加载时必然会经历reflow和repain。reflow和repain过程是非常消耗性能的，尤其是在移动设备上，它会破坏用户体验，有时会造成页面卡顿。所以我们应该尽可能少的减少reflow和repain。JS的解析是由浏览器中的JS解析引擎完成的。JS是单线程运行，JS有可能修改DOM结构，意味着JS执行完成前，后续所有资源的下载是没有必要的，所以JS是单线程，会阻塞后续资源下载。\n服务器关闭关闭TCP连接 一般情况下，一旦Web服务器向浏览器发送了请求数据，它就要关闭TCP连接，然后如果浏览器或者服务器在其头信息加入了这行代码：\n1 Connection:keep-alive TCP连接在发送后将仍然保持打开状态，于是，浏览器可以继续通过相同的连接发送请求。保持连接节省了为每个请求建立新连接所需的时间，还节约了网络带宽。\n自此一次完整的HTTP事务宣告完成.\n","permalink":"https://WFUing.github.io/posts/tech/network/http-process/","summary":"Resources 小林coding 3.1 HTTP 常见面试题 一次完整的HTTP请求过程 当我们在web浏览器的地址栏中输入：www.baidu.com，具体发生了什么？\n对www.baidu.com这个网址进行DNS域名解析，得到对应的IP地址 根据这个IP，找到对应的服务器，发起TCP的三次握手 建立TCP连接后发起HTTP请求 服务器响应HTTP请求，浏览器得到html代码 浏览器解析html代码，并请求html代码中的资源（如js、css、图片等）（先得到html代码，才能去找这些资源） 浏览器对页面进行渲染呈现给用户 服务器关闭关闭TCP连接 1.DNS怎么找到域名的？\nDNS域名解析采用的是递归查询的方式，过程是，先去找DNS缓存-\u0026gt;缓存找不到就去找根域名服务器-\u0026gt;根域名又会去找下一级，这样递归查找之后，找到了，给我们的web浏览器\n2.为什么HTTP协议要基于TCP来实现？\nTCP是一个端到端的可靠的面相连接的协议，HTTP基于传输层TCP协议不用担心数据传输的各种问题（当发生错误时，会重传）\n3.最后一步浏览器是如何对页面进行渲染的？\na）解析html文件构成 DOM树 b）解析CSS文件构成渲染树 c）边解析，边渲染 d）JS 单线程运行，JS有可能修改DOM结构，意味着JS执行完成前，后续所有资源的下载是没有必要的，所以JS是单线程，会阻塞后续资源下载\nDNS解析（域名解析服务器） 首先会搜索浏览器自身的DNS缓存（缓存时间比较短，大概只有1分钟，且只能容纳1000条缓存）\n如果浏览器自身的缓存里面没有找到，那么浏览器会搜索系统自身的DNS缓存\n如果还没有找到，那么尝试从 hosts文件 里面去找\n在前面三个过程都没获取到的情况下，就递归地去域名服务器去查找，具体过程如下\nDNS优化两个方面：DNS缓存、DNS负载均衡\nTCP连接建立（三次握手） 拿到域名对应的IP地址之后，User-Agent（一般指浏览器）会以一个随机端口（1024\u0026lt;端口\u0026lt;65535）向服务器的WEB程序（常用的有httpd，nginx）等的80端口。这个连接请求（原始的http请求经过 TCP/IP 4层模型的层层封包）到达服务器端后（这中间有各种路由设备，局域网内除外），进入到网卡，然后是进入到内核的TCP/IP协议栈（用于识别连接请求，解封包，一层一层的剥开），还有可能要经过Netfilter防火墙（属于内核的模块）的过滤，最终达到WEB程序，最终建立了 TCP/IP 的连接。\nTCP 是面向连接的协议，所以使用 TCP 前必须先建立连接，而建立连接是通过三次握手来进行的。三次握手的过程如下图：\n发起HTTP请求(建立连接后) HTTP请求报文由四部分组成：请求行、请求头、空格、请求正文\n请求行：用于描述客户端的请求方式（GET/POST等），请求的资源名称(URL)以及使用的HTTP协议的版本号 请求头：用于描述客户端请求哪台主机及其端口，以及客户端的一些环境信息等 空行：空行就是\\r\\n (POST请求时候有) 请求正文：当使用POST等方法时，通常需要客户端向服务器传递数据。这些数据就储存在请求正文中（GET方式是保存在url地址后面，不会放到这里） GET请求\n下面是浏览器对 http://localhost:8081/test?name=XXG\u0026amp;age=23的GET 请求时发送给服务器的数据：\n可以看出请求包含请求行和请求头两部分。其中请求行中包含 method（例如 GET、POST）、URI（通一资源标志符）和协议版本三部分，三个部分之间以空格分开。请求行和每个请求头各占一行，以换行符 CRLF（即 \\r\\n）分割。\nPOST请求\n下面是浏览器对 http://localhost:8081/test 的 POST 请求时发送给服务器的数据，消息体中带上参数 name=XXG\u0026amp;age=23\n可以看出，上面的请求包含四个部分：请求行、请求头、空格、消息体，比之前的 GET 请求多了一个请求消息，其中 请求头和消息体之间用一个空行分割。POST 请求的参数不在 URL 中，而是在消息体中，请求头中多了一项 Content-Length 用于表示消息体的字节数，这样服务器才能知道请求是否发送结束。这也就是 GET 请求和 POST 请求的主要区别。","title":"一次完整的HTTP请求过程"},{"content":"Akka 是一个用于在 JVM 上构建高并发、分布式和可容错的事件驱动应用程序的运行时工具包。Akka 既可以用于 Java，也可以用于 Scala。本指南通过描述 Java 版本的Hello World示例来介绍 Akka。\nActors 是 Akka 的执行单元。Actor 模型是一种抽象，它让编写正确的并发、并行和分布式系统更加容易。Hello World示例说明了 Akka 的基础知识。在 30 分钟内，你应该能够下载并运行示例，并使用本指南了解示例是如何构造的。这会让你初步了解 Akka 的魅力，希望这能够让你拥有深入了解 Akka 的兴趣！\n在体验过这个示例之后，想深入了解 Akka，阅读「Getting Started Guide」是一个很好的选择。\n下载示例 Java 版本的Hello World示例是一个包含 Maven 和 Gradle 构建文件的压缩项目。你可以在 Linux、MacOS 或 Windows 上运行它。唯一的先决条件是安装 Java 8 和 Maven 或 Gradle。\n下载和解压示例：\n在「Lightbend Tech Hub」上通过点击CREATE A PROJECT FOR ME下载压缩文件。 将 ZIP 文件解压缩到方便的位置： 在 Linux 和 OSX 系统上，打开终端并使用命令unzip akka-quickstart-java.zip。 在 Windows 上，使用文件资源管理器等工具提取项目。 运行示例 确保你已经安装了构建工具，然后打开终端窗口，并从项目目录中键入以下命令以运行Hello World：\n1 2 3 4 5 // Maven $ mvn compile exec:exec // Grade $ gradle run 输出应该如下所示（一直向右滚动以查看 Actor 输出）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 // Maven Scanning for projects... [INFO] [INFO] ------------------------\u0026lt; hello-akka-java:app \u0026gt;------------------------- [INFO] Building app 1.0 [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ app --- [WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent! [INFO] [INFO] --- exec-maven-plugin:1.6.0:exec (default-cli) @ app --- [2019-10-12 09:20:30,248] [INFO] [akka.event.slf4j.Slf4jLogger] [helloakka-akka.actor.default-dispatcher-3] [] - Slf4jLogger started SLF4J: A number (1) of logging calls during the initialization phase have been intercepted and are SLF4J: now being replayed. These are subject to the filtering rules of the underlying logging system. SLF4J: See also http://www.slf4j.org/codes.html#replay \u0026gt;\u0026gt;\u0026gt; Press ENTER to exit \u0026lt;\u0026lt;\u0026lt; [2019-10-12 09:20:30,288] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:20:30,290] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 1 for Charles [2019-10-12 09:20:30,291] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:20:30,291] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 2 for Charles [2019-10-12 09:20:30,291] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:20:30,291] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 3 for Charles // Grade :run [2019-10-12 09:47:16,399] [INFO] [akka.event.slf4j.Slf4jLogger] [helloakka-akka.actor.default-dispatcher-3] [] - Slf4jLogger started SLF4J: A number (1) of logging calls during the initialization phase have been intercepted and are SLF4J: now being replayed. These are subject to the filtering rules of the underlying logging system. SLF4J: See also http://www.slf4j.org/codes.html#replay \u0026gt;\u0026gt;\u0026gt; Press ENTER to exit \u0026lt;\u0026lt;\u0026lt; [2019-10-12 09:47:16,437] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:47:16,439] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 1 for Charles [2019-10-12 09:47:16,440] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:47:16,440] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 2 for Charles [2019-10-12 09:47:16,440] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:47:16,440] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 3 for Charles \u0026lt;=========----\u0026gt; 75% EXECUTING [27s] \u0026gt; :run 恭喜你，你刚刚运行了你的第一个 Akka 应用程序。\nHello World 都做了什么？ 示例包含了三个Actor：\nGreeter： 接收命令来Greet其他人，并使用Greeted来确认收到了消息。 GreeterBot：接收到从其他Greeter回复的问候，并发送多个额外的问候消息，并收集回复信息直到达到指定的数量。 GreeterMain：引导一切的守护Actor 使用 Actor 模型的好处 Akka 的以下特性使你能够以直观的方式解决困难的并发性和可伸缩性挑战：\n事件驱动模型：Event-driven model，Actor 通过响应消息来执行工作。Actor 之间的通信是异步的，允许 Actor 发送消息并继续自己的工作，而不是阻塞等待响应。 强隔离原则：Strong isolation principles，与 Java 中的常规对象不同，Actor 在调用的方法方面，没有一个公共 API。相反，它的公共 API 是通过 Actor 处理的消息来定义的。这可以防止 Actor 之间共享状态；观察另一个 Actor 状态的唯一方法是向其发送请求状态的消息。 位置透明：Location transparency，系统通过工厂方法构造 Actor 并返回对实例的引用。因为位置无关紧要，所以 Actor 实例可以启动、停止、移动和重新启动，以向上和向下扩展以及从意外故障中恢复。 轻量级：Lightweight，每个实例只消耗几百个字节，这实际上允许数百万并发 Actor 存在于一个应用程序中。 让我们看看在Hello World示例中使用 Actor 和消息一起工作的一些最佳实践。\n定义 Actor 和消息 每个Actor定义它可以接收的消息类型T。类(classes)和对象(objects)由于不可变并支持模式匹配，可以当做非常特别的消息类型。我们在Actor中会用到这些特性接收匹配的消息。\nHello World的 Actor 使用三种不同的消息：\nGreet：向Greeter执行问候的指令； Greeted：Greeter用来确认问候发生时回复的消息； SayHello：GreeterMain开始执行问候进程的指令； 在定义 Actor 及其消息时，请记住以下建议：\n因为消息是 Actor 的公共 API，所以定义具有良好名称、丰富语义和特定于域的含义的消息是一个很好的实践，即使它们只是包装你的数据类型，这将使基于 Actor 的系统更容易使用、理解和调试。 消息应该是不可变的，因为它们在不同的线程之间共享。 将 Actor 的关联消息作为静态类放在 Actor 的类中是一个很好的实践，这使得理解 Actor 期望和处理的消息类型更加容易。 通过静态工厂方法获得Actor的初始行为是一个很好的实践 让我们来看看Greeter，GreeterBot和GreeterMain的实现是如何证明上述的这些实践建议的。\n让我们看看 Actor 如何实现Greeter和Printer来演示这些最佳实践。\nGreeter Actor 下面的代码段来自于Greeter.java，其实现了Greeter Actor：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 public class Greeter extends AbstractBehavior\u0026lt;Greeter.Greet\u0026gt; { public static final class Greet { public final String whom; public final ActorRef\u0026lt;Greeted\u0026gt; replyTo; public Greet(String whom, ActorRef\u0026lt;Greeted\u0026gt; replyTo) { this.whom = whom; this.replyTo = replyTo; } } public static final class Greeted { public final String whom; public final ActorRef\u0026lt;Greet\u0026gt; from; public Greeted(String whom, ActorRef\u0026lt;Greet\u0026gt; from) { this.whom = whom; this.from = from; } } public static Behavior\u0026lt;Greet\u0026gt; create() { return Behaviors.setup(Greeter::new); } private Greeter(ActorContext\u0026lt;Greet\u0026gt; context) { super(context); } @Override public Receive\u0026lt;Greet\u0026gt; createReceive() { return newReceiveBuilder().onMessage(Greet.class, this::onGreet).build(); } private Behavior\u0026lt;Greet\u0026gt; onGreet(Greet command) { getContext().getLog().info(\u0026#34;Hello {}!\u0026#34;, command.whom); command.replyTo.tell(new Greeted(command.whom, getContext().getSelf())); return this; } } 上面这个代码片段定义了两种消息类型，一种被Actor用来问候其他人，另外一种被Actor用来确认问候已经完成。Greet类型不仅包含了被问候人的信息，还持有了ActorRef，是由消息发送者提供的以便于GreeterActor可以发回确认信息。\nActor的行为被定义为Greeter继承自AbstractBehavior，带有newReceiveBuilder的工厂行为。处理下一条信息然后可能导致与处理当前这条信息的行为不同。只要当前实例是可变的就可以通过修改当前实例来更新状态。在当前这个例子中，我们不需要更新任何状态，所以我们直接返回this而不包含任何字段更新，这也意味着，处理下一条消息的行为与当前相同。\n被当前行为处理的消息类型被声明为类Greet。通常，一个actor处理超过一种具体的消息类型，这样会有一个所有消息类型可以实现的公共的接口。\n在最后一行我们能看到GreeterActor使用tell方法发送消息到另外一个Actor。这是一个不会阻塞调用者线程的异步操作。\n因为replyTo地址通过类型ActorRef\u0026lt;Greeted\u0026gt;进行声明，编译器仅允许我们发送这种类型的消息，使用其他消息类型会导致编译错误。\n这个Actor可以接收的消息类型和回复的消息类型定义了我们所说的协议。当前用例是一个简单的请求-回复协议，但Actor可以定义任意我们需要的复杂协议。协议与其行为被恰当的包装在了一个范围——Greeter类\nGreeter bot actor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package $package$; import akka.actor.typed.Behavior; import akka.actor.typed.javadsl.*; public class GreeterBot extends AbstractBehavior\u0026lt;Greeter.Greeted\u0026gt; { public static Behavior\u0026lt;Greeter.Greeted\u0026gt; create(int max) { return Behaviors.setup(context -\u0026gt; new GreeterBot(context, max)); } private final int max; private int greetingCounter; private GreeterBot(ActorContext\u0026lt;Greeter.Greeted\u0026gt; context, int max) { super(context); this.max = max; } @Override public Receive\u0026lt;Greeter.Greeted\u0026gt; createReceive() { return newReceiveBuilder().onMessage(Greeter.Greeted.class, this::onGreeted).build(); } private Behavior\u0026lt;Greeter.Greeted\u0026gt; onGreeted(Greeter.Greeted message) { greetingCounter++; getContext().getLog().info(\u0026#34;Greeting {} for {}\u0026#34;, greetingCounter, message.whom); if (greetingCounter == max) { return Behaviors.stopped(); } else { message.from.tell(new Greeter.Greet(message.whom, getContext().getSelf())); return this; } } } 注意这个Actor如何使用实例变量管理计数器。不需要诸如synchronized或AtomicInteger这样的并发保护，因为一个Actor实例一次只处理一条消息。\nGreeter main actor 第三个Actor产生了Greeter和GreeterBot，并启动他们的交互，创建Actor以及spawn做了什么将在下面讨论。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package $package$; import akka.actor.typed.ActorRef; import akka.actor.typed.Behavior; import akka.actor.typed.javadsl.*; public class GreeterMain extends AbstractBehavior\u0026lt;GreeterMain.SayHello\u0026gt; { public static class SayHello { public final String name; public SayHello(String name) { this.name = name; } } private final ActorRef\u0026lt;Greeter.Greet\u0026gt; greeter; public static Behavior\u0026lt;SayHello\u0026gt; create() { return Behaviors.setup(GreeterMain::new); } private GreeterMain(ActorContext\u0026lt;SayHello\u0026gt; context) { super(context); //#create-actors greeter = context.spawn(Greeter.create(), \u0026#34;greeter\u0026#34;); //#create-actors } @Override public Receive\u0026lt;SayHello\u0026gt; createReceive() { return newReceiveBuilder().onMessage(SayHello.class, this::onSayHello).build(); } private Behavior\u0026lt;SayHello\u0026gt; onSayHello(SayHello command) { //#create-actors ActorRef\u0026lt;Greeter.Greeted\u0026gt; replyTo = getContext().spawn(GreeterBot.create(3), command.name); greeter.tell(new Greeter.Greet(command.name, replyTo)); //#create-actors return this; } } 创建 Actor 到目前为止，我们已经研究了 Actor 的定义和他们的消息。现在，让我们更深入地了解位置透明（location transparency）的好处，看看如何创建 Actor 实例。\n位置透明的好处 在 Akka 中，不能使用new关键字创建 Actor 的实例。相反，你应该使用工厂方法创建 Actor 实例。工厂不返回 Actor 实例，而是返回指向 Actor 实例的引用akka.actor.ActorRef。在分布式系统中，这种间接创建实例的方法增加了很多好处和灵活性。\n在 Akka 中位置无关紧要。位置透明性意味着，无论是在正在运行 Actor 的进程内，还是运行在远程计算机上，ActorRef都可以保持相同语义。如果需要，运行时可以通过更改 Actor 的位置或整个应用程序拓扑来优化系统。这就启用了故障管理的“让它崩溃（let it crash）”模型，在该模型中，系统可以通过销毁有问题的 Actor 和重新启动健康的 Actor 来自我修复。\nAkka ActorSystem ActorSystem是Akka的初始接入点。通常每个应用使用一个AcotrSystem来创建。ActorSystem有一个名称和一个守护Actor。应用的启动通常在守护Actor中完成。\n当前这个ActorSystem的守护Actor是GreeterMain。\n1 final ActorSystem\u0026lt;GreeterMain.SayHello\u0026gt; greeterMain = ActorSystem.create(GreeterMain.create(), \u0026#34;helloakka\u0026#34;); 它使用Behaviors.setup来启动应用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package $package$; import akka.actor.typed.ActorRef; import akka.actor.typed.Behavior; import akka.actor.typed.javadsl.*; public class GreeterMain extends AbstractBehavior\u0026lt;GreeterMain.SayHello\u0026gt; { public static class SayHello { public final String name; public SayHello(String name) { this.name = name; } } private final ActorRef\u0026lt;Greeter.Greet\u0026gt; greeter; public static Behavior\u0026lt;SayHello\u0026gt; create() { return Behaviors.setup(GreeterMain::new); } private GreeterMain(ActorContext\u0026lt;SayHello\u0026gt; context) { super(context); //#create-actors greeter = context.spawn(Greeter.create(), \u0026#34;greeter\u0026#34;); //#create-actors } @Override public Receive\u0026lt;SayHello\u0026gt; createReceive() { return newReceiveBuilder().onMessage(SayHello.class, this::onSayHello).build(); } private Behavior\u0026lt;SayHello\u0026gt; onSayHello(SayHello command) { //#create-actors ActorRef\u0026lt;Greeter.Greeted\u0026gt; replyTo = getContext().spawn(GreeterBot.create(3), command.name); greeter.tell(new Greeter.Greet(command.name, replyTo)); //#create-actors return this; } } 新建子actors 其他actor的创建在ActorContext上使用spawn方法。GreeterMain在启动时使用这种方式创建一个Greeter，并且每收到一个SayHello消息创建一个新的GreeterBot。\n1 2 3 4 greeter = context.spawn(Greeter.create(), \u0026#34;greeter\u0026#34;); ActorRef\u0026lt;Greeter.Greeted\u0026gt; replyTo = getContext().spawn(GreeterBot.create(3), command.name); greeter.tell(new Greeter.Greet(command.name, replyTo)); 异步通信 Actor 是被动的和消息驱动的。Actor 在收到消息前什么都不做。Actor 使用异步消息进行通信。这样可以确保发送者不会一直等待接收者处理他们的消息。相反，发件人将邮件放在收件人的邮箱之后，就可以自由地进行其他工作。Actor 的邮箱本质上是一个具有排序语义的消息队列。从同一个 Actor 发送的多条消息的顺序被保留，但可以与另一个 Actor 发送的消息交错。\n你可能想知道 Actor 在不处理消息的时候在做什么，比如，做什么实际的工作？实际上，它处于挂起状态，在这种状态下，它不消耗除内存之外的任何资源。同样，这也展示了 Actor 的轻量级和高效性。\n给 Actor 发生消息 要将消息放入 Actor 的邮箱，我们需要使用ActorRef的tell方法。例如，Hello World的主函数main向Greeter Actor 发送如下消息：\n1 greeterMain.tell(new GreeterMain.SayHello(\u0026#34;Charles\u0026#34;)); Greeter Actor 也回复确认消息：\n1 command.replyTo.tell(new Greeted(command.whom, getContext().getSelf())); 我们已经研究了如何创建 Actor 和发送消息。现在，让我们来回顾一下Main类的全部内容。\nMain class Hello World中的AkkaQuickstart对象创建了带有守护者的ActorSystem，守护者是顶层的负责启动应用的actor。守护者通常使用包含初始启动的Behaviors.setup进行定义。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package $package$; import akka.actor.typed.ActorSystem; import java.io.IOException; public class AkkaQuickstart { public static void main(String[] args) { //#actor-system final ActorSystem\u0026lt;GreeterMain.SayHello\u0026gt; greeterMain = ActorSystem.create(GreeterMain.create(), \u0026#34;helloakka\u0026#34;); //#actor-system //#main-send-messages greeterMain.tell(new GreeterMain.SayHello(\u0026#34;Charles\u0026#34;)); //#main-send-messages try { System.out.println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Press ENTER to exit \u0026lt;\u0026lt;\u0026lt;\u0026#34;); System.in.read(); } catch (IOException ignored) { } finally { greeterMain.terminate(); } } } 完整代码 下面是创建示例应用程序的三个类Greeter，GreeterBot，GreeterMain和AkkaQuickstart的完整源代码：\nGreater.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 package $package$; import akka.actor.typed.ActorRef; import akka.actor.typed.Behavior; import akka.actor.typed.javadsl.*; import java.util.Objects; // #greeter public class Greeter extends AbstractBehavior\u0026lt;Greeter.Greet\u0026gt; { public static final class Greet { public final String whom; public final ActorRef\u0026lt;Greeted\u0026gt; replyTo; public Greet(String whom, ActorRef\u0026lt;Greeted\u0026gt; replyTo) { this.whom = whom; this.replyTo = replyTo; } } public static final class Greeted { public final String whom; public final ActorRef\u0026lt;Greet\u0026gt; from; public Greeted(String whom, ActorRef\u0026lt;Greet\u0026gt; from) { this.whom = whom; this.from = from; } // #greeter @Override public boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; Greeted greeted = (Greeted) o; return Objects.equals(whom, greeted.whom) \u0026amp;\u0026amp; Objects.equals(from, greeted.from); } @Override public int hashCode() { return Objects.hash(whom, from); } @Override public String toString() { return \u0026#34;Greeted{\u0026#34; + \u0026#34;whom=\u0026#39;\u0026#34; + whom + \u0026#39;\\\u0026#39;\u0026#39; + \u0026#34;, from=\u0026#34; + from + \u0026#39;}\u0026#39;; } // #greeter } public static Behavior\u0026lt;Greet\u0026gt; create() { return Behaviors.setup(Greeter::new); } private Greeter(ActorContext\u0026lt;Greet\u0026gt; context) { super(context); } @Override public Receive\u0026lt;Greet\u0026gt; createReceive() { return newReceiveBuilder().onMessage(Greet.class, this::onGreet).build(); } private Behavior\u0026lt;Greet\u0026gt; onGreet(Greet command) { getContext().getLog().info(\u0026#34;Hello {}!\u0026#34;, command.whom); //#greeter-send-message command.replyTo.tell(new Greeted(command.whom, getContext().getSelf())); //#greeter-send-message return this; } } // #greeter GreeterBot.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 package $package$; import akka.actor.typed.Behavior; import akka.actor.typed.javadsl.*; public class GreeterBot extends AbstractBehavior\u0026lt;Greeter.Greeted\u0026gt; { public static Behavior\u0026lt;Greeter.Greeted\u0026gt; create(int max) { return Behaviors.setup(context -\u0026gt; new GreeterBot(context, max)); } private final int max; private int greetingCounter; private GreeterBot(ActorContext\u0026lt;Greeter.Greeted\u0026gt; context, int max) { super(context); this.max = max; } @Override public Receive\u0026lt;Greeter.Greeted\u0026gt; createReceive() { return newReceiveBuilder().onMessage(Greeter.Greeted.class, this::onGreeted).build(); } private Behavior\u0026lt;Greeter.Greeted\u0026gt; onGreeted(Greeter.Greeted message) { greetingCounter++; getContext().getLog().info(\u0026#34;Greeting {} for {}\u0026#34;, greetingCounter, message.whom); if (greetingCounter == max) { return Behaviors.stopped(); } else { message.from.tell(new Greeter.Greet(message.whom, getContext().getSelf())); return this; } } } GreeterMain.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 package $package$; import akka.actor.typed.ActorRef; import akka.actor.typed.Behavior; import akka.actor.typed.javadsl.*; public class GreeterMain extends AbstractBehavior\u0026lt;GreeterMain.SayHello\u0026gt; { public static class SayHello { public final String name; public SayHello(String name) { this.name = name; } } private final ActorRef\u0026lt;Greeter.Greet\u0026gt; greeter; public static Behavior\u0026lt;SayHello\u0026gt; create() { return Behaviors.setup(GreeterMain::new); } private GreeterMain(ActorContext\u0026lt;SayHello\u0026gt; context) { super(context); //#create-actors greeter = context.spawn(Greeter.create(), \u0026#34;greeter\u0026#34;); //#create-actors } @Override public Receive\u0026lt;SayHello\u0026gt; createReceive() { return newReceiveBuilder().onMessage(SayHello.class, this::onSayHello).build(); } private Behavior\u0026lt;SayHello\u0026gt; onSayHello(SayHello command) { //#create-actors ActorRef\u0026lt;Greeter.Greeted\u0026gt; replyTo = getContext().spawn(GreeterBot.create(3), command.name); greeter.tell(new Greeter.Greet(command.name, replyTo)); //#create-actors return this; } } AkkaQuickstart.java 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package $package$; import akka.actor.typed.ActorSystem; import java.io.IOException; public class AkkaQuickstart { public static void main(String[] args) { //#actor-system final ActorSystem\u0026lt;GreeterMain.SayHello\u0026gt; greeterMain = ActorSystem.create(GreeterMain.create(), \u0026#34;helloakka\u0026#34;); //#actor-system //#main-send-messages greeterMain.tell(new GreeterMain.SayHello(\u0026#34;Charles\u0026#34;)); //#main-send-messages try { System.out.println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Press ENTER to exit \u0026lt;\u0026lt;\u0026lt;\u0026#34;); System.in.read(); } catch (IOException ignored) { } finally { greeterMain.terminate(); } } } 作为另一个最佳实践，我们应该提供一些单元测试。\n测试 Actor Hello World示例中的测试展示了 JUnit 框架的使用。虽然测试的覆盖范围不完整，但它简单地展示了测试 Actor 代码是多么的容易，并提供了一些基本概念。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package $package$; import akka.actor.testkit.typed.javadsl.TestKitJunitResource; import akka.actor.testkit.typed.javadsl.TestProbe; import akka.actor.typed.ActorRef; import org.junit.ClassRule; import org.junit.Test; //#definition public class AkkaQuickstartTest { @ClassRule public static final TestKitJunitResource testKit = new TestKitJunitResource(); //#definition //#test @Test public void testGreeterActorSendingOfGreeting() { TestProbe\u0026lt;Greeter.Greeted\u0026gt; testProbe = testKit.createTestProbe(); ActorRef\u0026lt;Greeter.Greet\u0026gt; underTest = testKit.spawn(Greeter.create(), \u0026#34;greeter\u0026#34;); underTest.tell(new Greeter.Greet(\u0026#34;Charles\u0026#34;, testProbe.getRef())); testProbe.expectMessage(new Greeter.Greeted(\u0026#34;Charles\u0026#34;, underTest)); } //#test } 测试类定义 1 2 3 4 public class AkkaQuickstartTest { @ClassRule public static final TestKitJunitResource testKit = new TestKitJunitResource(); 使用TestKitJunitResource JUnit规则包含对JUnit的支持。自动创建并清理ActorTestKit。通过完整文档查看如何直接使用testkit\n测试方法 这个测试使用TestProbe 来检查并确认是否得到期望的行为，源码片段如下：\n1 2 3 4 5 6 7 @Test public void testGreeterActorSendingOfGreeting() { TestProbe\u0026lt;Greeter.Greeted\u0026gt; testProbe = testKit.createTestProbe(); ActorRef\u0026lt;Greeter.Greet\u0026gt; underTest = testKit.spawn(Greeter.create(), \u0026#34;greeter\u0026#34;); underTest.tell(new Greeter.Greet(\u0026#34;Charles\u0026#34;, testProbe.getRef())); testProbe.expectMessage(new Greeter.Greeted(\u0026#34;Charles\u0026#34;, underTest)); } 一旦我们有了TestProbe 的引用，我们将它传递给Greeter作为Greet消息的一部分。然后确认Greeter响应问候发生。\n完整测试程序 这里是完整的测试代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package $package$; import akka.actor.testkit.typed.javadsl.TestKitJunitResource; import akka.actor.testkit.typed.javadsl.TestProbe; import akka.actor.typed.ActorRef; import org.junit.ClassRule; import org.junit.Test; //#definition public class AkkaQuickstartTest { @ClassRule public static final TestKitJunitResource testKit = new TestKitJunitResource(); //#definition //#test @Test public void testGreeterActorSendingOfGreeting() { TestProbe\u0026lt;Greeter.Greeted\u0026gt; testProbe = testKit.createTestProbe(); ActorRef\u0026lt;Greeter.Greet\u0026gt; underTest = testKit.spawn(Greeter.create(), \u0026#34;greeter\u0026#34;); underTest.tell(new Greeter.Greet(\u0026#34;Charles\u0026#34;, testProbe.getRef())); testProbe.expectMessage(new Greeter.Greeted(\u0026#34;Charles\u0026#34;, underTest)); } //#test } 示例代码只涉及了ActorTestKit功能的一小部分，在「这里」可以找到更完整的概述。\n运行应用程序 你可以通过命令行或者 IDE 来运行Hello World应用程序。在本指南的最后一个主题，我们描述了如何在 IntelliJ IDEA 中运行该示例。但是，在我们再次运行应用程序之前，让我们先快速的查看构建文件。\nMaven POM 文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 \u0026lt;!-- #build-sample --\u0026gt; \u0026lt;project\u0026gt; \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; \u0026lt;groupId\u0026gt;hello-akka-java\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;app\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.0\u0026lt;/version\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;akka.version\u0026gt;$akka_version$\u0026lt;/akka.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-actor-typed_2.13\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;\\${akka.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;ch.qos.logback\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;logback-classic\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-actor-testkit-typed_2.13\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;\\${akka.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;junit\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;junit\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.13.1\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;build\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.5.1\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.8\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.8\u0026lt;/target\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.codehaus.mojo\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;exec-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;executable\u0026gt;java\u0026lt;/executable\u0026gt; \u0026lt;arguments\u0026gt; \u0026lt;argument\u0026gt;-classpath\u0026lt;/argument\u0026gt; \u0026lt;classpath /\u0026gt; \u0026lt;argument\u0026gt;$package$.AkkaQuickstart\u0026lt;/argument\u0026gt; \u0026lt;/arguments\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt; \u0026lt;/project\u0026gt; Grade 构建文件 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apply plugin: \u0026#39;java\u0026#39; apply plugin: \u0026#39;idea\u0026#39; apply plugin: \u0026#39;application\u0026#39; repositories { mavenCentral() mavenLocal() } dependencies { implementation \u0026#39;com.typesafe.akka:akka-actor-typed_2.13:$akka_version$\u0026#39; implementation \u0026#39;ch.qos.logback:logback-classic:1.2.3\u0026#39; testImplementation \u0026#39;com.typesafe.akka:akka-actor-testkit-typed_2.13:$akka_version$\u0026#39; testImplementation \u0026#39;junit:junit:4.13.1\u0026#39; } mainClassName = \u0026#34;$package$.AkkaQuickstart\u0026#34; run { standardInput = System.in } 注意：有些依赖有后缀_2.13，这个后缀是编译依赖的scala版本。所有依赖必须使用相同的scala版本编译。所以你不能在单个项目中使用akka-actors_2.13和akka-testkit_2.12，因为它们有不同的scala版本。\n运行项目 和前面一样，从控制台运行应用程序：\n1 2 3 4 5 // Maven $ mvn compile exec:exec // Grade $ gradle run 输出应该如下所示（一直向右滚动以查看 Actor 输出）：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 // Maven Scanning for projects... [INFO] [INFO] ------------------------\u0026lt; hello-akka-java:app \u0026gt;------------------------- [INFO] Building app 1.0 [INFO] --------------------------------[ jar ]--------------------------------- [INFO] [INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ app --- [WARNING] Using platform encoding (UTF-8 actually) to copy filtered resources, i.e. build is platform dependent! [INFO] [INFO] --- exec-maven-plugin:1.6.0:exec (default-cli) @ app --- [2019-10-12 09:20:30,248] [INFO] [akka.event.slf4j.Slf4jLogger] [helloakka-akka.actor.default-dispatcher-3] [] - Slf4jLogger started SLF4J: A number (1) of logging calls during the initialization phase have been intercepted and are SLF4J: now being replayed. These are subject to the filtering rules of the underlying logging system. SLF4J: See also http://www.slf4j.org/codes.html#replay \u0026gt;\u0026gt;\u0026gt; Press ENTER to exit \u0026lt;\u0026lt;\u0026lt; [2019-10-12 09:20:30,288] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:20:30,290] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 1 for Charles [2019-10-12 09:20:30,291] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:20:30,291] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 2 for Charles [2019-10-12 09:20:30,291] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:20:30,291] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 3 for Charles // Grade :run [2019-10-12 09:47:16,399] [INFO] [akka.event.slf4j.Slf4jLogger] [helloakka-akka.actor.default-dispatcher-3] [] - Slf4jLogger started SLF4J: A number (1) of logging calls during the initialization phase have been intercepted and are SLF4J: now being replayed. These are subject to the filtering rules of the underlying logging system. SLF4J: See also http://www.slf4j.org/codes.html#replay \u0026gt;\u0026gt;\u0026gt; Press ENTER to exit \u0026lt;\u0026lt;\u0026lt; [2019-10-12 09:47:16,437] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:47:16,439] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 1 for Charles [2019-10-12 09:47:16,440] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:47:16,440] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 2 for Charles [2019-10-12 09:47:16,440] [INFO] [com.lightbend.akka.sample.Greeter] [helloakka-akka.actor.default-dispatcher-6] [akka://helloakka/user/greeter] - Hello Charles! [2019-10-12 09:47:16,440] [INFO] [com.lightbend.akka.sample.GreeterBot] [helloakka-akka.actor.default-dispatcher-3] [akka://helloakka/user/Charles] - Greeting 3 for Charles \u0026lt;=========----\u0026gt; 75% EXECUTING [27s] \u0026gt; :run 还记得我们实现 Greeter Actor 使用 Akka 的 Logger 吗？这就是为什么我们记录东西时会有很多额外的信息。例如，日志输出包含诸如何时和从哪个 Actor 记录日志之类的信息。\n请注意应用程序一直执行，直到你按下回车键或使用其他方式中断。\n为了执行单元测试，我们输入test命令：\n1 2 3 4 5 // Maven $ mvn test // Grade $ gradle test 下一步 如果你使用 IntelliJ，请尝试将示例项目与 IntelliJ IDEA 集成。\n想要继续了解更多有关 Akka 和 Actor Systems 的信息，请参阅「Getting Started Guide」，欢迎你加入我们！\nIntelliJ IDEA JetBrains 的 IntelliJ 是 Java/Scala 社区中领先的 IDE 之一，它对 Akka 有着极好的支持。本节将指导你完成示例项目的设置、测试和运行。\n设置项目 设置项目很简单。打开 IntelliJ 并选择File -\u0026gt; Open...并指向你安装示例项目的目录。\n检查项目代码 如果我们打开文件src/main/java/com/lightbend/akka/sample/HelloAkka.java，我们将看到许多行以//# ...开头，作为文档的注释。为了从源代码中去掉这些行，我们可以在 IntelliJ 中使用出色的查找/替换功能。选择Edit -\u0026gt; Find -\u0026gt; Replace in Path...，选中Regex框并添加[//#].*正则表达式，然后单击查找窗口中的Replace in Find Window...。选择想要替换的内容，并对所有文件重复此操作。\n测试和运行 对于测试，我们只需右键单击文件src/test/java/com/lightbend/akka/sample/HelloAkkaTest.java，然后选择Run 'HelloAkkaTest'。\n类似地运行应用程序，我们右击文件src/main/java/com/lightbend/akka/sample/HelloAkka.java，并选择Run 'HelloAkka.main()'。\n有关更多详细信息，请参阅「运行应用程序」部分。\n想要进一步了解 IntelliJ IDEA，可以参阅「史上最简单的 IntelliJ IDEA 教程」系列文章。\n","permalink":"https://WFUing.github.io/posts/tech/architecture/iot/akka-java/","summary":"Akka 是一个用于在 JVM 上构建高并发、分布式和可容错的事件驱动应用程序的运行时工具包。Akka 既可以用于 Java，也可以用于 Scala。本指南通过描述 Java 版本的\u003ccode\u003eHello World\u003c/code\u003e示例来介绍 Akka。","title":"快速入门 Akka Java 指南"},{"content":"我们试图建立一个通用的术语来定义一个坚实的基础以对并发、分布式系统这些 Akka 的目标问题展开交流。请注意，对于这些术语并没有一个统一的定义。我们只是为了寻找一些可行的定义以便在整个文档中进行引用。\n并发 vs. 并行 并发与并行是相关的概念，但有一些不同点。并发意味着有两个或更多任务正在进行，即使不是在同时执行。这种例子可以通过时间切片来实现，其中一部分任务被顺序执行，并与其他部分任务混合。并行在另一方面来说意味着执行会真正的同时发生。\n异步 vs. 同步 一个方法调用，如果调用者直到方法返回一个值或抛出异常才能继续前进，则被认为这是同步调用。另一方面，一个异步调用允许调用者继续前进有限个步骤，而方法的完成则会通过一些额外的机制来告知调用者(比如注册回调、Future或通过消息)。\n无阻塞 vs. 阻塞 我们所说的阻塞是指一个线程的延迟会无限期的延迟其他线程。一个很好的例子是一个资源可以通过互斥量被一个线程独占使用。如果一个线程无限期的持有该资源(比如意外进入无线循环)，其他线程则无法继续前进。相反，无阻塞则意外着没有线程能够无限期的延迟其他线程。\n总是应该更优先选择使用无阻塞操作，因为阻塞操作将导致系统的整体进度无法保证。\n死锁 vs. 饥饿 vs. 活锁 当多个参与者都在相互等待对方到达一个特殊状态以便程序能够继续进行，则会发生死锁。因为在其他参与者到达一个确定状态(\u0026ldquo;Catch-22\u0026rdquo; 问题)之前没有一个能够继续进行下去，从而导致所有受影响的子系统失速。死锁与阻塞紧密相关，因为这必然是由于一个线程无期限的延迟了其他线程的进展。\n在死锁的情况下，没有参与者可以继续前进，相反则会发生饥饿，当一些参与者能够继续前进时，仍有一些不能前进。一个经典的场景是源生调度算法总是会选择高优先级的任务而非低优先级的那些。如果进入的高优先级任务的数量总是保持很高，这时没有任何低优先级的任务能够完成。\n活锁和死锁类似，也是没有参与者能够继续前进。但与之前被冻结在一个状态等待其他参与者继续前进不同的是，所有的参与者在连续不断的改变他们的状态。比如一个场景，有两个参与者拥有两个完全一致的可用资源。他们互相都在尝试获取资源，但同时也检查对方是否需要该资源。如果一个资源整备其他参与者访问，则该参与者会尝试请求资源的其他实例。不幸的情况是两个参与者可能会在两个资源之间来回跳，从来没有获得，而总是让给对方。\n竟态条件 如果一组事件的顺序会被外部的不确定因素影响，我们称之为竟态条件。竟态条件经常会发生在多个线程拥有共享的可变状态，而线程对状态的修改操作会被无法预期的行为打乱。虽然通常的情况是这样，但共享状态并非必须要有竟态条件。比如一个例子，一个客户端发送无序的 P1、P2 给服务端。由于包可能通过不同的网络路由传输，服务端可能会先收到 P2 然后才是 P1。如果消息中并不包含服务端可以识别发送顺序的信息，因此基于包的具体含义可能会引起静态条件。\n无阻塞保证(Progress Conditions) 阻塞由于多种原因是不被提倡的，包括死锁的危险和被缩减的系统吞吐量。\n无需等待(Wait-freedom) 一个方法的每次调用都保证会在有限个步骤后结束，则称该方法为\u0026quot;wait-free\u0026quot;。如果一个方法是有界的(bounded)\u0026ldquo;wait-free\u0026rdquo;，则步骤的数量拥有一个有限的上界(upper bound)。\n从这个定义中可以知道无等待方法从不会阻塞，因此死锁也不会发生。另外，因为每个参与者都会在有限个步骤后(即调用结束后)继续前进，无等待方法也不会出现饥饿。\n无锁(Lock-freedom) 无锁相比无等待是一个较弱的特性。在无锁(lock-free)调用中，有些方法通常无限制的在有限个步骤后结束。这个定义意味着无锁调用永远不会发生死锁。另一方面，一些调用在有限个步骤后结束的保证并不足以保证它们最终都会结束。换句话说就是无锁并不能足以保证饥饿的发生。\n无阻碍(Obstruction-freedom) 无阻碍是这里讨论的最弱的无阻塞保证。如果一个方法在隔离执行后(其他线程执行任何步骤，比如被挂起)有一个时间点，并在有限数量步骤后结束，则称该方法为无阻碍。所有无锁对象都是无障碍的，但相反则不能成立。\n乐观并发控制(Optimistic concurrency control , OCC) 方法通常是无阻碍的。OCC 方式是指每个参与者都尝试在共享对象上执行它们的操作，但是如果一个参与者检测到冲突，它会回滚修改，并根据一些调度规则再次尝试。如果一个时间点只有一个参与者在尝试，操作则会成功。\n","permalink":"https://WFUing.github.io/posts/tech/architecture/iot/concept/","summary":"试图建立一个通用的术语来定义一个坚实的基础以对并发、分布式系统这些 Akka 的目标问题展开交流。请注意，对于这些术语并没有一个统一的定义。我们只是为了寻找一些可行的定义以便在整个文档中进行引用。","title":"术语与概念"},{"content":"在不同领域工作的组织机构正在独立发现构建相同软件的模式。这些系统更强大、更有弹性、更灵活，能够更好地满足现代需求。\n之所以会发生这些变化，是因为近年来应用需求发生了巨大变化。仅在几年前，一个大型应用程序需要数十台服务器、数秒的响应时间、数小时的离线维护和数千兆字节的数据。如今，应用程序部署在从移动设备到运行数千个多核处理器的云计算集群等各种设备上。用户期望毫秒级的响应时间和 100% 的正常运行时间。数据的单位是 Petabytes。昨天的软件架构根本无法满足今天的需求。\n我们认为需要一种连贯一致的系统架构方法，而且我们相信所有必要的方面都已得到单独认可：我们希望系统具有响应性、复原性、弹性和消息驱动性。我们称之为反应式系统。\n作为反应式系统构建的系统更加灵活、松散耦合和可扩展。这使它们更易于开发和变更。它们对故障的容忍度更高，当故障发生时，它们会以优雅而非灾难的方式应对。反应式系统反应灵敏，能为用户提供有效的互动反馈。\nReactive Systems Responsive：如果可能，系统应及时作出反应。响应性是可用性和实用性的基石，但不仅如此，响应性还意味着可以快速发现问题并有效处理。响应式系统的重点是提供快速、一致的响应时间，建立可靠的上限，从而提供一致的服务质量。这种一致的行为反过来又简化了错误处理，建立了终端用户的信心，并鼓励了进一步的互动。\nResilient： 面对故障，系统仍能保持响应。这不仅适用于高可用性的关键任务系统，任何不具备弹性的系统在发生故障后都会反应迟钝。弹性是通过复制、遏制、隔离和授权来实现的。故障被控制在每个组件内，组件之间相互隔离，从而确保系统的部分组件可以在不影响整个系统的情况下发生故障并恢复。每个组件的恢复都委托给另一个（外部）组件，并在必要时通过复制确保高可用性。一个组件的客户端不承担处理其故障的负担。\nElastic：系统在不同的工作量下保持响应。反应型系统可以通过增加或减少分配用于服务这些输入的资源，对输入率的变化做出反应。这意味着设计不存在争用点或中心瓶颈，从而能够分片或复制组件，并在它们之间分配输入。反应式系统通过提供相关的实时性能测量，支持预测式和反应式扩展算法。它们在商品硬件和软件平台上以具有成本效益的方式实现了弹性。\nMessage Driven：反应式系统依靠异步消息传递来建立组件之间的边界，以确保松散耦合、隔离和位置透明。这种边界还提供了将故障作为消息委派的方法。采用显式消息传递可通过塑造和监控系统中的消息队列，并在必要时施加反向压力，实现负载管理、弹性和流量控制。将透明消息传递作为一种通信手段，可使故障管理在整个集群或单个主机内使用相同的结构和语义。无阻塞通信允许接收方仅在活动时消耗资源，从而减少系统开销。\n大型系统由较小的系统组成，因此依赖于其组成部分的反应特性。这意味着，反应式系统采用的设计原则使这些特性适用于所有规模的系统，从而使它们具有可组合性。世界上最大的系统都依赖于基于这些特性的架构，每天满足数十亿人的需求。现在是时候从一开始就有意识地应用这些设计原则了，而不是每次都要重新发现它们。\nResources http://reactivemanifesto.org/ ","permalink":"https://WFUing.github.io/posts/tech/architecture/iot/reactive-manifesto/","summary":"响应式系统具有响应性、复原性、弹性和消息驱动性。","title":"响应式宣言(Reactive Manifesto)"},{"content":"Akka可以在这里找到指定版本的下载链接： http://akka.io/downloads。\n所有的示例代码都是编译通过的，如果想要查看源码，请查看 Akka 文档在 Github 上子项目，包含 Java 和 Scala 两个部分。本教程主要是 Akka 的 Java 部分。\nActor System 使用 Akka 可以让你从为 Actor 系统创建基础设施和编写控制基本行为所需的初级（low-level）代码中解脱出来。为了理解这一点，让我们看看你在代码中创建的 Actor 与 Akka 在内部为你创建和管理的 Actor 之间的关系，Actor 的生命周期和失败处理。\n在你的项目中添加如下依赖：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 \u0026lt;!-- Maven --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.typesafe.akka\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;akka-actor_2.11\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.5.19\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- Gradle --\u0026gt; dependencies { compile group: \u0026#39;com.typesafe.akka\u0026#39;, name: \u0026#39;akka-actor_2.11\u0026#39;, version: \u0026#39;2.5.19\u0026#39; } \u0026lt;!-- sbt --\u0026gt; libraryDependencies += \u0026#34;com.typesafe.akka\u0026#34; %% \u0026#34;akka-actor\u0026#34; % \u0026#34;2.5.19\u0026#34; Akka 的 Actor 层级 Akka 的 Actor 总是属于父 Actor。通常，你可以通过调用getContext().actorOf()来创建 Actor。与创建一个\u0026quot;独立的\u0026quot; Actor 不同，这会将新 Actor 作为一个子节点注入到已经存在的树中：创建 Actor 的 Actor 成为新创建的子 Actor 的父级。你可能会问，你创造的第一个 Actor 的父节点是谁？\n如下图所示，所有的 Actor 都有一个共同的父节点，即用户守护者。可以使用system.actorOf()在当前 Actor 下创建新的 Actor 实例。正如我们在「快速入门 Akka Java 指南」中介绍的那样，创建 Actor 将返回一个有效的 URL 引用。例如，如果我们用system.actorOf(…, \u0026quot;someActor\u0026quot;)创建一个名为someActor的 Actor，它的引用将包括路径/user/someActor。\nPart 1: Actor Architecture 事实上，在你在代码中创建 Actor 之前，Akka 已经在系统中创建了三个 Actor 。这些内置的 Actor 的名字包含guardian，因为他们守护他们所在路径下的每一个子 Actor。守护者 Actor 包括：\n/，根守护者（root guardian）。这是系统中所有 Actor 的父 Actor，也是系统本身终止时要停止的最后一个 Actor。\n/user，守护者（guardian）。这是用户创建的所有 Actor 的父 Actor。不要让用户名混淆，它与最终用户和用户处理无关。使用 Akka 库创建的每个 Actor 都将有一个事先准备的固定路径/user/。\n/system，系统守护者（system guardian）。这是除上述三个 Actor 外，系统创建的所有 Actor 的父 Actor，\n在Hello World示例中，我们已经看到system.actorOf()如何直接在/user下创建 Actor。我们称之为顶级 Actor，尽管实际上它只是在用户定义的层次结构的顶部。你的ActorSystem中通常只有一个（或极少数）顶级 Actor。我们通过从现有的 Actor 调用context.actorOf()来创建子 Actor 或非顶级 Actor。context.actorOf()方法具有与system.actorOf()相同的签名，后者是其对应的顶级。\n查看 Actor 层次结构的最简单方法是打印ActorRef实例。在这个小实验中，我们创建了一个 Actor，打印了它的引用，创建了这个 Actor 的一个子 Actor，并打印了这个子 Actor 的引用。我们从Hello World项目开始，如果你还没有下载它，请从「Lightbend Tech Hub」下载 QuickStart 项目。\n在你的Hello World项目中，导航到com.example包并创建一个新的名为ActorHierarchyExperiments.java的 Java 文件。将下面代码段中的代码复制并粘贴到此新源文件中。保存文件并运行sbt \u0026quot;runMain com.example.ActorHierarchyExperiments\u0026quot;来观察输出。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 package com.example; import akka.actor.AbstractActor; import akka.actor.AbstractActor.Receive; import akka.actor.ActorRef; import akka.actor.ActorSystem; import akka.actor.Props; public class ActorHierarchyExperiments { public static void main(String[] args) throws java.io.IOException { ActorSystem system = ActorSystem.create(\u0026#34;testSystem\u0026#34;); ActorRef firstRef = system.actorOf(PrintMyActorRefActor.props(), \u0026#34;first-actor\u0026#34;); System.out.println(\u0026#34;First: \u0026#34; + firstRef); firstRef.tell(\u0026#34;printit\u0026#34;, ActorRef.noSender()); System.out.println(\u0026#34;\u0026gt;\u0026gt;\u0026gt; Press ENTER to exit \u0026lt;\u0026lt;\u0026lt;\u0026#34;); try { System.in.read(); } finally { system.terminate(); } } } class PrintMyActorRefActor extends AbstractActor { static Props props() { return Props.create(PrintMyActorRefActor.class, PrintMyActorRefActor::new); } @Override public Receive createReceive() { return receiveBuilder() .matchEquals(\u0026#34;printit\u0026#34;, p -\u0026gt; { ActorRef secondRef = getContext().actorOf(Props.empty(), \u0026#34;second-actor\u0026#34;); System.out.println(\u0026#34;Second: \u0026#34; + secondRef); }) .build(); } } 注意信息要求第一个 Actor 完成工作的方式。我们使用父 Actor 的引用firstRef.tell(\u0026quot;printit\u0026quot;, ActorRef.noSender())发送消息。当代码执行时，输出包括第一个 Actor 的引用，以及匹配printit模式时创建的子 Actor 的引用。你的输出应该与下面的内容相似：\n1 2 First: Actor[akka://testSystem/user/first-actor#1053618476] Second: Actor[akka://testSystem/user/first-actor/second-actor#-1544706041] 注意 Actor 引用的结构：\n两条路径都以akka://testSystem/开头。因为所有 Actor 的引用都是有效的 URL，所以akka://是协议字段的值。 接下来，就像在万维网（World Wide Web）上一样，URL 标识系统。在本例中，系统名为testSystem，但它可以是任何其他名称。如果启用了多个系统之间的远程通信，则 URL 的这一部分包括主机名，以便其他系统可以在网络上找到它。 因为第二个 Actor 的引用包含路径/first-actor/，这个标识它为第一个 Actor 的子 Actor。 Actor 引用的最后一部分，即#1053618476或#-1544706041是一个在大多数情况下可以忽略的唯一标识符。 既然你了解了 Actor 层次结构的样子，你可能会想：为什么我们需要这个层次结构？它是用来干什么的？\n层次结构的一个重要作用是安全地管理 Actor 的生命周期。接下来，我们来考虑一下，这些知识如何帮助我们编写更好的代码。\nActor 的生命周期 Actor 在被创建时就会出现，然后在用户请求时被停止。每当一个 Actor 被停止时，它的所有子 Actor 也会被递归地停止。这种行为大大简化了资源清理，并有助于避免诸如由打开的套接字和文件引起的资源泄漏。事实上，在处理初级多线程代码时，一个通常被忽视的困难是各种并发资源的生命周期管理。\n要停止 Actor，建议的模式是调用 Actor 内部的getContext().stop(getSelf())来停止自身，通常是对某些用户定义的停止消息的响应，或者当 Actor 完成其任务时。从技术上讲，通过调用getContext().stop(actorRef)是可以停止另一个 Actor 的，但通过这种方式停止任意的 Actor 被认为是一种糟糕的做法：停止 Actor 的一个比较好的方法是，尝试向他们发送一个\u0026quot;毒丸（PoisonPill）\u0026ldquo;或自定义的停止消息。\nAkka Actor 的 API 暴露了许多生命周期的钩子，你可以在 Actor 的实现中覆盖这些钩子。最常用的是preStart()和postStop()方法。\npreStart()在 Actor 启动之后但在处理其第一条消息之前调用。 postStop()在 Actor 停止之前调用，在此时之后将不再处理任何消息。 让我们在一个简单的实验中使用生命周期中的preStart()和postStop()钩子来观察停止一个 Actor 时的行为。首先，将以下两个 Actor 类添加到项目中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 class StartStopActor1 extends AbstractActor { static Props props() { return Props.create(StartStopActor1.class, StartStopActor1::new); } @Override public void preStart() { System.out.println(\u0026#34;first started\u0026#34;); getContext().actorOf(StartStopActor2.props(), \u0026#34;second\u0026#34;); } @Override public void postStop() { System.out.println(\u0026#34;first stopped\u0026#34;); } @Override public Receive createReceive() { return receiveBuilder() .matchEquals(\u0026#34;stop\u0026#34;, s -\u0026gt; { getContext().stop(getSelf()); }) .build(); } } class StartStopActor2 extends AbstractActor { static Props props() { return Props.create(StartStopActor2.class, StartStopActor2::new); } @Override public void preStart() { System.out.println(\u0026#34;second started\u0026#34;); } @Override public void postStop() { System.out.println(\u0026#34;second stopped\u0026#34;); } // Actor.emptyBehavior is a useful placeholder when we don\u0026#39;t // want to handle any messages in the actor. @Override public Receive createReceive() { return receiveBuilder() .build(); } } 接下来，创建一个主函数来启动 Actors，然后向他们发送stop消息：\n1 2 ActorRef first = system.actorOf(StartStopActor1.props(), \u0026#34;first\u0026#34;); first.tell(\u0026#34;stop\u0026#34;, ActorRef.noSender()); 你可以再次使用sbt命令来启动这个项目，其输出结果应该如下面这样：\n1 2 3 4 first started second started second stopped first stopped 当我们停止first Actor 时，它会在停止自身之前，先停止了它的子 Actor second。这个顺序是严格的，在调用父 Actor 的postStop()钩子之前，会先调用所有子 Actor 的postStop()钩子。\n在 Akka 参考手册的「Actor Lifecycle」部分提供了关于 Actor 的全套生命周期钩子的详细信息。\n失败处理 父 Actor 和子 Actor 在他们的生命周期中是相互联系的。当一个 Actor 失败（抛出一个异常或从接收中冒出一个未处理的异常）时，它将暂时挂起。如前所述，失败信息被传播到父 Actor，然后父 Actor 决定如何处理由子 Actor 引起的异常。这样，父 Actor 就可以作为子 Actor 的监督者（supervisors）。默认的监督策略是停止并重新启动子 Actor。如果不更改默认策略，所有失败都会导致重新启动。\n让我们在一个简单的实验中观察默认策略。将下面的类添加到项目中，就像之前的类一样：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 class SupervisingActor extends AbstractActor { static Props props() { return Props.create(SupervisingActor.class, SupervisingActor::new); } ActorRef child = getContext().actorOf(SupervisedActor.props(), \u0026#34;supervised-actor\u0026#34;); @Override public Receive createReceive() { return receiveBuilder() .matchEquals(\u0026#34;failChild\u0026#34;, f -\u0026gt; { child.tell(\u0026#34;fail\u0026#34;, getSelf()); }) .build(); } } class SupervisedActor extends AbstractActor { static Props props() { return Props.create(SupervisedActor.class, SupervisedActor::new); } @Override public void preStart() { System.out.println(\u0026#34;supervised actor started\u0026#34;); } @Override public void postStop() { System.out.println(\u0026#34;supervised actor stopped\u0026#34;); } @Override public Receive createReceive() { return receiveBuilder() .matchEquals(\u0026#34;fail\u0026#34;, f -\u0026gt; { System.out.println(\u0026#34;supervised actor fails now\u0026#34;); throw new Exception(\u0026#34;I failed!\u0026#34;); }) .build(); } } 然后运行：\n1 2 ActorRef supervisingActor = system.actorOf(SupervisingActor.props(), \u0026#34;supervising-actor\u0026#34;); supervisingActor.tell(\u0026#34;failChild\u0026#34;, ActorRef.noSender()); 你应该看到类似如下的输出结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 supervised actor started supervised actor fails now supervised actor stopped supervised actor started [ERROR] [03/29/2017 10:47:14.150] [testSystem-akka.actor.default-dispatcher-2] [akka://testSystem/user/supervising-actor/supervised-actor] I failed! java.lang.Exception: I failed! at tutorial_1.SupervisedActor$$anonfun$receive$4.applyOrElse(ActorHierarchyExperiments.scala:57) at akka.actor.Actor$class.aroundReceive(Actor.scala:513) at tutorial_1.SupervisedActor.aroundReceive(ActorHierarchyExperiments.scala:47) at akka.actor.ActorCell.receiveMessage(ActorCell.scala:519) at akka.actor.ActorCell.invoke(ActorCell.scala:488) at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:257) at akka.dispatch.Mailbox.run(Mailbox.scala:224) at akka.dispatch.Mailbox.exec(Mailbox.scala:234) at akka.dispatch.forkjoin.ForkJoinTask.doExec(ForkJoinTask.java:260) at akka.dispatch.forkjoin.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1339) at akka.dispatch.forkjoin.ForkJoinPool.runWorker(ForkJoinPool.java:1979) at akka.dispatch.forkjoin.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:107) 我们看到失败后，被监督的 Actor 停止并立即重新启动。我们还看到一个日志条目，报告处理的异常，在本例中是我们的测试异常。在这个例子中，我们使用了preStart()和postStop()钩子，这是重启后和重启前默认调用的钩子，因此我们无法区分 Actor 内部是第一次启动还是重启。这通常是正确的做法，重新启动的目的是将 Actor 设置为已知的良好状态，这通常意味着一个干净的开始阶段。实际上，在重新启动时，调用的是preRestart()和postRestart()方法，但如果不重写这两个方法，则默认分别委托给postStop()和preStart()。你可以尝试重写这些附加方法，并查看输出是如何变化的。\n无论如何，我们还是建议查看「监督和监控」，以了解更深入的细节。\nResources Gitter Chat，Akka 在线交流平台； Akka Forums，Akka 论坛； Akka in GitHub，Akka 开源项目仓库； Akka Official Website，Akka 官网； Akka Java API，Akka 应用程序编程接口。 快速入门指南 快速入门 Akka Java 指南 快速入门 Akka Scala 指南 gitbook https://zhangyi.gitbooks.io/akka-in-action/content/actor_system.html https://guobinhit.github.io/akka-guide/ ","permalink":"https://WFUing.github.io/posts/tech/architecture/iot/akka/","summary":"Akka 是一个开源项目，基于 Apache 2 License。AKKA框架是用Scala写的，主要用于高并发与分布式应用，目前已经得到广泛地运用，例如Spark、Spray等框架在底层都使用了AKKA进行并发处理。","title":"akka框架"},{"content":"一、公式使用参考 1．如何插入公式 $ \\LaTeX $ 的数学公式有两种：行中公式和独立公式。行中公式放在文中与其它文字混编，独立公式单独成行。\n行中公式可以用如下方法表示： $ 数学公式 $\n独立公式可以用如下方法表示： $$ 数学公式 $$\n自动编号的公式可以用如下方法表示： 若需要手动编号，参见“大括号和行标的使用”。 \\begin{equation} 数学公式 \\label{eq:当前公式名} \\end{equation}\n自动编号后的公式可在全文任意处使用 \\eqref{eq:公式名} 语句引用。\n例子： 1 $ J_\\alpha(x) = \\sum_{m=0}^\\infty \\frac{(-1)^m}{m! \\Gamma (m + \\alpha + 1)} {\\left({ \\frac{x}{2} }\\right)}^{2m + \\alpha} \\text {，行内公式示例} $ 显示：$ J_\\alpha(x) = \\sum_{m=0}^\\infty \\frac{(-1)^m}{m! \\Gamma (m + \\alpha + 1)} {\\left({ \\frac{x}{2} }\\right)}^{2m + \\alpha} \\text {，行内公式示例} $\n例子：\n1 $$ J_\\alpha(x) = \\sum_{m=0}^\\infty \\frac{(-1)^m}{m! \\Gamma (m + \\alpha + 1)} {\\left({ \\frac{x}{2} }\\right)}^{2m + \\alpha} \\text {，独立公式示例} $$ 显示：$$ J_\\alpha(x) = \\sum_{m=0}^\\infty \\frac{(-1)^m}{m! \\Gamma (m + \\alpha + 1)} {\\left({ \\frac{x}{2} }\\right)}^{2m + \\alpha} \\text {，独立公式示例} $$\n例子：\n1 2 3 4 5 6 $$ 在公式 \\eqref{eq:sample} 中，我们看到了这个被自动编号的公式。$$ \\begin{equation} E=mc^2 \\text{，自动编号公式示例} \\label{eq:sample} \\end{equation} 显示： $$ 在公式 \\eqref{eq:sample} 中，我们看到了这个被自动编号的公式。$$\n\\begin{equation} E=mc^2 \\text{，自动编号公式示例} \\label{eq:sample} \\end{equation}\n2．如何输入上下标 ^ 表示上标, _ 表示下标。如果上下标的内容多于一个字符，需要用 {} 将这些内容括成一个整体。上下标可以嵌套，也可以同时使用。\n例子： 1 $$ x^{y^z}=(1+{\\rm e}^x)^{-2xy^w} $$ 显示：$$ x^{y^z}=(1+{\\rm e}^x)^{-2xy^w} $$ 另外，如果要在左右两边都有上下标，可以使用 \\sideset 命令；也可以简单地在符号前面多打一个上下标，此时会以行内公式渲染。\n例子： 1 $$ \\sideset{^1_2}{^3_4}\\bigotimes \\quad or \\quad {^1_2}\\bigotimes {^3_4} $$ 显示：$$\\sideset{^1_2}{^3_4}\\bigotimes \\quad or \\quad {^1_2}\\bigotimes {^3_4} $$ 3．如何输入括号和分隔符 ()、[] 和 | 表示符号本身，使用 \\{\\} 来表示 {} 。当要显示大号的括号或分隔符时，要用 \\left 和 \\right 命令。\n一些特殊的括号：\n输入 显示 输入 显示 \\langle $\\langle$ \\rangle $\\rangle$ \\lceil $\\lceil$ \\rceil $\\rceil$ \\lfloor $\\lfloor$ \\rfloor $\\rfloor$ \\lbrace $\\lbrace$ \\rbrace $\\rbrace$ \\lvert $\\lvert$ \\rvert $\\rvert$ \\lVert $\\lVert$ \\rVert $\\rVert$ @lymd 有时，我们需要在行内使用两个竖杠表示向量间的某种空间距离，可以这样写 \\lVert \\boldsymbol{X}_i - \\boldsymbol{S}_j \\rVert^2 → $\\lVert \\boldsymbol{X}_i - \\boldsymbol{S}_j \\rVert^2$ 例子： 1 $$ f(x,y,z) = 3y^2z \\left( 3+\\frac{7x+5}{1+y^2} \\right) $$ 显示：$$ f(x,y,z) = 3y^2z \\left( 3+\\frac{7x+5}{1+y^2} \\right) $$ 有时要用 \\left. 或 \\right. 进行匹配而不显示本身。\n例子： 1 $$ \\left. \\frac{{\\rm d}u}{{\\rm d}x} \\right| _{x=0} $$ 显示：$$ \\left. \\frac{{\\rm d}u}{{\\rm d}x} \\right| _{x=0} $$ 4．如何输入分数 通常使用 \\frac {分子} {分母} 来生成一个分数，分数可多层嵌套。如果分式较为复杂，亦可使用 分子 \\over 分母 此时分数仅有一层。\n例子： 1 $$ \\frac{a-1}{b-1} \\quad or \\quad {a+1 \\over b+1} $$ 显示：$$ \\frac{a-1}{b-1} \\quad or \\quad {a+1 \\over b+1} $$ 当分式 仅有两个字符时 可直接输入 \\frac ab 来快速生成一个 $\\large\\frac ab$ 。\n例子： 1 $$ \\frac 12,\\frac 1a,\\frac a2 \\quad \\mid \\quad \\text{2 letters only:} \\quad \\frac 12a \\,, k\\frac q{r^2} $$ 显示：$$ \\frac 12,\\frac 1a,\\frac a2 \\quad \\mid \\quad \\text{2 letters only:} \\quad \\frac 12a ,, k\\frac q{r^2} $$ 5．如何输入开方 使用 \\sqrt [根指数，省略时为2] {被开方数} 命令输入开方。\n例子： 1 $$ \\sqrt{2} \\quad or \\quad \\sqrt[n]{3} $$ 显示：$$ \\sqrt{2} \\quad or \\quad \\sqrt[n]{3} $$ 6．如何输入省略号 数学公式中常见的省略号有两种，\\ldots 表示与 文本底线 对齐的省略号，\\cdots 表示与 文本中线 对齐的省略号。\n例子： 1 $$ f(x_1,x_2,\\underbrace{\\ldots}_{\\rm ldots} ,x_n) = x_1^2 + x_2^2 + \\underbrace{\\cdots}_{\\rm cdots} + x_n^2 $$ 显示：$$ f(x_1,x_2,\\underbrace{\\ldots}{\\rm ldots} ,x_n) = x_1^2 + x_2^2 + \\underbrace{\\cdots}{\\rm cdots} + x_n^2 $$ 7．如何输入向量 使用 \\vec{向量} 来自动产生一个向量。也可以使用 \\overrightarrow 等命令自定义字母上方的符号。\n例子： 1 $$ \\vec{a} \\cdot \\vec{b}=0 $$ 显示：$$ \\vec{a} \\cdot \\vec{b}=0 $$\n例子：\n1 $$ xy \\text{ with arrows:} \\quad \\overleftarrow{xy} \\; \\mid \\; \\overleftrightarrow{xy} \\; \\mid \\; \\overrightarrow{xy} $$ 显示：$$ xy \\text{ with arrows:} \\quad \\overleftarrow{xy} ; \\mid ; \\overleftrightarrow{xy} ; \\mid ; \\overrightarrow{xy} $$ 8．如何输入积分 使用 \\int_积分下限^积分上限 {被积表达式} 来输入一个积分。\n例子：\n1 $$ \\int_0^1 {x^2} \\,{\\rm d}x $$ 显示：$$ \\int_0^1 {x^2} ,{\\rm d}x $$\n本例中 \\, 和 {\\rm d} 部分可省略，但加入能使式子更美观，详见“在字符间加入空格”及“如何进行字体转换”。\n9．如何输入极限运算 使用 \\lim_{变量 \\to 表达式} 表达式 来输入一个极限。如有需求，可以更改 \\to 符号至任意符号。\n例子：\n1 $$ \\lim_{n \\to \\infty} \\frac{1}{n(n+1)} \\quad and \\quad \\lim_{x\\leftarrow{示例}} \\frac{1}{n(n+1)} $$ 显示：$$ \\lim_{n \\to \\infty} \\frac{1}{n(n+1)} \\quad and \\quad \\lim_{x\\leftarrow{示例}} \\frac{1}{n(n+1)} $$\n10．如何输入累加、累乘运算 使用 \\sum_{下标表达式}^{上标表达式} {累加表达式} 来输入一个累加。与之类似，使用 \\prod \\bigcup \\bigcap 来分别输入累乘、并集和交集，更多符号可参考“其它特殊字符”。 此类符号在行内显示时上下标表达式将会移至右上角和右下角，如 $\\sum_{i=1}^n \\frac{1}{i^2}$。\n例子： 1 $$ \\sum_{i=1}^n \\frac{1}{i^2} \\quad and \\quad \\prod_{i=1}^n \\frac{1}{i^2} \\quad and \\quad \\bigcup_{i=1}^{2} \\Bbb{R} $$ 显示：$$ \\sum_{i=1}^n \\frac{1}{i^2} \\quad and \\quad \\prod_{i=1}^n \\frac{1}{i^2} \\quad and \\quad \\bigcup_{i=1}^{2} \\Bbb{R} $$ 11．如何输入希腊字母 输入 \\小写希腊字母英文全称 和 \\首字母大写希腊字母英文全称 来分别输入小写和大写希腊字母。 对于大写希腊字母与现有字母相同的，直接输入大写字母即可。\n输入 显示 输入 显示 输入 显示 输入 显示 \\alpha $\\alpha$ A $A$ \\beta $\\beta$ B $B$ \\gamma $\\gamma$ \\Gamma $\\Gamma$ \\delta $\\delta$ \\Delta $\\Delta$ \\epsilon $\\epsilon$ E $E$ \\zeta $\\zeta$ Z $Z$ \\eta $\\eta$ H $H$ \\theta $\\theta$ \\Theta $\\Theta$ \\iota $\\iota$ I $I$ \\kappa $\\kappa$ K $K$ \\lambda $\\lambda$ \\Lambda $\\Lambda$ \\mu $\\mu$ M $M$ \\nu $\\nu$ N $N$ \\xi $\\xi$ \\Xi $\\Xi$ o $o$ O $O$ \\pi $\\pi$ \\Pi $\\Pi$ \\rho $\\rho$ P $P$ \\sigma $\\sigma$ \\Sigma $\\Sigma$ \\tau $\\tau$ T $T$ \\upsilon $\\upsilon$ \\Upsilon $\\Upsilon$ \\phi $\\phi$ \\Phi $\\Phi$ \\chi $\\chi$ X $X$ \\psi $\\psi$ \\Psi $\\Psi$ \\omega $\\omega$ \\Omega $\\Omega$ 部分字母有变量专用形式，以 \\var- 开头。\n小写形式 大写形式 变量形式 显示 \\epsilon E \\varepsilon $\\epsilon \\mid E \\mid \\varepsilon$ \\theta \\Theta \\vartheta $\\theta \\mid \\Theta \\mid \\vartheta$ \\rho P \\varrho $\\rho \\mid P \\mid \\varrho$ \\sigma \\Sigma \\varsigma $\\sigma \\mid \\Sigma \\mid \\varsigma$ \\phi \\Phi \\varphi $\\phi \\mid \\Phi \\mid \\varphi$ 12．如何输入其它特殊字符 **完整的 $\\LaTeX$ 可用符号列表可以在 这份文档 中查阅（极长，共 348 页），大部分常用符号可以参阅 这份精简版文档 查询。**需要注意的是，$\\LaTeX$ 符号并不保证在 MathJax v2.2 中可用，即在 Cmd Markdown 编辑阅读器中可能并不支持所输入的特定命令。\n若需要显示更大或更小的字符，在符号前插入 \\large 或 \\small 命令。 MathJax 针对任意元素均提供从小至大 \\tiny \\Tiny \\scriptsize \\small *默认值 \\normalsize \\large \\Large \\LARGE \\huge \\Huge 共十种渲染大小，详见官方文档。\n若找不到需要的符号，推荐使用 $\\large\\rm{Detexify}$ 来画出想要的符号 (1)．关系运算符 输入 显示 输入 显示 输入 显示 输入 显示 \\pm $\\pm$ \\times $\\times$ \\div $\\div$ \\mid $\\mid$ \\nmid $\\nmid$ \\cdot $\\cdot$ \\circ $\\circ$ \\ast $\\ast$ \\bigodot $\\bigodot$ \\bigotimes $\\bigotimes$ \\bigoplus $\\bigoplus$ \\leq $\\leq$ \\geq $\\geq$ \\neq $\\neq$ \\approx $\\approx$ \\equiv $\\equiv$ \\sum $\\sum$ \\prod $\\prod$ \\coprod $\\coprod$ \\backslash $\\backslash$ (2)．集合运算符 输入 显示 输入 显示 输入 显示 \\emptyset $\\emptyset$ \\in $\\in$ \\notin $\\notin$ \\subset $\\subset$ \\supset $\\supset$ \\subseteq $\\subseteq$ \\supseteq $\\supseteq$ \\cap $\\cap$ \\cup $\\cup$ \\vee $\\vee$ \\wedge $\\wedge$ \\uplus $\\uplus$ \\top $\\top$ \\bot $\\bot$ \\complement $\\complement$ (3)．对数运算符 输入 显示 输入 显示 输入 显示 \\log $\\log$ \\lg $\\lg$ \\ln $\\ln$ (4)．三角运算符 输入 显示 输入 显示 输入 显示 \\backsim $\\backsim$ \\cong $\\cong$ \\angle A $\\angle A$ \\sin $\\sin$ \\cos $\\cos$ \\tan $\\tan$ \\csc $\\csc$ \\sec $\\sec$ \\cot $\\cot$ (5)．微积分运算符 输入 显示 输入 显示 输入 显示 \\int $\\int$ \\iint $\\iint$ \\iiint $\\iiint$ \\partial $\\partial$ \\oint $\\oint$ \\prime $\\prime$ \\lim $\\lim$ \\infty $\\infty$ \\nabla $\\nabla$ (6)．逻辑运算符 输入 显示 输入 显示 输入 显示 \\because $\\because$ \\therefore $\\therefore$ \\neg $\\neg$ \\forall $\\forall$ \\exists $\\exists$ \\not\\subset $\\not\\subset$ \\not\u0026lt; $\\not\u0026lt;$ \\not\u0026gt; $\\not\u0026gt;$ \\not= $\\not=$ (7)．戴帽符号 输入 显示 输入 显示 输入 显示 \\hat{xy} $\\hat{xy}$ \\widehat{xyz} $\\widehat{xyz}$ \\bar{y} $\\bar{y}$ \\tilde{xy} $\\tilde{xy}$ \\widetilde{xyz} $\\widetilde{xyz}$ \\acute{y} $\\acute{y}$ \\breve{y} $\\breve{y}$ \\check{y} $\\check{y}$ \\grave{y} $\\grave{y}$ \\dot{x} $\\dot{x}$ \\ddot{x} $\\ddot{x}$ \\dddot{x} $\\dddot{x}$ 若需要在特定文字顶部\\底部放置内容，可使用 \\overset{顶部内容}{正常内容} 和 \\underset{底部内容}{正常内容} 命令。\n例子： 1 $$ \\verb+\\overset{above}{level}+ \\qquad \\overset{xx}{ABC} \\;\\; \\mid \\quad \\overset{x^2}{\\longmapsto}\\ \\, \\mid \\quad \\overset{\\bullet\\circ\\circ\\bullet}{T} $$ 显示： $$ \\verb+\\overset{above}{level}+ \\qquad \\overset{xx}{ABC} ;; \\mid \\quad \\overset{x^2}{\\longmapsto}\\ , \\mid \\quad \\overset{\\bullet\\circ\\circ\\bullet}{T} $$\n例子：\n1 $$ \\verb+\\underset{below}{level}+ \\qquad \\underset{xx}{ABC} \\;\\; \\mid \\quad \\underset{x^2}{\\longmapsto}\\ \\, \\mid \\quad \\underset{\\bullet\\circ\\circ\\bullet}{T} $$ 显示： $$ \\verb+ \\underset{below}{level}+ \\qquad \\underset{xx}{ABC} ;; \\mid \\quad \\underset{x^2}{\\longmapsto}\\ , \\mid \\quad \\underset{\\bullet\\circ\\circ\\bullet}{T} $$ 此命令可叠加嵌套使用，生成类似化学反应式的多重条件符号， 如 \\overset{H_2}{\\underset{1300℃}{\\Longleftrightarrow}}： $$ \\rm{SrO+V^{\u0026rsquo;\u0026rsquo;}{Sr} \\overset{H_2}{\\underset{1300℃}{\\Longleftrightarrow}} Sr^{\\times}{Sr}+2e^{\u0026rsquo;}+\\frac 12O_2(g)} $$ 和 \\overset{Surface/bulk}{\\underset{diffusion}{\\longleftrightarrow}}： $$ \\rm{2OH^{\\bullet}{O(STN)}+2O^{\\times}{O(YSZ)} ; \\overset{Surface/bulk}{\\underset{diffusion}{\\longleftrightarrow}} ;; 2OH^{\\bullet}{O(YSZ)}+2O^{\\times}{O(STN)}} $$\n一般建议在书写化学方程式时声明 \\require{AMDcd} 语句，使用 MathJax 内置的交换图表功能，具体例子可参见下文。\n(8)．连线符号 其它可用的文字修饰符可参见官方文档 \u0026ldquo;Additional decorations\u0026rdquo;。\n输入 显示 \\fbox{a+b+c+d} 高级框选需声明 enclose 标签 $\\fbox{a+b+c+d}$ \\overleftarrow{a+b+c+d} $\\overleftarrow{a+b+c+d}$ \\overrightarrow{a+b+c+d} $\\overrightarrow{a+b+c+d}$ \\overleftrightarrow{a+b+c+d} $\\overleftrightarrow{a+b+c+d}$ \\underleftarrow{a+b+c+d} $\\underleftarrow{a+b+c+d}$ \\underrightarrow{a+b+c+d} $\\underrightarrow{a+b+c+d}$ \\underleftrightarrow{a+b+c+d} $\\underleftrightarrow{a+b+c+d}$ \\overline{a+b+c+d} $\\overline{a+b+c+d}$ \\underline{a+b+c+d} $\\underline{a+b+c+d}$ \\overbrace{a+b+c+d}^{Sample} $\\overbrace{a+b+c+d}^{Sample}$ \\underbrace{a+b+c+d}_{Sample} $\\underbrace{a+b+c+d}_{Sample}$ \\overbrace{a+\\underbrace{b+c}_{1.0}+d}^{2.0} $\\overbrace{a+\\underbrace{b+c}_{1.0}+d}^{2.0}$ \\underbrace{a\\cdot a\\cdots a}_{b\\text{ times}} $\\underbrace{a\\cdot a\\cdots a}_{b\\text{ times}}$ (9)．箭头符号 推荐使用符号：\n输入 显示 输入 显示 输入 显示 \\to $\\to$ \\mapsto $\\mapsto$ \\underrightarrow{1℃/min} $\\underrightarrow{1℃/min}$ \\implies $\\implies$ \\iff $\\iff$ \\impliedby $\\impliedby$ 其它可用符号：\n输入 显示 输入 显示 \\uparrow $\\uparrow$ \\Uparrow $\\Uparrow$ \\downarrow $\\downarrow$ \\Downarrow $\\Downarrow$ \\leftarrow $\\leftarrow$ \\Leftarrow $\\Leftarrow$ \\rightarrow $\\rightarrow$ \\Rightarrow $\\Rightarrow$ \\leftrightarrow $\\leftrightarrow$ \\Leftrightarrow $\\Leftrightarrow$ \\longleftarrow $\\longleftarrow$ \\Longleftarrow $\\Longleftarrow$ \\longrightarrow $\\longrightarrow$ \\Longrightarrow $\\Longrightarrow$ \\longleftrightarrow $\\longleftrightarrow$ \\Longleftrightarrow $\\Longleftrightarrow$ 13．如何进行字体转换 若要对公式的某一部分字符进行字体转换，可以用 {\\字体 {需转换的部分字符}} 命令，其中 \\字体 部分可以参照下表选择合适的字体。一般情况下，公式默认为斜体字 $italic$ 。\n示例中 全部大写 的字体仅大写可用。\n输入 全字母可用 显示 输入 仅大写可用 显示 \\rm 罗马体 $\\rm{Sample}$ \\mathcal 花体（数学符号等） $\\mathcal{SAMPLE}$ \\it 斜体 $\\it{Sample}$ \\mathbb 黑板粗体（定义域等） $\\mathbb{SAMPLE}$ \\bf 粗体 $\\bf{Sample}$ \\mit 数学斜体 $\\mit{SAMPLE}$ \\sf 等线体 $\\sf{Sample}$ \\scr 手写体 $\\scr{SAMPLE}$ \\tt 打字机体 $\\tt{Sample}$ \\frak 旧德式字体 $\\frak{Sample}$ @lymd \\boldsymbol{\\alpha} 用来表示向量或者矩阵的加粗斜体，如向量 $\\boldsymbol{\\vec\\alpha}$。\n转换字体十分常用，例如在积分中：\n例子： 1 2 3 4 5 \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\\\ \\hline \\\\ \\int_0^1 x^2 dx \u0026amp; \\int_0^1 x^2 \\,{\\rm d}x \\end{array} 显示： \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\ \\hline \\ \\int_0^1 x^2 dx \u0026amp; \\int_0^1 x^2 ,{\\rm d}x \\end{array} 注意比较两个式子间 $dx$ 与 ${\\rm d} x$ 的不同。 使用 \\operatorname 命令也可以达到相同的效果，详见“定义新的运算符”。\n14．如何高亮一行公式 使用 \\bbox[底色, (可选)边距, (可选)边框 border: 框宽度 框类型 框颜色] 命令来高亮一行公式。 底色和框颜色支持详见“更改文字颜色”，边距及框宽度支持 绝对像素 px 或 相对大小 em，框类型支持 实线 solid 或 虚线 dashed。\n例子： 1 2 3 4 5 $$ \\bbox[yellow]{ e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n \\qquad (1) } $$ 显示： $$ \\bbox[yellow]{ e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n \\qquad (1) } $$ 例子： 1 2 3 4 5 $$ \\bbox[#9ff, 5px]{ % 此处向外添加 5 像素的边距 e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n \\qquad (1) } $$ 显示： $$ \\bbox[#9ff, 5px]{ e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n \\qquad (1) } $$ 例子： 1 2 3 4 5 6 $$ % 此处使用 0.5 倍行高作为边距，附加 2 像素的实线边框（Ctrl+Alt+Y 可见） \\bbox[#2f3542, 0.5em, border:2px solid #f1f2f6]{ \\color{#f1f2f6}{e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n \\qquad (1)} } $$ 显示： $$ \\bbox[#2f3542, 0.5em, border:2px solid #f1f2f6]{ \\color{#f1f2f6}{e^x=\\lim_{n\\to\\infty} \\left( 1+\\frac{x}{n} \\right)^n \\qquad (1)} } $$ 15．大括号和行标的使用 在 \\left 和 \\right 之后加上要使用的括号来创建自动匹配高度的圆括号 ( )，方括号 [ ] 和花括号 \\{ \\}。 在每个公式末尾前使用 \\tag {行标} 来实现行标。\n例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $$ f\\left( \\left[ \\frac{ 1+\\left\\{x,y\\right\\} }{ \\left( \\frac xy + \\frac yx \\right) (u+1) }+a \\right]^{3/2} \\right) \\tag {行标} $$ 显示： $$ f\\left( \\left[ \\frac{ 1+\\left{x,y\\right} }{ \\left( \\frac xy + \\frac yx \\right) (u+1) }+a \\right]^{3/2} \\right) \\tag {行标} $$ 如果你需要在不同的行显示对应括号，可以在每一行对应处使用 \\left. 或 \\right. 来放一个“不存在的括号”。\n例子： 1 2 3 4 5 6 $$ \\begin{align*} a=\u0026amp;\\left(1+2+3+ \\cdots \\right. \\\\ \u0026amp;\\cdots+\\left. \\infty-2+\\infty-1+\\infty\\right) \\end{align*} $$ 显示： $$ \\begin{align*} a=\u0026amp;\\left(1+2+3+ \\cdots \\right. \\ \u0026amp;\\cdots+\\left. \\infty-2+\\infty-1+\\infty\\right) \\end{align*} $$ 如果你需要将大括号里面显示的分隔符也变大，可以使用 \\middle 命令，此处分别使用单竖线 | 和双竖线 \\\\| 。\n例子： 1 2 3 4 5 6 7 $$ \\left\\langle q \\; \\middle| \\frac{\\frac xy}{\\frac uv} \\middle\\| p \\right\\rangle $$ 显示： $$ \\left\\langle\nq ; \\middle| \\frac{\\frac xy}{\\frac uv} \\middle| p \\right\\rangle $$ 16．其它命令 (1)．定义新的运算符 \\operatorname 当需要使用的运算符不在 MathJax 的内置库中时，程序可能会报错或产生错误的渲染结果。此时可以使用 \\operatorname 命令定义一个新的运算符号。\n反例： 1 2 3 4 5 6 \\begin{array}{c|c} \\mathrm{Error} \u0026amp; \\text{Wrong rendering} \\\\ \\hline \\\\ \\arsinh(x) \u0026amp; arsinh(x) \\\\ \\Res_{z=1} \u0026amp; Res_{z=1}{\\frac{1}{z^2-z}=1} \\\\ \\end{array} 显示： \\begin{array}{c|c} \\mathrm{Error} \u0026amp; \\text{Wrong rendering} \\ \\hline \\ \\arsinh(x) \u0026amp; arsinh(x) \\ \\Res_{z=1} \u0026amp; Res_{z=1}{\\frac{1}{z^2-z}=1} \\ \\end{array} 使用 \\operatorname{运算符}{式子} 来生成一个普通运算，或使用 \\operatorname*{运算符}_{下标}^{上标}{式子} 来生成一个含上下标的自定义运算。\n例子： 1 2 3 4 5 6 \\begin{array}{c|c} \\text{Normal Operator} \u0026amp; \\text{Operator with label above and below} \\\\ \\hline \\\\ \\scriptsize\\text{\\operatorname{arsinh}{x}} \u0026amp; \\scriptsize\\text{\\operatorname*{Res}_{z=1}{\\frac{1}{z^2-z}=1}} \\\\ \\operatorname{arsinh}{x} \u0026amp; \\operatorname*{Res}_{z=1}{\\frac{1}{z^2-z}=1} \\\\ \\end{array} 显示： \\begin{array}{c|c} \\text{Normal Operator} \u0026amp; \\text{Operator with label above and below} \\ \\scriptsize\\text{\\operatorname{arsinh}{x}} \u0026amp; \\scriptsize\\text{\\operatorname*{Res}{z=1}{\\frac{1}{z^2-z}=1}} \\[2ex] \\hline \\ \\operatorname{arsinh}{x} \u0026amp; \\operatorname*{Res}{z=1}{\\frac{1}{z^2-z}=1} \\end{array} 查询关于此命令的定义和关于此命令的讨论来进一步了解此命令。\n(2)．添加注释文字 \\text 在 \\text {文字} 中仍可以使用 $公式$ 插入其它公式。\n例子： 1 $$ f(n)= \\begin{cases} n/2, \u0026amp; \\text {if $n$ is even} \\\\ 3n+1, \u0026amp; \\text{if $n$ is odd} \\end{cases} $$ 显示： $$ f(n)= \\begin{cases} n/2, \u0026amp; \\text {if $n$ is even} \\ 3n+1, \u0026amp; \\text{if $n$ is odd} \\end{cases} $$ (3)．在字符间加入空格 有四种宽度的空格可以使用： \\,、\\;、\\quad 和 \\qquad，灵活使用 \\text{n个空格} 也可以在任意位置实现空格。 同时存在一种负空格 \\! 用来减小字符间距，一般在物理单位中使用。 反复使用 \\! 命令能够实现不同元素的叠加渲染，如$\\wedge!!!!!!!!;\\bigcirc$ 和 $ }!!!!!\\div $\n例子： 1 2 3 4 5 \\begin{array}{c|c} \\text{Spaces} \u0026amp; \\text{Negative Space in Units} \\\\ \\hline \\\\ \\overbrace{a \\! b}^{\\text{\\!}} \\mid \\underbrace{ab}_{\\rm{default}} \\mid \\overbrace{a \\, b}^{\\text{\\,}} \\mid \\underbrace{a \\; b}_{\\text{\\;}} \\mid \\overbrace{a \\quad b}^{\\text{\\quad}} \\mid \\underbrace{a \\qquad b}_{\\text{\\qquad}} \u0026amp; \\mathrm{N}\\!\\cdot\\!\\mathrm{m} \\mid \\mathrm{s}\\!\\cdot\\!\\mathrm{A} \\mid \\mathrm{kg}\\!\\cdot\\!\\mathrm{m}^2 \\\\ \\end{array} 显示： \\begin{array}{c|c} \\text{Spaces} \u0026amp; \\text{Negative Space in Units} \\ \\hline \\ \\overbrace{a ! b}^{\\text{!}} \\mid \\underbrace{ab}{\\rm{default}} \\mid \\overbrace{a , b}^{\\text{,}} \\mid \\underbrace{a ; b}{\\text{;}} \\mid \\overbrace{a \\quad b}^{\\text{\\quad}} \\mid \\underbrace{a \\qquad b}_{\\text{\\qquad}} \u0026amp; \\mathrm{N}!\\cdot!\\mathrm{m} \\mid \\mathrm{s}!\\cdot!\\mathrm{A} \\mid \\mathrm{kg}!\\cdot!\\mathrm{m}^2 \\ \\end{array} 一些常见的公式单位可表达如下：\n例子： 1 2 3 $$ \\mu_0=4\\pi\\times10^{-7} \\ \\left.\\mathrm{\\mathrm{T}\\!\\cdot\\!\\mathrm{m}}\\middle/\\mathrm{A}\\right. $$ $$ 180^\\circ=\\pi \\ \\mathrm{rad} $$ $$ \\mathrm{N_A} = 6.022\\times10^{23} \\ \\mathrm{mol}^{-1} $$ 显示： $$ \\mu_0=4\\pi\\times10^{-7} \\ \\left.\\mathrm{\\mathrm{T}!\\cdot!\\mathrm{m}}\\middle/\\mathrm{A}\\right. $$ $$ 180^\\circ=\\pi \\ \\mathrm{rad} $$ $$ \\mathrm{N_A} = 6.022\\times10^{23} \\ \\mathrm{mol}^{-1} $$ (4)．更改文字颜色 \\color 使用 \\color{颜色}{文字} 来更改特定的文字颜色。\n更改文字颜色需要浏览器支持 ，如果浏览器不知道你所需的颜色，那么文字将被渲染为黑色。对于较旧的浏览器（HTML4 \u0026amp; CSS2），以下颜色是被支持的：\n输入 显示 输入 显示 black $\\color{black}{text}$ grey $\\color{grey}{text}$ silver $\\color{silver}{text}$ white $\\color{white}{text}$ maroon $\\color{maroon}{text}$ red $\\color{red}{text}$ yellow $\\color{yellow}{text}$ lime $\\color{lime}{text}$ olive $\\color{olive}{text}$ green $\\color{green}{text}$ teal $\\color{teal}{text}$ auqa $\\color{auqa}{text}$ blue $\\color{blue}{text}$ navy $\\color{navy}{text}$ purple $\\color{purple}{text}$ fuchsia $\\color{fuchsia}{text}$ 对于较新的浏览器（HTML5 \u0026amp; CSS3），HEX 颜色将被支持：\n输入 \\color {#rgb} {text} 来自定义更多的颜色，其中 #rgb 或 #rrggbb 的 r g b 可输入 0-9 和 a-f 来表示红色、绿色和蓝色的纯度（饱和度）。\n例子： 1 2 3 4 5 6 7 8 9 10 \\begin{array}{|rrrrrrrr|}\\hline \\verb+#000+ \u0026amp; \\color{#000}{text} \u0026amp; \u0026amp; \u0026amp; \\verb+#00F+ \u0026amp; \\color{#00F}{text} \u0026amp; \u0026amp; \\\\ \u0026amp; \u0026amp; \\verb+#0F0+ \u0026amp; \\color{#0F0}{text} \u0026amp; \u0026amp; \u0026amp; \\verb+#0FF+ \u0026amp; \\color{#0FF}{text} \\\\ \\verb+#F00+ \u0026amp; \\color{#F00}{text} \u0026amp; \u0026amp; \u0026amp; \\verb+#F0F+ \u0026amp; \\color{#F0F}{text} \u0026amp; \u0026amp; \\\\ \u0026amp; \u0026amp; \\verb+#FF0+ \u0026amp; \\color{#FF0}{text} \u0026amp; \u0026amp; \u0026amp; \\verb+#FFF+ \u0026amp; \\color{#FFF}{text} \\\\ \\hline\\end{array} 显示： \\begin{array}{|rrrrrrrr|}\\hline \\verb+#000+ \u0026amp; \\color{#000}{text} \u0026amp; \u0026amp; \u0026amp; \\verb+#00F+ \u0026amp; \\color{#00F}{text} \u0026amp; \u0026amp; \\ \u0026amp; \u0026amp; \\verb+#0F0+ \u0026amp; \\color{#0F0}{text} \u0026amp; \u0026amp; \u0026amp; \\verb+#0FF+ \u0026amp; \\color{#0FF}{text} \\ \\verb+#F00+ \u0026amp; \\color{#F00}{text} \u0026amp; \u0026amp; \u0026amp; \\verb+#F0F+ \u0026amp; \\color{#F0F}{text} \u0026amp; \u0026amp; \\ \u0026amp; \u0026amp; \\verb+#FF0+ \u0026amp; \\color{#FF0}{text} \u0026amp; \u0026amp; \u0026amp; \\verb+#FFF+ \u0026amp; \\color{#FFF}{text} \\ \\hline\\end{array} 例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \\begin{array}{|rrrrrrrr|}\\hline \\verb+#000+ \u0026amp; \\color{#000}{text} \u0026amp; \\verb+#005+ \u0026amp; \\color{#005}{text} \u0026amp; \\verb+#00A+ \u0026amp; \\color{#00A}{text} \u0026amp; \\verb+#00F+ \u0026amp; \\color{#00F}{text} \\\\ \\verb+#500+ \u0026amp; \\color{#500}{text} \u0026amp; \\verb+#505+ \u0026amp; \\color{#505}{text} \u0026amp; \\verb+#50A+ \u0026amp; \\color{#50A}{text} \u0026amp; \\verb+#50F+ \u0026amp; \\color{#50F}{text} \\\\ \\verb+#A00+ \u0026amp; \\color{#A00}{text} \u0026amp; \\verb+#A05+ \u0026amp; \\color{#A05}{text} \u0026amp; \\verb+#A0A+ \u0026amp; \\color{#A0A}{text} \u0026amp; \\verb+#A0F+ \u0026amp; \\color{#A0F}{text} \\\\ \\verb+#F00+ \u0026amp; \\color{#F00}{text} \u0026amp; \\verb+#F05+ \u0026amp; \\color{#F05}{text} \u0026amp; \\verb+#F0A+ \u0026amp; \\color{#F0A}{text} \u0026amp; \\verb+#F0F+ \u0026amp; \\color{#F0F}{text} \\\\ \\hline \\verb+#080+ \u0026amp; \\color{#080}{text} \u0026amp; \\verb+#085+ \u0026amp; \\color{#085}{text} \u0026amp; \\verb+#08A+ \u0026amp; \\color{#08A}{text} \u0026amp; \\verb+#08F+ \u0026amp; \\color{#08F}{text} \\\\ \\verb+#580+ \u0026amp; \\color{#580}{text} \u0026amp; \\verb+#585+ \u0026amp; \\color{#585}{text} \u0026amp; \\verb+#58A+ \u0026amp; \\color{#58A}{text} \u0026amp; \\verb+#58F+ \u0026amp; \\color{#58F}{text} \\\\ \\verb+#A80+ \u0026amp; \\color{#A80}{text} \u0026amp; \\verb+#A85+ \u0026amp; \\color{#A85}{text} \u0026amp; \\verb+#A8A+ \u0026amp; \\color{#A8A}{text} \u0026amp; \\verb+#A8F+ \u0026amp; \\color{#A8F}{text} \\\\ \\verb+#F80+ \u0026amp; \\color{#F80}{text} \u0026amp; \\verb+#F85+ \u0026amp; \\color{#F85}{text} \u0026amp; \\verb+#F8A+ \u0026amp; \\color{#F8A}{text} \u0026amp; \\verb+#F8F+ \u0026amp; \\color{#F8F}{text} \\\\ \\hline \\verb+#0F0+ \u0026amp; \\color{#0F0}{text} \u0026amp; \\verb+#0F5+ \u0026amp; \\color{#0F5}{text} \u0026amp; \\verb+#0FA+ \u0026amp; \\color{#0FA}{text} \u0026amp; \\verb+#0FF+ \u0026amp; \\color{#0FF}{text} \\\\ \\verb+#5F0+ \u0026amp; \\color{#5F0}{text} \u0026amp; \\verb+#5F5+ \u0026amp; \\color{#5F5}{text} \u0026amp; \\verb+#5FA+ \u0026amp; \\color{#5FA}{text} \u0026amp; \\verb+#5FF+ \u0026amp; \\color{#5FF}{text} \\\\ \\verb+#AF0+ \u0026amp; \\color{#AF0}{text} \u0026amp; \\verb+#AF5+ \u0026amp; \\color{#AF5}{text} \u0026amp; \\verb+#AFA+ \u0026amp; \\color{#AFA}{text} \u0026amp; \\verb+#AFF+ \u0026amp; \\color{#AFF}{text} \\\\ \\verb+#FF0+ \u0026amp; \\color{#FF0}{text} \u0026amp; \\verb+#FF5+ \u0026amp; \\color{#FF5}{text} \u0026amp; \\verb+#FFA+ \u0026amp; \\color{#FFA}{text} \u0026amp; \\verb+#FFF+ \u0026amp; \\color{#FFF}{text} \\\\ \\hline\\end{array} 显示： \\begin{array}{|rrrrrrrr|}\\hline \\verb+#000+ \u0026amp; \\color{#000}{text} \u0026amp; \\verb+#005+ \u0026amp; \\color{#005}{text} \u0026amp; \\verb+#00A+ \u0026amp; \\color{#00A}{text} \u0026amp; \\verb+#00F+ \u0026amp; \\color{#00F}{text} \\ \\verb+#500+ \u0026amp; \\color{#500}{text} \u0026amp; \\verb+#505+ \u0026amp; \\color{#505}{text} \u0026amp; \\verb+#50A+ \u0026amp; \\color{#50A}{text} \u0026amp; \\verb+#50F+ \u0026amp; \\color{#50F}{text} \\ \\verb+#A00+ \u0026amp; \\color{#A00}{text} \u0026amp; \\verb+#A05+ \u0026amp; \\color{#A05}{text} \u0026amp; \\verb+#A0A+ \u0026amp; \\color{#A0A}{text} \u0026amp; \\verb+#A0F+ \u0026amp; \\color{#A0F}{text} \\ \\verb+#F00+ \u0026amp; \\color{#F00}{text} \u0026amp; \\verb+#F05+ \u0026amp; \\color{#F05}{text} \u0026amp; \\verb+#F0A+ \u0026amp; \\color{#F0A}{text} \u0026amp; \\verb+#F0F+ \u0026amp; \\color{#F0F}{text} \\ \\hline \\verb+#080+ \u0026amp; \\color{#080}{text} \u0026amp; \\verb+#085+ \u0026amp; \\color{#085}{text} \u0026amp; \\verb+#08A+ \u0026amp; \\color{#08A}{text} \u0026amp; \\verb+#08F+ \u0026amp; \\color{#08F}{text} \\ \\verb+#580+ \u0026amp; \\color{#580}{text} \u0026amp; \\verb+#585+ \u0026amp; \\color{#585}{text} \u0026amp; \\verb+#58A+ \u0026amp; \\color{#58A}{text} \u0026amp; \\verb+#58F+ \u0026amp; \\color{#58F}{text} \\ \\verb+#A80+ \u0026amp; \\color{#A80}{text} \u0026amp; \\verb+#A85+ \u0026amp; \\color{#A85}{text} \u0026amp; \\verb+#A8A+ \u0026amp; \\color{#A8A}{text} \u0026amp; \\verb+#A8F+ \u0026amp; \\color{#A8F}{text} \\ \\verb+#F80+ \u0026amp; \\color{#F80}{text} \u0026amp; \\verb+#F85+ \u0026amp; \\color{#F85}{text} \u0026amp; \\verb+#F8A+ \u0026amp; \\color{#F8A}{text} \u0026amp; \\verb+#F8F+ \u0026amp; \\color{#F8F}{text} \\ \\hline \\verb+#0F0+ \u0026amp; \\color{#0F0}{text} \u0026amp; \\verb+#0F5+ \u0026amp; \\color{#0F5}{text} \u0026amp; \\verb+#0FA+ \u0026amp; \\color{#0FA}{text} \u0026amp; \\verb+#0FF+ \u0026amp; \\color{#0FF}{text} \\ \\verb+#5F0+ \u0026amp; \\color{#5F0}{text} \u0026amp; \\verb+#5F5+ \u0026amp; \\color{#5F5}{text} \u0026amp; \\verb+#5FA+ \u0026amp; \\color{#5FA}{text} \u0026amp; \\verb+#5FF+ \u0026amp; \\color{#5FF}{text} \\ \\verb+#AF0+ \u0026amp; \\color{#AF0}{text} \u0026amp; \\verb+#AF5+ \u0026amp; \\color{#AF5}{text} \u0026amp; \\verb+#AFA+ \u0026amp; \\color{#AFA}{text} \u0026amp; \\verb+#AFF+ \u0026amp; \\color{#AFF}{text} \\ \\verb+#FF0+ \u0026amp; \\color{#FF0}{text} \u0026amp; \\verb+#FF5+ \u0026amp; \\color{#FF5}{text} \u0026amp; \\verb+#FFA+ \u0026amp; \\color{#FFA}{text} \u0026amp; \\verb+#FFF+ \u0026amp; \\color{#FFF}{text} \\ \\hline\\end{array} (5)．添加删除线 使用删除线功能必须声明 $$ 符号。\n在公式内使用 \\require{cancel} 来允许片段删除线的显示。 声明片段删除线后，使用 \\cancel{字符}、\\bcancel{字符}、\\xcancel{字符} 和 \\cancelto{字符} 来实现各种片段删除线效果。\n例子： 1 2 3 4 5 6 7 8 9 10 11 $$ \\require{cancel} \\begin{array}{rl} \\verb|y+\\cancel{x}| \u0026amp; y+\\cancel{x} \\\\ \\verb|\\cancel{y+x}| \u0026amp; \\cancel{y+x} \\\\ \\verb|y+\\bcancel{x}| \u0026amp; y+\\bcancel{x} \\\\ \\verb|y+\\xcancel{x}| \u0026amp; y+\\xcancel{x} \\\\ \\verb|y+\\cancelto{0}{x}| \u0026amp; y+\\cancelto{0}{x} \\\\ \\verb+\\frac{1\\cancel9}{\\cancel95} = \\frac15+\u0026amp; \\frac{1\\cancel9}{\\cancel95} = \\frac15 \\\\ \\end{array} $$ 显示： $$ \\require{cancel} \\begin{array}{rl} \\verb|y+\\cancel{x}| \u0026amp; y+\\cancel{x} \\ \\verb|\\cancel{y+x}| \u0026amp; \\cancel{y+x} \\ \\verb|y+\\bcancel{x}| \u0026amp; y+\\bcancel{x} \\ \\verb|y+\\xcancel{x}| \u0026amp; y+\\xcancel{x} \\ \\verb|y+\\cancelto{0}{x}| \u0026amp; y+\\cancelto{0}{x} \\ \\verb+\\frac{1\\cancel9}{\\cancel95} = \\frac15+\u0026amp; \\frac{1\\cancel9}{\\cancel95} = \\frac15 \\ \\end{array} $$ 使用 \\require{enclose} 来允许整段删除线的显示。 声明整段删除线后，使用 \\enclose{删除线效果}{字符} 来实现各种整段删除线效果。 其中，删除线效果有 horizontalstrike、verticalstrike、updiagonalstrike 和 downdiagonalstrike，可叠加使用。\n例子： 1 2 3 4 5 6 7 8 9 10 $$ \\require{enclose} \\begin{array}{rl} \\verb|\\enclose{horizontalstrike}{x+y}| \u0026amp; \\enclose{horizontalstrike}{x+y} \\\\ \\verb|\\enclose{verticalstrike}{\\frac xy}| \u0026amp; \\enclose{verticalstrike}{\\frac xy} \\\\ \\verb|\\enclose{updiagonalstrike}{x+y}| \u0026amp; \\enclose{updiagonalstrike}{x+y} \\\\ \\verb|\\enclose{downdiagonalstrike}{x+y}| \u0026amp; \\enclose{downdiagonalstrike}{x+y} \\\\ \\verb|\\enclose{horizontalstrike,updiagonalstrike}{x+y}| \u0026amp; \\enclose{horizontalstrike,updiagonalstrike}{x+y} \\\\ \\end{array} $$ 显示： $$ \\require{enclose} \\begin{array}{rl} \\verb|\\enclose{horizontalstrike}{x+y}| \u0026amp; \\enclose{horizontalstrike}{x+y} \\ \\verb|\\enclose{verticalstrike}{\\frac xy}| \u0026amp; \\enclose{verticalstrike}{\\frac xy} \\ \\verb|\\enclose{updiagonalstrike}{x+y}| \u0026amp; \\enclose{updiagonalstrike}{x+y} \\ \\verb|\\enclose{downdiagonalstrike}{x+y}| \u0026amp; \\enclose{downdiagonalstrike}{x+y} \\ \\verb|\\enclose{horizontalstrike,updiagonalstrike}{x+y}| \u0026amp; \\enclose{horizontalstrike,updiagonalstrike}{x+y} \\ \\end{array} $$ 此外， \\enclose 命令还可以产生包围的边框和圆等，参见 MathML Menclose Documentation 以查看更多效果。\n例子： 分别使用 circle 和 roundedbox 包围的公式 1 2 3 4 5 6 7 $$ \\require{enclose} \\begin{array}{c} \\enclose{circle}{f(\\top),\\, f^2(\\top),\\, f^3(\\top) \\,\\cdots\\, f^n(\\top)} \\\\ \\enclose{roundedbox}{f(\\bot),\\, f^2(\\bot),\\, f^3(\\bot) \\,\\cdots\\, f^n(\\bot)} \\\\ \\end{array} $$ 使用 box 框住所有公式 1 2 3 4 5 6 7 8 9 $$ \\require{enclose} \\enclose{box}{ \\begin{array}{c} f(\\top),\\, f^2(\\top),\\, f^3(\\top) \\,\\cdots\\, f^n(\\top) \\\\ f(\\bot),\\, f^2(\\bot),\\, f^3(\\bot) \\,\\cdots\\, f^n(\\bot) \\\\ \\end{array} } $$ 显示： 分别使用 circle 和 roundedbox 包围的公式 使用 box 框住所有公式 $$ \\require{enclose} \\begin{array}{c} \\enclose{circle}{f(\\top),, f^2(\\top),, f^3(\\top) ,\\cdots, f^n(\\top)} \\ \\enclose{roundedbox}{f(\\bot),, f^2(\\bot),, f^3(\\bot) ,\\cdots, f^n(\\bot)} \\ \\end{array} $$ $$ \\require{enclose} \\enclose{box}{ \\begin{array}{c} f(\\top),, f^2(\\top),, f^3(\\top) ,\\cdots, f^n(\\top) \\ f(\\bot),, f^2(\\bot),, f^3(\\bot) ,\\cdots, f^n(\\bot) \\ \\end{array} } $$ 此例语法可参见“如何输入一个数组或表格”。\n二、矩阵使用参考 1．如何输入无框矩阵 在开头使用 \\begin{matrix}，在结尾使用 \\end{matrix}，在中间插入矩阵元素，每个元素之间插入 \u0026amp; ，并在每行结尾处使用 \\\\ 。 使用矩阵时必须声明 $ 或 $$ 符号。\n例子： 1 2 3 4 5 6 7 $$ \\begin{matrix} 1 \u0026amp; x \u0026amp; x^2 \\\\ 1 \u0026amp; y \u0026amp; y^2 \\\\ 1 \u0026amp; z \u0026amp; z^2 \\\\ \\end{matrix} $$ 显示： $$ \\begin{matrix} 1 \u0026amp; x \u0026amp; x^2 \\ 1 \u0026amp; y \u0026amp; y^2 \\ 1 \u0026amp; z \u0026amp; z^2 \\ \\end{matrix} $$ 2．如何输入边框矩阵 在开头将 matrix 替换为 pmatrix bmatrix Bmatrix vmatrix Vmatrix 。\n例子： 1 2 3 4 5 6 $ \\begin{matrix} 1 \u0026amp; 2 \\\\ 3 \u0026amp; 4 \\\\ \\end{matrix} $ $ \\begin{pmatrix} 1 \u0026amp; 2 \\\\ 3 \u0026amp; 4 \\\\ \\end{pmatrix} $ $ \\begin{bmatrix} 1 \u0026amp; 2 \\\\ 3 \u0026amp; 4 \\\\ \\end{bmatrix} $ $ \\begin{Bmatrix} 1 \u0026amp; 2 \\\\ 3 \u0026amp; 4 \\\\ \\end{Bmatrix} $ $ \\begin{vmatrix} 1 \u0026amp; 2 \\\\ 3 \u0026amp; 4 \\\\ \\end{vmatrix} $ $ \\begin{Vmatrix} 1 \u0026amp; 2 \\\\ 3 \u0026amp; 4 \\\\ \\end{Vmatrix} $ 显示： matrix pmatrix bmatrix Bmatrix vmatrix Vmatrix $ \\begin{matrix} 1 \u0026amp; 2 \\ 3 \u0026amp; 4 \\ \\end{matrix} $ $ \\begin{pmatrix} 1 \u0026amp; 2 \\ 3 \u0026amp; 4 \\ \\end{pmatrix} $ $ \\begin{bmatrix} 1 \u0026amp; 2 \\ 3 \u0026amp; 4 \\ \\end{bmatrix} $ $ \\begin{Bmatrix} 1 \u0026amp; 2 \\ 3 \u0026amp; 4 \\ \\end{Bmatrix} $ $ \\begin{vmatrix} 1 \u0026amp; 2 \\ 3 \u0026amp; 4 \\ \\end{vmatrix} $ $ \\begin{Vmatrix} 1 \u0026amp; 2 \\ 3 \u0026amp; 4 \\ \\end{Vmatrix} $ 3．如何输入带省略符号的矩阵 使用 \\cdots $\\cdots$ , \\ddots $\\ddots$ , \\vdots $\\vdots$ 来输入省略符号。\n例子： 1 2 3 4 5 6 7 8 $$ \\begin{pmatrix} 1 \u0026amp; a_1 \u0026amp; a_1^2 \u0026amp; \\cdots \u0026amp; a_1^n \\\\ 1 \u0026amp; a_2 \u0026amp; a_2^2 \u0026amp; \\cdots \u0026amp; a_2^n \\\\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\\\ 1 \u0026amp; a_m \u0026amp; a_m^2 \u0026amp; \\cdots \u0026amp; a_m^n \\\\ \\end{pmatrix} $$ 显示： $$ \\begin{pmatrix} 1 \u0026amp; a_1 \u0026amp; a_1^2 \u0026amp; \\cdots \u0026amp; a_1^n \\ 1 \u0026amp; a_2 \u0026amp; a_2^2 \u0026amp; \\cdots \u0026amp; a_2^n \\ \\vdots \u0026amp; \\vdots \u0026amp; \\vdots \u0026amp; \\ddots \u0026amp; \\vdots \\ 1 \u0026amp; a_m \u0026amp; a_m^2 \u0026amp; \\cdots \u0026amp; a_m^n \\ \\end{pmatrix} $$ ##4．如何输入带分割符号的矩阵\n详见\u0026quot;数组使用参考\u0026quot;。\n例子： 1 2 3 4 5 6 7 8 $$ \\left[ \\begin{array}{cc|c} 1 \u0026amp; 2 \u0026amp; 3 \\\\ 4 \u0026amp; 5 \u0026amp; 6 \\\\ \\end{array} \\right] $$ 显示： $$ \\left[ \\begin{array}{cc|c} 1 \u0026amp; 2 \u0026amp; 3 \\ 4 \u0026amp; 5 \u0026amp; 6 \\ \\end{array} \\right] $$ 其中 cc|c 代表在一个三列矩阵中的第二和第三列之间插入分割线。\n5．如何输入行中矩阵 若想在一行内显示矩阵， 使用\\bigl(\\begin{smallmatrix} ... \\end{smallmatrix}\\bigr)。\n例子： 1 这是一个行中矩阵的示例 $\\bigl(\\begin{smallmatrix} a \u0026amp; b \\\\ c \u0026amp; d \\end{smallmatrix}\\bigr)$ 。 显示：这是一个行中矩阵的示例 $\\bigl(\\begin{smallmatrix} a \u0026amp; b \\ c \u0026amp; d \\end{smallmatrix}\\bigr)$ 。 三、方程式序列使用参考 1．如何输入一个方程式序列 人们经常想要一列整齐且居中的方程式序列。使用 \\begin{align}…\\end{align} 来创造一列方程式，其中在每行结尾处使用 \\\\ 。使用方程式序列无需声明公式符号 $ 或 $$ 。\n请注意 {align} 语句是自动编号的，使用 {align*} 声明不自动编号。\n例子： 1 2 3 4 5 6 7 \\begin{align} \\sqrt{37} \u0026amp; = \\sqrt{\\frac{73^2-1}{12^2}} \\\\ \u0026amp; = \\sqrt{\\frac{73^2}{12^2}\\cdot\\frac{73^2-1}{73^2}} \\\\ \u0026amp; = \\sqrt{\\frac{73^2}{12^2}}\\sqrt{\\frac{73^2-1}{73^2}} \\\\ \u0026amp; = \\frac{73}{12}\\sqrt{1-\\frac{1}{73^2}} \\\\ \u0026amp; \\approx \\frac{73}{12}\\left(1-\\frac{1}{2\\cdot73^2}\\right) \\\\ \\end{align} 显示：\n\\begin{align} \\sqrt{37} \u0026amp; = \\sqrt{\\frac{73^2-1}{12^2}} \\ \u0026amp; = \\sqrt{\\frac{73^2}{12^2}\\cdot\\frac{73^2-1}{73^2}} \\ \u0026amp; = \\sqrt{\\frac{73^2}{12^2}}\\sqrt{\\frac{73^2-1}{73^2}} \\ \u0026amp; = \\frac{73}{12}\\sqrt{1-\\frac{1}{73^2}} \\ \u0026amp; \\approx \\frac{73}{12}\\left(1-\\frac{1}{2\\cdot73^2}\\right) \\ \\end{align}\n本例中每行公式的编号续自“如何插入公式”中的自动编号公式\\eqref{eq:sample} 。\n2．在一个方程式序列的每一行中注明原因 在 {align} 中后添加 \u0026amp; 符号来自动对齐后面的内容，可灵活组合 \\text 和 \\tag 语句。\\tag 语句编号优先级高于自动编号。\n例子： 1 2 3 4 5 \\begin{align} v + w \u0026amp; = 0 \u0026amp; \\text{Given} \\tag 1 \\\\ -w \u0026amp; = -w + 0 \u0026amp; \\text{additive identity} \\tag 2 \\\\ -w + 0 \u0026amp; = -w + (v + w) \u0026amp; \\text{equations $(1)$ and $(2)$} \\\\ \\end{align} 显示： \\begin{align} v + w \u0026amp; = 0 \u0026amp; \\text{Given} \\tag 1 \\ -w \u0026amp; = -w + 0 \u0026amp; \\text{additive identity} \\tag 2 \\ -w + 0 \u0026amp; = -w + (v + w) \u0026amp; \\text{equations $(1)$ and $(2)$} \\ \\end{align} 本例中第一、第二行的自动编号被 \\tag 语句覆盖，第三行的编号为自动编号。\n@joyphys 如何引用 \\tag 标记的公式？ 使用 \\tag{yourtag} 来标记公式，然后在 \\tag 之后加上 \\label{yourlabel} 四、条件表达式使用参考 1．如何输入一个条件表达式 使用 \\begin{cases}…\\end{cases} 来创造一组条件表达式，在每一行条件中插入 \u0026amp; 来指定需要对齐的内容，并在每一行结尾处使用 \\\\。\n例子： 1 2 3 4 5 6 7 $$ f(n) = \\begin{cases} n/2, \u0026amp; \\text{if $n$ is even} \\\\ 3n+1, \u0026amp; \\text{if $n$ is odd} \\\\ \\end{cases} $$ 显示： $$ f(n) = \\begin{cases} n/2, \u0026amp; \\text{if $n$ is even} \\ 3n+1, \u0026amp; \\text{if $n$ is odd} \\ \\end{cases} $$ @Sherlockk 用 markdown+math 编辑时 \\text 内需用 \\(equation\\)\n2．如何输入一个左侧对齐的条件表达式 若想让文字在左侧对齐显示，则有如下方式：\n例子： 1 2 3 4 5 6 7 8 9 $$ \\left. \\begin{array}{l} \\text{if $n$ is even:} \u0026amp; n/2 \\\\ \\text{if $n$ is odd:} \u0026amp; 3n+1 \\\\ \\end{array} \\right\\} =f(n) $$ 显示： $$ \\left. \\begin{array}{l} \\text{if $n$ is even:} \u0026amp; n/2 \\ \\text{if $n$ is odd:} \u0026amp; 3n+1 \\ \\end{array} \\right} =f(n) $$ 3．如何使条件表达式适配行高 在一些情况下，条件表达式中某些行的行高为非标准高度，此时使用 \\\\[2ex] 语句代替该行末尾的 \\\\ 来让编辑器适配。\n例子： 不适配[2ex] 1 2 3 4 5 6 7 $$ f(n) = \\begin{cases} \\frac{n}{2}, \u0026amp; \\text{if $n$ is even} \\\\ 3n+1, \u0026amp; \\text{if $n$ is odd} \\\\ \\end{cases} $$ 适配[2ex] 1 2 3 4 5 6 7 $$ f(n) = \\begin{cases} \\frac{n}{2}, \u0026amp; \\text{if $n$ is even} \\\\[2ex] 3n+1, \u0026amp; \\text{if $n$ is odd} \\\\ \\end{cases} $$ 显示： 不适配[2ex] 适配[2ex] $$ f(n) = \\begin{cases} \\frac{n}{2}, \u0026amp; \\text{if $n$ is even} \\ 3n+1, \u0026amp; \\text{if $n$ is odd} \\ \\end{cases} $$ $$ f(n) = \\begin{cases} \\frac{n}{2}, \u0026amp; \\text{if $n$ is even} \\[2ex] 3n+1, \u0026amp; \\text{if $n$ is odd} \\ \\end{cases} $$ 一个 [ex] 指一个 \u0026ldquo;X-Height\u0026rdquo;，即 x 字母高度。可以根据情况指定多个 [ex]，如 [3ex]、[4ex] 等。 其实可以在任意换行处使用 \\\\[2ex] 语句，只要你觉得合适。\n五、数组与表格使用参考 1．如何输入一个数组或表格 通常，一个格式化后的表格比单纯的文字或排版后的文字更具有可读性。 数组和表格均以 \\begin{array} 开头，并在其后定义列数及每一列的文本对齐属性，c l r 分别代表居中、左对齐及右对齐。若需要插入垂直分割线，在定义式中插入 | ，若要插入水平分割线，在下一行输入前插入 \\hline 。 与矩阵相似，每行元素间均须要插入 \u0026amp; ，每行元素以 \\\\ 结尾，最后以 \\ end{array} 结束数组。 使用单个数组或表格时无需声明 $ 或 $$ 符号。\n例子： 1 2 3 4 5 6 7 \\begin{array}{c|lcr} n \u0026amp; \\text{左对齐} \u0026amp; \\text{居中对齐} \u0026amp; \\text{右对齐} \\\\ \\hline 1 \u0026amp; 0.24 \u0026amp; 1 \u0026amp; 125 \\\\ 2 \u0026amp; -1 \u0026amp; 189 \u0026amp; -8 \\\\ 3 \u0026amp; -20 \u0026amp; 2000 \u0026amp; 1+10i \\\\ \\end{array} 显示： \\begin{array}{c|lcr} n \u0026amp; \\text{左对齐} \u0026amp; \\text{居中对齐} \u0026amp; \\text{右对齐} \\ \\hline 1 \u0026amp; 0.24 \u0026amp; 1 \u0026amp; 125 \\ 2 \u0026amp; -1 \u0026amp; 189 \u0026amp; -8 \\ 3 \u0026amp; -20 \u0026amp; 2000 \u0026amp; 1+10i \\ \\end{array} 2．如何输入一个嵌套的数组或表格 多个数组\\表格可 互相嵌套 并组成一组数组或表格。 使用嵌套前必须声明 $$ 符号。\n例子： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 $$ \\begin{array}{c} % 总表格 \\begin{array}{cc} % 第一行内分成两列 \\begin{array}{c|cccc} % 第一列\u0026#34;最小值\u0026#34;数组 \\text{min} \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\\\ \\hline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\\\ 1 \u0026amp; 0 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\\\ 2 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 2 \\\\ 3 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\\\ \\end{array} \u0026amp; \\begin{array}{c|cccc} % 第二列\u0026#34;最大值\u0026#34;数组 \\text{max} \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\\\ \\hline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\\\ 2 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2 \u0026amp; 3 \\\\ 3 \u0026amp; 3 \u0026amp; 3 \u0026amp; 3 \u0026amp; 3 \\\\ \\end{array} \\end{array} % 第一行表格组结束 \\\\ \\begin{array}{c|cccc} % 第二行 Delta 值数组 \\Delta \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\\\ \\hline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\\\ 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \\\\ 2 \u0026amp; 2 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \\\\ 3 \u0026amp; 3 \u0026amp; 2 \u0026amp; 1 \u0026amp; 0 \\\\ \\end{array} % 第二行表格结束 \\end{array} % 总表格结束 $$ 显示： $$ \\begin{array}{c} % 总表格 \\begin{array}{cc} % 第一行内分成两列 \\begin{array}{c|cccc} % 第一列\u0026quot;最小值\u0026quot;数组 \\text{min} \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\ \\hline 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 0 \\ 1 \u0026amp; 0 \u0026amp; 1 \u0026amp; 1 \u0026amp; 1 \\ 2 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 2 \\ 3 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\ \\end{array} \u0026amp; \\begin{array}{c|cccc} % 第二列\u0026quot;最大值\u0026quot;数组 \\text{max} \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\ \\hline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\ 1 \u0026amp; 1 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\ 2 \u0026amp; 2 \u0026amp; 2 \u0026amp; 2 \u0026amp; 3 \\ 3 \u0026amp; 3 \u0026amp; 3 \u0026amp; 3 \u0026amp; 3 \\ \\end{array} \\end{array} % 第一行表格组结束 \\ \\begin{array}{c|cccc} % 第二行 Delta 值数组 \\Delta \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\ \\hline 0 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \u0026amp; 3 \\ 1 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \u0026amp; 2 \\ 2 \u0026amp; 2 \u0026amp; 1 \u0026amp; 0 \u0026amp; 1 \\ 3 \u0026amp; 3 \u0026amp; 2 \u0026amp; 1 \u0026amp; 0 \\ \\end{array} % 第二行表格结束 \\end{array} % 总表格结束 $$ ##3．如何输入一个方程组\n可以使用 \\begin{array} … \\end{array} 和 \\left\\{ … \\right. 来创建一个方程组：\n例子： 1 2 3 4 5 6 7 8 9 $$ \\left\\{ \\begin{array}{c} a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3 \\\\ \\end{array} \\right. $$ 显示： $$ \\left{ \\begin{array}{c} a_1x+b_1y+c_1z=d_1 \\ a_2x+b_2y+c_2z=d_2 \\ a_3x+b_3y+c_3z=d_3 \\ \\end{array} \\right. $$ 或使用条件表达式组 \\begin{cases} … \\end{cases} 来实现相同效果：\n例子： 1 2 3 4 5 \\begin{cases} a_1x+b_1y+c_1z=d_1 \\\\ a_2x+b_2y+c_2z=d_2 \\\\ a_3x+b_3y+c_3z=d_3 \\\\ \\end{cases} 显示： \\begin{cases} a_1x+b_1y+c_1z=d_1 \\ a_2x+b_2y+c_2z=d_2 \\ a_3x+b_3y+c_3z=d_3 \\ \\end{cases} 六、连分数使用参考 1．如何输入一个连分式 就像输入分式时使用 \\frac 一样，使用 \\cfrac 来创建一个连分数。\n例子： 1 2 3 4 5 6 7 8 9 10 11 $$ x = a_0 + \\cfrac{1^2}{a_1 + \\cfrac{2^2}{a_2 + \\cfrac{3^2}{a_3 + \\cfrac{4^4}{a_4 + \\cdots } } } } $$ 显示： $$ x = a_0 + \\cfrac{1^2}{a_1 + \\cfrac{2^2}{a_2 + \\cfrac{3^2}{a_3 + \\cfrac{4^4}{a_4 + \\cdots } } } } $$ 不要使用普通的 \\frac 或 \\over 来生成连分数，这样会看起来很恶心。\n反例： 1 2 3 4 5 6 7 8 9 10 11 $$ x = a_0 + \\frac{1^2}{a_1 + \\frac{2^2}{a_2 + \\frac{3^2}{a_3 + \\frac{4^4}{a_4 + \\cdots } } } } $$ 显示： $$ x = a_0 + \\frac{1^2}{a_1 + \\frac{2^2}{a_2 + \\frac{3^2}{a_3 + \\frac{4^4}{a_4 + \\cdots } } } } $$ 当然，你可以使用 \\frac 来表达连分数的紧缩记法。\n例子： 1 2 3 4 5 6 7 $$ x = a_0 + \\frac{1^2}{a_1 +} \\frac{2^2}{a_2 +} \\frac{3^2}{a_3 +} \\frac{4^4}{a_4 +} \\cdots $$ 显示： $$ x = a_0 + \\frac{1^2}{a_1 +} \\frac{2^2}{a_2 +} \\frac{3^2}{a_3 +} \\frac{4^4}{a_4 +} \\cdots $$ 连分数通常都太大以至于不易排版，所以建议在连分数前后声明 $$ 符号，或使用像 [a0,a1,a2,a3,…] 一样的紧缩记法。\n七、交换图表使用参考 1．如何输入一个交换图表 推荐使用 Cmd Markdown 自带的各种图功能，详见 Cmd Markdown 高阶语法手册。\n使用一行 \\require{AMScd} 语句来允许交换图表的显示。 声明交换图表后，语法与矩阵相似，在开头使用 \\begin{CD}，在结尾使用 \\ end{CD}，在中间插入图表元素，每个元素之间插入 \u0026amp; ，并在每行结尾处使用 \\\\。\n例子： 1 2 3 4 5 6 7 8 $$ \\require{AMScd} \\begin{CD} A @\u0026gt;a\u0026gt;\u0026gt; B \\\\ @V b V V\\# @VV c V \\\\ C @\u0026gt;\u0026gt;d\u0026gt; D \\\\ \\end{CD} $$ 显示： $$ \\require{AMScd} \\begin{CD} A @\u0026gt;a\u0026raquo; B \\ @V b V V# @VV c V \\ C @\u0026raquo;d\u0026gt; D \\ \\end{CD} $$ 其中，@\u0026gt;\u0026gt;\u0026gt; 代表右箭头、@\u0026lt;\u0026lt;\u0026lt; 代表左箭头、@VVV 代表下箭头、@AAA 代表上箭头、@= 代表水平双实线、@| 代表竖直双实线、@.代表没有箭头。 在 @\u0026gt;\u0026gt;\u0026gt; 的 \u0026gt;\u0026gt;\u0026gt; 之间任意插入文字即代表该箭头的注释文字。\n例子： 1 2 3 4 5 6 7 8 $$ \\require{AMDcd} \\begin{CD} A @\u0026gt;\u0026gt;\u0026gt; B @\u0026gt;{\\text{very long label}}\u0026gt;\u0026gt; C \\\\ @. @AAA @| \\\\ D @= E @\u0026lt;\u0026lt;\u0026lt; F \\\\ \\end{CD} $$ 显示： $$ \\require{AMDcd} \\begin{CD} A @\u0026raquo;\u0026gt; B @\u0026gt;{\\text{very long label}}\u0026raquo; C \\ @. @AAA @| \\ D @= E @\u0026laquo;\u0026lt; F \\ \\end{CD} $$ 在本例中，very long label 自动延长了它所在箭头以及对应箭头的长度，因而交换图表十分适合进行化学反应式的书写。\n例子： 1 2 3 4 5 6 $$ \\require{AMDcd} \\begin{CD} \\rm{RCOHR^{\u0026#39;}SO_3Na} @\u0026gt;{\\large\\text{Hydrolysis, $\\Delta$, Dil.HCl}}\u0026gt;\u0026gt; \\rm{(RCOR^{\u0026#39;})+NaCl+SO_2+ H_2O} \\end{CD} $$ 显示： $$ \\require{AMDcd} \\begin{CD} \\rm{RCOHR^{\u0026rsquo;}SO_3Na} @\u0026gt;{\\large\\text{Hydrolysis, $\\Delta$, Dil.HCl}}\u0026raquo; \\rm{(RCOR^{\u0026rsquo;})+NaCl+SO_2+ H_2O} \\end{CD} $$ 八、一些特殊的注意事项 !! 本段内容为个人翻译，可能有不准确之处 !! These are issues that won\u0026rsquo;t affect the correctness of formulas, but might make them look significantly better or worse. Beginners should feel free to ignore this advice; someone else will correct it for them, or more likely nobody will care.\n现在指出的小问题并不会影响公式的正确显示，但能让它们看起来明显更好看。初学者可无视这些建议，自然会有强迫症患者替你们改掉它的，或者更可能地，不会有人在意这些细节。\nDon\u0026rsquo;t use \\frac in exponents or limits of integrals; it looks bad and can be confusing, which is why it is rarely done in professional mathematical typesetting. Write the fraction horizontally, with a slash:\n在以 $e$ 为底的指数函数、极限和积分中尽量不要使用 \\frac 符号——它会使整段函数看起来很奇怪并可能产生歧义，因此它在专业数学排版中几乎从不出现。可试着横着写这些分式，中间使用斜线间隔 / （用斜线代替分数线）。\n例子： 1 2 3 4 5 6 \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\\\ \\hline \\\\ \\large e^{i\\frac{\\pi}2} \\quad e^{\\frac{i\\pi}2}\u0026amp; \\large e^{i\\pi/2} \\\\[2ex] \\int_{-\\frac\\pi2}^\\frac\\pi2 \\sin x\\,dx \u0026amp; \\int_{-\\pi/2}^{\\pi/2}\\sin x\\,dx \\\\ \\end{array} 显示： \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\ \\hline \\ \\large e^{i\\frac{\\pi}2} \\quad e^{\\frac{i\\pi}2}\u0026amp; \\large e^{i\\pi/2} \\[2ex] \\int_{-\\frac\\pi2}^\\frac\\pi2 \\sin x,dx \u0026amp; \\int_{-\\pi/2}^{\\pi/2}\\sin x,dx \\ \\end{array} The | symbol has the wrong spacing when it is used as a divider, for example in set comprehensions. Use \\mid instead:\n使用 | 符号作为分隔符时会产生错误的间距，因此在需要分隔时最好使用 \\mid 来代替它。\n例子: 1 2 3 4 5 \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\\\ \\hline \\\\ \\{x|x^2\\in\\Bbb Z\\} \u0026amp; \\{x\\mid x^2\\in\\Bbb Z\\} \\\\ \\end{array} 显示： \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\ \\hline \\ {x|x^2\\in\\Bbb Z} \u0026amp; {x\\mid x^2\\in\\Bbb Z} \\ \\end{array} For double and triple integrals, don\u0026rsquo;t use \\int\\int or \\int\\int\\int. Instead use the special forms \\iint and \\iiint:\n使用多重积分符号时，不要多次使用 \\int 来声明，直接使用 \\iint 来表示二重积分，使用 \\iiint 来表示三重积分。 个人补充：在表示面积分和体积分时下标建议使用 \\boldsymbol{S} 和 \\boldsymbol{V} 符号；对于多维函数的超体积，可使用 \\idotsint，如下面的例子所示。\n例子： 1 2 3 4 5 6 7 8 \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\\\ \\hline \\\\ \\int\\int_S f(x)\\,dy\\,dx \u0026amp; \\iint_{\\boldsymbol{S}} f(x)\\,{\\rm d}y\\,{\\rm d}x \\\\ \\int\\int\\int_V f(x)\\,dz\\,dy\\,dx \u0026amp; \\iiint_{\\boldsymbol{V}} f(x)\\,{\\rm d}z\\,{\\rm d}y\\,{\\rm d}x \\\\[3ex] \\hline \\\\ \\text{多重积分示例} \u0026amp; \\idotsint_{\\boldsymbol{D}} f(x_1,x_2,\\,\\cdots\\, ,x_n)\\,{\\rm d}x_1\\cdots{\\rm d}x_n \\end{array} 显示： $$ \\require{AMSmath} \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\ \\hline \\ \\int\\int_S f(x),dy,dx \u0026amp; \\iint_{\\boldsymbol{S}} f(x),{\\rm d}y,{\\rm d}x \\ \\int\\int\\int_V f(x),dz,dy,dx \u0026amp; \\iiint_{\\boldsymbol{V}} f(x),{\\rm d}z,{\\rm d}y,{\\rm d}x \\[3ex] \\hline \\ \\text{多重积分示例} \u0026amp; \\idotsint_{\\boldsymbol{D}} f(x_1,x_2,,\\cdots, ,x_n),{\\rm d}x_1\\cdots{\\rm d}x_n \\end{array} $$ Use \\,, to insert a thin space before differentials; without this $\\TeX$ will mash them together:\n使用多重积分时，在被积变量后加入 \\, （或在微分符号 ${\\rm d}$ 之前）来插入一个小的间距，否则各种被积变量将会挤成一团。注意比较 ${\\rm d}z{\\rm d} y{\\rm d} x$ 的不同。\n例子： 1 2 3 4 5 \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\\\ \\hline \\\\ \\iiint_V f(x){\\rm d}z {\\rm d}y {\\rm d}x \u0026amp; \\iiint_{\\boldsymbol{V}} f(x)\\,{\\rm d}z\\,{\\rm d}y\\,{\\rm d}x \\\\ \\end{array} 显示： \\begin{array}{cc} \\mathrm{Bad} \u0026amp; \\mathrm{Better} \\ \\hline \\ \\iiint_V f(x){\\rm d}z {\\rm d}y {\\rm d}x \u0026amp; \\iiint_{\\boldsymbol{V}} f(x),{\\rm d}z,{\\rm d}y,{\\rm d}x \\ \\end{array} 感谢您花费时间阅读这份指导手册，本手册内容可能有疏漏之处，欢迎更改指正。 更多语法请参见：Cmd Markdown 简明语法手册，Cmd Markdown 高阶语法手册。 祝您记录、阅读、分享愉快！\nDrafted \u0026amp; Translated by Eric P. 2015-10-02\n","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/li-hongyis-notes/markdown%E5%85%AC%E5%BC%8F%E8%AF%AD%E6%B3%95/","summary":"一、公式使用参考 1．如何插入公式 $ \\LaTeX $ 的数学公式有两种：行中公式和独立公式。行中公式放在文中与其它文字混编，独立公式单独成行。\n行中公式可以用如下方法表示： $ 数学公式 $\n独立公式可以用如下方法表示： $$ 数学公式 $$\n自动编号的公式可以用如下方法表示： 若需要手动编号，参见“大括号和行标的使用”。 \\begin{equation} 数学公式 \\label{eq:当前公式名} \\end{equation}\n自动编号后的公式可在全文任意处使用 \\eqref{eq:公式名} 语句引用。\n例子： 1 $ J_\\alpha(x) = \\sum_{m=0}^\\infty \\frac{(-1)^m}{m! \\Gamma (m + \\alpha + 1)} {\\left({ \\frac{x}{2} }\\right)}^{2m + \\alpha} \\text {，行内公式示例} $ 显示：$ J_\\alpha(x) = \\sum_{m=0}^\\infty \\frac{(-1)^m}{m! \\Gamma (m + \\alpha + 1)} {\\left({ \\frac{x}{2} }\\right)}^{2m + \\alpha} \\text {，行内公式示例} $\n例子：\n1 $$ J_\\alpha(x) = \\sum_{m=0}^\\infty \\frac{(-1)^m}{m! \\Gamma (m + \\alpha + 1)} {\\left({ \\frac{x}{2} }\\right)}^{2m + \\alpha} \\text {，独立公式示例} $$ 显示：$$ J_\\alpha(x) = \\sum_{m=0}^\\infty \\frac{(-1)^m}{m!","title":"Markdown公式语法.md"},{"content":"二、回归模型 [toc]\n2.1 线性回归模型 回归模型应用案例 股票市场预测（Stock Market Forecast）：预测某个公司明天的股票情况 自动驾驶车（Self-Driving Car）：预测方向盘的转动角度 推荐系统（Recommendation）：预测某用户购买某商品的可能性 线性回归模型（Linear Regression Model） 形式如下： $y= f(x) = w \\cdot x + b $\ny是输出，$\\widehat{y}$ 是真实值/标签（label) w是权重（weight） b是偏置（bias） x是输入（input），也可叫做特征（feature）。数据集中一般包含多个object，每个object一般包含多个component。此时，上标是object的索引，下标是component的索引 损失函数（Loss Function）如果不考虑模型的好坏，衡量一个函数的好坏，其实是衡量模型参数的好坏。以线性模型为例，就是衡量参数和的好坏。如 $ L(f) = L(w,b) = \\sum_{n=1} ^{10}{ \\widehat{y} - (b + w \\cdot x_n)} $ ，把所有的样本误差的平方和作为损失函数 输入：一个函数 输出：多么地不好（how bad it is）。损失函数值越大，则这个函数越差、与数据集中内容月不相符 梯度下降（Gradient Descent） 梯度下降可以优化损失函数的值，使其尽量小，即可找到最好（在数据集上模拟效果最好）的模型参数。 现在假设模型$f$中只有一个参数 $w$，则损失函数为$L(f) = L(w)$ ，梯度下降算法如下\n初始化参数：随机选取一个 $ w_0 $（并不一定是随机选取），令 $ w = w_0 $ 计算梯度 $\\frac{dL(f)}{dw}|_{w=w_0}$ ，如果小于0，此时w增大则L（f）减小，如果大于0，此时w减小则L（w）会减小。如果模型中有多个参数，则计算损失函数在各个参数方向上的偏导数 更新模型参数，$w_1 = w_0 - lr \\frac{dL(f)}{dw}|_{w=w_0}$ ，w的变化量取决于梯度和学习率（Learning Rate）的大小：梯度绝对值或学习率越大，则w变化量越大。如果模型有多个参数，则用上一步计算出的偏导数对应更新各参数。 重复第2步和第3步，经过多次参数更新/迭代（iteration），可以使损失函数的值达到局部最小（即局部最优，Local Optimal），但不一定是全局最优。 现在假设模型$f$中只有两个参数 $w$，则损失函数为$L(f) = L(w)$ ，梯度下降算法如下（若模型中有多个参数，按相同方法更新各参数）\n初始化参数：随机选取初始值$w_0$和$b_0$（并不一定是随机选取），令$w = w_0$，$b=b_0$ 计算梯度 $ \\frac{dL(f)}{dw}|{w=w_0,b=b_0} $， $ \\frac{dL(f)}{db}|{w=w_0,b=b_0} $ 更新模型参数，$ w_1 = w_0 - lr \\frac{dL(f)}{dw}|{w=w_0,b=b_0} $ ， $ b_1 = b_0 - lr \\frac{dL(f)}{db}|{w=w_0,b=b_0} $ 。 重复第2步和第3步，经过多次参数更新/迭代（iteration），可以使损失函数的值达到局部最小（即局部最优，Local Optimal），但不一定是全局最优。 2.2 如何选择模型、减小误差 模型选择（How to select model） 模型越复杂，一般在训练集上的误差（Error）越小。因为更复杂的模型（函数集）包含更多的函数。比如二次模型包含一次模型 模型越复杂，其在测试集上的误差（Error）不一定越小，因为模型过于复杂时，越容易被数据影响，可能导致过拟合。 误差（Error） 误差的来源 暂时称通过机器学习得到的函数为人工函数，它其实是对“上帝函数”的估计（Estimator），和“上帝函数”之间是有误差的。\n误差来源于两方面：一是Bias，二是Variance，需要权衡（trade-off）两者以使总误差最小。\n如上图所示，Bias是指人工函数（的期望）和上帝函数之间的距离，Variance是指人工函数的离散程度（或者说是不稳定程度）\n如上图所示，横轴是模型的复杂程度（1次幂、2次幂、……），纵轴是误差大小。模型越复杂，Bias越小，Variance越大。\nVariance 使用相同模型在不同数据上拟合得到的函数是不同的，这些函数之间的离散程度就是Variance。以射箭为例，Variance衡量的就是射得稳不稳。模型越复杂，Variance越大。因为模型越简单，越不容易被数据影响（对数据不敏感，感知数据变化的能力较差），那Variance就越小。\nBias 使用相同模型在不同数据上拟合得到的函数是不同的，取这些函数的“期望”，该期望与“真理”的差距就是Bias。以射箭为例，Bias衡量的就是射得准不准（这里的“准”的含义有待商榷）。**模型越简单，Bias越大。**因为模型就是个函数集（Function Set）。模型越简单，则其包含的函数就越少、包含“上帝函数”的几率就越小，甚至可能不包括上帝函数。\n在函数集很小的情况下，即使是其中最好的函数，它与“上帝函数”的差距也还是很大的。\n2.3 欠拟合与过拟合 欠拟合（Underfitting） Bias较大、Variance较小。如果模型在训练集上的误差很大，则此时Bias是大的，情况为欠拟合。\nBias大时如何处理：使用更复杂的模型，比如添加考虑更多维度的输入、把线性模型换成非线性模型。\n过拟合（Overfitting） Bias较小、Variance较大。如果模型在训练集上的误差很小，但是在测试集上的误差很大，则此时Variance是大的，情况为过拟合。\nVariance大时如何处理：\n使用更复杂的数据集：比如添加数据（很有效，但不一定做得到）、数据增强等方法。 使用更简单的模型（不是根本方法），可能是模型过于复杂导致了过拟合，因此可以简化模型缓解过拟合。 正则化（Regularization）：正则化可能会使Bias增大，所以需要调整正则化的参数。如$L_{new} = L_{old} + \\lambda \\sum{w_i^2}$ ，其中$\\lambda$ 是一个常数。加上正则项 $\\lambda \\sum{w_i^2}$ 的目的是让函数参数尽可能地接近0，使函数变得平滑。 平滑（Smooth） 平滑是指输入变化影响输出变化的程度（输出对输入的敏感程度）。假设输入变化，如果函数越不平滑，则输出变化程度越大。函数参数越接近0，这个函数就越平滑（smooth）。\n我们为什么喜欢一个平滑的函数？适度平滑的函数可以缓解函数输入中包含的噪声对函数输出的影响。如果输入中包含一些噪声/干扰（noise），那平滑函数的输出受输入中包含的噪声干扰的程度更小。 我们为什么不喜欢过于平滑的函数？函数过于平滑，就无法有效地提取数据的特征，这不是我们想要的函数。假设有一个极限平滑的函数，即该函数的输出不受输入的影响，那当然不是个好的函数。 2.4交叉验证 在机器学习中，同城不能将全部数据用于模型训练，否则将没有数据集可以用来评估模型\nThe Validation Set Approach 将数据集划分成训练集（Training Set）和测试集（Test Set）两部分。\n缺点：这种方法的缺点是依赖于训练集和测试集的划分方法，并且只用了部分数据进行模型的训练。\nLOOCV（Leave One Out Cross Validation） 假设数据集中有N个数据，取其中1个数据作为测试集，将剩下的N-1个数据作为训练集，这样重复N次就得到N个模型以及N个误差值，最终使用这N个误差值的平均值评估该模型。\n优点：该方法不受训练集和测试集划分方法的影响，因为每个数据都单独做过测试集；同时该方法用了N-1个数据训练模型，也几乎用到了所有的数据，保证了模型的Bias更小。\n缺点：该方法的缺点是计算量过大，是The Validation Set Approach耗时的N-1倍。\nK折交叉验证（K-fold Cross Validation） 该方法是LOOCV的折中，即将数据集分成K份。\n如何选取K的值：K的选取是一个Bias和Variance的trade-off。一般选择K=5或10。K越大，每次训练时训练集的数据量就越大，则Bias越小；但每次训练时的训练集之间的相关性越大（考虑最极端的情况K=N，也就是LOOCV，每次训练使用的数据几乎是一样的），这种大相关性会导致最终的误差具有更大的Variance。\n","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/li-hongyis-notes/%E4%BA%8C%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B/","summary":"二、回归模型 [toc]\n2.1 线性回归模型 回归模型应用案例 股票市场预测（Stock Market Forecast）：预测某个公司明天的股票情况 自动驾驶车（Self-Driving Car）：预测方向盘的转动角度 推荐系统（Recommendation）：预测某用户购买某商品的可能性 线性回归模型（Linear Regression Model） 形式如下： $y= f(x) = w \\cdot x + b $\ny是输出，$\\widehat{y}$ 是真实值/标签（label) w是权重（weight） b是偏置（bias） x是输入（input），也可叫做特征（feature）。数据集中一般包含多个object，每个object一般包含多个component。此时，上标是object的索引，下标是component的索引 损失函数（Loss Function）如果不考虑模型的好坏，衡量一个函数的好坏，其实是衡量模型参数的好坏。以线性模型为例，就是衡量参数和的好坏。如 $ L(f) = L(w,b) = \\sum_{n=1} ^{10}{ \\widehat{y} - (b + w \\cdot x_n)} $ ，把所有的样本误差的平方和作为损失函数 输入：一个函数 输出：多么地不好（how bad it is）。损失函数值越大，则这个函数越差、与数据集中内容月不相符 梯度下降（Gradient Descent） 梯度下降可以优化损失函数的值，使其尽量小，即可找到最好（在数据集上模拟效果最好）的模型参数。 现在假设模型$f$中只有一个参数 $w$，则损失函数为$L(f) = L(w)$ ，梯度下降算法如下\n初始化参数：随机选取一个 $ w_0 $（并不一定是随机选取），令 $ w = w_0 $ 计算梯度 $\\frac{dL(f)}{dw}|_{w=w_0}$ ，如果小于0，此时w增大则L（f）减小，如果大于0，此时w减小则L（w）会减小。如果模型中有多个参数，则计算损失函数在各个参数方向上的偏导数 更新模型参数，$w_1 = w_0 - lr \\frac{dL(f)}{dw}|_{w=w_0}$ ，w的变化量取决于梯度和学习率（Learning Rate）的大小：梯度绝对值或学习率越大，则w变化量越大。如果模型有多个参数，则用上一步计算出的偏导数对应更新各参数。 重复第2步和第3步，经过多次参数更新/迭代（iteration），可以使损失函数的值达到局部最小（即局部最优，Local Optimal），但不一定是全局最优。 现在假设模型$f$中只有两个参数 $w$，则损失函数为$L(f) = L(w)$ ，梯度下降算法如下（若模型中有多个参数，按相同方法更新各参数）","title":"二、回归模型.md"},{"content":"Tips for Training DNN [toc]\n6.1 神经网络训练问题与解决方案 明确问题类型及其对应方法 在深度学习中，一般有两种问题：\n在训练集上性能不好 在测试集上性能不好。 当一个方法被提出时，它往往是针对这两个问题其中之一的，比如dropout方法是用来处理在测试集上性能不好的情况。\n处理神经网络在训练集上性能不好的情况和方法 修改神经网络架构，比如换成更好的激活函数： sigmoid函数会导致梯度消失，可以换成ReLU、Leaky ReLU、Parametric ReLU、Maxout 调整学习率： 比如RMSProp、Momentum、Adam 处理神经网络在测试集上性能不好的情况和方法 Early Stopping、Regularization，这两个是比较传统的方法，不只适用于深度学习 Dropout，比较有深度学习的特色 一些性能优化方法的简介 下面3点都是在增加模型的随机性，鼓励模型做更多的exploration。\nShuffling： 输入数据的顺序不要固定，mini-batch每次要重新生成 Dropout： 鼓励每个神经元都学到东西，也可以广义地理解为增加随机性 Gradient noise： 2015年提出，计算完梯度后，加上Gaussian noise。 随着迭代次数增加，noise应该逐渐变小。 下面3点是关于学习率调整的技巧\nwarm up： 开始时学习率较小，等稳定之后学习率变大 Curriculum learning： 2009年提出，先使用简单的数据训练模型（一方面此时模型比较弱，另一方面在clean data中更容易提取到核心特征），然后再用难的数据训练模型。 这样可以提高模型的鲁棒性。 Fine-tuning 下面3点是关于数据预处理的技巧，避免模型学习到太极端的参数\nNormalization： 有Batch Normalization、Instance Normalization、Group Normalization、Layer Normalization、Positional Normalization Regularization 6.2 神经网络精度低不一定是因为过拟合 相比于决策树等方法，神经网络更不容易过拟合：K近邻、决策树等方法在训练集上更容易得到100%等很高的正确率，神经网络一般不能，训练神经网络首先遇到的问题一般是在训练集上的精度不高。 不要总是把精度低归咎于过拟合：如果模型在训练集上精度高，对于K近邻、决策树等方法我们可以直接判断为过拟合，但对于神经网络来说我们还需要检查神经网络在测试集上的精度。如果神经网络在训练集上精度高但在测试集上精度低，这才说明神经网络过拟合了。 如果56层的神经网络和20层的神经网络相比，56层网络在测试集上的精度低于20层网络，这还不能判断为56层网络包含了过多参数导致过拟合。一般来讲，56层网络优于20层网络，但如果我们发现56层网络在训练集上的精度本来就低于20层网络，那原因可能有很多而非过拟合，比如56层网络没训练好导致一个不好的局部最优、虽然56层网络的参数多但结构有问题等等。 感兴趣可以看看ResNet论文**Deep Residual Learning for Image Recognition**，这篇论文可能与该问题有关。 6.3 常用激活函数（训练集） 梯度消失（Vanishing Gradient Problem） 定义：1980年代常用的激活函数是sigmoid函数。以MNIST手写数字识别为例，在使用sigmoid函数时会发现随着神经网络层数增加，识别准确率逐渐下降，这个现象的原因并不是过拟合（原因见上文），而是梯度消失。\n如上图所示，当神经网络层数很多时，靠近输入层的参数的梯度会很小，靠近输出层的参数的梯度会很大。当每个参数的学习率相同时，靠近输入层的参数会更新得很慢，靠近输出层的几层参数会更新得很快。所以，当靠近输入层的参数几乎还是随机数时，靠近输出层的参数已经收敛了。\n原因： 按照反向传播的式子，这确实是会发生的。直观感觉上，sigmoid函数输入的范围是无穷大，但输出的范围是[0,1]，也就是说sigmoid函数减弱了输入变化导致输出变化的幅度。那为什么靠近输出层的参数的梯度更大呢？sigmoid函数是一层层叠起来的，不断地减弱靠近输入层的参数的变化导致输出变化的幅度，所以更靠后的参数的梯度越大。 解决方法： Hinton提出无监督逐层训练方法以解决这个问题，其基本思想是每次训练一层隐节点。 后来Hinton等人提出修改激活函数，比如换成ReLU。 ReLU（Rectified Linear Unit） 定义： 当输入小于等于0时，输出为0；当输入大于0时，输出等于输入，如下图所示。\n优点： 相比于sigmoid函数，它有以下优点\n运算更快 更符合生物学 等同于无穷多个bias不同的sigmoid函数叠加起来 可以解决梯度消失问题 如何解决梯度消失问题？ 当ReLU输出为0时该激活函数对神经网络不起作用，所以在神经网络中生效的激活函数都是输出等于输入，所以就不会出现sigmoid函数导致的减弱输入变化导致输出变化的幅度的情况。 ReLU会使整个神经网络变成线性的吗？ 可知有效的激活函数都是线性的，但整个神经网络还是非线性的。当输入改变很小、不改变每个激活函数的Operation Region（操作区域，大概意思就是输入范围）时，整个神经网络是线性的；当输入改变很大、改变了Operation Region时，整个神经网络就是非线性的。==目前我是凭直觉理解这一点，还未细究== ReLU可以做微分吗？ 不用处理输入为0的情况，当输入小于0时，微分就是0，当输入大于0时微分就是1。 Leaky ReLU 当输入小于等于0时，输出为输入的0.01倍；当输入大于0时，输出等于输入。\nParametric ReLU 当输入小于等于0时，输出为输入的 $\\alpha$ 倍；当输入大于0时，输出等于输入。\n其中 $\\alpha$ 是通过梯度下降学习到的参数\nMaxout 通过学习得到一个激活函数，人为将每层输出的多个值分组，然后输出每组值中的最大值。（跟maxpooling一模一样），其实ReLU是Maxout的一个特例。\nMaxout比ReLU包含了更多的函数\nMaxout 可以得到任意的分段线性凸函数（piecewise linear convex），有几个分段取决于每组里有几个值\n如何训练Maxout Maxout只是选择输出哪一个线性函数的值而已，因此Maxout激活函数还是线性的。 因为在多个值中只选择最大值进行输出，所以会形成一个比较瘦长/窄深的神经网络。 在多个值中只选择最大值进行输出，这并不会导致一些参数无法被训练：因为输入不同导致一组值中的最大值不同，所以各个参数都可能被训练到。 当输入不同时，形成的也是不同结构的神经网络。\n6.4 学习率调整方法（训练集） Adagrad Adaptive Gradient Descent，自适应梯度下降，解决不同参数应该使用不同的更新速率的问题。Adagrad自适应地为各个参数分配不同学习率的算法。2011年提出，核心是每个参数（parameter）有不同的学习率。每次迭代中，学习率要除以它对应参数的之前梯度的均方根（RMS），即 $w_{t+1} = w_t-\\frac{\\eta}{\\sqrt{\\sum_{i=0}^{t}{(g_t)^2}}}g_t$ 。\nRMSProp 背景 RMSProp是Adagrad的升级版，在2013年Hinton在Coursera提出。 在训练神经网络时，损失函数不一定是凸函数（局部最小值即为全局最小值），可能是各种各样的函数，有时需要较大的学习率，有时需要较小的学习率，而Adagrad并不能实现这种效果，因此产生了RMSProp。\n定义 $w_{t+1}=w_{t}-\\frac{\\eta}{\\sigma_t}g_t$ （$\\sigma_0=g_0 , \\sigma_t=\\sqrt{\\alpha(\\sigma_{t+1})^2+(1-\\alpha)(g_t)^2}$），其中 $w$ 是某个参数， $\\eta$ 是学习率，$g$ 是梯度， $\\alpha$ 代表旧的梯度的重要性，值越小则旧的梯度越不重要。\n神经网络中很难找到最优的参数吗？ 面临的问题有plateau、saddle point和local minima。\n2007年有人（名字读音好像是young la ken）指出神经网络的error surface是很平滑的，没有很多局部最优。假设有1000个参数，一个参数处于局部最优的概率是 $p$ ，则整个神经网络处于局部最优的概率是 $p^{1000}$ ，这个值是很小的。\nMomentum 如何处理停滞期、鞍点、局部最小值等问题？ 考虑现实世界中物体具有惯性、动量（Momentum）的特点，尽可能避免“小球”陷入error surface上的这几种位置。\n定义 1986年提出。如下图所示，不仅考虑当前的梯度，还考虑上一次的移动方向：$v_t = \\lambda v_{t-1}-\\eta g_t$ ， $v_0=0$，其中 $t$ 是迭代次数，$v$ 指移动方向（movement），类似物理里的速度，$g$ 是梯度（gradient），$\\lambda$ 用来控制惯性的重要性，值越大代表惯性越重要，$\\eta$ 是学习率\nAdam RMSProp+Momentum+Bias Correction，2015年提出\nAdam VS SGDM 目前常用的就是Adam和SGDM。\nAdam训练速度快，large generalization gap（在训练集和验证集上的性能差异大），但不稳定； SGDM更稳定，little generalization gap，更加converge（收敛）。 SGDM适用于计算机视觉，Adam适用于NLP、Speech Synthesis、GAN、Reinforcement Learning。 ####　SWATS\n2017年提出，尝试把Adam和SGDM结合，其实就是前一段时间用Adam，后一段时间用SGDM，但在切换时需要解决一些问题。\n尝试改进Adam AMSGrad Adam的问题: Non-informative gradients contribute more than informative gradients. 在Adam中，之前所有的梯度都会对第 $t$ 步的movement产生影响。然而较早阶段(比如第1、2步)的梯度信息是相对无效的，较晚阶段（比如 $t-1$ 、$t-2$ 步)的梯度信息是相对有效的。在Adam中，可能发生较早阶段梯度相对于较晚阶段梯度比重更大的问题。 提出AMSGrad: 2018年提出 AdaBound 2019年提出，目的也是改进Adam。 Adam需要warm up吗？需要。 warm up：开始时学习率小，后面学习率大。 因为实验结果说明在刚开始的几次（大概是10次）迭代中，参数值的分布比较散乱（distort），因此梯度值就比较散乱，导致梯度下降不稳定。 RAdam 2020年提出 Lookahead 2019年提出，像一个wrapper一样套在优化器外面，适用于Adam、SGDM等任何优化器。 迭代几次后会回头检查一下。 Nadam 2016年提出，把NAG的概念应用到Adam上。 AdamW 2017年提出，这个优化器还是有重要应用的（训练出了某个BERT模型）。 尝试改进SGDM LR range test 2017年提出 Cyclical LR 2017年提出 SGDR 2017年提出，模拟Cosine但并不是Cosine One-cycle LR 2017年提出，warm-up+annealing+fine-tuning SGDW 2017年提出 改进Momentum 背景 如果梯度指出要停下来，但动量说要继续走，这样可能导致坏的结果。\nNAG（Nesterov accelerated gradient） 1983年提出，会预测下一步。 6.5 处理测试集性能不好的方法 6.5.1 Early Stopping 如果学习率调整得较好，随着迭代次数增加，神经网络在训练集上的loss会越来越小，但因为验证集（Validation set）和训练集不完全一样，所以神经网络在验证集上的loss可能不降反升，所以我们应该在神经网络在验证集上loss最小时停止训练。\n6.5.2 Regularization 正则化，L2 regularization如下图所示（$||\\theta||^2$ ，L2范式的平方），一般不考虑bias项。\nL2 regularization 的偏微分，每次都会使 $w_t$ 接近0，因为 $1-\\eta\\lambda$ 接近1但是小于1，比如0.99，每次成0.99，都会向0接近。\n当然，regularization 也可以有其他形式，比如是 $w_i$ 绝对值的集合，成为L1 regularization，具体如下图。但是，这个方法每次使得梯度减少的速度都一样，都是 1 或 -1 乘上 $\\eta\\lambda$ 。\n6.5.3 Dropout dropout是指在深度学习网络的训练过程中，对于神经网络单元，按照一定的概率将其暂时从网络中丢弃。注意是暂时，对于随机梯度下降来说，由于是随机丢弃，故而每一个mini-batch都在训练不同的网络。\ndropout 在test集合上不使用，只用在Validation set上，并且在test集合上的时候，需要把weight 乘上 $(1-p)%$ 。\n直观的解释：一个团队中，每个人都希望自己的同伴会做这个工作，最后什么都没有做；但是如果你知道你的同伴会dropdout，你就会做的更好，去carry他；不过当testing的时候，没有人会去dropout，所以最后的结果会更好。\n为什么要乘 $(1-p)%$ ？直观的解释如下图。\ndropout是一个整体\n做dropout 的时候是训练了一堆 neural structual\n那这些值的 average 与一开始算的 $\\hat y$ 是否相等呢？\n其实是一样的。\n","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/li-hongyis-notes/%E5%85%ADtips-for-training-dnn/","summary":"Tips for Training DNN [toc]\n6.1 神经网络训练问题与解决方案 明确问题类型及其对应方法 在深度学习中，一般有两种问题：\n在训练集上性能不好 在测试集上性能不好。 当一个方法被提出时，它往往是针对这两个问题其中之一的，比如dropout方法是用来处理在测试集上性能不好的情况。\n处理神经网络在训练集上性能不好的情况和方法 修改神经网络架构，比如换成更好的激活函数： sigmoid函数会导致梯度消失，可以换成ReLU、Leaky ReLU、Parametric ReLU、Maxout 调整学习率： 比如RMSProp、Momentum、Adam 处理神经网络在测试集上性能不好的情况和方法 Early Stopping、Regularization，这两个是比较传统的方法，不只适用于深度学习 Dropout，比较有深度学习的特色 一些性能优化方法的简介 下面3点都是在增加模型的随机性，鼓励模型做更多的exploration。\nShuffling： 输入数据的顺序不要固定，mini-batch每次要重新生成 Dropout： 鼓励每个神经元都学到东西，也可以广义地理解为增加随机性 Gradient noise： 2015年提出，计算完梯度后，加上Gaussian noise。 随着迭代次数增加，noise应该逐渐变小。 下面3点是关于学习率调整的技巧\nwarm up： 开始时学习率较小，等稳定之后学习率变大 Curriculum learning： 2009年提出，先使用简单的数据训练模型（一方面此时模型比较弱，另一方面在clean data中更容易提取到核心特征），然后再用难的数据训练模型。 这样可以提高模型的鲁棒性。 Fine-tuning 下面3点是关于数据预处理的技巧，避免模型学习到太极端的参数\nNormalization： 有Batch Normalization、Instance Normalization、Group Normalization、Layer Normalization、Positional Normalization Regularization 6.2 神经网络精度低不一定是因为过拟合 相比于决策树等方法，神经网络更不容易过拟合：K近邻、决策树等方法在训练集上更容易得到100%等很高的正确率，神经网络一般不能，训练神经网络首先遇到的问题一般是在训练集上的精度不高。 不要总是把精度低归咎于过拟合：如果模型在训练集上精度高，对于K近邻、决策树等方法我们可以直接判断为过拟合，但对于神经网络来说我们还需要检查神经网络在测试集上的精度。如果神经网络在训练集上精度高但在测试集上精度低，这才说明神经网络过拟合了。 如果56层的神经网络和20层的神经网络相比，56层网络在测试集上的精度低于20层网络，这还不能判断为56层网络包含了过多参数导致过拟合。一般来讲，56层网络优于20层网络，但如果我们发现56层网络在训练集上的精度本来就低于20层网络，那原因可能有很多而非过拟合，比如56层网络没训练好导致一个不好的局部最优、虽然56层网络的参数多但结构有问题等等。 感兴趣可以看看ResNet论文**Deep Residual Learning for Image Recognition**，这篇论文可能与该问题有关。 6.3 常用激活函数（训练集） 梯度消失（Vanishing Gradient Problem） 定义：1980年代常用的激活函数是sigmoid函数。以MNIST手写数字识别为例，在使用sigmoid函数时会发现随着神经网络层数增加，识别准确率逐渐下降，这个现象的原因并不是过拟合（原因见上文），而是梯度消失。","title":"六、Tips for Training DNN.md"},{"content":"七、Convolutional Neural Network [toc]\n7.1 CNN入门详解 卷积神经网络（CNN）常常被用来做图像处理，当然也可以用一般的神经网络，那它们各自有什么优缺点呢？\nFNN用于图片处理的缺点 使用一般的全连接前馈神经网络（FNN）处理图片时的缺点：\n需要很多的参数： 假设有一张尺寸100×100的图片（尺寸已经算很小了），那输入层就有100×100×3=30K个像素，假设第一个隐藏层有1K个神经元（一个神经元包含30K个参数），这就已经需要30M个参数了…… 该架构中每个神经元就是一个分类器，这是没必要的： 第一个隐藏层作为最基础的pattern分类器（比如判断有无绿色、边缘等），第二个隐藏层基于第一个隐藏层继续做pattern分类（比如木头、肉类），以此类推…… 按照人类的直观理解，我们不是像全连接神经网络一样去处理图片的。具体来看，有哪些方面呢？\n图片的一些性质 结合全连接前馈神经网络的缺点和人类对图片的直观理解，可以得到下述图片的3个性质。\n性质1：Some patterns are much smaller than the whole image. 在识别某个模式（pattern）时，一个神经元并不需要图片的所有像素点。对于一张人类全身照的图片，我们只需要看到头部而非整张图片就可以判断它是一个人脸。所以我们应该是可以用少量参数去识别这些pattern的。\n性质2：The same patterns appear in different regions. 比如说人脸可以在图片的中间区域，也可以在图片的某个角落区域。所以识别不同区域中的相同pattern的多个分类器（或detector）应该用同一组参数或者共享参数。\n性质3：Subsampling the pixels will not change the object CNN架构说明 2014年在ECCV上提出，针对上述的图片的3个性质，确定了CNN的架构如下。\n如上图所示，图片经过卷积层然后进行最大池化（max pooling），这个步骤可以进行多次；然后将数据展开（Flatten），然后将数据传进全连接前馈网络得到最后的图片分类结果。\n如上图所示，卷积是针对了图片的性质1和性质2，最大池化是针对了图片的性质3。\n卷积(Convolution) ★ 假设有一张6×6的二值图，即一个6×6的矩阵。\n卷积核（Filter） 神经元就是一个计算/函数，卷积核其实就是神经元。如下图所示，1个卷积层可以有多个卷积核，矩阵里元素的值就是需要通过学习得到的参数。因为这里的输入是一个矩阵，所以卷积核也是1个矩阵（卷积核的通道数等于输入的通道数）。假设卷积核大小是3×3，这对应了图片的性质1，即用小的卷积核识别一个小的pattern。\n怎么做卷积 如下图所示\n卷积区域： 根据该卷积核的大小（以3×3为例），选择图片中相同大小的区域进行卷积。 卷积的计算方法： 从图片中扫描得到的3×3矩阵和卷积核的3×3矩阵，这2个矩阵相同位置的元素相乘可以得到9个值并求和（也就是内积）得到1个值，这就是1次卷积操作。 卷积顺序和方向： 卷积核按照从左到右、从上到下的顺序，从图片左上角开始移动，移动步长（stride）可以设置（以1为例）。在扫描到的每个区域中，都进行1次卷积。1个卷积核移动结束后，则得到1个新的矩阵（大小为4×4），即1个卷积核的输出是1个矩阵。 卷积层有多个卷积核，每个卷积核都按照该方式进行卷积得到多个矩阵，这些矩阵合起来就形成了1个卷积层的特征图（Feature Map），这个特征图也就是卷积层的输出。 卷积层特征图的通道数等于该卷积层中卷积核的数量，即某卷积层有多少个卷积核，那该卷积层的特征图就有多少个通道。 ","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/li-hongyis-notes/%E4%B8%83convolutional-neural-network/","summary":"七、Convolutional Neural Network [toc]\n7.1 CNN入门详解 卷积神经网络（CNN）常常被用来做图像处理，当然也可以用一般的神经网络，那它们各自有什么优缺点呢？\nFNN用于图片处理的缺点 使用一般的全连接前馈神经网络（FNN）处理图片时的缺点：\n需要很多的参数： 假设有一张尺寸100×100的图片（尺寸已经算很小了），那输入层就有100×100×3=30K个像素，假设第一个隐藏层有1K个神经元（一个神经元包含30K个参数），这就已经需要30M个参数了…… 该架构中每个神经元就是一个分类器，这是没必要的： 第一个隐藏层作为最基础的pattern分类器（比如判断有无绿色、边缘等），第二个隐藏层基于第一个隐藏层继续做pattern分类（比如木头、肉类），以此类推…… 按照人类的直观理解，我们不是像全连接神经网络一样去处理图片的。具体来看，有哪些方面呢？\n图片的一些性质 结合全连接前馈神经网络的缺点和人类对图片的直观理解，可以得到下述图片的3个性质。\n性质1：Some patterns are much smaller than the whole image. 在识别某个模式（pattern）时，一个神经元并不需要图片的所有像素点。对于一张人类全身照的图片，我们只需要看到头部而非整张图片就可以判断它是一个人脸。所以我们应该是可以用少量参数去识别这些pattern的。\n性质2：The same patterns appear in different regions. 比如说人脸可以在图片的中间区域，也可以在图片的某个角落区域。所以识别不同区域中的相同pattern的多个分类器（或detector）应该用同一组参数或者共享参数。\n性质3：Subsampling the pixels will not change the object CNN架构说明 2014年在ECCV上提出，针对上述的图片的3个性质，确定了CNN的架构如下。\n如上图所示，图片经过卷积层然后进行最大池化（max pooling），这个步骤可以进行多次；然后将数据展开（Flatten），然后将数据传进全连接前馈网络得到最后的图片分类结果。\n如上图所示，卷积是针对了图片的性质1和性质2，最大池化是针对了图片的性质3。\n卷积(Convolution) ★ 假设有一张6×6的二值图，即一个6×6的矩阵。\n卷积核（Filter） 神经元就是一个计算/函数，卷积核其实就是神经元。如下图所示，1个卷积层可以有多个卷积核，矩阵里元素的值就是需要通过学习得到的参数。因为这里的输入是一个矩阵，所以卷积核也是1个矩阵（卷积核的通道数等于输入的通道数）。假设卷积核大小是3×3，这对应了图片的性质1，即用小的卷积核识别一个小的pattern。\n怎么做卷积 如下图所示\n卷积区域： 根据该卷积核的大小（以3×3为例），选择图片中相同大小的区域进行卷积。 卷积的计算方法： 从图片中扫描得到的3×3矩阵和卷积核的3×3矩阵，这2个矩阵相同位置的元素相乘可以得到9个值并求和（也就是内积）得到1个值，这就是1次卷积操作。 卷积顺序和方向： 卷积核按照从左到右、从上到下的顺序，从图片左上角开始移动，移动步长（stride）可以设置（以1为例）。在扫描到的每个区域中，都进行1次卷积。1个卷积核移动结束后，则得到1个新的矩阵（大小为4×4），即1个卷积核的输出是1个矩阵。 卷积层有多个卷积核，每个卷积核都按照该方式进行卷积得到多个矩阵，这些矩阵合起来就形成了1个卷积层的特征图（Feature Map），这个特征图也就是卷积层的输出。 卷积层特征图的通道数等于该卷积层中卷积核的数量，即某卷积层有多少个卷积核，那该卷积层的特征图就有多少个通道。 ","title":"七、Convolutional Neural Network.md"},{"content":"三、梯度下降 [toc]\n梯度下降伪代码 梯度下降可以优化损失函数的值，使其尽量小，即可找到最好（在数据集上拟合效果最好）的模型参数。现在假设模型 $f$ 中只有一个参数 $w$ ，则损失函数为 $L(f) = L(w)$ ，梯度下降算法如下（若模型有多个参数，按相同方法更新各方法）\n初始化参数：随机选取一个 $w_0$ （$w_0$ 并不一定是随机选取） 计算梯度 $\\frac{dL(f)}{dw}$ ，如果小于0，此时 $w$ 增大则 $L(f)$ 会减小；如果大于0，此时 $w$ 增大则 $L(w)$ 会减小。如果模型有多个参数，则计算损失函数在各个参数方向上的偏导数。 更新模型参数 $w_1=w_0-lr\\frac{dL(f)}{dw}$ ，$w$ 的变化量取决于梯度和学习率（Learning Rate）的大小：梯度绝对值或学习率越大，则 $w$ 变化量越大。如果模型有多个参数，则用上一步计算出的偏导数对应更新各参数。 重复第2步和第3步。经过多次参数更新/迭代（iteration），可以使损失函数的值达到局部最小（即局部最优，Local Optimal），但不一定是全局最优。 自适应学习率（Adaptive Learning Rate） 梯度下降的过程中，固定学习率并不合理。学习率太大，可能导致loss不减小反而增大；学习率太小，loss会减小得很慢。基本原则是随着参数迭代更新，学习率应该越来越小，比如 $\\eta_t = \\frac{\\eta}{\\sqrt{t+1}}$ 。更好的办法是每个参数都有各自的学习率，比如Adagrad。\nAdagrad Adaptive Gradient Descent，自适应梯度下降。2011年提出，核心是每个参数（parameter）有不同的学习率。每次迭代中，学习率要除以它对应参数的之前梯度的均方根（RMS），即 $w_{t+1} = w_t-\\frac{\\eta}{\\sqrt{\\sum_{i=0}^{t}{(g_t)^2}}}g_t$ ，其中 $t$ 是迭代次数，$w$ 是参数，$g$ 是梯度，$\\eta$ 是初始学习率。随着参数迭代，$t$ 越来越大，$\\sqrt{\\sum_{i=0}^{t}{(g_t)^2}}$ 也越来越大，因此学习率的变化趋势是越来越小。\nAdagrad的矛盾（Contradiction） 一般的梯度下降方法中 $w_{t+1}=w_t-\\eta_tg_t$ ，其中 $\\eta_t$ 是常数，梯度越大时，则参数更新的步幅越大，这是由 $g_t$ 项决定的。在Adagrad中，$\\eta$ 是常量，梯度 $g_t$ 越大时，会使得参数更新的步幅越大，但 $\\sqrt{\\sum_{i=0}^{t}{(g_t)^2}}$ 越大会使得参数更新的步幅越小，这是一个矛盾吗？\n为什么要除以之前的梯度的均方根？\n一种直观的解释：增强参数更新步幅变化的惯性。与之前梯度相比如果现在的梯度更大，则现在梯度除以之前的梯度会使参数更新的步幅更大；如果现在的梯度更小，则会使步幅更新的步幅更小。这样就相当于增强了参数更新步幅变化的惯性，即如果参数更新的步幅突然变大或变小，就扩大这个趋势。 同时考虑一次梯度和二次梯度：在Adagrad中，之前梯度的均方根是用来通过一次梯度估计二次梯度（虽然可以直接使用二次梯度，但其很难计算） 只考虑一个参数：当参数只有一个或只考虑一个参数时，梯度越大，离最优点就越远，参数更新的步幅应该越大。 考虑多个参数：当参数由多个参数时，上述内容不一定成立。如果参数1的梯度比参数2的梯度大，但如果损失函数关于参数1的曲线比关于参数2的曲线更陡峭（即二次梯度更大），那参数1离最优点的距离可能比参数2更近。所以当参数有多个或者考虑多个参数时，我们既要考虑一次梯度又要考虑二次梯度。结论是一次梯度越大、二次梯度越小，离最优点就越远，参数更新的步幅应该越大。 SGD Stochastic Gradient Descent，随机梯度下降，1847年提出，可以让训练过程更快。普通梯度下降中需要计算所有样本的Loss，二SGD只计算一个样本的Loss，然后进行梯度下降。\n梯度下降的数学理论 初始化一组参数后，我们找到领域中另一个使损失函数最小的一组参数并更新参数（然后不断重复这一步骤）。 在极小的邻域中，可以利用泰勒级数将损失函数简化，然后求其最小值，损失函数简化后，要使其最小即是让其中两个向量的内积最小，由此可以得出新的一组参数的值（具体过程略），这就是梯度下降算法。 学习率的作用是限制邻域大小，学习率太大可能使邻域太大，导致损失函数展开程泰勒级数时的误差较大。 当然也可以将损失函数展开成2次（比如牛顿迭代式），但这并不实用，因为要计算二次微分，甚至可能要求除海森矩阵（Hessian Matrix）逆矩阵等等，这些在做深度学习时是不实用的。 梯度下降的局限性 梯度下降过程中，每次参数更新不一定都会使损失函数的值更小。求出的知识局部最小值（Local Minima）甚至是鞍点（Saddle Point），不一定是全局最优解。\n","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/li-hongyis-notes/%E4%B8%89%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/","summary":"三、梯度下降 [toc]\n梯度下降伪代码 梯度下降可以优化损失函数的值，使其尽量小，即可找到最好（在数据集上拟合效果最好）的模型参数。现在假设模型 $f$ 中只有一个参数 $w$ ，则损失函数为 $L(f) = L(w)$ ，梯度下降算法如下（若模型有多个参数，按相同方法更新各方法）\n初始化参数：随机选取一个 $w_0$ （$w_0$ 并不一定是随机选取） 计算梯度 $\\frac{dL(f)}{dw}$ ，如果小于0，此时 $w$ 增大则 $L(f)$ 会减小；如果大于0，此时 $w$ 增大则 $L(w)$ 会减小。如果模型有多个参数，则计算损失函数在各个参数方向上的偏导数。 更新模型参数 $w_1=w_0-lr\\frac{dL(f)}{dw}$ ，$w$ 的变化量取决于梯度和学习率（Learning Rate）的大小：梯度绝对值或学习率越大，则 $w$ 变化量越大。如果模型有多个参数，则用上一步计算出的偏导数对应更新各参数。 重复第2步和第3步。经过多次参数更新/迭代（iteration），可以使损失函数的值达到局部最小（即局部最优，Local Optimal），但不一定是全局最优。 自适应学习率（Adaptive Learning Rate） 梯度下降的过程中，固定学习率并不合理。学习率太大，可能导致loss不减小反而增大；学习率太小，loss会减小得很慢。基本原则是随着参数迭代更新，学习率应该越来越小，比如 $\\eta_t = \\frac{\\eta}{\\sqrt{t+1}}$ 。更好的办法是每个参数都有各自的学习率，比如Adagrad。\nAdagrad Adaptive Gradient Descent，自适应梯度下降。2011年提出，核心是每个参数（parameter）有不同的学习率。每次迭代中，学习率要除以它对应参数的之前梯度的均方根（RMS），即 $w_{t+1} = w_t-\\frac{\\eta}{\\sqrt{\\sum_{i=0}^{t}{(g_t)^2}}}g_t$ ，其中 $t$ 是迭代次数，$w$ 是参数，$g$ 是梯度，$\\eta$ 是初始学习率。随着参数迭代，$t$ 越来越大，$\\sqrt{\\sum_{i=0}^{t}{(g_t)^2}}$ 也越来越大，因此学习率的变化趋势是越来越小。\nAdagrad的矛盾（Contradiction） 一般的梯度下降方法中 $w_{t+1}=w_t-\\eta_tg_t$ ，其中 $\\eta_t$ 是常数，梯度越大时，则参数更新的步幅越大，这是由 $g_t$ 项决定的。在Adagrad中，$\\eta$ 是常量，梯度 $g_t$ 越大时，会使得参数更新的步幅越大，但 $\\sqrt{\\sum_{i=0}^{t}{(g_t)^2}}$ 越大会使得参数更新的步幅越小，这是一个矛盾吗？","title":"三、梯度下降.md"},{"content":"四、分类模型 [toc]\n4.1 分类简介及其与回归的区别 分类模型应用案例（Classification Cases） 信用评分（Credit Scoring） 输入：收入、储蓄、职业、年龄、信用历史等等 输出：是否贷款 医疗诊断（Medical Diagnosis） 输入：现在症状、年龄、性别、病史 输出：哪种疾病 手写文字识别（Handwritten Character Recognition） 输入：文字图片 输出：是哪一个汉字 人脸识别（Face Recognition） 输入：面部图片 输出：是哪个人 把分类当成回归去做 不行\n假设有两个类别，其中类别1的标签为1，类别2的标签为-1，那0就是分界线，大于0就是类别1，小于0就是类别2。但是回归模型会惩罚哪些太正确的样本，如果结果远远大于1，它的分类应该是类别1还是类别2？这时为了降低整体误差，需要调整已经找到的回归函数，就会导致结果的不准确。 假设有多个类别，类别1的标签是1，类别2的标签是2，类别3的标签是3。这样的话，标签间具有2和3相近、3大于2这种本来不存在的数字关系。 理想替代方案（Ideal Alternatives） 模型：模型可以根据特征判断类型，输入是特征，输出是类别 损失函数：预测错误的次数，即$L(f)=\\sum_n{\\sigma(f(x_n) \\neq \\hat{y_n} }$ 。这个函数不可微。 如何找到最好的函数，比如感知机（Perceptron）、支持向量机（SVM） 4.2 分类模型指概率生成模型 贝叶斯公式 $P(A \\cap B) = P(A)P(B|A) = P(B)P(A|B)$ $P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$ 全概率公式 $P(B)=\\sum_{i=1}^{n}{P(A_i)P(B|A_i)}$\n概率生成模型（Probalitity Genetative Model） 理论与定义 假设有两个类别的$C_1和C_2$，要判断对象$x$属于哪个类别，这样把分类问题变成了概率计算问题。\n根据贝叶斯公式（Bayes\u0026rsquo; theorem）和全概率公式（Total Probability Theorem）可以知道，$x$属于类别$C_1$的概率为$P(C_1|x)= \\frac{P(x|C_1)P(C_1)}{P(x)}=\\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}$ ，如果$P(C_1|x)\u0026gt;0.5$ 则类别为$C_1$ ，否则类别为$C_2$。 概率生成模型的意思就是可以通过这个模型生成一个$$x$$。具体来讲就是，根据$P(x)=P(x|C_1)P(C_1)+P(x|C_2)P(C_2)$ 计算出$P(x)$，就可以知道 $x$ 的分布进而生成 $x$ 。如果想要计算出$P(x)$，就要根据训练集估计出$P(C_1)$、$P(x|C_1)$、$P(C_2)$、$P(x|C_2)$这四个值。更直观一点地讲，每个类别就是一个多元正态分布，其中多元是因为每个样本有多个维度的特征。 可以根据数据集中属于两个类别的对象的数量计算 $P(C_1)$ 和 $P(C_2)$ 这两个先验概率（Prior Probability）。如果有2个样本属于类别$C_1$ ，4个样本属于类别$C_2$ ，那$P(C_1)= \\frac{1}{3}$、$P(C_2)= \\frac{2}{3}$。 要计算后验概率（Posterior Probability）$P(x|C_1)$ 和 $P(x|C_2)$，可以假设训练集中的各类别样本的特征分别是从某个多元正太分布（多元对应特征的多维）中取样得到的，或者说是假设训练集中各类别样本的特征分别符合某多元正态分布。该正太分布的输入是一个样本的特征 $x$，输出为样本 $x$ 是从这个正太分布取样得到（或者说该样本属于某类别）的概率密度，然后通过积分就可以求得 $P(x|C_1)$ 和 $P(x|C_2)$ 。 正太分布公式为 $f_{\\mu,\\sum{(x)}}=\\frac{1}{(2\\pi)^\\frac{D}{2}} \\frac{1}{|\\sum|^\\frac{1}{2}} {e^{-\\frac{1}{2}(x-\\mu)^T\\sum^{-1}{x-\\mu}}}$ 。正太分布有2个参数，即均值 $\\mu$ （代表正太分布的中心位置）和协方差矩阵（Covariance Matrix）$\\sum$ （代表正态分布的离散程度），计算出均值 $\\mu$ 和协方差 $\\sum$ 即可得到该正态分布。公式中的 $D$ 为多维特征的维度。 实际上从任何一个正态分布中取样都有可能得到训练集中的特征，只是概率不同而已。通过极大值似然估计（Maximum Likelihood Estimate，MLE），我们可以找到取样得到训练集特征的概率最大的那个正态分布，假设其均值和协方差矩阵为 $ \\mu^* $ 和 $ \\sum^* $ 。 根据某正态分布的均值 $\\mu$ 和协方差 $\\sum$ ，可以计算出从该正态分布取样得到训练集的概率。 $ L(\\mu,\\sum) = f_{\\mu,\\sum}{x_1} f_{\\mu,\\sum}{x_2}f_{\\mu,\\sum}{x_3}\u0026hellip;f_{\\mu,\\sum}{x_N} $ ，这就是似然函数（Likelihood Function），其中$N$ 是训练集中某个类别样本的数量。 $\\mu^,\\sum^=\\arg\\max_{\\mu,\\sum}{L(\\mu,\\sum)}$，当然可以求导。直觉：$\\mu^=\\frac{1}{N}\\sum_{i=1}^{N}{x_i}$，$\\sum^ = \\frac{1}{N}\\sum_{i=1}^{N}(x_i-\\mu^*)^2T$ 协方差矩阵共享 每个类别的特征符合一个多元正态分布，每个多元正态分布也有不同的均值和协方差矩阵。让每个类别对应的多元正态分布共享一个协方差矩阵（各个协方差矩阵的加权平均和），公式为 $\\sum = \\frac{N_1}{N_1+N_2}\\sum_1+\\frac{N_2}{N_1+N_2}\\sum_2$，可以减少模型参数，缓解过拟合\n极大似然估计 极大似然估计指已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，然后通过若干次试验，观察其结果，利用结果推出参数的大概值。一般说来，在一次试验中如果事件A发生了，则认为此时的参数值会使得 $P(A|\\theta)$ 最大，极大似然估计法就是要这样估计出的参数值，使所选取的样本在被选的总体中出现的可能性为最大。\n求极大似然函数估计值的一般步骤：\n写出似然函数 对似然函数取对数，并整理 求导数 解似然函数 当共享协方差矩阵时，此时似然函数是$L(\\mu_1,\\mu_2,\\sum)=f_{\\mu_1,\\sum}(x_1)f_{\\mu_1,\\sum}(x_2)\u0026hellip;f_{\\mu_1,\\sum}{(x_{N1}) \\times f_{\\mu_2,\\sum}(x_{N1+1})f_{\\mu_2,\\sum}(x_{N1+2})\u0026hellip;f_{\\mu_2,\\sum}(x_{N1+N2})}$ ，其中 $N_1$ 为训练集中类别 $C_1$ 的样本数、$N_2$ 为训练集中类别 $C_2$ 的样本数。当只有两个类别、两个特征时，如果共享协方差矩阵，那最终得到的两个类别的分界线是直线（横纵轴是两个特征），这一点可以在下文解释。\n除了正态分布，还可以用其它的概率模型。 比如对于二值特征，可以使用伯努利分布（Bernouli Distribution）。 朴素贝叶斯分类：如果假设样本各个维度的数据是互相独立的，那这就是朴素贝叶斯分类器（Naive Bayes Classfier）。 Sigmoid 函数 由上我们可知，$P(C_1|x)= \\frac{P(x|C_1)P(C_1)}{P(x)}=\\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}=\\frac{1} {1+\\frac{P(x|C_2)P(C_2)}{P(x|C_1)P(C_1)}}$ ，令 $z=\\ln{\\frac{P(x|C_1)P(C_1)}{P(x|C_2)P(C_2)}}$ ，则 $P(C_1|x) =\\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}=\\frac{1} {1+\\frac{P(x|C_2)P(C_2)}{P(x|C_1)P(C_1)}}=\\frac{1}{1+e^{-z}} = \\delta(z)$ ，这就是Sigmoid函数。\n如果共享协方差矩阵，经过运算可以得到 $z=w_T+b$ 的形式，其中常量 $w_T = (\\mu_1-\\mu_2)^T\\sum^{-1}$，常量 $b=-\\frac{1}{2}(\\mu_1)^T(\\sum_1)^{-1}\\mu_1+\\frac{1}{2}(\\mu_2)^T(\\sum_2)^{-1}\\mu_2+\\ln{\\frac{N_1}{N_2}}$ ，即形如 $P(C_1|x) = \\delta(w\\cdot x+b)$ 。\n4.3 分类模型之逻辑回归 逻辑回归 假设训练集如下图所示，有2个类别 $C_1$ 和 $C_2$ ，下图表格中的每列为一个样本。\n$x_1$ $x_2$ $x_3$ \u0026hellip; $x_N$ $C_1$ $C_1$ $C_2$ \u0026hellip; $C_1$ $\\hat{y_1} =1$ $\\hat{y_2} =1$ $\\hat{y_3} = 0$ \u0026hellip; $\\hat{y_n} =1$ 例如，第一列表示样本 $x_1$ 的类别为 $C_1$ ，所以它标签是 $\\hat{y_1}$ 是1。\n模型定义 在分类（Classification）一节中，我们要找到一个模型 $P_{w,b}(C_1|x)$ ，如果 $P_{w,b}(C_1|x)\\geq0.5$ ，则 $x$ 属于类别 $C_1$ ，否则属于类别 $C_2$ 。可知 $P_{w,b}(C_1|x) = \\sigma(z)$ ，其中 $\\sigma(z)=\\frac{1}{1+e^{-z}}$ （Sigmoid Fuction），$z=w \\cdot x+b=\\sum^{N}{i=1}{w_ix_i+b} $ 。最终我们找到了模型 $f{w,b(x)}=\\sigma(\\sum^N_{i=1}{w_ix_i+b})$。 最终我们找到了模型 $f_{w,b(x)=\\sigma(\\sum^N_{i=1}{w_ix_i+b})}$ ，这其实就是逻辑回归（Logistic Regression）。\n损失函数 从模型 $ f_{w,b}(x)=P_{w,b}(C_1|x) $ 中取样得到训练集的概率为： $ L(w,b)=f_{w,b}(x_1)f_{w,b}(x_2)(1-f_{w,b}(x_3))\u0026hellip;f_{w,b}(x_N) $ （似然函数）。\n我们要求出 $w^,b^=\\arg\\max_{w,b}L(w,b)$，等同于 $w^,b^=\\arg\\min_{w,b}-\\ln{L(w,b)}$ （对数似然方程，Log-likelihood Equation）。\n而 $ -\\ln{L(w,b)=-\\ln{f_{w,b}{x_1}} -\\ln{f_{w,b}{x_2}}} -\\ln{(1-f_{w,b}{x_3})}\u0026hellip;$ ，其中 $ \\ln{f_{w,b}(x_N)=\\hat{y^N}\\ln{f_{w,b}{(x^N)}} + (1-\\hat{y^N})\\ln{(1-f_{w,b}{(x^N)})}} $ ，所以 $ -\\ln{L(w,b)=\\sum^N_{n=1}{-[\\hat y^N\\ln{f_{w,b}(x^N)}+(1-\\hat y^n)\\ln(1-f_{w,b}(x^N))]}} $ ，式中N用来选择某个样本。\n假设有两个伯努利分布 $p$ 和 $q$ ，在 $p$ 中有 $p(x=1)=\\hat {y^N}$ ，$p(x=0)=1-\\hat{y^N}$ ，在 $q$ 中有 $q(x=1)=f(x_N)$ ，$q(x=0)=1-f(x_N)$ ，则 $p$ 和 $q$ 的交叉熵（Cross Entropy，代表两个分布有多接近，两个分布一摸一样时交叉熵为0），为 $H(p,q)=-\\sum_x{p(x)\\ln(q(x))}$ 。所以损失函数 $L(f)=\\sum^N_{n=1}{C(f(x_n),\\hat{y^N})}$ ，其中 $C(f(x_N),\\hat{y^N})=-[\\hat y^N\\ln{f_{w,b}(x^N)}+(1-\\hat y^n)\\ln(1-f_{w,b}(x^N))]$ ，即损失函数为所有样本的 $f(x_N)$ 与 $\\hat{y_N}$ 的交叉熵之和，式中 $N$ 用来选择某个样本。\n梯度 $ \\frac{-\\ln{L(w,b)}}{\\sigma_{w_i}} = \\sum^N_{n=1}{-(\\hat{y^n}-f_{w,b}{(x^n)})x_i^n} $ ，其中 $i$ 用来选择数据的某个维度， $n$ 用来选择某个样本， $ N $ 为数据集中样本个数。该式表明，预测值与label相差越大时，参数更新的步幅越大，这符合常理。\n逻辑回归 VS 线性回归 模型 逻辑函数模型比线性回归模型多了一个sigmoid函数。逻辑函数输出是[0,1]，而线性回归的输出是任意值。\n损失函数 逻辑回归模型使用的数据集中label的值必须是0或1，而线性回归模型训练集中label的值是真实值。\n图中的 $\\frac{1}{2}$ 是为了方便求导 。这里有一个问题，为什么逻辑回归模型中不适用Square Error呢？这个问题的答案见下文\n梯度 逻辑回归模型和线性回归模型的梯度公式一样\n为什么逻辑回归模型中不使用Square Error 由上图可知，当label的值为1时，不管预测值是0还是1，梯度都为0，当label值为0时也是这样。\n如下图所示，如果在逻辑回归中使用Square Error，当梯度接近0时，我们无法判断目前与最优解的距离，也就无法调节学习率；并且在大多数时候梯度都是接近0的，收敛速度会很慢。\n判别模型 VS 生成模型 形式对比 逻辑回归是一个判别模型（Discriminative Model），用正态分布描述后验概率（Posterior Probability）则是生成模型（Generative Model）。如果生成模型中公用协方差矩阵，那两个模型/函数集其实是一样的，都是 $ P(C_1|x)=\\sigma(w \\cdot x+b) $ 。因为做了不同的假，即使是使用同一个数据集、同一个模型，找到的函数是不一样的。\n优劣对比 如果现在数据很少，当假设了概率分布以后，就可以需要更少的数据用于训练，受数据影响较小；而判别模型就只根据数据来学习，易受数据影响，需要更多数据 当假设了概率分布后，生成模型受数据影响小，对噪声的鲁棒性更强 对于生成模型来讲，先验的和基于类别的概率（Prors and class-dependent probabilities），即 $ P(C_1) $ 和 $ P(C_2) $ ，可以从不同的来源估计得到。以语音识别为例，如果用生成模型，可能并不需要声音的数据，网上的文本也可以用来估计某段文本出现的概率 多分类（Multi-class Classification） 以3个类别 $C_1、C2和 C3$ 为例，分别对应参数$w_1、b_1、W_2、b_2、W_3、b_3$，即$z_1=w_1 \\cdot x+b_1、z_2=w_2 \\cdot x+b_2、z_3=w_3 \\cdot x+b_3$\nSoftmax 使用softmax（$y_i=\\frac{e_{z_i}}{\\sum^c_{j=1}{e_{z_j}}}$）\nsoftmax公式中为什么要用$e$？这是由原因的/可解释的，可以看下PRML，也可以搜一下最大熵\n最大熵（Maximum Entropy）其实也是一种分类器，和逻辑回归一样，只是从信息论的角度来看\n损失函数 计算预测值$y$和$\\hat y$都是一个向量，即$-\\sum^3_{i=1}{{\\hat y}_i\\ln{y_i}}$\n这时需要使用one-hot编码：如果$x\\in C_1$，则$y=\\begin{bmatrix} 1\\ 0\\ 0\\ \\end{bmatrix}$；如果$x\\in C_1$，则$y=\\begin{bmatrix} 0\\ 1\\ 0\\ \\end{bmatrix}$；如果$x\\in C_1$，则$y=\\begin{bmatrix} 0\\ 0\\ 1\\ \\end{bmatrix}$。\n梯度 和逻辑回归的思路一样。\n逻辑回归的局限性 如下图所示，假如有2个类别，数据集中有4个样本，每个样本有2维特征，将这4个样本画在图上。\n如下图所示，假如用逻辑回归做分类，即$y=\\sigma(z)=\\sigma(w_1\\cdot x_1+w_2\\cdot x_2+b)$，我们找不到一个可以把“蓝色”样本和“红色”样本间隔开的函数。\n假如一定要用逻辑回归，那我们可以怎么办呢？我们可以尝试特征变换（Feature Transformation）。\n特征变换（Feature Transformation） 在上面的例子中，我们并不能找到一个能将蓝色样本和红色样本间隔开的函数。如下图所示，我们可以把原始的数据/特征转换到另外一个空间，在这个新的特征空间中，找到一个函数将“蓝色”样本和“红色”样本间隔开。比如把原始的两维特征变换为$\\begin{bmatrix} 0\\ 0\\ \\end{bmatrix} 和 \\begin{bmatrix} 1\\ 1\\ \\end{bmatrix}$ 的距离，在这个新的特征空间，“蓝色”样本和“红色”样本是可分的。\n但有一个问题是，我们并不一定知道怎么进行特征变换。或者说我们想让机器自己学会特征变换，这可以通过级联逻辑回归模型实现，即把多个逻辑回归模型连接起来，如下图所示。下图中有3个逻辑回归模型，根据颜色称它们为小蓝、小绿和小红。小蓝和小绿的作用是分别将原始的2维特征变换为新的特征$x_1\u0026rsquo;和x_2\u0026rsquo;$，小红的作用是在新的特征空间$\\begin{bmatrix} x_1\u0026rsquo;\\ x_2\u0026rsquo;\\ \\end{bmatrix}$上将样本分类。\n如下图所示，举一个例子。小蓝的功能是（下图左上角），离$(1,0)$越远、离$(0,1)$越近，则$x_1\u0026rsquo;$越大；小蓝的功能是（下图左上角），离$(1,0)$越远、离$(0,1)$越近，则$x_1\u0026rsquo;$越小。小蓝和小绿将特征映射到新的特征空间$\\begin{bmatrix} x_1\u0026rsquo;\\ x_2\u0026rsquo;\\ \\end{bmatrix}$中，结果见下图右下角，然后小红就能找到一个函数将“蓝色”样本和“红色”样本间隔开。\n神经网络（Neural Network） 假如把上例中的一个逻辑回归叫做神经元（Neuron），那我们就形成了一个神经网络。\nROC 在信号检测理论中，接收者操作特征曲线(receiver operating characteristic curve，或者叫ROC曲线)是坐标图式的分析工具，用于 (1) 选择最佳的信号侦测模型、舍弃次佳的模型。 (2) 在同一模型中设定最佳阈值。在做决策时，ROC分析能不受成本／效益的影响，给出客观中立的建议。\nROC曲线首先是由二战中的电子工程师和雷达工程师发明的，用来侦测战场上的敌军载具(飞机、船舰)，也就是信号检测理论。之后很快就被引入了心理学来进行信号的知觉检测。数十年来，ROC分析被用于医学、无线电、生物学、犯罪心理学领域中，而且最近在机器学习(machine learning)和数据挖掘(data mining)领域也得到了很好的发展。\n术语\n阳性(P, positive) 阴性(N, Negative) 真阳性 (TP, true positive) 正确的肯定。又称：命中 (hit) 真阴性 (TN, true negative) 正确的否定。又称：正确拒绝 (correct rejection) 伪阳性 (FP, false positive) 错误的肯定，又称：假警报 (false alarm)，第一型错误伪阴性 (FN, false negative) 错误的否定，又称：未命中 (miss)，第二型错误 真阳性率 (TPR, true positive rate) 又称：命中率 (hit rate)、敏感度(sensitivity) TPR = TP / P = TP / (TP+FN) 伪阳性率(FPR, false positive rate) 又称：错误命中率，假警报率 (false alarm rate) FPR = FP / N = FP / (FP + TN) 准确度 (ACC, accuracy) ACC = (TP + TN) / (P + N) 即：(真阳性+真阴性) / 总样本数真阴性率 (TNR) 又称：特异度 (SPC, specificity) SPC = TN / N = TN / (FP + TN) = 1 - FPR 阳性预测值 (PPV) PPV = TP / (TP + FP) 阴性预测值 (NPV) NPV = TN / (TN + FN) 假发现率 (FDR) FDR = FP / (FP + TP) ","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/li-hongyis-notes/%E5%9B%9B%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B/","summary":"四、分类模型 [toc]\n4.1 分类简介及其与回归的区别 分类模型应用案例（Classification Cases） 信用评分（Credit Scoring） 输入：收入、储蓄、职业、年龄、信用历史等等 输出：是否贷款 医疗诊断（Medical Diagnosis） 输入：现在症状、年龄、性别、病史 输出：哪种疾病 手写文字识别（Handwritten Character Recognition） 输入：文字图片 输出：是哪一个汉字 人脸识别（Face Recognition） 输入：面部图片 输出：是哪个人 把分类当成回归去做 不行\n假设有两个类别，其中类别1的标签为1，类别2的标签为-1，那0就是分界线，大于0就是类别1，小于0就是类别2。但是回归模型会惩罚哪些太正确的样本，如果结果远远大于1，它的分类应该是类别1还是类别2？这时为了降低整体误差，需要调整已经找到的回归函数，就会导致结果的不准确。 假设有多个类别，类别1的标签是1，类别2的标签是2，类别3的标签是3。这样的话，标签间具有2和3相近、3大于2这种本来不存在的数字关系。 理想替代方案（Ideal Alternatives） 模型：模型可以根据特征判断类型，输入是特征，输出是类别 损失函数：预测错误的次数，即$L(f)=\\sum_n{\\sigma(f(x_n) \\neq \\hat{y_n} }$ 。这个函数不可微。 如何找到最好的函数，比如感知机（Perceptron）、支持向量机（SVM） 4.2 分类模型指概率生成模型 贝叶斯公式 $P(A \\cap B) = P(A)P(B|A) = P(B)P(A|B)$ $P(A|B) = \\frac{P(A)P(B|A)}{P(B)}$ 全概率公式 $P(B)=\\sum_{i=1}^{n}{P(A_i)P(B|A_i)}$\n概率生成模型（Probalitity Genetative Model） 理论与定义 假设有两个类别的$C_1和C_2$，要判断对象$x$属于哪个类别，这样把分类问题变成了概率计算问题。\n根据贝叶斯公式（Bayes\u0026rsquo; theorem）和全概率公式（Total Probability Theorem）可以知道，$x$属于类别$C_1$的概率为$P(C_1|x)= \\frac{P(x|C_1)P(C_1)}{P(x)}=\\frac{P(x|C_1)P(C_1)}{P(x|C_1)P(C_1)+P(x|C_2)P(C_2)}$ ，如果$P(C_1|x)\u0026gt;0.5$ 则类别为$C_1$ ，否则类别为$C_2$。 概率生成模型的意思就是可以通过这个模型生成一个$$x$$。具体来讲就是，根据$P(x)=P(x|C_1)P(C_1)+P(x|C_2)P(C_2)$ 计算出$P(x)$，就可以知道 $x$ 的分布进而生成 $x$ 。如果想要计算出$P(x)$，就要根据训练集估计出$P(C_1)$、$P(x|C_1)$、$P(C_2)$、$P(x|C_2)$这四个值。更直观一点地讲，每个类别就是一个多元正态分布，其中多元是因为每个样本有多个维度的特征。 可以根据数据集中属于两个类别的对象的数量计算 $P(C_1)$ 和 $P(C_2)$ 这两个先验概率（Prior Probability）。如果有2个样本属于类别$C_1$ ，4个样本属于类别$C_2$ ，那$P(C_1)= \\frac{1}{3}$、$P(C_2)= \\frac{2}{3}$。 要计算后验概率（Posterior Probability）$P(x|C_1)$ 和 $P(x|C_2)$，可以假设训练集中的各类别样本的特征分别是从某个多元正太分布（多元对应特征的多维）中取样得到的，或者说是假设训练集中各类别样本的特征分别符合某多元正态分布。该正太分布的输入是一个样本的特征 $x$，输出为样本 $x$ 是从这个正太分布取样得到（或者说该样本属于某类别）的概率密度，然后通过积分就可以求得 $P(x|C_1)$ 和 $P(x|C_2)$ 。 正太分布公式为 $f_{\\mu,\\sum{(x)}}=\\frac{1}{(2\\pi)^\\frac{D}{2}} \\frac{1}{|\\sum|^\\frac{1}{2}} {e^{-\\frac{1}{2}(x-\\mu)^T\\sum^{-1}{x-\\mu}}}$ 。正太分布有2个参数，即均值 $\\mu$ （代表正太分布的中心位置）和协方差矩阵（Covariance Matrix）$\\sum$ （代表正态分布的离散程度），计算出均值 $\\mu$ 和协方差 $\\sum$ 即可得到该正态分布。公式中的 $D$ 为多维特征的维度。 实际上从任何一个正态分布中取样都有可能得到训练集中的特征，只是概率不同而已。通过极大值似然估计（Maximum Likelihood Estimate，MLE），我们可以找到取样得到训练集特征的概率最大的那个正态分布，假设其均值和协方差矩阵为 $ \\mu^* $ 和 $ \\sum^* $ 。 根据某正态分布的均值 $\\mu$ 和协方差 $\\sum$ ，可以计算出从该正态分布取样得到训练集的概率。 $ L(\\mu,\\sum) = f_{\\mu,\\sum}{x_1} f_{\\mu,\\sum}{x_2}f_{\\mu,\\sum}{x_3}\u0026hellip;f_{\\mu,\\sum}{x_N} $ ，这就是似然函数（Likelihood Function），其中$N$ 是训练集中某个类别样本的数量。 $\\mu^,\\sum^=\\arg\\max_{\\mu,\\sum}{L(\\mu,\\sum)}$，当然可以求导。直觉：$\\mu^=\\frac{1}{N}\\sum_{i=1}^{N}{x_i}$，$\\sum^ = \\frac{1}{N}\\sum_{i=1}^{N}(x_i-\\mu^*)^2T$ 协方差矩阵共享 每个类别的特征符合一个多元正态分布，每个多元正态分布也有不同的均值和协方差矩阵。让每个类别对应的多元正态分布共享一个协方差矩阵（各个协方差矩阵的加权平均和），公式为 $\\sum = \\frac{N_1}{N_1+N_2}\\sum_1+\\frac{N_2}{N_1+N_2}\\sum_2$，可以减少模型参数，缓解过拟合","title":"四、分类模型.md"},{"content":"五、深度学习 [toc]\n5.1引言 深度学习的历史 1958年：心理学家Rosenblatt提出感知机（Perceptron） 它是一个线性模型。 1969年：有人说感知机是线性模型，具有局限性。 1980年代：多层感知机（Multi-layer Perceptron） 和当今的神经网络是没有本质差别的。 1986年：Hinton提出反向传播算法（Backpropagation） 但是超过3个隐藏层的神经网络，还是训练不出好的结果。 1989年：有人提出一个隐藏层就可以得到任何函数，为什么要多层？ 多层感知机慢慢淡出大家的视野。 2006年：受限玻尔兹曼机初始化（RBM Initialization） Hinton提出用受限玻尔兹曼机做初始化，很多人觉得这是个大突破，但实际上用处并不大。 至少让多层感知机回到大家的视野。 2009年：GPU 2011年：神经网络用于语音识别 2012年：神经网络技术赢得ILSVRC（ImageNet Large Scale Visual Recognition Challenge） 深度学习的三个步骤 和机器学习一样：\n确定模型（Model）/函数集（Function Set），在深度学习中就是定义一个神经网络。 不同的连接会构成多样的网络结构。 确定如何评价函数的好坏 如果是多分类，那和Classification一章中一样，计算每个样本预测结果与Ground Truth的交叉熵，然后求和，即为Loss。 确定如何找到最好的函数 还是Gradient Descent。 神经网络模型对应的函数比较复杂，而反向传播算法（Backpropagation）是一个很有效的计算神经网络梯度的方法。 神经网络的结构 输入层（Input Layer）：实际上就是输入，并不是真正的“层”。 隐藏层（Hidden Layers）：输入层和输出层之间的层，Deep指有很多隐藏层，多少层才算Deep并没有统一标准。可以看成特征提取器（Feature Extractor），作用是代替特征工程（Feature Engineering）。 输出层（Output Layer）：最后一层，可以看成分类器 全连接前反馈神经网络 即Fully Connected Feedforward Neural Network，FFN。\n全连接是指每个神经元与上一层的所有神经元相连。 前馈神经网络（FNN，Feedforward Neural Network）是指各神经元分层排列，每个神经元只与前一层的神经元相连，接收前一层的输出，并输出给下一层，各层间没有反馈。 一些网络 其中Residual Net并不是一般的全连接前馈神经网络\n网络结构 提出年份 层数 ImageNet错误率 AlexNet 2012 8 16.4% 2014 19 7.3% VGGNet 2014 22 6.7% Residual Net 2015 152 3.57% 机器学习和深度学习面对的不同问题 在机器学习中，人类需要手工做特征工程（Feature Engineering），人类需要思考如何提取特征。 有了深度学习以后，人类可以不做特征工程，但也遇到了新的问题：人类需要设计合适的网络结构。 这两个问题哪个更容易呢？可能后者更容易些，比如在图像识别、语音识别任务中，人类可能并不知道自己是如何识别图像和语音的，就无法通过符号主义进行特征工程。\n关于深度学习的一些疑问 虽然深度学习的的准确度很高，但是它使用的参数更多，参数多、准确度高也是很正常的事，所以有什么特别之处呢？ 只用一个神经元足够多的隐藏层，这个模型就包括了任意函数，那为什么不这么做而非要深度呢？为什么要是Deep而不是Fat呢？ 如何设计神经网络的结构？ 多少层？每一层有多少个神经元？ 只能凭经验（实验结果）和直觉，当然可以让机器自己去找网络结构，即网络架构搜索（NAS，Network Architecture Search）。 必须用全连接前馈神经网络吗？ 不是。比如卷积神经网络（Convolutional Neural Networks, CNN）。 5.2 神经网络为什么要是深度的 深度的原因 矮胖的神经网络和高瘦的神经网络，假设它们参数量相同，哪一个更好呢？ 2011年有一个实验，证明在参数量相当的情况下，高瘦的神经网络（即深度神经网络）的准确度更高，因为深度可以实现模块化。 只用一个神经元足够多的隐藏层，这个模型就包括了任意函数，那为什么不这么做呢？ 这样确实可以包括任意函数，但实现的效率不高。 相关网址，也可以通过谷歌等找找其它答案。 “深度”的好处 模块化（Modularization） 就像写程序一样，我们不能把所有代码写在main函数里，而需要通过定义函数等方式将程序模块化。 如下图所示，假如要做一个图片的四分类，两个维度分别是头发长短和性别，如果使用矮胖的神经网络会遇到一个问题，就是短头发的女生样本和长头发的男生样本会比较少，那这两个类别的分类器就会比较差。\n如下图所示，我们可以先定义各属性的分类器（Classifiers for the attributes），即先定义性别和头发长短的分类器，然后再做四分类。这样第一层分类器就不会遇到样本少的问题，第二层的分类器也容易训练，整体上也需要更少的训练集。\n在深度神经网络中，每层网络都可以作为下一层网络使用的一个模块，并且这个模块化是通过机器学习自动得到的。 常有“人工智能=机器学习+大数据”的说法，但实际上“深度”使得需要的数据更少，如果数据集无限大，根本就不需要机器学习，只要去数据库里拿就好了。深度学习也并不是通过大量参数暴力拟合出一个模型，反而是在通过模块化有效利用数据。 这里只是一个图像分类的例子，“深度”产生的模块化在语音识别任务中也有体现，与逻辑电路也有相似的问题和结论，具体可以看**李宏毅视频**。\n端到端学习（End-to-end Learning） 深度神经网络模型就像是把一个个函数串接在一起，每个函数负责某个功能，每个函数负责什么功能是通过机器学习根据数据自动确定的。**李宏毅视频**中有讲这一点在语音识别、CV任务中的体现。\n处理复杂任务 有时类似的输入要输出差别很大的结果，比如白色的狗和北极熊看起来差不多，但分类结果非常不同；有时差别很大的输入要输出相同的结果，比如火车正面和侧面的图片都应该被分类成火车。 只有一个隐藏层的网络是无法处理这种任务的。**李宏毅视频**中有讲这一点在语音识别、CV任务中的体现。\n其它 Do deep nets really need to be deep? **李宏毅视频**里也还有很多关于“深度”的探讨。\n5.3 神经网络中的反向传播算法 链式法则（Chain Rule） $\\begin{cases} z=h(y)\\y=g(x)\\end{cases} \\rightarrow \\frac{dz}{dx}=\\frac{dz}{dy} \\frac{dy}{dx}$ $\\begin{cases} z=k(x,y)\\x=g(s)\\y=h(s)\\end{cases} \\rightarrow \\frac{dz}{ds}=\\frac{dz}{dx} \\frac{dx}{ds}+\\frac{dz}{dy} \\frac{dy}{ds}$ 反向传播算法（Backpropagation） 变量定义 如下图所示，设神经网络输入为 $x_n$ ，该输入对应的 label 是 $\\hat y^n$ ，神经网络的参数是 $\\theta$ ，神经网络的输出是 $\\hat y^n$ 。整个神经网络的Loss为 $L(\\theta)=\\sum^N_{n=1}{C^n(\\theta)}$ 。假设 $\\theta$ 中有一个参数 $w$ ，那 $\\frac{\\partial{L(\\theta)}}{\\partial{w}}=\\sum^N_{n=1}{\\frac{\\partial{C^n(\\theta)}}{\\partial{w}}}$ 。\n一个神经元的情况 如下图所示， $z=x_1w_1+x_2w_2+b$ ，根据链式法则可知 $\\frac{\\partial{C}}{\\partial{w}}=\\frac{\\partial{z}}{\\partial{w}}\\frac{\\partial{C}}{\\partial{z}}$ ，其中为所有参数 $w$ 计算 $\\frac{\\partial{z}}{\\partial{w}}$ 是 Forward Pass，为所有激活函数的输入 z 计算 $\\frac{\\partial{C}}{\\partial{z}}$ 是 Backward Pass。\nForward Pass Forward Pass 是为所有参数 $w$ 计算 $\\frac{\\partial{z}}{\\partial{w}}$ ，它的方向是从钱往后算的，所以叫做 Forward Pass。一一个神经元为例，因为 $z=x_1w_1+x_2w_2+b$ ，所以 $\\frac{\\partial{z}}{\\partial{w_1} }= x_1 $ ， $\\frac{\\partial{z}}{\\partial{w_2} }= x_2 $ ，如下图所示。\n规律是：该权重乘以的那个输入的值。所以当有多个神经元时，如下图所示。\nBackward Pass Backward Pass 是为所有激活函数的输入 z 计算 $\\frac{\\partial{C}}{\\partial{z}}$ ，它的方向是从后往前算的，要先算出输出层的 $\\frac{\\partial{C}}{\\partial{z\u0026rsquo;}}$ ，再往前计算它神经元的 $\\frac{\\partial{C}}{\\partial{z}}$ ，所以叫做 Backword Pass。\n如上图所示，令 $a=\\sigma(z)$ ，根据链式法则，可知 $\\frac{\\partial{C}}{\\partial{z}}=\\frac{\\partial{C}}{\\partial{a}}$ ，其中 $\\frac{\\partial{C}}{\\partial{a}}=\\sigma\u0026rsquo;(z)$ 是一个常数，因为在 Forward Pass 时 z 的值就已经确定了，而 $\\frac{\\partial{C}}{\\partial{a}}=\\frac{\\partial{z}\u0026rsquo;}{\\partial{a}}\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;}+\\frac{\\partial{z}\u0026rsquo;\u0026rsquo;}{\\partial{a}}\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;\u0026rsquo;}=w_3\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;}+w_4\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;\u0026rsquo;}$ ，所以 $ \\frac{\\partial{C}}{\\partial{z}}=\\sigma\u0026rsquo;(z)[w_3\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;}+w_4\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;\u0026rsquo;}]$ 。\n对于式子 $\\frac{\\partial{C}}{\\partial{z}}=\\sigma\u0026rsquo;(z)[w_3\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;}+w_4\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;\u0026rsquo;}]$ ，我们可以发现两点：\n1、$\\frac{\\partial{C}}{\\partial{z}}$ 的计算式是递归的，因为在计算 $\\frac{\\partial{C}}{\\partial{z}}$ 的时候需要计算 $\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;}$ 和 $\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;\u0026rsquo;}$ 。如下图所示，输出层的 $\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;}$ 和 $\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;\u0026rsquo;}$ 是容易计算的。\n2、$\\frac{\\partial{C}}{\\partial{z}}$ 的计算式 $\\frac{\\partial{C}}{\\partial{z}}=\\sigma\u0026rsquo;(z)[w_3\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;}+w_4\\frac{\\partial{C}}{\\partial{z}\u0026rsquo;\u0026rsquo;}]$ 是一个神经元的形式。如下图所示，只不过没有嵌套 sigmoid 函数，而是乘一个常数 $\\sigma\u0026rsquo;(z)$ ，每一个 $\\frac{\\partial{C}}{\\partial{z}}$ 都是一个神经元的形式，所以可以通过神经网络计算 $\\frac{\\partial{C}}{\\partial{z}}$ 。\n总结 通过Forward Pass ，为所有参数 $w$ 计算 $\\frac{\\partial{z}}{\\partial{w}}$ ； 通过 Backward Pass ，为所有激活函数的输入 z 计算 $\\frac{\\partial{C}}{\\partial{z}}$ ； 最后通过 $\\frac{\\partial{C}}{\\partial{w}}=\\frac{\\partial{z}}{\\partial{w}}\\frac{\\partial{C}}{\\partial{z}}$ ，也就求出了梯度。 ","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/li-hongyis-notes/%E4%BA%94%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/","summary":"五、深度学习 [toc]\n5.1引言 深度学习的历史 1958年：心理学家Rosenblatt提出感知机（Perceptron） 它是一个线性模型。 1969年：有人说感知机是线性模型，具有局限性。 1980年代：多层感知机（Multi-layer Perceptron） 和当今的神经网络是没有本质差别的。 1986年：Hinton提出反向传播算法（Backpropagation） 但是超过3个隐藏层的神经网络，还是训练不出好的结果。 1989年：有人提出一个隐藏层就可以得到任何函数，为什么要多层？ 多层感知机慢慢淡出大家的视野。 2006年：受限玻尔兹曼机初始化（RBM Initialization） Hinton提出用受限玻尔兹曼机做初始化，很多人觉得这是个大突破，但实际上用处并不大。 至少让多层感知机回到大家的视野。 2009年：GPU 2011年：神经网络用于语音识别 2012年：神经网络技术赢得ILSVRC（ImageNet Large Scale Visual Recognition Challenge） 深度学习的三个步骤 和机器学习一样：\n确定模型（Model）/函数集（Function Set），在深度学习中就是定义一个神经网络。 不同的连接会构成多样的网络结构。 确定如何评价函数的好坏 如果是多分类，那和Classification一章中一样，计算每个样本预测结果与Ground Truth的交叉熵，然后求和，即为Loss。 确定如何找到最好的函数 还是Gradient Descent。 神经网络模型对应的函数比较复杂，而反向传播算法（Backpropagation）是一个很有效的计算神经网络梯度的方法。 神经网络的结构 输入层（Input Layer）：实际上就是输入，并不是真正的“层”。 隐藏层（Hidden Layers）：输入层和输出层之间的层，Deep指有很多隐藏层，多少层才算Deep并没有统一标准。可以看成特征提取器（Feature Extractor），作用是代替特征工程（Feature Engineering）。 输出层（Output Layer）：最后一层，可以看成分类器 全连接前反馈神经网络 即Fully Connected Feedforward Neural Network，FFN。\n全连接是指每个神经元与上一层的所有神经元相连。 前馈神经网络（FNN，Feedforward Neural Network）是指各神经元分层排列，每个神经元只与前一层的神经元相连，接收前一层的输出，并输出给下一层，各层间没有反馈。 一些网络 其中Residual Net并不是一般的全连接前馈神经网络\n网络结构 提出年份 层数 ImageNet错误率 AlexNet 2012 8 16.4% 2014 19 7.","title":"五、深度学习.md"},{"content":"李宏毅机器学习笔记 [toc]\n一、机器学习概论 机器学习是什么 机器学习就是让机器能自动找到一个函数function\n语音识别（Speech Recognition）：输入是音频，输出是音频对应的文字 图像分类：输入是图片，输出是类别（比如猫、狗） AlphaGo下围棋：输入是当前棋盘的状态，输出是下一步落棋的位置 对话/问答系统 机器能够找到哪些函数 为解决不同的问题、完成不同的任务，需要找到不同的函数，那机器学习能找到哪些函数呢？\n回归（Regression）：输出是一个连续的数值、标量，比如PM2.5预测 分类（Classification）：输出是一个离散的值。 二分类（Binary Classification）的输出就是0或1、Yes或No、\u0026hellip;，比如文本情感分析的输出可以是正面和负面 多分类（Multi-Category Classification）的输出就是[1,2,3,\u0026hellip;,N]，比如图像分类里判断一张图片是猫还是狗还是杯子 生成（Generation）：很多教科书吧机器学习划分为回归问题和分类问题，但其实不止这两种问题，比如生成（Generation）。生成是指让机器学习如何创造/生成，比如生成文本、图片等。 如何告诉机器我们希望找到什么函数 我们该如何为机器提供学习资料？\n有监督学习（Supervised Learning）：可以把有监督学习种的“监督”理解为标签（Label），即数据集种不仅包括特征还包括标签。有了标签，我们就可以评价一个函数的好坏，进而优化这个函数。使用Loss判断函数的好坏，Loss越小，函数越好。 强化学习（Reinforcement Learning）：原始的AlphaGo是先通过有监督学习优化到一定程度，然后用强化学习继续优化。新版本的AlphaGo是完全通过强化学习实现的，优于原始的AlphaGo。 无监督学习（Unsupervised Learning）：只给机器提供数据特征，但不提供数据标签。那机器能学到什么呢？ 下面以让机器学习下围棋为例：有监督学习VS强化学习\n有监督学习：函数的输入（数据特征）就是期盼状态，函数的输出（数据标签）就是下一步落棋的位置。此时，我们需要为机器提供的数据就类似棋谱（如果现在棋局是这样，那下一步怎么落棋最好），但其实人类不一定知道怎么落棋最好。 强化学习：让机器跟自己、别人下棋，把结果（赢或输）作为Reward，引导机器学习如何下棋。如果它赢了，那它就知道这一盘里有几步棋下得好，但不知道是哪几步；如果它输了，它就知道这一盘里有几步棋下得不好，但不知道是哪几步。 机器如何找出我们想找到的函数 我们要给定函数形式/范围（模型），比如假定函数是线性模型、神经网络等等。模型就是一个函数集，模型的参数确定以后，才得到一个函数。 找到更好的函数： 使用梯度下降（Gradient Descent），找到更好的函数。 前沿研究 AI的可解释性（Explainable AI）：比如，机器为什么认为这张图片里有一只猫？ 对抗攻击（Adversarial Attack）：对输入故意添加一些人无法察觉的细微的干扰，导致模型以高置信度给出一个错误的输出。 模型压缩（Network Compression）： 把模型压缩以减少模型对计算资源消耗。 异常检测（Anomaly Detection）：使机器知道它遇到了自己不知道的东西。 迁移学习（Transfer Learning/Domain Adversarial Learning）： 一个模型已经学到了一些知识，将这些知识应用到另一个任务中。 元学习（Meta Learning）： 让机器学习如何学习。机器学习是我们教机器学习某种知识，元学习是我们教机器如何学习。 终身学习（Life-Long Learning）：让机器终身学习，学习完任务1、再继续学任务2、…… 机器学习的三个步骤 确定模型（Model）/函数集（Function Set） 确定如何评价函数的好坏 确定如何找到最好的函数 ","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/li-hongyis-notes/%E4%B8%80%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%AE%BA/","summary":"李宏毅机器学习笔记 [toc]\n一、机器学习概论 机器学习是什么 机器学习就是让机器能自动找到一个函数function\n语音识别（Speech Recognition）：输入是音频，输出是音频对应的文字 图像分类：输入是图片，输出是类别（比如猫、狗） AlphaGo下围棋：输入是当前棋盘的状态，输出是下一步落棋的位置 对话/问答系统 机器能够找到哪些函数 为解决不同的问题、完成不同的任务，需要找到不同的函数，那机器学习能找到哪些函数呢？\n回归（Regression）：输出是一个连续的数值、标量，比如PM2.5预测 分类（Classification）：输出是一个离散的值。 二分类（Binary Classification）的输出就是0或1、Yes或No、\u0026hellip;，比如文本情感分析的输出可以是正面和负面 多分类（Multi-Category Classification）的输出就是[1,2,3,\u0026hellip;,N]，比如图像分类里判断一张图片是猫还是狗还是杯子 生成（Generation）：很多教科书吧机器学习划分为回归问题和分类问题，但其实不止这两种问题，比如生成（Generation）。生成是指让机器学习如何创造/生成，比如生成文本、图片等。 如何告诉机器我们希望找到什么函数 我们该如何为机器提供学习资料？\n有监督学习（Supervised Learning）：可以把有监督学习种的“监督”理解为标签（Label），即数据集种不仅包括特征还包括标签。有了标签，我们就可以评价一个函数的好坏，进而优化这个函数。使用Loss判断函数的好坏，Loss越小，函数越好。 强化学习（Reinforcement Learning）：原始的AlphaGo是先通过有监督学习优化到一定程度，然后用强化学习继续优化。新版本的AlphaGo是完全通过强化学习实现的，优于原始的AlphaGo。 无监督学习（Unsupervised Learning）：只给机器提供数据特征，但不提供数据标签。那机器能学到什么呢？ 下面以让机器学习下围棋为例：有监督学习VS强化学习\n有监督学习：函数的输入（数据特征）就是期盼状态，函数的输出（数据标签）就是下一步落棋的位置。此时，我们需要为机器提供的数据就类似棋谱（如果现在棋局是这样，那下一步怎么落棋最好），但其实人类不一定知道怎么落棋最好。 强化学习：让机器跟自己、别人下棋，把结果（赢或输）作为Reward，引导机器学习如何下棋。如果它赢了，那它就知道这一盘里有几步棋下得好，但不知道是哪几步；如果它输了，它就知道这一盘里有几步棋下得不好，但不知道是哪几步。 机器如何找出我们想找到的函数 我们要给定函数形式/范围（模型），比如假定函数是线性模型、神经网络等等。模型就是一个函数集，模型的参数确定以后，才得到一个函数。 找到更好的函数： 使用梯度下降（Gradient Descent），找到更好的函数。 前沿研究 AI的可解释性（Explainable AI）：比如，机器为什么认为这张图片里有一只猫？ 对抗攻击（Adversarial Attack）：对输入故意添加一些人无法察觉的细微的干扰，导致模型以高置信度给出一个错误的输出。 模型压缩（Network Compression）： 把模型压缩以减少模型对计算资源消耗。 异常检测（Anomaly Detection）：使机器知道它遇到了自己不知道的东西。 迁移学习（Transfer Learning/Domain Adversarial Learning）： 一个模型已经学到了一些知识，将这些知识应用到另一个任务中。 元学习（Meta Learning）： 让机器学习如何学习。机器学习是我们教机器学习某种知识，元学习是我们教机器如何学习。 终身学习（Life-Long Learning）：让机器终身学习，学习完任务1、再继续学任务2、…… 机器学习的三个步骤 确定模型（Model）/函数集（Function Set） 确定如何评价函数的好坏 确定如何找到最好的函数 ","title":"一、机器学习概论.md"},{"content":"cluster 模块 cluster模块用于组建 Node.js 应用的集群。\ncluster.isMaster属性表示当前进程是否为主进程。\n1 2 const cluster = require(\u0026#39;cluster\u0026#39;); const isMaster = cluster.isMaster; cluster.fork()方法复制当前进程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 const cluster = require(\u0026#39;cluster\u0026#39;); const { cpus } = require(\u0026#39;os\u0026#39;); const numWorkers = cpus().length; const isMaster = cluster.isMaster; if (isMaster) { process.stdout.write(\u0026#39;master process\u0026#39;); const workers = []; for(let i = 0; i \u0026lt; numWorkers; i++) { workers.push(cluster.fork()); } } else { process.stdout.write(\u0026#39;worker process\u0026#39;); } 上面代码按照 CPU 内核的数目新建 Worker 进程。\n主线程可以负责监听整个集群的运行情况。我们使用cluster.on()方法监听集群的事件。online事件在 Worker 进程上线时触发，exit事件在 Worker 进程下线时触发。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 if (isMaster) { log(`Forking ${numWorkers} workers`); const workers = []; for(let i = 0; i \u0026lt; numWorkers; i++) { workers.push(cluster.fork()); } cluster.on(\u0026#39;online\u0026#39;, (worker) =\u0026gt; log(`Worker ${worker.process.pid} is online`)); cluster.on(\u0026#39;exit\u0026#39;, (worker, exitCode) =\u0026gt; { log(`Worker ${worker.process.id} exited with code ${exitCode}`); log(`Starting a new worker`); cluster.fork(); }) } 上面代码中，主进程如果发现一个 Worker 进程下线，就再新建一个 Worker 进程。\n至于每个 Worker 进程可以指定运行的任务。\n1 2 3 4 5 if (isMaster) { // ... } else { // 应用的内容 } 参考链接 How to scale your Node.js server using clustering, Michele Riva ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/stdlib/cluster/","summary":"cluster 模块 cluster模块用于组建 Node.js 应用的集群。\ncluster.isMaster属性表示当前进程是否为主进程。\n1 2 const cluster = require(\u0026#39;cluster\u0026#39;); const isMaster = cluster.isMaster; cluster.fork()方法复制当前进程。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 const cluster = require(\u0026#39;cluster\u0026#39;); const { cpus } = require(\u0026#39;os\u0026#39;); const numWorkers = cpus().length; const isMaster = cluster.isMaster; if (isMaster) { process.stdout.write(\u0026#39;master process\u0026#39;); const workers = []; for(let i = 0; i \u0026lt; numWorkers; i++) { workers.push(cluster.fork()); } } else { process.","title":"cluster.md"},{"content":"events 模块 Node 通过 events 模块提供事件，形成模块之间的通信机制，消除模块与模块的强耦合。\n概述 events模块提供一个构造函数，可以用来生成事件发生器的实例。\n1 2 const EventEmitter = require(\u0026#39;events\u0026#39;); const emitter = new EventEmitter(); 上面代码中，emitter就是事件发生器的实例。\nemit()方法用于触发事件。\n1 emitter.emit(\u0026#39;user-registered\u0026#39;, user); 上面代码触发了user-registered事件，第二个参数user是事件传递的数据。\non()方法用于监听事件。\n1 2 3 emitter.on(\u0026#39;user-registered\u0026#39;, (user) =\u0026gt; { console.log(\u0026#39;event has occured\u0026#39;); }); 注意，emit()方法和on()方法都是同步的，请看下面的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 emitter.on(\u0026#39;someEvent\u0026#39;, function () { console.log(\u0026#39;event has occured\u0026#39;); }); function f() { console.log(\u0026#39;start\u0026#39;); emitter.emit(\u0026#39;someEvent\u0026#39;); console.log(\u0026#39;end\u0026#39;); } f() // start // event has occured // end 上面代码中，emit()方法执行以后，on()方法会立刻执行。只有等到on()方法执行结束以后，emit()后面的方法才会继续执行。\n事件接口的部署 事件接口可以部署在任意对象上，使得这些对象也能订阅和发布消息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; function Dog(name) { this.name = name; } Dog.prototype.__proto__ = EventEmitter.prototype; // 另一种写法 // Dog.prototype = Object.create(EventEmitter.prototype); var simon = new Dog(\u0026#39;simon\u0026#39;); simon.on(\u0026#39;bark\u0026#39;, function () { console.log(this.name + \u0026#39; barked\u0026#39;); }); setInterval(function () { simon.emit(\u0026#39;bark\u0026#39;); }, 500); 上面代码新建了一个构造函数Dog，然后让其继承EventEmitter，因此Dog就拥有了EventEmitter的接口。最后，为Dog的实例指定bark事件的监听函数，再使用EventEmitter的emit方法，触发bark事件。\nNode 内置模块util的inherits方法，提供了另一种继承 Event Emitter 接口的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 var util = require(\u0026#39;util\u0026#39;); var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; var Radio = function (station) { var self = this; setTimeout(function() { self.emit(\u0026#39;open\u0026#39;, station); }, 0); setTimeout(function() { self.emit(\u0026#39;close\u0026#39;, station); }, 5000); this.on(\u0026#39;newListener\u0026#39;, function(listener) { console.log(\u0026#39;Event Listener: \u0026#39; + listener); }); }; util.inherits(Radio, EventEmitter); module.exports = Radio; 上面代码中，Radio是一个构造函数，它的实例继承了EventEmitter接口。下面是使用这个模块的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 var Radio = require(\u0026#39;./radio.js\u0026#39;); var station = { freq: \u0026#39;80.16\u0026#39;, name: \u0026#39;Rock N Roll Radio\u0026#39;, }; var radio = new Radio(station); radio.on(\u0026#39;open\u0026#39;, function(station) { console.log(\u0026#39;\u0026#34;%s\u0026#34; FM %s 打开\u0026#39;, station.name, station.freq); console.log(\u0026#39;♬ ♫♬\u0026#39;); }); radio.on(\u0026#39;close\u0026#39;, function(station) { console.log(\u0026#39;\u0026#34;%s\u0026#34; FM %s 关闭\u0026#39;, station.name, station.freq); }); Event Emitter 的实例方法 Event Emitter 的实例方法如下。\nemitter.on(name, f) 对事件name指定监听函数f emitter.addListener(name, f) addListener是on方法的别名 emitter.once(name, f) 与on方法类似，但是监听函数f是一次性的，使用后自动移除 emitter.listeners(name) 返回一个数组，成员是事件name所有监听函数 emitter.removeListener(name, f) 移除事件name的监听函数f emitter.removeAllListeners(name) 移除事件name的所有监听函数 emit() EventEmitter实例对象的emit方法，用来触发事件。它的第一个参数是事件名称，其余参数都会依次传入回调函数。\n1 2 3 4 5 6 7 8 9 10 var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; var myEmitter = new EventEmitter(); var connection = function (id) { console.log(\u0026#39;client id: \u0026#39; + id); }; myEmitter.on(\u0026#39;connection\u0026#39;, connection); myEmitter.emit(\u0026#39;connection\u0026#39;, 6); // client id: 6 once() 该方法类似于on方法，但是回调函数只触发一次。\n1 2 3 4 5 6 7 8 9 10 var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; var myEmitter = new EventEmitter; myEmitter.once(\u0026#39;message\u0026#39;, function(msg){ console.log(\u0026#39;message: \u0026#39; + msg); }); myEmitter.emit(\u0026#39;message\u0026#39;, \u0026#39;this is the first message\u0026#39;); myEmitter.emit(\u0026#39;message\u0026#39;, \u0026#39;this is the second message\u0026#39;); myEmitter.emit(\u0026#39;message\u0026#39;, \u0026#39;welcome to nodejs\u0026#39;); 上面代码触发了三次message事件，但是回调函数只会在第一次调用时运行。\n下面代码指定，一旦服务器连通，只调用一次的回调函数。\n{% highlight javascript %}\nserver.once(\u0026lsquo;connection\u0026rsquo;, function (stream) { console.log(\u0026lsquo;Ah, we have our first user!\u0026rsquo;); });\n{% endhighlight %}\n该方法返回一个EventEmitter对象，因此可以链式加载监听函数。\nremoveListener() 该方法用于移除回调函数。它接受两个参数，第一个是事件名称，第二个是回调函数名称。这就是说，不能用于移除匿名函数。\n1 2 3 4 5 6 7 8 9 10 11 12 var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; var emitter = new EventEmitter; emitter.on(\u0026#39;message\u0026#39;, console.log); setInterval(function(){ emitter.emit(\u0026#39;message\u0026#39;, \u0026#39;foo bar\u0026#39;); }, 300); setTimeout(function(){ emitter.removeListener(\u0026#39;message\u0026#39;, console.log); }, 1000); 上面代码每300毫秒触发一次message事件，直到1000毫秒后取消监听。\n另一个例子是使用removeListener方法模拟once方法。\n1 2 3 4 5 6 7 8 9 var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; var emitter = new EventEmitter; function onlyOnce () { console.log(\u0026#34;You\u0026#39;ll never see this again\u0026#34;); emitter.removeListener(\u0026#34;firstConnection\u0026#34;, onlyOnce); } emitter.on(\u0026#34;firstConnection\u0026#34;, onlyOnce); setMaxListeners() Node默认允许同一个事件最多可以指定10个回调函数。\n1 2 3 emitter.on(\u0026#39;someEvent\u0026#39;, function () { console.log(\u0026#39;event 1\u0026#39;); }); emitter.on(\u0026#39;someEvent\u0026#39;, function () { console.log(\u0026#39;event 2\u0026#39;); }); emitter.on(\u0026#39;someEvent\u0026#39;, function () { console.log(\u0026#39;event 3\u0026#39;); }); 超过10个回调函数，会发出一个警告。这个门槛值可以通过setMaxListeners方法改变。\n1 emitter.setMaxListeners(20); removeAllListeners() 该方法用于移除某个事件的所有回调函数。\n1 2 3 4 5 6 var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; var emitter = new EventEmitter; // some code here emitter.removeAllListeners(\u0026#34;firstConnection\u0026#34;); 如果不带参数，则表示移除所有事件的所有回调函数。\n{% highlight javascript %}\nemitter.removeAllListeners();\n{% endhighlight %}\nlisteners() listeners方法接受一个事件名称作为参数，返回该事件所有回调函数组成的数组。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; var ee = new EventEmitter; function onlyOnce () { console.log(ee.listeners(\u0026#34;firstConnection\u0026#34;)); ee.removeListener(\u0026#34;firstConnection\u0026#34;, onlyOnce); console.log(ee.listeners(\u0026#34;firstConnection\u0026#34;)); } ee.on(\u0026#34;firstConnection\u0026#34;, onlyOnce) ee.emit(\u0026#34;firstConnection\u0026#34;); ee.emit(\u0026#34;firstConnection\u0026#34;); // [ [Function: onlyOnce] ] // [] 上面代码显示两次回调函数组成的数组，第一次只有一个回调函数onlyOnce，第二次是一个空数组，因为removeListener方法取消了回调函数。\n错误捕获 事件处理过程中抛出的错误，可以使用try...catch捕获。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 var EventEmitter = require(\u0026#39;events\u0026#39;).EventEmitter; var emitter = new EventEmitter(); emitter.on(\u0026#39;beep\u0026#39;, function () { console.log(\u0026#39;beep\u0026#39;); }); emitter.on(\u0026#39;beep\u0026#39;, function () { throw Error(\u0026#39;oops!\u0026#39;); }); emitter.on(\u0026#39;beep\u0026#39;, function () { console.log(\u0026#39;beep again\u0026#39;); }); console.log(\u0026#39;before emit\u0026#39;); try { emitter.emit(\u0026#39;beep\u0026#39;); } catch(err) { console.error(\u0026#39;caught while emitting:\u0026#39;, err.message); } console.log(\u0026#39;after emit\u0026#39;); 上面的代码，beep一共绑定了三个监听函数。其中，第二个监听函数会抛出错误。执行上面的代码，会得到下面的结果。\n1 2 3 4 before emit beep caught while emitting: oops! after emit 可以看到，第二个监听函数抛出的错误被try...catch代码块捕获了。一旦被捕获，该事件后面的监听函数都不会再执行了。\n如果不使用try...catch，可以让进程监听uncaughtException事件。\n1 2 3 4 5 6 7 8 9 10 process.on(\u0026#39;uncaughtException\u0026#39;, function (err) { console.error(\u0026#39;uncaught exception:\u0026#39;, err.stack || err); // 关闭资源 closeEverything(function(err) { if (err) console.error(\u0026#39;Error while closing everything:\u0026#39;, err.stack || err); // 退出进程 process.exit(1); }); }); 事件类型 Events模块默认支持两个事件。\nnewListener事件：添加新的回调函数时触发。 removeListener事件：移除回调时触发。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 ee.on(\u0026#34;newListener\u0026#34;, function (evtName) { console.log(\u0026#34;New Listener: \u0026#34; + evtName); }); ee.on(\u0026#34;removeListener\u0026#34;, function (evtName) { console.log(\u0026#34;Removed Listener: \u0026#34; + evtName); }); function foo() {} ee.on(\u0026#34;save-user\u0026#34;, foo); ee.removeListener(\u0026#34;save-user\u0026#34;, foo); // New Listener: removeListener // New Listener: save-user // Removed Listener: save-user 上面代码会触发两次newListener事件，以及一次removeListener事件。\n参考链接 Hage Yaapa, Node.js EventEmitter Tutorial ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/stdlib/events/","summary":"events 模块 Node 通过 events 模块提供事件，形成模块之间的通信机制，消除模块与模块的强耦合。\n概述 events模块提供一个构造函数，可以用来生成事件发生器的实例。\n1 2 const EventEmitter = require(\u0026#39;events\u0026#39;); const emitter = new EventEmitter(); 上面代码中，emitter就是事件发生器的实例。\nemit()方法用于触发事件。\n1 emitter.emit(\u0026#39;user-registered\u0026#39;, user); 上面代码触发了user-registered事件，第二个参数user是事件传递的数据。\non()方法用于监听事件。\n1 2 3 emitter.on(\u0026#39;user-registered\u0026#39;, (user) =\u0026gt; { console.log(\u0026#39;event has occured\u0026#39;); }); 注意，emit()方法和on()方法都是同步的，请看下面的例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 emitter.on(\u0026#39;someEvent\u0026#39;, function () { console.log(\u0026#39;event has occured\u0026#39;); }); function f() { console.log(\u0026#39;start\u0026#39;); emitter.emit(\u0026#39;someEvent\u0026#39;); console.log(\u0026#39;end\u0026#39;); } f() // start // event has occured // end 上面代码中，emit()方法执行以后，on()方法会立刻执行。只有等到on()方法执行结束以后，emit()后面的方法才会继续执行。","title":"events.md"},{"content":"http 模块 http模块用于 HTTP 通信。\nhttp.Server http.Server属性指向一个类，表示 Web 服务器实例。\n这个类继承了net.Server，而net.Server继承了 EventEmitter 接口，因此可以使用server.on()方法监听事情。最重要的一个事件是request，表示收到 HTTP 请求。\n1 2 3 server.on(\u0026#39;request\u0026#39;, (request, response) =\u0026gt; { response.end(\u0026#39;Hello, world!\u0026#39;); }); server.listen()方法用于启动 Web 服务。这个方法需要指定监听的端口，以及一个回调函数（启动后要做什么）。\n1 2 3 server.listen(PORT, () =\u0026gt; { console.log(`starting server at port ${PORT}`); }); http.createServer() http.createServer()方法用于创建一个 Web 服务器，它的返回值就是一个http.Server实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 const { createServer } = require(\u0026#39;http\u0026#39;); // 指定端口 const PORT = process.env.PORT || 8080; const server = createServer(); server.on(\u0026#39;request\u0026#39;, (request, response) =\u0026gt; { response.end(\u0026#39;Hello, world!\u0026#39;); }); server.listen(PORT, () =\u0026gt; { console.log(`starting server at port ${PORT}`); }); request事件的回调函数，可以作为createServer()方法的参数。因此，上面的代码也可以写成下面的样子。\n1 2 3 4 5 6 7 8 9 const { createServer } = require(\u0026#39;http\u0026#39;); const PORT = process.env.PORT || 8080; const server = createServer((request, response) =\u0026gt; { response.end(\u0026#39;Hello, world!\u0026#39;); }).listen(PORT, () =\u0026gt; { console.log(`starting server at port ${PORT}`); }); response 对象 HTTP 请求和回应都是数据流（stream），request是只读数据流，response是可写数据流。\nresponse.write()方法表示依次向 HTTP 回应写入内容。\nresponse.end()方法表示写入数据以后，关闭response数据流。\n1 2 3 4 5 6 7 8 9 const { createServer } = require(\u0026#39;http\u0026#39;); createServer((request, response) =\u0026gt; { // 等同于 response.end(\u0026#39;Hello, world!\u0026#39;) response.write(\u0026#39;Hello\u0026#39;); response.write(\u0026#39;, \u0026#39;); response.write(\u0026#39;World!\u0026#39;); response.end(); }).listen(8080); 注意，response.end()是必需的，而且必须写在最后，否则 Node 不会关闭请求。\n如果要向客户端发送文件，也可以写成数据流。\n1 2 3 4 5 6 const { createReadStream } = require(\u0026#39;fs\u0026#39;); const { createServer } = require(\u0026#39;http\u0026#39;); createServer((request, response) =\u0026gt; { createReadStream(__filename).pipe(response); }).listen(8080); 上面代码会将这个脚本代码，发送给客户端。这时不用写response.end()方法，因为pipe()方法会在发送结束后，自动关闭数据流。\nresponse.setHeader()方法用于设置返回的头信息。\n1 2 3 4 5 6 const { createServer } = require(\u0026#39;http\u0026#39;); createServer((req, res) =\u0026gt; { res.setHeader(\u0026#39;content-type\u0026#39;, \u0026#39;application/json\u0026#39;); res.end(JSON.stringify({ foo: \u0026#39;bar\u0026#39; })); }).listen(8080); 下面是设置 Cookie 的例子。\n1 2 3 4 5 6 7 8 9 10 const { createServer } = require(\u0026#39;http\u0026#39;); createServer((req, res) =\u0026gt; { res.setHeader( \u0026#39;Set-Cookie\u0026#39;, [\u0026#39;myCookie=myValue\u0026#39;], [\u0026#39;mySecondCookie=mySecondValue\u0026#39;] ); res.end(`Your cookies are: ${req.headers.cookie}`); }).listen(8080); response.writeHead()方法与response.setHeader()类似，但是优先级更高。它可以设置返回的 HTTP 状态码，第一个参数是状态码，第二个参数是状态说明。\n1 2 3 4 5 6 const { createServer } = require(\u0026#39;http\u0026#39;); createServer((req, res) =\u0026gt; { res.writeHead(204, \u0026#39;My Custom Message\u0026#39;); res.end(); }).listen(8080); request 对象 request.headers属性返回一个对象，包含了 HTTP 请求的头信息。该对象的键名是头信息的字段名，键值是头信息的字段值。\n1 2 3 4 5 6 const { createServer } = require(\u0026#34;http\u0026#34;); createServer((request, response) =\u0026gt; { const languages = request.headers[\u0026#39;accept-language\u0026#39;]; response.end(languages); }).listen(8080); 上面代码返回 HTTP 请求的头信息accept-language。\nrequest.url属性返回浏览器请求的路径，可以基于这个属性做一个简单的路由。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 const { createServer } = require(\u0026#39;http\u0026#39;); createServer((req, res) =\u0026gt; { switch (req.url) { case \u0026#39;/\u0026#39;: res.end(\u0026#39;You are on the main page!\u0026#39;); break; case \u0026#39;/about\u0026#39;: res.end(\u0026#39;You are on about page!\u0026#39;); break; default: res.statusCode = 404; res.end(\u0026#39;Page not found!\u0026#39;); } }).listen(8080); 获取查询字符串，可以用 Node 内置的url模块解析request.url属性。\n1 2 3 4 5 6 7 8 9 10 const { createServer } = require(\u0026#39;http\u0026#39;); createServer((req, res) =\u0026gt; { const { query } = require(\u0026#39;url\u0026#39;).parse(req.url, true); if (query.name) { res.end(`You requested parameter name with value ${query.name}`); } else { res.end(\u0026#39;Hello!\u0026#39;); } }).listen(8080); request.method属性返回浏览器请求的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 const { createServer } = require(\u0026#39;http\u0026#39;); createServer((req, res) =\u0026gt; { if (req.method === \u0026#39;GET\u0026#39;) { return res.end(\u0026#39;List of data\u0026#39;); } else if (req.method === \u0026#39;POST\u0026#39;) { return res.end(\u0026#39;success\u0026#39;); } else { res.statusCode(400); return res.end(\u0026#39;Unsupported method\u0026#39;); } }).listen(8080); POST 请求发送的数据体是一个数据流（stream），可以用request.on()方法监听data事件，累加数据流的每一部分；监听end事件，得到数据流接收结束的通知。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 const { createServer } = require(\u0026#39;http\u0026#39;); createServer((req, res) =\u0026gt; { if (req.method === \u0026#39;POST\u0026#39;) { let data = \u0026#39;\u0026#39;; req.on(\u0026#39;data\u0026#39;, chunk =\u0026gt; { data += chunk; }); req.on(\u0026#39;end\u0026#39;, () =\u0026gt; { try { const requestData = JSON.parse(data); requestData.ourMessage = \u0026#39;success\u0026#39;; res.setHeader(\u0026#39;Content-Type\u0026#39;, \u0026#39;application/json\u0026#39;); res.end(JSON.stringify(requestData)); } catch (e) { res.statusCode = 400; res.end(\u0026#39;Invalid JSON\u0026#39;); } }); } else { res.statusCode = 400; res.end(\u0026#39;Unsupported method, please POST a JSON object\u0026#39;); } }).listen(8080); 参考链接 Node.js Fundamentals: Web Server Without Dependencies, Seva Zaikov ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/stdlib/http/","summary":"http 模块 http模块用于 HTTP 通信。\nhttp.Server http.Server属性指向一个类，表示 Web 服务器实例。\n这个类继承了net.Server，而net.Server继承了 EventEmitter 接口，因此可以使用server.on()方法监听事情。最重要的一个事件是request，表示收到 HTTP 请求。\n1 2 3 server.on(\u0026#39;request\u0026#39;, (request, response) =\u0026gt; { response.end(\u0026#39;Hello, world!\u0026#39;); }); server.listen()方法用于启动 Web 服务。这个方法需要指定监听的端口，以及一个回调函数（启动后要做什么）。\n1 2 3 server.listen(PORT, () =\u0026gt; { console.log(`starting server at port ${PORT}`); }); http.createServer() http.createServer()方法用于创建一个 Web 服务器，它的返回值就是一个http.Server实例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 const { createServer } = require(\u0026#39;http\u0026#39;); // 指定端口 const PORT = process.env.PORT || 8080; const server = createServer(); server.","title":"http.md"},{"content":"os 模块 cpus属性返回一个数组，每个成员对应一个 CPU 内核。下面代码可以获取本机的 CPU 内核数目。\n1 2 const { cpus } = require(\u0026#39;os\u0026#39;); const numWorkers = cpus().length; ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/stdlib/os/","summary":"os 模块 cpus属性返回一个数组，每个成员对应一个 CPU 内核。下面代码可以获取本机的 CPU 内核数目。\n1 2 const { cpus } = require(\u0026#39;os\u0026#39;); const numWorkers = cpus().length; ","title":"os.md"},{"content":"process 对象 process对象是 Node 原生提供的对象，表示当前运行的 Node 进程。它不用引入模块，可以直接使用。\nprocess.argv process.argv是一个数组，表示启动脚本时的命令行参数。\n它的前两项是固定的。\n第一项是 Node 可执行文件的路径 第二项是 JavaScript 脚本的路径 后面的数组成员都是命令行参数。\n1 $ node index.js --watch 上面这个命令执行后，在index.js脚本里面，process.argv数组共有三项。\nprocess.argv[0]：/path/to/node process.argv[1]：/path/to/index.js process.argv[2]：\u0026ndash;watch 如果只需要命令行参数，可以用解构赋值获取。\n1 2 const [ , , ...args ] = process.argv; console.log(args[0]); // \u0026#34;--watch\u0026#34; 上面代码，args数组就是通过解构赋值，拿到的所有命令行参数。\n参考链接 Extracting command line arguments from Node.js using destructuring, Nicholas C. Zakas ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/stdlib/process/","summary":"process 对象 process对象是 Node 原生提供的对象，表示当前运行的 Node 进程。它不用引入模块，可以直接使用。\nprocess.argv process.argv是一个数组，表示启动脚本时的命令行参数。\n它的前两项是固定的。\n第一项是 Node 可执行文件的路径 第二项是 JavaScript 脚本的路径 后面的数组成员都是命令行参数。\n1 $ node index.js --watch 上面这个命令执行后，在index.js脚本里面，process.argv数组共有三项。\nprocess.argv[0]：/path/to/node process.argv[1]：/path/to/index.js process.argv[2]：\u0026ndash;watch 如果只需要命令行参数，可以用解构赋值获取。\n1 2 const [ , , ...args ] = process.argv; console.log(args[0]); // \u0026#34;--watch\u0026#34; 上面代码，args数组就是通过解构赋值，拿到的所有命令行参数。\n参考链接 Extracting command line arguments from Node.js using destructuring, Nicholas C. Zakas ","title":"process.md"},{"content":"npm update 更新所有依赖项。\n1 $ npm update 更新单个依赖。\n1 $ npm update xml2js 同时更新 package.json 里面每个依赖的版本号。\n1 $ npm update --save ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-update/","summary":"npm update 更新所有依赖项。\n1 $ npm update 更新单个依赖。\n1 $ npm update xml2js 同时更新 package.json 里面每个依赖的版本号。\n1 $ npm update --save ","title":"npm-update.md"},{"content":"npm version npm version用来指定模块的版本，然后会将新的版本号写入package.json和package-lock.json。\n它的命令行用法如下。\n1 2 3 4 5 npm version [ \u0026lt;newversion\u0026gt; | major | minor | patch | premajor | preminor | prepatch | prerelease | from-git ] 上面可以归纳为三种用法。\n（1）\u0026lt;newversion\u0026gt;：自己指定版本号。\n（2）七个版本关键字：patch，minor，major，prepatch，preminor，premajor，prerelease。这时原有版本号，会在相应的位置增加1。\nmajor：规则如下。\n（1）如果没有预发布号，则增加主版本号，并将次版本号和预发布号设为0。\n1 2 # 版本号从 3.1.0 变为 4.0.0 $ npm version major （2）如果有预发布号，且次版本号和补丁号都为0，则不升级主版本号，只去掉预发布号。\n1 2 3 4 5 # 版本号从 4.0.0 变为 5.0.0-0 $ npm version premajor # 版本号从 5.0.0-0 变为 5.0.0 $ npm version major （3）如果有预发布号，且次版本号和补丁号都不为0，则增加主版本号，将次版本号和补丁号都置为0，并去掉预发布号。\n1 2 3 4 5 # 版本号从 5.0.0-0 变为 5.1.0-0 $ npm version preminor : 5.0.0-0–\u0026gt; 5.1.0-0 # 版本号从 5.1.0-0 变为 6.0.0 $ npm version major minor：规则如下。\n（1）如果没有预发布号，则增加次版本号，并将补丁号设为0。\n1 2 # 版本号从 2.0.1 变为 2.1.0 $ npm version minor （2）如果有预发布号，且补丁号为0，则去掉预发布号，其他不变。\n1 2 3 4 5 # 版本号从 2.1.0 变为 3.0.0-0 $ npm version premajor # 版本号从 3.0.0-0 变为 3.0.0 $ npm version minor （3）如果有预发布号，且补丁号不为0，则去掉预发布号，增加次版本号，补丁号设为0。\n1 2 3 4 5 # 版本号从 3.0.0 变为 3.0.1-0 $ npm version prepatch # 版本号从 3.0.1-0 变为 3.1.0 $ npm version minor patch：如果预发布号，则去掉预发布后，其他保持不变；如果没有预发布号，则升级补丁号。\n1 2 3 4 5 # 版本号从 2.0.0-0 变为 2.0.0 $ npm version patch # 版本号从 2.0.0 变为 2.0.1 $ npm version patch premajor：增加主版本号，将次版本号和补丁号都设为0，增加预发布号为0。\n1 2 # 版本号从 1.1.0-0 变为 2.0.0-0 $ npm version premajor preminor：增加次版本号，补丁号设为0，预发布号设为0。\n1 2 # 版本号从 1.0.2-0 变为 1.1.0-0 $ npm version preminor prepatch：增加补丁号，同时预发布号设为0。\n1 2 # 版本号从 1.0.1-1 变为 1.0.2-0 $ npm version prepatch prerelease：如果没有预发布号，则增加补丁号，同时预发布号设为0；如果有预发布号，则预发布号增加1。\n1 2 3 4 5 # 版本号从 1.0.0 变为 1.0.1-0 $ npm version prerelease # 版本号从 1.0.1-0 变为 1.0.1-1 $ npm version prerelease （3）from-git：使用最新的 Git 标签，将其作为 npm 版本。\n这个命令如果是在一个 Git 仓库里面运行，它会创造一个新的提交和标签。如果不希望生成标签，可以使用命令行参数--no-git-tag-version。\n命令行参数-m或者--message可以指定提交信息。提交信息里面的%s参数会被替换成新的版本号。\n1 $ npm version patch -m \u0026#34;Upgrade to %s for reasons\u0026#34; \u0026ndash;pre-id npm version命令的--pre-id参数，可以指定预发布号的前缀。\n1 $ npm version prerelease --pre-id rc 上面的命令会产生诸如1.0.0-rc.0的版本号。\n参考链接 npm version 常用命令及用法示例 ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-version/","summary":"npm version npm version用来指定模块的版本，然后会将新的版本号写入package.json和package-lock.json。\n它的命令行用法如下。\n1 2 3 4 5 npm version [ \u0026lt;newversion\u0026gt; | major | minor | patch | premajor | preminor | prepatch | prerelease | from-git ] 上面可以归纳为三种用法。\n（1）\u0026lt;newversion\u0026gt;：自己指定版本号。\n（2）七个版本关键字：patch，minor，major，prepatch，preminor，premajor，prerelease。这时原有版本号，会在相应的位置增加1。\nmajor：规则如下。\n（1）如果没有预发布号，则增加主版本号，并将次版本号和预发布号设为0。\n1 2 # 版本号从 3.1.0 变为 4.0.0 $ npm version major （2）如果有预发布号，且次版本号和补丁号都为0，则不升级主版本号，只去掉预发布号。\n1 2 3 4 5 # 版本号从 4.0.0 变为 5.0.0-0 $ npm version premajor # 版本号从 5.0.0-0 变为 5.0.0 $ npm version major （3）如果有预发布号，且次版本号和补丁号都不为0，则增加主版本号，将次版本号和补丁号都置为0，并去掉预发布号。","title":"npm-version.md"},{"content":"npm view 命令 查看某个模块发布过的所有版本。\n1 $ npm view [PackageName] versions ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-view/","summary":"npm view 命令 查看某个模块发布过的所有版本。\n1 $ npm view [PackageName] versions ","title":"npm-view.md"},{"content":"npm whoami npm whoami命令返回当前登录的 npm 用户名。\n1 $ npm whoami ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-whoami/","summary":"npm whoami npm whoami命令返回当前登录的 npm 用户名。\n1 $ npm whoami ","title":"npm-whoami.md"},{"content":"npx 使用教程 npm 从5.2版开始，增加了 npx 命令，它有很多用处。\nNode 自带 npm 模块，所以可以直接使用 npx 命令。万一不能用，就要手动安装一下。\n1 $ npm install -g npx 调用项目安装的模块 npx 想要解决的主要问题，就是调用项目内部安装的模块。比如，项目内部安装了测试工具 Mocha。\n1 $ npm install -D mocha 一般来说，调用 Mocha ，只能在项目脚本和 package.json 的scripts字段里面， 如果想在命令行下调用，必须像下面这样。\n1 2 # 项目的根目录下执行 $ node-modules/.bin/mocha --version npx 就是想解决这个问题，让项目内部安装的模块用起来更方便，只要像下面这样调用就行了。\n1 $ npx mocha --version npx 的原理很简单，就是运行的时候，会到node_modules/.bin路径和环境变量$PATH里面，检查命令是否存在。\n由于 npx 会检查环境变量$PATH，所以系统命令也可以调用。\n1 2 # 等同于 ls $ npx ls 注意，Bash 内置的命令不在$PATH里面，所以不能用。比如，cd是 Bash 命令，因此就不能用npx cd。\n避免全局安装模块 除了调用项目内部模块，npx 还能避免全局安装的模块。比如，create-react-app这个模块是全局安装，npx 可以运行它，而且不进行全局安装。\n1 $ npx create-react-app my-react-app 上面代码运行时，npx 将create-react-app下载到一个临时目录，使用以后再删除。所以，以后再次执行上面的命令，会重新下载create-react-app。\n下载全局模块时，npx 允许指定版本。\n1 $ npx uglify-js@3.1.0 main.js -o ./dist/main.js 上面代码指定使用 3.1.0 版本的uglify-js压缩脚本。\n注意，只要 npx 后面的模块无法在本地发现，就会下载同名模块。比如，本地没有安装http-server模块，下面的命令会自动下载该模块，在当前目录启动一个 Web 服务。\n1 $ npx http-server --no-install 参数和--ignore-existing 参数 如果想让 npx 强制使用本地模块，不下载远程模块，可以使用--no-install参数。如果本地不存在该模块，就会报错。\n1 $ npx --no-install http-server 反过来，如果忽略本地的同名模块，强制安装使用远程模块，可以使用--ignore-existing参数。比如，本地已经全局安装了create-react-app，但还是想使用远程模块，就用这个参数。\n1 $ npx --ignore-existing create-react-app my-react-app 使用不同版本的 node 利用 npx 可以下载模块这个特点，可以指定某个版本的 Node 运行脚本。它的窍门就是使用 npm 的 node 模块。\n1 2 $ npx node@0.12.8 -v v0.12.8 上面命令会使用 0.12.8 版本的 Node 执行脚本。原理是从 npm 下载这个版本的 node，使用后再删掉。\n某些场景下，这个方法用来切换 Node 版本，要比 nvm 那样的版本管理器方便一些。\n-p 参数 -p参数用于指定 npx 所要安装的模块，所以上一节的命令可以写成下面这样。\n1 2 $ npx -p node@0.12.8 node -v v0.12.8 上面命令先指定安装node@0.12.8，然后再执行node -v命令。\n-p参数对于需要安装多个模块的场景很有用。\n1 $ npx -p lolcatjs -p cowsay [command] -c 参数 如果 npx 安装多个模块，默认情况下，所执行的命令之中，只有第一个可执行项会使用 npx 安装的模块，后面的可执行项还是会交给 Shell 解释。\n1 2 $ npx -p lolcatjs -p cowsay \u0026#39;cowsay hello | lolcatjs\u0026#39; # 报错 上面代码中，cowsay hello | lolcatjs执行时会报错，原因是第一项cowsay由 npx 解释，而第二项命令localcatjs由 Shell 解释，但是lolcatjs并没有全局安装，所以报错。\n-c参数可以将所有命令都用 npx 解释。有了它，下面代码就可以正常执行了。\n1 $ npx -p lolcatjs -p cowsay -c \u0026#39;cowsay hello | lolcatjs\u0026#39; -c参数的另一个作用，是将环境变量带入所要执行的命令。举例来说，npm 提供当前项目的一些环境变量，可以用下面的命令查看。\n1 $ npm run env | grep npm_ -c参数可以把这些 npm 的环境变量带入 npx 命令。\n1 $ npx -c \u0026#39;echo \u0026#34;$npm_package_name\u0026#34;\u0026#39; 上面代码会输出当前项目的项目名。\n执行 GitHub 源码 npx 还可以执行 GitHub 上面的模块源码。\n1 2 3 4 5 # 执行 Gist 代码 $ npx https://gist.github.com/zkat/4bc19503fe9e9309e2bfaa2c58074d32 # 执行仓库代码 $ npx github:piuccio/cowsay hello 注意，远程代码必须是一个模块，即必须包含package.json和入口脚本。\n参考链接 npx Speed Up Your npm Workflow With npx Introducing npx: an npm package runner ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npx/","summary":"npx 使用教程 npm 从5.2版开始，增加了 npx 命令，它有很多用处。\nNode 自带 npm 模块，所以可以直接使用 npx 命令。万一不能用，就要手动安装一下。\n1 $ npm install -g npx 调用项目安装的模块 npx 想要解决的主要问题，就是调用项目内部安装的模块。比如，项目内部安装了测试工具 Mocha。\n1 $ npm install -D mocha 一般来说，调用 Mocha ，只能在项目脚本和 package.json 的scripts字段里面， 如果想在命令行下调用，必须像下面这样。\n1 2 # 项目的根目录下执行 $ node-modules/.bin/mocha --version npx 就是想解决这个问题，让项目内部安装的模块用起来更方便，只要像下面这样调用就行了。\n1 $ npx mocha --version npx 的原理很简单，就是运行的时候，会到node_modules/.bin路径和环境变量$PATH里面，检查命令是否存在。\n由于 npx 会检查环境变量$PATH，所以系统命令也可以调用。\n1 2 # 等同于 ls $ npx ls 注意，Bash 内置的命令不在$PATH里面，所以不能用。比如，cd是 Bash 命令，因此就不能用npx cd。\n避免全局安装模块 除了调用项目内部模块，npx 还能避免全局安装的模块。比如，create-react-app这个模块是全局安装，npx 可以运行它，而且不进行全局安装。","title":"npx.md"},{"content":"package.json files 字段 files字段是一个数组，里面指定了一组文件。当模块发布到 NPM 网站时，这组文件会被包括。这个字段是可选的，如果没有指定内容，那么发布时所有文件都会被包括在内。如果files字段包含目录名，该目录里面的所有文件都会被计入。\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;name\u0026#34;: \u0026#34;@adam_baldwin/wombats\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;files\u0026#34;: [ \u0026#34;index.js\u0026#34; ], ... } npm不会发布.gitignore里面列出的文件和目录。项目的根目录或子目录里面，还可以放置一个.npmignore文件，该文件会覆盖.gitignore，里面指定的文件和目录不会被发布。\n项目的根目录下，files字段优先级最高；子目录下，.npmignore优先。files字段指定的文件，不会被.npmignore或.gitignore排除。\n以下文件，发布的时候总是会包含。\npackage.json README CHANGES / CHANGELOG / HISTORY LICENSE / LICENCE NOTICE main字段里面的文件 README、CHANGES、LICENSE和NOTICE这四个文件名，可以采取任意的大小写组合。\n以下文件，发布的时候总是会被排除。\n.git CVS .svn .hg .lock-wscript .wafpickle-N .*.swp .DS_Store ._* npm-debug.log .npmrc node_modules config.gypi *.orig package-lock.json 基本上，npm 会发布files字段指定的文件和目录，以及那些总是会包含在内的文件（比如package.json），然后再除去那些被其他规则排除的文件和目录。\nnpm-packlist 模块会列出所有将要打包发布的文件和模块。npm pack命令则会将那些将要发布的内容打成一个tgz压缩包，放在项目的根目录下。\n","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/package.json/","summary":"package.json files 字段 files字段是一个数组，里面指定了一组文件。当模块发布到 NPM 网站时，这组文件会被包括。这个字段是可选的，如果没有指定内容，那么发布时所有文件都会被包括在内。如果files字段包含目录名，该目录里面的所有文件都会被计入。\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;name\u0026#34;: \u0026#34;@adam_baldwin/wombats\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;main\u0026#34;: \u0026#34;index.js\u0026#34;, \u0026#34;files\u0026#34;: [ \u0026#34;index.js\u0026#34; ], ... } npm不会发布.gitignore里面列出的文件和目录。项目的根目录或子目录里面，还可以放置一个.npmignore文件，该文件会覆盖.gitignore，里面指定的文件和目录不会被发布。\n项目的根目录下，files字段优先级最高；子目录下，.npmignore优先。files字段指定的文件，不会被.npmignore或.gitignore排除。\n以下文件，发布的时候总是会包含。\npackage.json README CHANGES / CHANGELOG / HISTORY LICENSE / LICENCE NOTICE main字段里面的文件 README、CHANGES、LICENSE和NOTICE这四个文件名，可以采取任意的大小写组合。\n以下文件，发布的时候总是会被排除。\n.git CVS .svn .hg .lock-wscript .wafpickle-N .*.swp .DS_Store ._* npm-debug.log .npmrc node_modules config.gypi *.orig package-lock.json 基本上，npm 会发布files字段指定的文件和目录，以及那些总是会包含在内的文件（比如package.json），然后再除去那些被其他规则排除的文件和目录。\nnpm-packlist 模块会列出所有将要打包发布的文件和模块。npm pack命令则会将那些将要发布的内容打成一个tgz压缩包，放在项目的根目录下。","title":"package.json.md"},{"content":"发布 发布标签 npm 支持为版本打上标签，这叫做发布标签（dist-tag）。如果不指定发布标签，默认就是latest。用户下载模块时，默认安装的就是latest标签指向的版本。\n新发布的版本，如果不希望用户默认安装，就需要自己指定标签。举例来说，某个模块的最新版本是4.6.12，但是有些用户还在使用老版本3.2.13。现在，你修正了一些老版本的 bug，发了一个新版本3.2.14。如果不指定发布标签，3.2.14的发布标签就是latest，因为它是最新发布的。\n这导致的后果就是，用户执行下面的命令，进行默认安装时，会出现非预期的结果。\n1 $ npm install \u0026lt;package\u0026gt; 执行上面命令时，用户会默认安装3.2.14，而不是4.6.12。因为latest标签指向3.2.14。\n解决方法就是，发布3.2.14的时候，为它打上一个发布标签。这样，3.2.14就不会占用latest标签。\n1 $ npm publish --tag=previous 执行上面的命令后，3.2.14的发布标签就是previous。\n安装时，必须指定这个标签，才能安装到3.2.14。\n1 2 3 $ npm install \u0026lt;package\u0026gt;@previous # 或者 $ npm install \u0026lt;package\u0026gt; --tag previous 上面的命令的两种语法都可以指定标签名。由于latest是默认标签，所以可以省略。\n1 2 3 $ npm install \u0026lt;package\u0026gt; # 等同于 $ npm install \u0026lt;package\u0026gt;@latest 一种常见的做法是，发布下一个大版本时，指定它的发布标签为next。\n1 2 3 4 5 # 发布 $ npm publish --tag=next # 安装 $ npm publish \u0026lt;package\u0026gt;@next 这样的话，用户默认安装的还是主流版本，但是愿意尝鲜的用户，可以使用新版本。\n等到新版本足够可靠以后，再把latest标签指定到新版本。\n1 $ npm dist-tag add \u0026lt;package\u0026gt;@5.0.1 latest 如果希望把默认的发布标签改掉，不再是latest，可以写在package.json里面。\n1 2 3 4 5 6 { … \u0026#34;publishConfig\u0026#34;: { \u0026#34;tag\u0026#34;: \u0026#34;next\u0026#34; } } 上面的设置，可以使得发布新版本时，发布标签默认为next。\n常用的发布标签有stable、beta、dev等等。\nnpm dist-tag 命令 npm dist-tag命令用来管理发布标签。\nnpm dist-tag ls用来列出所有的发布标签。如果不指定模块名，那么默认为当前模块。\n1 $ npm dist-tag ls [\u0026lt;pkg\u0026gt;] npm dist-tag add用来为一个版本指定发布标签。\n1 $ npm dist-tag add \u0026lt;pkg\u0026gt;@\u0026lt;version\u0026gt; [\u0026lt;tag\u0026gt;] npm dist-tag rm用来移除一个发布标签。\n1 $ npm dist-tag rm \u0026lt;pkg\u0026gt; \u0026lt;tag\u0026gt; .gitignore，.npmignore 如果当前项目的根目录下有.gitignore文件，该文件里面的路径不会打包进入 npm 模块。\n如果有.npmignore文件，那么 npm 将忽略.gitignore文件，不将.npmignore文件里面的路径打包进入 npm 模块。如果有些文件不希望进入 npm 模块（比如测试用例），但是希望进入 Git 仓库，那么可以使用.npmignore。\n1 2 3 4 5 6 # .gitignore node_modules # .npmignore node_modules tests 此外，package.json的files字段，也可以用来排除进入 npm 模块的文件。\n1 2 3 4 5 { \u0026#34;files\u0026#34;: [ \u0026#34;index.js\u0026#34; ] } npm 会最优先排除files字段里面的文件。另外，无论如何设置，package.json文件都会进入 npm 模块。\nnpm pack 命令 npm pack命令用来打包当前项目，打包后的文件会在当前目录下生成，文件名为\u0026lt;name\u0026gt;-\u0026lt;version\u0026gt;.tgz。\n1 $ npm pack 如果多次运行该命令，每次生成的包将覆盖前一次的包。\nnpm pack可以接受路径作为参数，打包该路径下的模块。如果没有提供任何参数，将打包当前目录。\n1 $ npm pack foo/bar --dry-run参数会输出打包的内容，而不生成打包文件。\n1 $ npm pack --dry-run 参考链接 One simple trick for JavaScript package maintainers, by Stephan Bönnemann ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/publish/","summary":"发布 发布标签 npm 支持为版本打上标签，这叫做发布标签（dist-tag）。如果不指定发布标签，默认就是latest。用户下载模块时，默认安装的就是latest标签指向的版本。\n新发布的版本，如果不希望用户默认安装，就需要自己指定标签。举例来说，某个模块的最新版本是4.6.12，但是有些用户还在使用老版本3.2.13。现在，你修正了一些老版本的 bug，发了一个新版本3.2.14。如果不指定发布标签，3.2.14的发布标签就是latest，因为它是最新发布的。\n这导致的后果就是，用户执行下面的命令，进行默认安装时，会出现非预期的结果。\n1 $ npm install \u0026lt;package\u0026gt; 执行上面命令时，用户会默认安装3.2.14，而不是4.6.12。因为latest标签指向3.2.14。\n解决方法就是，发布3.2.14的时候，为它打上一个发布标签。这样，3.2.14就不会占用latest标签。\n1 $ npm publish --tag=previous 执行上面的命令后，3.2.14的发布标签就是previous。\n安装时，必须指定这个标签，才能安装到3.2.14。\n1 2 3 $ npm install \u0026lt;package\u0026gt;@previous # 或者 $ npm install \u0026lt;package\u0026gt; --tag previous 上面的命令的两种语法都可以指定标签名。由于latest是默认标签，所以可以省略。\n1 2 3 $ npm install \u0026lt;package\u0026gt; # 等同于 $ npm install \u0026lt;package\u0026gt;@latest 一种常见的做法是，发布下一个大版本时，指定它的发布标签为next。\n1 2 3 4 5 # 发布 $ npm publish --tag=next # 安装 $ npm publish \u0026lt;package\u0026gt;@next 这样的话，用户默认安装的还是主流版本，但是愿意尝鲜的用户，可以使用新版本。\n等到新版本足够可靠以后，再把latest标签指定到新版本。","title":"publish.md"},{"content":"脚本功能 npm run npm不仅可以用于模块管理，还可以用于执行脚本。package.json文件有一个scripts字段，可以用于指定脚本命令，供npm直接调用。\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;name\u0026#34;: \u0026#34;myproject\u0026#34;, \u0026#34;devDependencies\u0026#34;: { \u0026#34;jshint\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;browserify\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;mocha\u0026#34;: \u0026#34;latest\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;jshint **.js\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;mocha test/\u0026#34; } } 上面代码中，scripts字段指定了两项命令lint和test。命令行输入npm run-script lint或者npm run lint，就会执行jshint **.js，输入npm run-script test或者npm run test，就会执行mocha test/。npm run是npm run-script的缩写，一般都使用前者，但是后者可以更好地反应这个命令的本质。\nnpm run命令会自动在环境变量$PATH添加node_modules/.bin目录，所以scripts字段里面调用命令时不用加上路径，这就避免了全局安装NPM模块。\nnpm run如果不加任何参数，直接运行，会列出package.json里面所有可以执行的脚本命令。\nnpm内置了两个命令简写，npm test等同于执行npm run test，npm start等同于执行npm run start。\nnpm run会创建一个Shell，执行指定的命令，并临时将node_modules/.bin加入PATH变量，这意味着本地模块可以直接运行。\n举例来说，你执行ESLint的安装命令。\n1 $ npm i eslint --save-dev 运行上面的命令以后，会产生两个结果。首先，ESLint被安装到当前目录的node_modules子目录；其次，node_modules/.bin目录会生成一个符号链接node_modules/.bin/eslint，指向ESLint模块的可执行脚本。\n然后，你就可以在package.json的script属性里面，不带路径的引用eslint这个脚本。\n1 2 3 4 5 6 7 8 9 { \u0026#34;name\u0026#34;: \u0026#34;Test Project\u0026#34;, \u0026#34;devDependencies\u0026#34;: { \u0026#34;eslint\u0026#34;: \u0026#34;^1.10.3\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;eslint .\u0026#34; } } 等到运行npm run lint的时候，它会自动执行./node_modules/.bin/eslint .。\n如果直接运行npm run不给出任何参数，就会列出scripts属性下所有命令。\n1 2 3 4 5 6 $ npm run Available scripts in the user-service package: lint jshint **.js test mocha test/ 下面是另一个package.json文件的例子。\n1 2 3 4 5 6 \u0026#34;scripts\u0026#34;: { \u0026#34;watch\u0026#34;: \u0026#34;watchify client/main.js -o public/app.js -v\u0026#34;, \u0026#34;build\u0026#34;: \u0026#34;browserify client/main.js -o public/app.js\u0026#34;, \u0026#34;start\u0026#34;: \u0026#34;npm run watch \u0026amp; nodemon server.js\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;node test/all.js\u0026#34; }, 上面代码在scripts项，定义了四个别名，每个别名都有对应的脚本命令。\n1 2 3 4 $ npm run watch $ npm run build $ npm run start $ npm run test 其中，start和test属于特殊命令，可以省略run。\n1 2 $ npm start $ npm test 如果希望一个操作的输出，是另一个操作的输入，可以借用Linux系统的管道命令，将两个操作连在一起。\n1 \u0026#34;build-js\u0026#34;: \u0026#34;browserify browser/main.js | uglifyjs -mc \u0026gt; static/bundle.js\u0026#34; 但是，更方便的写法是引用其他npm run命令。\n1 \u0026#34;build\u0026#34;: \u0026#34;npm run build-js \u0026amp;\u0026amp; npm run build-css\u0026#34; 上面的写法是先运行npm run build-js，然后再运行npm run build-css，两个命令中间用\u0026amp;\u0026amp;连接。如果希望两个命令同时平行执行，它们中间可以用\u0026amp;连接。\n下面是一个流操作的例子。\n1 2 3 4 5 6 7 8 \u0026#34;devDependencies\u0026#34;: { \u0026#34;autoprefixer\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;cssmin\u0026#34;: \u0026#34;latest\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;build:css\u0026#34;: \u0026#34;autoprefixer -b \u0026#39;last 2 versions\u0026#39; \u0026lt; assets/styles/main.css | cssmin \u0026gt; dist/main.css\u0026#34; } 写在scripts属性中的命令，也可以在node_modules/.bin目录中直接写成bash脚本。下面是一个bash脚本。\n1 2 3 4 #!/bin/bash cd site/main browserify browser/main.js | uglifyjs -mc \u0026gt; static/bundle.js 假定上面的脚本文件名为build.sh，并且权限为可执行，就可以在scripts属性中引用该文件。\n1 \u0026#34;build-js\u0026#34;: \u0026#34;bin/build.sh\u0026#34; 参数 npm run命令还可以添加参数。\n1 2 3 \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;mocha test/\u0026#34; } 上面代码指定npm test，实际运行mocha test/。如果要通过npm test命令，将参数传到mocha，则参数之前要加上两个连词线。\n1 2 3 $ npm run test -- anothertest.js # 等同于 $ mocha test/ anothertest.js 上面命令表示，mocha要运行所有test子目录的测试脚本，以及另外一个测试脚本anothertest.js。\nnpm run本身有一个参数-s，表示关闭npm本身的输出，只输出脚本产生的结果。\n1 2 3 4 5 // 输出npm命令头 $ npm run test // 不输出npm命令头 $ npm run -s test scripts脚本命令最佳实践 scripts字段的脚本命令，有一些最佳实践，可以方便开发。首先，安装npm-run-all模块。\n1 $ npm install npm-run-all --save-dev 这个模块用于运行多个scripts脚本命令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 继发执行 $ npm-run-all build:html build:js # 等同于 $ npm run build:html \u0026amp;\u0026amp; npm run build:js # 并行执行 $ npm-run-all --parallel watch:html watch:js # 等同于 $ npm run watch:html \u0026amp; npm run watch:js # 混合执行 $ npm-run-all clean lint --parallel watch:html watch:js # 等同于 $ npm-run-all clean lint $ npm-run-all --parallel watch:html watch:js # 通配符 $ npm-run-all --parallel watch:* （1）start脚本命令\nstart脚本命令，用于启动应用程序。\n1 \u0026#34;start\u0026#34;: \u0026#34;npm-run-all --parallel dev serve\u0026#34; 上面命令并行执行dev脚本命令和serve脚本命令，等同于下面的形式。\n1 $ npm run dev \u0026amp; npm run serve 如果start脚本没有配置，npm start命令默认执行下面的脚本，前提是模块的根目录存在一个server.js文件。\n1 $ node server.js （2）dev脚本命令\ndev脚本命令，规定开发阶段所要做的处理，比如构建网页资源。\n1 \u0026#34;dev\u0026#34;: \u0026#34;npm-run-all dev:*\u0026#34; 上面命令用于继发执行所有dev的子命令。\n1 \u0026#34;predev:sass\u0026#34;: \u0026#34;node-sass --source-map src/css/hoodie.css.map --output-style nested src/sass/base.scss src/css/hoodie.css\u0026#34; 上面命令将sass文件编译为css文件，并生成source map文件。\n1 \u0026#34;dev:sass\u0026#34;: \u0026#34;node-sass --source-map src/css/hoodie.css.map --watch --output-style nested src/sass/base.scss src/css/hoodie.css\u0026#34; 上面命令会监视sass文件的变动，只要有变动，就自动将其编译为css文件。\n1 \u0026#34;dev:autoprefix\u0026#34;: \u0026#34;postcss --use autoprefixer --autoprefixer.browsers \\\u0026#34;\u0026gt; 5%\\\u0026#34; --output src/css/hoodie.css src/css/hoodie.css\u0026#34; 上面命令为css文件加上浏览器前缀，限制条件是只考虑市场份额大于5%的浏览器。\n（3）serve脚本命令\nserve脚本命令用于启动服务。\n1 \u0026#34;serve\u0026#34;: \u0026#34;live-server dist/ --port=9090\u0026#34; 上面命令启动服务，用的是live-server模块，将服务启动在9090端口，展示dist子目录。\nlive-server模块有三个功能。\n启动一个HTTP服务器，展示指定目录的index.html文件，通过该文件加载各种网络资源，这是file://协议做不到的。 添加自动刷新功能。只要指定目录之中，文件有任何变化，它就会刷新页面。 npm run serve命令执行以后，自动打开浏览器。、 以前，上面三个功能需要三个模块来完成：http-server、live-reload和opener，现在只要live-server一个模块就够了。\n（4）test脚本命令\ntest脚本命令用于执行测试。\n1 2 \u0026#34;test\u0026#34;: \u0026#34;npm-run-all test:*\u0026#34;, \u0026#34;test:lint\u0026#34;: \u0026#34;sass-lint --verbose --config .sass-lint.yml src/sass/*\u0026#34; 上面命令规定，执行测试时，运行lint脚本，检查脚本之中的语法错误。\n（5）prod脚本命令\nprod脚本命令，规定进入生产环境时需要做的处理。\n1 2 3 \u0026#34;prod\u0026#34;: \u0026#34;npm-run-all prod:*\u0026#34;, \u0026#34;prod:sass\u0026#34;: \u0026#34;node-sass --output-style compressed src/sass/base.scss src/css/prod/hoodie.min.css\u0026#34;, \u0026#34;prod:autoprefix\u0026#34;: \u0026#34;postcss --use autoprefixer --autoprefixer.browsers \u0026#34;\u0026gt; 5%\u0026#34; --output src/css/prod/hoodie.min.css src/css/prod/hoodie.min.css\u0026#34; 上面命令将sass文件转为css文件，并加上浏览器前缀。\n（6）help脚本命令\nhelp脚本命令用于展示帮助信息。\n1 \u0026#34;help\u0026#34;: \u0026#34;markdown-chalk --input DEVELOPMENT.md\u0026#34; 上面命令之中，markdown-chalk模块用于将指定的markdown文件，转为彩色文本显示在终端之中。\n（7）docs脚本命令\ndocs脚本命令用于生成文档。\n1 \u0026#34;docs\u0026#34;: \u0026#34;kss-node --source src/sass --homepage ../../styleguide.md\u0026#34; 上面命令使用kss-node模块，提供源码的注释生成markdown格式的文档。\npre- 和 post- 脚本 npm run为每条命令提供了pre-和post-两个钩子（hook）。以npm run lint为例，执行这条命令之前，npm会先查看有没有定义prelint和postlint两个钩子，如果有的话，就会先执行npm run prelint，然后执行npm run lint，最后执行npm run postlint。\n1 2 3 4 5 6 7 8 9 10 11 12 13 { \u0026#34;name\u0026#34;: \u0026#34;myproject\u0026#34;, \u0026#34;devDependencies\u0026#34;: { \u0026#34;eslint\u0026#34;: \u0026#34;latest\u0026#34; \u0026#34;karma\u0026#34;: \u0026#34;latest\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;eslint --cache --ext .js --ext .jsx src\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;karma start --log-leve=error karma.config.js --single-run=true\u0026#34;, \u0026#34;pretest\u0026#34;: \u0026#34;npm run lint\u0026#34;, \u0026#34;posttest\u0026#34;: \u0026#34;echo \u0026#39;Finished running tests\u0026#39;\u0026#34; } } 上面代码是一个package.json文件的例子。如果执行npm test，会按下面的顺序执行相应的命令。\npretest test posttest 如果执行过程出错，就不会执行排在后面的脚本，即如果prelint脚本执行出错，就不会接着执行lint和postlint脚本。\n下面是一个例子。\n1 2 3 4 5 { \u0026#34;test\u0026#34;: \u0026#34;karma start\u0026#34;, \u0026#34;test:lint\u0026#34;: \u0026#34;eslint . --ext .js --ext .jsx\u0026#34;, \u0026#34;pretest\u0026#34;: \u0026#34;npm run test:lint\u0026#34; } 上面代码中，在运行npm run test之前，会自动检查代码，即运行npm run test:lint命令。\n下面是一些常见的pre-和post-脚本。\nprepublish：发布一个模块前执行。 postpublish：发布一个模块后执行。 preinstall：用户执行npm install命令时，先执行该脚本。 postinstall：用户执行npm install命令时，安装结束后执行该脚本，通常用于将下载的源码编译成用户需要的格式，比如有些模块需要在用户机器上跟本地的C++模块一起编译。 preuninstall：卸载一个模块前执行。 postuninstall：卸载一个模块后执行。 preversion：更改模块版本前执行。 postversion：更改模块版本后执行。 pretest：运行npm test命令前执行。 posttest：运行npm test命令后执行。 prestop：运行npm stop命令前执行。 poststop：运行npm stop命令后执行。 prestart：运行npm start命令前执行。 poststart：运行npm start命令后执行。 prerestart：运行npm restart命令前执行。 postrestart：运行npm restart命令后执行。 对于最后一个npm restart命令，如果没有设置restart脚本，prerestart和postrestart会依次执行stop和start脚本。\n另外，不能在pre脚本之前再加pre，即prepretest脚本不起作用。\n注意，即使Npm可以自动运行pre和post脚本，也可以手动执行它们。\n1 $ npm run prepublish 下面是post install的例子。\n1 2 3 { \u0026#34;postinstall\u0026#34;: \u0026#34;node lib/post_install.js\u0026#34; } 上面的这个命令，主要用于处理从Git仓库拉下来的源码。比如，有些源码是用TypeScript写的，可能需要转换一下。\n下面是publish钩子的一个例子。\n1 2 3 4 5 6 7 { \u0026#34;dist:modules\u0026#34;: \u0026#34;babel ./src --out-dir ./dist-modules\u0026#34;, \u0026#34;gh-pages\u0026#34;: \u0026#34;webpack\u0026#34;, \u0026#34;gh-pages:deploy\u0026#34;: \u0026#34;gh-pages -d gh-pages\u0026#34;, \u0026#34;prepublish\u0026#34;: \u0026#34;npm run dist:modules\u0026#34;, \u0026#34;postpublish\u0026#34;: \u0026#34;npm run gh-pages \u0026amp;\u0026amp; npm run gh-pages:deploy\u0026#34; } 上面命令在运行npm run publish时，会先执行Babel编译，然后调用Webpack构建，最后发到Github Pages上面。\n以上都是npm相关操作的钩子，如果安装某些模块，还能支持Git相关的钩子。下面以husky模块为例。\n1 $ npm install husky --save-dev 安装以后，就能在package.json添加precommit、prepush等钩子。\n1 2 3 4 5 6 7 8 { \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;eslint yourJsFiles.js\u0026#34;, \u0026#34;precommit\u0026#34;: \u0026#34;npm run test \u0026amp;\u0026amp; npm run lint\u0026#34;, \u0026#34;prepush\u0026#34;: \u0026#34;npm run test \u0026amp;\u0026amp; npm run lint\u0026#34;, \u0026#34;...\u0026#34;: \u0026#34;...\u0026#34; } } 类似作用的模块还有pre-commit、precommit-hook等。\n内部变量 scripts字段可以使用一些内部变量，主要是package.json的各种字段。\n比如，package.json的内容是{\u0026quot;name\u0026quot;:\u0026quot;foo\u0026quot;, \u0026quot;version\u0026quot;:\u0026quot;1.2.5\u0026quot;}，那么变量npm_package_name的值是foo，变量npm_package_version的值是1.2.5。\n1 2 3 4 5 { \u0026#34;scripts\u0026#34;:{ \u0026#34;bundle\u0026#34;: \u0026#34;mkdir -p build/$npm_package_version/\u0026#34; } } 运行npm run bundle以后，将会生成build/1.2.5/子目录。\nconfig字段也可以用于设置内部字段。\n1 2 3 4 5 6 7 \u0026#34;name\u0026#34;: \u0026#34;fooproject\u0026#34;, \u0026#34;config\u0026#34;: { \u0026#34;reporter\u0026#34;: \u0026#34;xunit\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;test\u0026#34;: \u0026#34;mocha test/ --reporter $npm_package_config_reporter\u0026#34; } 上面代码中，变量npm_package_config_reporter对应的就是reporter。\n通配符 npm 的通配符的规则如下。\n* 匹配0个或多个字符 ? 匹配1个字符 [...] 匹配某个范围的字符。如果该范围的第一个字符是!或^，则匹配不在该范围的字符。 !(pattern|pattern|pattern) 匹配任何不符合给定的模式 ?(pattern|pattern|pattern) 匹配0个或1个给定的模式 +(pattern|pattern|pattern) 匹配1个或多个给定的模式 *(a|b|c) 匹配0个或多个给定的模式 @(pattern|pat*|pat?erN) 只匹配给定模式之一 ** 如果出现在路径部分，表示0个或多个子目录。 ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/scripts/","summary":"脚本功能 npm run npm不仅可以用于模块管理，还可以用于执行脚本。package.json文件有一个scripts字段，可以用于指定脚本命令，供npm直接调用。\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;name\u0026#34;: \u0026#34;myproject\u0026#34;, \u0026#34;devDependencies\u0026#34;: { \u0026#34;jshint\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;browserify\u0026#34;: \u0026#34;latest\u0026#34;, \u0026#34;mocha\u0026#34;: \u0026#34;latest\u0026#34; }, \u0026#34;scripts\u0026#34;: { \u0026#34;lint\u0026#34;: \u0026#34;jshint **.js\u0026#34;, \u0026#34;test\u0026#34;: \u0026#34;mocha test/\u0026#34; } } 上面代码中，scripts字段指定了两项命令lint和test。命令行输入npm run-script lint或者npm run lint，就会执行jshint **.js，输入npm run-script test或者npm run test，就会执行mocha test/。npm run是npm run-script的缩写，一般都使用前者，但是后者可以更好地反应这个命令的本质。\nnpm run命令会自动在环境变量$PATH添加node_modules/.bin目录，所以scripts字段里面调用命令时不用加上路径，这就避免了全局安装NPM模块。\nnpm run如果不加任何参数，直接运行，会列出package.json里面所有可以执行的脚本命令。\nnpm内置了两个命令简写，npm test等同于执行npm run test，npm start等同于执行npm run start。\nnpm run会创建一个Shell，执行指定的命令，并临时将node_modules/.bin加入PATH变量，这意味着本地模块可以直接运行。\n举例来说，你执行ESLint的安装命令。\n1 $ npm i eslint --save-dev 运行上面的命令以后，会产生两个结果。首先，ESLint被安装到当前目录的node_modules子目录；其次，node_modules/.","title":"scripts.md"},{"content":"Yarn 的用法 简介 Yarn 是 Facebook 联合其他大公司推出的模块管理器。相比 npm，它有两个显著特点。\n（1）安装速度较快。\nYarn 采用平行安装模式，而 npm 采用的是线性模式，只有前一个模块安装完，才会安装下一个。\n（2）默认开启“版本锁定”功能\nYarn 希望安装依赖时，所有依赖的版本在不同机器都保持相同。为了达到这个目的，第一次安装依赖时，它默认生成一个锁定文件yarn.lock，将这个文件放到代码库之中，下次安装时就能保证，总是安装相同版本的依赖。这与npm shrinkwrap命令生成的npm-shrinkwrap.json的作用相似，只不过 Yarn 默认就可以生成这个文件。\n全局参数 global 如果要全局执行一个命令，必须加上global参数。目前，add、bin、ls和remove四个命令，支持global参数。\n1 $ yarn global add create-react-app --prefix /usr/local yarn install yarn install命令用于安装一个模块。如果yarn.lock文件存在，会优先读取该文件，按照该文件指定的版本安装。\n使用--production参数或环境变量NODE_ENV等于production，将不会安装devDependencies字段指定的模块。\n1 $ yarn install --production 如果使用--no-lockfile参数，yarn install将不会读取或生成yarn.lock。\n1 $ yarn install --no-lockfile yarn add yarn add命令允许新增安装一个模块。它默认会将该模块加入package.json文件的dependencies字段。如果想加入devDependencies字段，要使用--dev参数。\n1 2 3 $ yarn add package-name $ yarn add package-name@1.2.3 $ yarn add package-name@tag yarn licenses yarn licenses命令有两个子命令。\nyarn licenses ls命令列出所有模块的许可证。\nyarn licenses generate-disclaimer命令将所有模块的许可证的条款，全部显示出来。\nyarn why yarn why命令列出之所以安装某个模块的原因，即为什么安装了它。\n1 $ yarn why jest 你也可以用它分析某个目录或者某个文件。\n1 2 $ yarn why node_modules/once $ yarn why node_modules/once/once.js yarn upgrade yarn upgrade命令会按照package.json里面指定的版本范围，更新依赖版本，重新生成yarn.lock。\n1 $ yarn upgrade 如果单独升级某个模块，yarn upgrade会将它升级到latest标签指定的版本，然后改写package.json。这意味着该命令可能会将一个1.x版本的模块，升级到2.x。\n1 $ yarn upgrade d3-scale 更新时指定版本范围或标签，也是允许的。\n1 2 $ yarn upgrade d3-scale@1.0.2 $ yarn upgrade react@next yarn generate-lock-entry yarn generate-lock-entry命令依照package.json文件，生成yarn.lock文件。\n1 $ yarn generate-lock-entry yarn.lock 文件 yarn.lock是一个锁文件，用来记录当前项目的依赖模块的精确版本。只要项目的根目录有这个文件，下次安装依赖的时候，总是会安装一模一样的node_modules目录，这个特点称为决定性（determinism）。\n如果当前项目没有这个文件，那么第一次运行yarn install或者yarn add [模块名]命令的时候，就会生成这个文件。以后，再运行yarn add命令，会更新这个文件。\n举例来说，yarn add supports-color命令会产生下面的yarn.lock文件。\n1 2 3 4 5 6 7 8 9 has-flag@^1.0.0: version \u0026#34;1.0.0\u0026#34; resolved \u0026#34;https://registry.yarnpkg.com/has-flag/-/has-flag-1.0.0.tgz#9d9e793165ce017a00f00418c43f942a7b1d11fa\u0026#34; supports-color@^3.2.3: version \u0026#34;3.2.3\u0026#34; resolved \u0026#34;https://registry.yarnpkg.com/supports-color/-/supports-color-3.2.3.tgz#65ac0504b3954171d8a64946b2ae3cbb8a5f54f6\u0026#34; dependencies: has-flag \u0026#34;^1.0.0\u0026#34; 上面代码中，模块之间使用空行分隔。每个模块会指明当前安装的精确版本（version字段）和下载地址（resovled字段），以及依赖的模块（dependencies字段）。\n注意，从yarn.lock文件看不出来，哪个模块会安装在node_modules目录的顶层，必须结合package.json才能看出来，具体的算法由 Yarn 决定。这也意味着，不同版本的 Yarn 处理同样的yarn.lock文件，可能会得到不一样的node_modules目录，但是每个模块的版本肯定都是相同的。只有相同版本的 Yarn，才能保证一定会得到相同的node_modules目录。\n参考链接 Yarn determinism, by Sebastian McKenzie Running Yarn offline, by Konstantin Raev Yarn CLI ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/yarn/","summary":"Yarn 的用法 简介 Yarn 是 Facebook 联合其他大公司推出的模块管理器。相比 npm，它有两个显著特点。\n（1）安装速度较快。\nYarn 采用平行安装模式，而 npm 采用的是线性模式，只有前一个模块安装完，才会安装下一个。\n（2）默认开启“版本锁定”功能\nYarn 希望安装依赖时，所有依赖的版本在不同机器都保持相同。为了达到这个目的，第一次安装依赖时，它默认生成一个锁定文件yarn.lock，将这个文件放到代码库之中，下次安装时就能保证，总是安装相同版本的依赖。这与npm shrinkwrap命令生成的npm-shrinkwrap.json的作用相似，只不过 Yarn 默认就可以生成这个文件。\n全局参数 global 如果要全局执行一个命令，必须加上global参数。目前，add、bin、ls和remove四个命令，支持global参数。\n1 $ yarn global add create-react-app --prefix /usr/local yarn install yarn install命令用于安装一个模块。如果yarn.lock文件存在，会优先读取该文件，按照该文件指定的版本安装。\n使用--production参数或环境变量NODE_ENV等于production，将不会安装devDependencies字段指定的模块。\n1 $ yarn install --production 如果使用--no-lockfile参数，yarn install将不会读取或生成yarn.lock。\n1 $ yarn install --no-lockfile yarn add yarn add命令允许新增安装一个模块。它默认会将该模块加入package.json文件的dependencies字段。如果想加入devDependencies字段，要使用--dev参数。\n1 2 3 $ yarn add package-name $ yarn add package-name@1.2.3 $ yarn add package-name@tag yarn licenses yarn licenses命令有两个子命令。","title":"yarn.md"},{"content":"概述 npm有两种含义。\n首先，npm 是一个网站，用来登记和管理 Node 的模块，网址为npmjs.org。\n其次，npm 是一个命令行软件，用来在用户的电脑上安装和管理 Node 模块。\n安装 npm不需要单独安装。安装 Node 的时候，会默认一起安装npm。\n但是，默认安装的npm可能不是最新版本。在 Node 安装成功后，最好用下面的命令，更新到最新版本。\n1 $ npm install npm@latest -g 然后，运行下面的命令，查看一下 npm 的版本。\n1 2 3 $ npm --version # 等同于 $ npm -v 下面三个命令，也可以用来获取帮助。\n1 2 3 4 5 6 7 8 # 查看 npm 命令列表 $ npm help # 查看各个命令的简单用法 $ npm -l # 查看 npm 的配置 $ npm config list -l npm init npm init用来初始化生成一个新的package.json文件。它会向用户提问一系列问题，如果你觉得不用修改默认配置，一路回车就可以了。\n如果使用了-f（代表force）、-y（代表yes），则跳过提问阶段，直接生成一个新的package.json文件。\n1 $ npm init -y npm set npm set用来设置环境变量。\n1 2 3 4 $ npm set init-author-name \u0026#39;Your name\u0026#39; $ npm set init-author-email \u0026#39;Your email\u0026#39; $ npm set init-author-url \u0026#39;http://yourdomain.com\u0026#39; $ npm set init-license \u0026#39;MIT\u0026#39; 上面命令等于为npm init设置了默认值，以后执行npm init的时候，package.json的作者姓名、邮件、主页、许可证字段就会自动写入预设的值。这些信息会存放在用户主目录的 ~/.npmrc文件，使得用户不用每个项目都输入。如果某个项目有不同的设置，可以针对该项目运行npm config。\n1 $ npm set save-exact true 上面命令设置加入模块时，package.json将记录模块的确切版本，而不是一个可选的版本范围。\nnpm config 1 $ npm config set prefix $dir 上面的命令将指定的$dir目录，设为模块的全局安装目录。如果当前有这个目录的写权限，那么运行npm install的时候，就不再需要sudo命令授权了。\n1 $ npm config set save-prefix \u0026#39;~\u0026#39; 上面的命令使得npm install --save和npm install --save-dev安装新模块时，允许的版本范围从克拉符号（^）改成波浪号（~），即从允许小版本升级，变成只允许补丁包的升级。\n1 2 $ npm config set init.author.name $name $ npm config set init.author.email $email 上面命令指定使用npm init时，生成的package.json文件的字段默认值。\nnpm info npm info命令可以查看每个模块的具体信息。比如，查看underscore模块的信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 $ npm info underscore { name: \u0026#39;underscore\u0026#39;, description: \u0026#39;JavaScript\\\u0026#39;s functional programming helper library.\u0026#39;, \u0026#39;dist-tags\u0026#39;: { latest: \u0026#39;1.5.2\u0026#39;, stable: \u0026#39;1.5.2\u0026#39; }, repository: { type: \u0026#39;git\u0026#39;, url: \u0026#39;git://github.com/jashkenas/underscore.git\u0026#39; }, homepage: \u0026#39;http://underscorejs.org\u0026#39;, main: \u0026#39;underscore.js\u0026#39;, version: \u0026#39;1.5.2\u0026#39;, devDependencies: { phantomjs: \u0026#39;1.9.0-1\u0026#39; }, licenses: { type: \u0026#39;MIT\u0026#39;, url: \u0026#39;https://raw.github.com/jashkenas/underscore/master/LICENSE\u0026#39; }, files: [ \u0026#39;underscore.js\u0026#39;, \u0026#39;underscore-min.js\u0026#39;, \u0026#39;LICENSE\u0026#39; ], readmeFilename: \u0026#39;README.md\u0026#39;} 上面命令返回一个JavaScript对象，包含了underscore模块的详细信息。这个对象的每个成员，都可以直接从info命令查询。\n1 2 3 4 5 6 7 8 $ npm info underscore description JavaScript\u0026#39;s functional programming helper library. $ npm info underscore homepage http://underscorejs.org $ npm info underscore version 1.5.2 npm search npm search命令用于搜索npm仓库，它后面可以跟字符串，也可以跟正则表达式。\n1 $ npm search \u0026lt;搜索词\u0026gt; 下面是一个例子。\n1 2 3 4 5 6 $ npm search node-gyp // NAME DESCRIPTION // autogypi Autogypi handles dependencies for node-gyp projects. // grunt-node-gyp Run node-gyp commands from Grunt. // gyp-io Temporary solution to let node-gyp run `rebuild` under… // ... npm list npm list命令以树型结构列出当前项目安装的所有模块，以及它们依赖的模块。\n1 $ npm list 加上global参数，会列出全局安装的模块。\n1 $ npm list -global npm list命令也可以列出单个模块。\n1 $ npm list underscore npm link 开发NPM模块的时候，有时我们会希望，边开发边试用，比如本地调试的时候，require('myModule')会自动加载本机开发中的模块。Node规定，使用一个模块时，需要将其安装到全局的或项目的node_modules目录之中。对于开发中的模块，解决方法就是在全局的node_modules目录之中，生成一个符号链接，指向模块的本地目录。\nnpm link就能起到这个作用，会自动建立这个符号链接。\n请设想这样一个场景，你开发了一个模块myModule，目录为src/myModule，你自己的项目myProject要用到这个模块，项目目录为src/myProject。首先，在模块目录（src/myModule）下运行npm link命令。\n1 src/myModule$ npm link 上面的命令会在NPM的全局模块目录内，生成一个符号链接文件，该文件的名字就是package.json文件中指定的模块名。\n1 /path/to/global/node_modules/myModule -\u0026gt; src/myModule 这个时候，已经可以全局调用myModule模块了。但是，如果我们要让这个模块安装在项目内，还要进行下面的步骤。\n切换到项目目录，再次运行npm link命令，并指定模块名。\n1 src/myProject$ npm link myModule 上面命令等同于生成了本地模块的符号链接。\n1 src/myProject/node_modules/myModule -\u0026gt; /path/to/global/node_modules/myModule 然后，就可以在你的项目中，加载该模块了。\n1 var myModule = require(\u0026#39;myModule\u0026#39;); 这样一来，myModule的任何变化，都可以直接反映在myProject项目之中。但是，这样也出现了风险，任何在myProject目录中对myModule的修改，都会反映到模块的源码中。\n如果你的项目不再需要该模块，可以在项目目录内使用npm unlink命令，删除符号链接。\n1 src/myProject$ npm unlink myModule npm bin npm bin命令显示相对于当前目录的，Node模块的可执行脚本所在的目录（即.bin目录）。\n1 2 3 # 项目根目录下执行 $ npm bin ./node_modules/.bin npm adduser npm adduser用于在npmjs.com注册一个用户。\n1 2 3 4 $ npm adduser Username: YOUR_USER_NAME Password: YOUR_PASSWORD Email: YOUR_EMAIL@domain.com npm publish npm publish用于将当前模块发布到npmjs.com。执行之前，需要向npmjs.com申请用户名。\n1 $ npm adduser 如果已经注册过，就使用下面的命令登录。\n1 $ npm login 登录以后，就可以使用npm publish命令发布。\n1 $ npm publish 如果当前模块是一个beta版，比如1.3.1-beta.3，那么发布的时候需要使用tag参数，将其发布到指定标签，默认的发布标签是latest。\n1 $ npm publish --tag beta 如果发布私有模块，模块初始化的时候，需要加上scope参数。只有npm的付费用户才能发布私有模块。\n1 $ npm init --scope=\u0026lt;yourscope\u0026gt; Scopes相当于npm模块的命名空间，scoped package的包名格式为：\n1 @scope/project-name 包名以@开头，介于@和/之间的为scope。\nScoped Package默认为私有模块，付费用户才能发布，不过发布时可以指定为公开模块，就不需要付费。\n1 $ npm publish --access=public 如果你的模块是用ES6写的，那么发布的时候，最好转成ES5。首先，需要安装Babel。\n1 $ npm install --save-dev babel-cli@6 babel-preset-es2015@6 然后，在package.json里面写入build脚本。\n1 2 3 4 \u0026#34;scripts\u0026#34;: { \u0026#34;build\u0026#34;: \u0026#34;babel source --presets babel-preset-es2015 --out-dir distribution\u0026#34;, \u0026#34;prepublish\u0026#34;: \u0026#34;npm run build\u0026#34; } 运行上面的脚本，会将source目录里面的ES6源码文件，转为distribution目录里面的ES5源码文件。然后，在项目根目录下面创建两个文件.npmignore和.gitignore，分别写入以下内容。\n1 2 3 4 5 6 // .npmignore source // .gitignore node_modules distribution npm deprecate 如果想废弃某个版本的模块，可以使用npm deprecate命令。\n1 $ npm deprecate my-thing@\u0026#34;\u0026lt; 0.2.3\u0026#34; \u0026#34;critical bug fixed in v0.2.3\u0026#34; 运行上面的命令以后，小于0.2.3版本的模块的package.json都会写入一行警告，用户安装这些版本时，这行警告就会在命令行显示。\nnpm owner 模块的维护者可以发布新版本。npm owner命令用于管理模块的维护者。\n1 2 3 4 5 6 7 8 # 列出指定模块的维护者 $ npm owner ls \u0026lt;package name\u0026gt; # 新增维护者 $ npm owner add \u0026lt;user\u0026gt; \u0026lt;package name\u0026gt; # 删除维护者 $ npm owner rm \u0026lt;user\u0026gt; \u0026lt;package name\u0026gt; 其他命令 npm home，npm repo npm home命令可以打开一个模块的主页，npm repo命令则是打开一个模块的代码仓库。\n1 2 $ npm home $package $ npm repo $package 这两个命令不需要模块先安装。\nnpm outdated npm outdated命令检查当前项目所依赖的模块，是否已经有新版本。\n1 2 3 4 $ npm outdated Package Current Wanted Latest Location normalize.css 4.0.0 4.2.0 5.0.0 photo-gallery 它会输出当前版本（current version）、应当安装的版本（wanted version）和最新发布的版本（latest version）。\nnpm prune npm prune检查当前项目的node_modules目录中，是否有package.json里面没有提到的模块，然后将所有这些模块输出在命令行。\n1 $ npm prune npm shrinkwrap npm shrinkwrap的作用是锁定当前项目的以来模块的版本。\n1 $ npm shrinkwrap 运行该命令后，会在当前项目的根目录下生成一个npm-shrinkwrap.json文件，内容是node_modules目录下所有已经安装模块的版本。\n下次运行npm install命令时，npm发现当前目录下有npm-shrinkwrap.json文件，就会只安装里面提到的模块，且版本也会保持一致。\n命令行参数 \u0026ndash;proxy --proxy参数允许对npm命令设置代理。\n1 2 3 4 $ npm --proxy http://127.0.0.1:8100 install # or $ npm config set proxy http://127.0.0.1:8100 $ npm install 上面的命令将通过本机的8100端口代理npm的通信。\n如果设置了环境变量HTTP-PROXY或者http-proxy和HTTPS-PROXY或者https-proxy，那么代理设置将以这个环境变量为准。\n\u0026ndash;registry --registry参数设置npm与之通信的远程主机，默认是https://registry.npmjs.org/。\n1 2 3 4 $ npm install --registry=https://registry.npm.taobao.org # or $ npm config set registry \u0026#34;https://registry.npm.taobao.org\u0026#34; $ npm install 上面的命令将远程主机设为npm的淘宝镜像。\n参考链接 James Halliday, task automation with npm run: npm run命令（package.json文件的script属性）的用法 Keith Cirkel, How to Use npm as a Build Tool justjs, npm link: developing your own npm modules without tears hoodie-css, Development Environment Help Stephan Bönnemann, How to make use of npm’s package distribution tags to create release channels Alex Booker, How to Build and Publish ES6 npm Modules Today, with Babel ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/basic/","summary":"概述 npm有两种含义。\n首先，npm 是一个网站，用来登记和管理 Node 的模块，网址为npmjs.org。\n其次，npm 是一个命令行软件，用来在用户的电脑上安装和管理 Node 模块。\n安装 npm不需要单独安装。安装 Node 的时候，会默认一起安装npm。\n但是，默认安装的npm可能不是最新版本。在 Node 安装成功后，最好用下面的命令，更新到最新版本。\n1 $ npm install npm@latest -g 然后，运行下面的命令，查看一下 npm 的版本。\n1 2 3 $ npm --version # 等同于 $ npm -v 下面三个命令，也可以用来获取帮助。\n1 2 3 4 5 6 7 8 # 查看 npm 命令列表 $ npm help # 查看各个命令的简单用法 $ npm -l # 查看 npm 的配置 $ npm config list -l npm init npm init用来初始化生成一个新的package.","title":"basic.md"},{"content":"安装 npm install 基本用法 npm install命令用于安装模块。npm i是该命令的别名。\n1 $ npm install lodash 上面命令在当前目录中安装了lodash模块。\n默认安装的是最新版本（即latest标签指向的版本），但是你可以 semver 表达式指定安装的版本。\n1 2 3 4 5 6 7 8 9 10 11 # 等同于 npm install lodash $ npm install lodash@latest # 指定确定的版本 $ npm install lodash@4.17.4 # 指定版本范围 $ npm install sax@\u0026#34;\u0026gt;=4.15.0 \u0026lt;4.18.0\u0026#34; # 指定大版本 $ npm install lodash@^4.0.0 上面最后一行命令，指定安装最新的4.x版。\n默认情况下，npm install不会修改package.json。--save或-S参数，将模块写入package.json的dependencies字段，--save-dev或-D，将模块加入package.json的devDependencies字段。\n1 2 3 4 5 6 7 # 将模块写入 package.json 的 dependencies 字段 $ npm install lodash --save $ npm install lodash -S # 将模块写入 package.json 的 devDependencies 字段 $ npm install lodash --save-dev $ npm install lodash -D 上面命令将模块写入package.json的时候，如果npm install没有指定版本，npm 会在安装的版本号前面添加^。比如，假定 lodash 的最新版是4.17.4，那么执行npm install -S lodash以后，package.json将写入的版本范围如下。\n1 2 3 4 \u0026#34;dependencies\u0026#34;: { \u0026#34;lodash\u0026#34;: \u0026#34;^4.17.4\u0026#34;, ... }, 上面的^4.17.4，表示兼容 4.17.4 以后的 4.x 版。\n如果不希望出现这种默认行为，可以使用--save-exact指定只将当前确定的版本号，写入package.json。\n1 2 3 $ npm install lodash --save --save-exact # 或者 $ npm install lodash --save-dev --save-exact 执行上面的命令以后，package.json里面的版本号将是固定的。\n1 2 3 4 \u0026#34;dependencies\u0026#34;: { \u0026#34;lodash\u0026#34;: \u0026#34;4.17.4\u0026#34;, ... }, 注意，--save-exact单独使用是无效的，必须与--save或--save-dev一起使用。\nnpm install也支持直接输入 Github 代码库地址。\n1 2 $ npm install git://github.com/package/path.git $ npm install git://github.com/package/path.git#0.1.0 全局安装 npm 还可以将模块安装在全局，供所有项目使用。注意，一般情况下，全局安装只适用于一些命令行工具。\n全局安装，要使用--global或-g参数。此时，加上--save、--save-exact、--save-dev都是无效的。\n1 2 3 $ npm install create-react-app --global # 或者 $ npm install create-react-app -g 上面命令全局安装create-react-app模块。\n安装机制与重装 本地安装后，模块将存放在当前项目的node_modules子目录，然后只有在项目目录之中，才能调用这个模块。全局安装后，模块将存放在全局目录之中（通常是/usr/local/lib/），所有项目都可以调用这个模块，但是不应该这样做。\n安装之前，npm install会先检查，node_modules目录之中是否已经存在指定模块。如果存在，就不再重新安装了，即使远程仓库已经有了一个新版本，也是如此。\n如果你希望，一个模块不管是否安装过，npm 都要强制重新安装，可以使用-f或--force参数。\n1 $ npm install lodash --force 如果所有模块都要强制重新安装，那就删除node_modules目录，重新执行npm install。\n1 2 $ rm -rf node_modules $ npm install 安装项目依赖 不使用任何参数时，只使用npm install，会默认安装package.json里面的dependencies字段和devDependencies字段列出的所有模块。\n1 $ npm install 如果使用--production参数，可以只安装dependencies字段的模块。\n1 2 3 $ npm install --production # 等同于 $ NODE_ENV=production npm install 避免安装权限 默认情况下，npm 全局模块都安装在系统目录（比如/usr/local/lib/），普通用户没有写入权限，需要用到sudo命令。这不是很方便，我们可以在没有 root 权限的情况下，安装全局模块。\n首先，在主目录下新建配置文件.npmrc，在该文件中将prefix变量定义到一个你的个人目录下面（假定该目录是~/my-npm-modules）。\n1 prefix = /home/yourUsername/my-npm-modules 此后，全局安装的模块都会安装在这个子目录中，npm也会到~/my-npm-modules/bin目录去寻找命令。\n最后，将这个路径在.bash_profile文件（或.bashrc文件）中加入PATH变量。\n1 export PATH=~/my-npm-modules/bin:$PATH npm update npm update命令可以更新本地安装的模块到最新版本（符合 semver 的设置），如果该模块没有安装，则会安装该模块。npm up和npm upgrade是该命令的缩写。\n1 2 3 4 5 # 升级当前项目的某个模块 $ npm update lodash # 升级全局安装的某个模块 $ npm update -g lodash 不使用任何参数时，将更新当前项目的所有dependencies字段里面的模块。如果有模块没有安装，也将一起安装。\n1 $ npm update --dev参数会连带安装和更新devDependencies字段里面的模块。\n1 $ npm update --dev 更新时，会先到远程仓库查询最新版本，然后查询本地版本。如果本地版本不存在，或者远程版本较新，就会安装最新版本。\n使用-S或--save参数，可以在安装的同时，更新package.json里面模块的版本号。\n1 2 3 4 5 6 7 8 9 // 更新之前的package.json dependencies: { dep1: \u0026#34;^1.1.1\u0026#34; } // 更新之后的package.json dependencies: { dep1: \u0026#34;^1.2.2\u0026#34; } 注意，从 npm v2.6.1 开始，npm update只更新顶层模块，而不更新依赖的依赖，以前版本是递归更新的。如果想取到老版本的效果，要使用下面的命令。\n1 $ npm --depth 9999 update 注意，如果已经安装的模块版本比 semver 指定的版本更加新时，npm update有降级效果。\nnpm uninstall npm uninstall命令，用来卸载已安装的模块。npm remove、npm rm、npm r、npm un和npm unlink，都是该命令的别名。\n1 2 3 4 5 6 # 卸载项目模块 $ npm uninstall lodash # 卸载全局模块 $ npm uninstall lodash --global $ npm uninstall lodash -g 使用--save参数（或-S），该模块将会从package.json的dependencies字段中移除。使用--save-dev参数（或-D）时，该模块将会从package.json的devDependencies字段中移除。\n1 2 $ npm uninstall lodash --save $ npm uninstall lodash --save-dev package-lock.json 从 npm 5.0 版本开始，npm 模块默认会锁版本。在npm install命令安装依赖时，会自动生成package-lock.json文件，如果该文件已存在，则会更新该文件。下面是package-lock.json的一个例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 { \u0026#34;name\u0026#34;: \u0026#34;react-example\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;lockfileVersion\u0026#34;: 1, \u0026#34;dependencies\u0026#34;: { \u0026#34;has-flag\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;resolved\u0026#34;: \u0026#34;https://registry.npmjs.org/has-flag/-/has-flag-1.0.0.tgz\u0026#34;, \u0026#34;integrity\u0026#34;: \u0026#34;sha1-nZ55MWXOAXoA8AQYxD+UKnsdEfo=\u0026#34; }, \u0026#34;supports-color\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;3.2.3\u0026#34;, \u0026#34;resolved\u0026#34;: \u0026#34;https://registry.npmjs.org/supports-color/-/supports-color-3.2.3.tgz\u0026#34;, \u0026#34;integrity\u0026#34;: \u0026#34;sha1-ZawFBLOVQXHYpklGsq48u4pfVPY=\u0026#34; }, \u0026#34;duplexify\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;3.5.0\u0026#34;, \u0026#34;resolved\u0026#34;: \u0026#34;https://registry.npmjs.org/duplexify/-/duplexify-3.5.0.tgz\u0026#34;, \u0026#34;integrity\u0026#34;: \u0026#34;sha1-GqdzAC4VeEV+nZ1KULDMquvL1gQ=\u0026#34;, \u0026#34;dependencies\u0026#34;: { \u0026#34;end-of-stream\u0026#34;: { \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, \u0026#34;resolved\u0026#34;: \u0026#34;https://registry.npmjs.org/end-of-stream/-/end-of-stream-1.0.0.tgz\u0026#34;, \u0026#34;integrity\u0026#34;: \u0026#34;sha1-1FlucCc0qT5A6a+GQxnqvZn/Lw4=\u0026#34; } } } } } 这个文件不仅指定了每个模块的精确版本，而且还指定了node_modules目录的结构（即哪些模块要安装在目录的顶层）。也就是说，哪怕你使用不同版本的 npm，只要有这个文件，最后得到的总是同样的node_modules目录。可以理解成，这个文件是node_modules目录的一个快照。\n上面的例子中可以看到，每个目录不仅有精确版本（version字段），还有下载地址（resolved字段）、哈希值（integrity字段）和依赖模块（dependencies字段）。\npackage-lock.json文件的lockfileVersion字段目前固定为1，以前的npm-shrinkwrap.json文件对应的lockfileVersion为0。这表明，前者实际上是后者的升级版。之所以叫一个新名字，是因为想表明这是一种全新的锁版本设计。\npackage-lock.json与npm-shrinkwrap.json有一些区别。首先，npm 在任何情况下，都不会将package-lock.json加入发布的代码之中。然后，在一个有package-lock.json的目录之中，执行npm shrinkwrap命令时，npm 会自动将package-lock.json改名为npm-shrinkwrap.json。\n如果同一个目录之中，同时存在package-lock.json与npm-shrinkwrap.json两个文件。这时，npm 会忽略package-lock.json，只使用npm-shrinkwrap.json。\n","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/install/","summary":"安装 npm install 基本用法 npm install命令用于安装模块。npm i是该命令的别名。\n1 $ npm install lodash 上面命令在当前目录中安装了lodash模块。\n默认安装的是最新版本（即latest标签指向的版本），但是你可以 semver 表达式指定安装的版本。\n1 2 3 4 5 6 7 8 9 10 11 # 等同于 npm install lodash $ npm install lodash@latest # 指定确定的版本 $ npm install lodash@4.17.4 # 指定版本范围 $ npm install sax@\u0026#34;\u0026gt;=4.15.0 \u0026lt;4.18.0\u0026#34; # 指定大版本 $ npm install lodash@^4.0.0 上面最后一行命令，指定安装最新的4.x版。\n默认情况下，npm install不会修改package.json。--save或-S参数，将模块写入package.json的dependencies字段，--save-dev或-D，将模块加入package.json的devDependencies字段。\n1 2 3 4 5 6 7 # 将模块写入 package.json 的 dependencies 字段 $ npm install lodash --save $ npm install lodash -S # 将模块写入 package.","title":"install.md"},{"content":"npm exec 命令 npm exec用来执行某个 npm 模块的内部命令，不管该模块在本地还是在远程。它有一个别名x，即npm exec等同于npm x。\n该命令与npx命令的作用类似，但是使用上有所不同。\nnpx会将所有参数原样传入模块内部。\n1 2 3 $ npx foo@latest bar --param=@npmcli/foo # 等同于 $ foo bar --param=@npmcli/foo npm exec则需要使用--分隔符，指定所要执行的命令和它的参数。\n1 2 3 $ npm exec -- foo@latest bar --param=@npmcli/foo # 等同于 $ foo bar --param=@npmcli/foo npm exec也可以用--package参数指定模块。\n1 2 3 $ npm exec --package=foo -- bar --bar-argument # 等同于 $ npx --package=foo bar --bar-argument --call或-c参数用来指定执行的整个命令。\n1 2 3 $ npm exec -c \u0026#39;eslint \u0026amp;\u0026amp; say \u0026#34;hooray, lint passed\u0026#34;\u0026#39; # 等同于 $ npx -c \u0026#39;eslint \u0026amp;\u0026amp; say \u0026#34;hooray, lint passed\u0026#34;\u0026#39; ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-exec/","summary":"npm exec 命令 npm exec用来执行某个 npm 模块的内部命令，不管该模块在本地还是在远程。它有一个别名x，即npm exec等同于npm x。\n该命令与npx命令的作用类似，但是使用上有所不同。\nnpx会将所有参数原样传入模块内部。\n1 2 3 $ npx foo@latest bar --param=@npmcli/foo # 等同于 $ foo bar --param=@npmcli/foo npm exec则需要使用--分隔符，指定所要执行的命令和它的参数。\n1 2 3 $ npm exec -- foo@latest bar --param=@npmcli/foo # 等同于 $ foo bar --param=@npmcli/foo npm exec也可以用--package参数指定模块。\n1 2 3 $ npm exec --package=foo -- bar --bar-argument # 等同于 $ npx --package=foo bar --bar-argument --call或-c参数用来指定执行的整个命令。\n1 2 3 $ npm exec -c \u0026#39;eslint \u0026amp;\u0026amp; say \u0026#34;hooray, lint passed\u0026#34;\u0026#39; # 等同于 $ npx -c \u0026#39;eslint \u0026amp;\u0026amp; say \u0026#34;hooray, lint passed\u0026#34;\u0026#39; ","title":"npm-exec.md"},{"content":"npm init 命令 npm init命令的作用，是生成package.json文件。它的别名是create。\n新建一个目录，作为模块的开发目录。进入该目录，执行npm init，屏幕上会依次出现一些问题，要求用户回答。用户回答以后，就会生成package.json文件。\n1 $ npm init 如果觉得回答问题太麻烦，想使用package.json的默认值，那就使用--yes或-y参数。\n1 2 3 $ npm init --yes # 或者 $ npm init -y 如果想设置package.json的一些默认值（作者、Email、许可证），需要提前用npm set命令设置。\n1 2 3 $ npm set init-author-email \u0026#34;example-user@example.com\u0026#34; $ npm set init-author-name \u0026#34;example_user\u0026#34; $ npm set init-license \u0026#34;MIT\u0026#34; npm init也可以格式化创建项目。\n1 2 3 $ npm init foo # 等同于 $ npm exec create-foo 上面的npm init foo这条命令，会去执行create-foo这个模块（package.json的bin属性）。\n举例来说，如果要执行create-react-app创建一个 React 项目，可以执行下面的命令。\n1 $ npm init react-app ./my-react-app 这种用法时，往往使用npm init命令的别名npm create。\n1 2 3 4 5 6 7 $ npm create xyz // 等同于 $ npm init xyz // 等同于 $ npx create-xyz ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-init/","summary":"npm init 命令 npm init命令的作用，是生成package.json文件。它的别名是create。\n新建一个目录，作为模块的开发目录。进入该目录，执行npm init，屏幕上会依次出现一些问题，要求用户回答。用户回答以后，就会生成package.json文件。\n1 $ npm init 如果觉得回答问题太麻烦，想使用package.json的默认值，那就使用--yes或-y参数。\n1 2 3 $ npm init --yes # 或者 $ npm init -y 如果想设置package.json的一些默认值（作者、Email、许可证），需要提前用npm set命令设置。\n1 2 3 $ npm set init-author-email \u0026#34;example-user@example.com\u0026#34; $ npm set init-author-name \u0026#34;example_user\u0026#34; $ npm set init-license \u0026#34;MIT\u0026#34; npm init也可以格式化创建项目。\n1 2 3 $ npm init foo # 等同于 $ npm exec create-foo 上面的npm init foo这条命令，会去执行create-foo这个模块（package.json的bin属性）。\n举例来说，如果要执行create-react-app创建一个 React 项目，可以执行下面的命令。\n1 $ npm init react-app .","title":"npm-init.md"},{"content":"npm link 命令 有时候，我们在本地修改了一些模块，想先测试这些修改是否有效。那么，怎么才能让依赖于该模块的应用，能够加载这些本地模块呢？\n一种方法是使用npm install的--save参数。\n1 $ npm install --no-save \u0026lt;模块的本地路径h\u0026gt; 上面的命令会从本地目录安装指定模块，但是不写入package.json。这样就可以让应用加载本地模块。\n另一种则是使用npm link命令，在node_modules目录里面建立一个符号链接，链接到本地模块。\n它分成两步，第一步先在本地模块的目录里，执行npm link。\n1 $ npm link 第二步是到你的应用目录，执行npm link \u0026lt;本地模块名\u0026gt;，在node_modules目录里面产生本地模块的符号链接。\n1 $ npm link \u0026lt;本地模块名\u0026gt; 也可以将上面两步合二为一，在应用目录里面，直接链接本地模块的路径。\n1 $ npm link \u0026lt;本地模块的路径\u0026gt; 等到测试完毕，再用npm unlink命令，先在应用目录删除符号链接。\n1 $ npm unlink --no-save \u0026lt;本地模块名\u0026gt; 再到本地模块的目录里面，执行npm unlink。\n1 $ npm unlink ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-link/","summary":"npm link 命令 有时候，我们在本地修改了一些模块，想先测试这些修改是否有效。那么，怎么才能让依赖于该模块的应用，能够加载这些本地模块呢？\n一种方法是使用npm install的--save参数。\n1 $ npm install --no-save \u0026lt;模块的本地路径h\u0026gt; 上面的命令会从本地目录安装指定模块，但是不写入package.json。这样就可以让应用加载本地模块。\n另一种则是使用npm link命令，在node_modules目录里面建立一个符号链接，链接到本地模块。\n它分成两步，第一步先在本地模块的目录里，执行npm link。\n1 $ npm link 第二步是到你的应用目录，执行npm link \u0026lt;本地模块名\u0026gt;，在node_modules目录里面产生本地模块的符号链接。\n1 $ npm link \u0026lt;本地模块名\u0026gt; 也可以将上面两步合二为一，在应用目录里面，直接链接本地模块的路径。\n1 $ npm link \u0026lt;本地模块的路径\u0026gt; 等到测试完毕，再用npm unlink命令，先在应用目录删除符号链接。\n1 $ npm unlink --no-save \u0026lt;本地模块名\u0026gt; 再到本地模块的目录里面，执行npm unlink。\n1 $ npm unlink ","title":"npm-link.md"},{"content":"npm tag npm 允许为版本添加标签，方便用户安装特定版本。只要指定标签，就可以安装该标签下的最新版本。\n发布模块时，如果不指定 tag，默认使用latest。安装时也是如此，不指定版本时，npm 默认安装latest标签对应的最新版本。\n如果指定 tag，发布时会将该 tag 指向最新发布的版本。用户如果想安装该版本，需要在安装时指定 tag。\n1 $ npm publish --tag beta 上面示例中，新发布版本的标签是beta。\n下面的命令为已发布的版本指定标签。注意，这一步之前不需要先移除已经存在的标签。\n1 2 3 4 5 # 语法 $ npm dist-tag add [PackageName]@[Version] [Tag] # 例子 $ npm dist-tag add foo-package@0.0.0 latest 安装时指定标签。\n1 2 3 $ npm install \u0026lt;package\u0026gt;@\u0026lt;tag\u0026gt; # 或者 $ npm install --tag \u0026lt;tag\u0026gt; 下面的命令查看所有 tag 和对应的版本。\n1 2 3 $ npm dist-tag ls # 或者 $ npm view [模块名] dist-tags 删除已经发布的标签。\n1 $ npm dist-tag rm [PackageName] [Tag] ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-tag/","summary":"npm tag npm 允许为版本添加标签，方便用户安装特定版本。只要指定标签，就可以安装该标签下的最新版本。\n发布模块时，如果不指定 tag，默认使用latest。安装时也是如此，不指定版本时，npm 默认安装latest标签对应的最新版本。\n如果指定 tag，发布时会将该 tag 指向最新发布的版本。用户如果想安装该版本，需要在安装时指定 tag。\n1 $ npm publish --tag beta 上面示例中，新发布版本的标签是beta。\n下面的命令为已发布的版本指定标签。注意，这一步之前不需要先移除已经存在的标签。\n1 2 3 4 5 # 语法 $ npm dist-tag add [PackageName]@[Version] [Tag] # 例子 $ npm dist-tag add foo-package@0.0.0 latest 安装时指定标签。\n1 2 3 $ npm install \u0026lt;package\u0026gt;@\u0026lt;tag\u0026gt; # 或者 $ npm install --tag \u0026lt;tag\u0026gt; 下面的命令查看所有 tag 和对应的版本。\n1 2 3 $ npm dist-tag ls # 或者 $ npm view [模块名] dist-tags 删除已经发布的标签。","title":"npm-tag.md"},{"content":"npm token npm token命令用来管理认证令牌。\nnpm token list命令列出所有激活的认证令牌。\n1 $ npm token list 上面命令的返回结果，以表格形式显示。如果加上--json参数，则返回 JSON 格式；加上--parseable参数，返回 Tab 键分隔的数据。\nnpm token create命令生成一个新的认证令牌。\n1 $ npm token create --read-only参数用来生成只读令牌，默认是读写令牌。--cidr=\u0026lt;cidr-ranges\u0026gt;参数用来指定令牌生效的 IP 地址范围。\nnpm token revoke命令收回令牌。\n1 $ npm token revoke \u0026lt;token|id\u0026gt; ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/npm/npm-token/","summary":"npm token npm token命令用来管理认证令牌。\nnpm token list命令列出所有激活的认证令牌。\n1 $ npm token list 上面命令的返回结果，以表格形式显示。如果加上--json参数，则返回 JSON 格式；加上--parseable参数，返回 Tab 键分隔的数据。\nnpm token create命令生成一个新的认证令牌。\n1 $ npm token create --read-only参数用来生成只读令牌，默认是读写令牌。--cidr=\u0026lt;cidr-ranges\u0026gt;参数用来指定令牌生效的 IP 地址范围。\nnpm token revoke命令收回令牌。\n1 $ npm token revoke \u0026lt;token|id\u0026gt; ","title":"npm-token.md"},{"content":"定时器 process.nextTick()会立即执行回调函数。 微任务队列。\nsetImmediate()， clearImmediate() setImmediate(). It can be passed to clearImmediate()\nsetImmediate()会在下一轮执行回调函数。\n定时器在 IO 操作的回调函数之前执行。\nTimer: setTimeout和setInterval回调函数。 I/O callbacks: 处理除了setTimeout、setInterval、setImmediate的回调函数。 Check: 处理setImmediate()指定的回调函数。 nextTickQueue: 处理process.nextTick()的回调函数，不是 event loop 的一部分。 ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/timer/","summary":"定时器 process.nextTick()会立即执行回调函数。 微任务队列。\nsetImmediate()， clearImmediate() setImmediate(). It can be passed to clearImmediate()\nsetImmediate()会在下一轮执行回调函数。\n定时器在 IO 操作的回调函数之前执行。\nTimer: setTimeout和setInterval回调函数。 I/O callbacks: 处理除了setTimeout、setInterval、setImmediate的回调函数。 Check: 处理setImmediate()指定的回调函数。 nextTickQueue: 处理process.nextTick()的回调函数，不是 event loop 的一部分。 ","title":"timer"},{"content":"fs 模块 fs.createReadStream() fs.createReadStream方法读取一个文件，以 stream 的形式返回。\n1 2 3 4 const readStream = fs.createReadStream( inputFilePath, { encoding: \u0026#39;utf8\u0026#39;, highWaterMark: 1024 } ); 该方法的第一个参数是文件的路径，第二个参数是一个配置对象。\n配置对象的encoding属性，决定了fs.createReadStream方法的返回值。如果该属性为null，返回的是二进制的 buffer；如果为字符串（比如utf8），返回的是这种编码的字符串。\n配置对象的highWaterMark属性指定了每次返回的 buffer 或字符串的最大体积（单位字节）。\nstream 以事件的形式获取。\n1 2 3 4 5 6 readStream.on(\u0026#39;data\u0026#39;, (chunk) =\u0026gt; { console.log(\u0026#39;\u0026gt;\u0026gt;\u0026gt; \u0026#39;+chunk); }); readStream.on(\u0026#39;end\u0026#39;, () =\u0026gt; { console.log(\u0026#39;### DONE ###\u0026#39;); }); Node v10 开始，Stream 有异步遍历器（asynchronous iteration）接口（即具有Symbol.asyncIterator属性），因此可以使用for-await-of读取。\n1 2 3 4 5 6 7 8 9 async function main(inputFilePath) { const readStream = fs.createReadStream(inputFilePath, { encoding: \u0026#39;utf8\u0026#39;, highWaterMark: 1024 }); for await (const chunk of readStream) { console.log(\u0026#39;\u0026gt;\u0026gt;\u0026gt; \u0026#39;+chunk); } console.log(\u0026#39;### DONE ###\u0026#39;); } 参考链接 Using async iteration natively in Node.js, by Axel Rauschmayer ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/fs/","summary":"fs 模块 fs.createReadStream() fs.createReadStream方法读取一个文件，以 stream 的形式返回。\n1 2 3 4 const readStream = fs.createReadStream( inputFilePath, { encoding: \u0026#39;utf8\u0026#39;, highWaterMark: 1024 } ); 该方法的第一个参数是文件的路径，第二个参数是一个配置对象。\n配置对象的encoding属性，决定了fs.createReadStream方法的返回值。如果该属性为null，返回的是二进制的 buffer；如果为字符串（比如utf8），返回的是这种编码的字符串。\n配置对象的highWaterMark属性指定了每次返回的 buffer 或字符串的最大体积（单位字节）。\nstream 以事件的形式获取。\n1 2 3 4 5 6 readStream.on(\u0026#39;data\u0026#39;, (chunk) =\u0026gt; { console.log(\u0026#39;\u0026gt;\u0026gt;\u0026gt; \u0026#39;+chunk); }); readStream.on(\u0026#39;end\u0026#39;, () =\u0026gt; { console.log(\u0026#39;### DONE ###\u0026#39;); }); Node v10 开始，Stream 有异步遍历器（asynchronous iteration）接口（即具有Symbol.asyncIterator属性），因此可以使用for-await-of读取。\n1 2 3 4 5 6 7 8 9 async function main(inputFilePath) { const readStream = fs.","title":"fs"},{"content":"Promise UnhandledPromiseRejectionWarning 如果 Promise 运行过程中抛出错误，或者状态变为rejected，但是没有相应的处理代码，那么 Node 会抛出一个警告UnhandledPromiseRejectionWarning。\n1 2 3 4 5 6 new Promise(function (resolve, reject) { reject(\u0026#39;message\u0026#39;); console.log(\u0026#39;hello\u0026#39;); }) // hello // UnhandledPromiseRejectionWarning: message 上面代码中，Promise 变为rejected状态，但是没有处理的代码，导致抛出警告UnhandledPromiseRejectionWarning。由于抛出的是警告，而不是错误，所以不影响hello的输出。请跟下面的代码比较一下。\n1 2 3 4 5 new Promise(function (resolve, reject) { throw new Error(\u0026#39;message\u0026#39;); console.log(\u0026#39;hello\u0026#39;); }) // UnhandledPromiseRejectionWarning: Error: message 上面代码中，Promise 内部抛出错误，没有得到处理，所以会有警告UnhandledPromiseRejectionWarning。Promise 内部的错误阻止 Promise 内部的代码继续向下运行，所以不会输出hello。\n消除这个警告的方法很简单，就是为 Promise 加上错误处理代码，即catch代码块。\n1 2 3 4 5 6 new Promise(function (resolve, reject) { reject(\u0026#39;message\u0026#39;); console.log(\u0026#39;hello\u0026#39;); }).catch(function (err) { console.log (err) }) // hello // message 上面代码中，由于catch代码块的存在，所以不会抛出警告。\nasync 函数里面使用 Promise，也要放在try/catch代码块之中。\n1 2 3 4 5 6 7 8 9 10 11 12 const p = new Promise(function (resolve, reject) { reject(\u0026#39;message\u0026#39;); }); (async function () { try { await p; } catch (err) { console.log(err); } })(); // message 上面代码中，如果 Promise 没有放在try/catch代码块，就会抛出警告UnhandledPromiseRejectionWarning。\nNode 还提供process对象的unhandledRejection事件，在抛出警告UnhandledPromiseRejectionWarning之前，就会触发这个事件。如果设置了这个事件的处理代码，就不会抛出警告UnhandledPromiseRejectionWarning。\n1 2 3 4 5 6 7 8 new Promise(function (resolve, reject) { reject(\u0026#39;message\u0026#39;); }); process.on(\u0026#39;unhandledRejection\u0026#39;, function (err) { console.log(err); }); // message Node 开发团队打算废除UnhandledPromiseRejectionWarning，以后如果没有相应的处理代码，Promise 内部抛错或者变为rejected状态，会导致 Node 进程终止执行，并且有一个非零的返回码。所以应该养成习惯，只要有 Promise，就要部署失败情况下的代码。\n","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/promise/","summary":"Promise UnhandledPromiseRejectionWarning 如果 Promise 运行过程中抛出错误，或者状态变为rejected，但是没有相应的处理代码，那么 Node 会抛出一个警告UnhandledPromiseRejectionWarning。\n1 2 3 4 5 6 new Promise(function (resolve, reject) { reject(\u0026#39;message\u0026#39;); console.log(\u0026#39;hello\u0026#39;); }) // hello // UnhandledPromiseRejectionWarning: message 上面代码中，Promise 变为rejected状态，但是没有处理的代码，导致抛出警告UnhandledPromiseRejectionWarning。由于抛出的是警告，而不是错误，所以不影响hello的输出。请跟下面的代码比较一下。\n1 2 3 4 5 new Promise(function (resolve, reject) { throw new Error(\u0026#39;message\u0026#39;); console.log(\u0026#39;hello\u0026#39;); }) // UnhandledPromiseRejectionWarning: Error: message 上面代码中，Promise 内部抛出错误，没有得到处理，所以会有警告UnhandledPromiseRejectionWarning。Promise 内部的错误阻止 Promise 内部的代码继续向下运行，所以不会输出hello。\n消除这个警告的方法很简单，就是为 Promise 加上错误处理代码，即catch代码块。\n1 2 3 4 5 6 new Promise(function (resolve, reject) { reject(\u0026#39;message\u0026#39;); console.log(\u0026#39;hello\u0026#39;); }).catch(function (err) { console.","title":"promise"},{"content":"Node 的 REPL 环境 简介 REPL 是 read-eval-print-loop 的缩写，表示命令行下的 Node 引擎的一个互动式对话环境。用户在其中输入命令，就可以立刻看到结果。read 表示读取用户的输入，eval 表示执行，print 表示输出运行的结果，loop 表示重复执行这个过程。\n命令行下输入node，就可以进入 Node 的 REPL 环境。\n1 2 $ node \u0026gt; REPL 环境的提示符是一个大于号（\u0026gt;）。\n退出 REPL，可以在行首按下 Ctrl + d，或者连续两次按下 Ctrl + c。\nREPL 环境与 Node 脚本的执行环境基本相似，只有一些很小的差异。比如，REPL 环境不是通过脚本触发的，所以没有__dirname和__filename这两个内置变量。\nREPL 会自动加载 Node 的核心模块，比如 fs、http、os、path等，不必require就可以直接使用。\n1 2 3 $ node \u0026gt; fs.read [Function] 上面代码中，REPL 环境可以直接使用fs.read方法，不必先加载fs模块。\nnode命令的-e参数，实际上就是在 REPL 环境运行代码。\n1 2 $ node -e \u0026#34;console.log(os.platform())\u0026#34; darwin _变量 REPL 环境下，有一个内置变量_，上一个表达式的值就存放在这个变量之中。\n1 2 3 4 \u0026gt; require(\u0026#39;./example\u0026#39;); { some: \u0026#39;some text\u0026#39; } \u0026gt; _.some \u0026#39;some text\u0026#39; 上面代码中，require()方法加载了一个脚本，这行表达式的值就自动存放在_里面。\nREPL 允许用户对_变量赋值。\n1 2 3 4 \u0026gt; _ = \u0026#39;something\u0026#39; \u0026#39;something\u0026#39; \u0026gt; _ \u0026#39;something\u0026#39; 上面代码中，我们将something赋值给_，这时_就是一个普通变量了。\n.editor 命令 REPL 环境下，按下回车键，就会提交并执行当前的输入。这对输入多行的代码非常不方便，有两个办法可以输入多行代码。一个是按 Shift + 回车键，另一个是使用.editor命令，键入编辑模式。\n1 2 3 4 5 6 \u0026gt; .editor function sum(a, b) { return a + b; } sum(5, 4); 输入.editor命令后，就可以输入多行文本。输入完成后，按下 Ctrl + d 就会执行这些代码；按下 Ctrl + c 就会取消本次输入，回到输入.editor之前的状态。\n特殊命令 除了.editor命令以外，REPL 还提供其他一些命令。\n.break：按下 Shift + 回车进入多行文本输入的过程中，输入.break命令会取消本次输入，相当于按下 Ctrl + c。 .clear：重置 REPL 上下文为空，并清除当前输入的多行文本。 .exit：关闭当前的 I/O 读写，退出 REPL 环境。 .help：显示 REPL 环境的特殊命令列表。 .save：将当前的 REPL 对换保存成一个文件，比如.save ./file/to/save.js。 .load：加载一个文件进入当前的 REPL 对话，比如.load ./file/to/load.js。 repl 模块 Node 提供repl模块，可以在脚本中唤起 REPL 环境。\n1 2 3 4 5 // repl.js const repl = require(\u0026#39;repl\u0026#39;); // Our own prompt repl.start(\u0026#39;Code:: \u0026#39;); 上面代码中，repl.start()方法用于唤起 REPL 环境，该方法的参数是自定义的 REPL 环境提示符。执行上面的脚本，就会出现这个提示符。\n1 2 $ node repl.js Code:: 这个模块允许开发者向 REPL 环境注入变量，因此可以做很多事情。\n1 2 3 4 // repl.js const repl = require(\u0026#39;repl\u0026#39;); const r = repl.start(\u0026#39;Code:: \u0026#39;); r.context.sum = (...args) =\u0026gt; args.reduce((a, b) =\u0026gt; a + b, 0); 上面代码向 REPL 环境输入了一个sum函数。\n1 2 3 4 $ node repl.js Code:: sum(1, 2, 3) 6 Code:: .exit 参考链接 Node.js REPL in Depth, by Seva Zaikov ","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/repl/","summary":"Node 的 REPL 环境 简介 REPL 是 read-eval-print-loop 的缩写，表示命令行下的 Node 引擎的一个互动式对话环境。用户在其中输入命令，就可以立刻看到结果。read 表示读取用户的输入，eval 表示执行，print 表示输出运行的结果，loop 表示重复执行这个过程。\n命令行下输入node，就可以进入 Node 的 REPL 环境。\n1 2 $ node \u0026gt; REPL 环境的提示符是一个大于号（\u0026gt;）。\n退出 REPL，可以在行首按下 Ctrl + d，或者连续两次按下 Ctrl + c。\nREPL 环境与 Node 脚本的执行环境基本相似，只有一些很小的差异。比如，REPL 环境不是通过脚本触发的，所以没有__dirname和__filename这两个内置变量。\nREPL 会自动加载 Node 的核心模块，比如 fs、http、os、path等，不必require就可以直接使用。\n1 2 3 $ node \u0026gt; fs.read [Function] 上面代码中，REPL 环境可以直接使用fs.read方法，不必先加载fs模块。\nnode命令的-e参数，实际上就是在 REPL 环境运行代码。\n1 2 $ node -e \u0026#34;console.log(os.platform())\u0026#34; darwin _变量 REPL 环境下，有一个内置变量_，上一个表达式的值就存放在这个变量之中。\n1 2 3 4 \u0026gt; require(\u0026#39;.","title":"repl"},{"content":"this 变量 Node 应用的顶层变量是global，对应浏览器的window变量。\n顶层的 this 在 REPL 环境，顶层的this就指向global。\n1 2 \u0026gt; global === this true 顶层变量是global和this的属性。\n1 2 3 4 5 \u0026gt; var foo = \u0026#34;bar\u0026#34;; \u0026gt; this.foo bar \u0026gt; global.foo bar 上面代码中，foo是一个顶层变量，自动生成了this.foo和global.foo两个属性。\n在模块环境，顶层的this指向当前模块，即module.exports，默认是一个空对象，与global不是同一个对象。\n1 2 3 // 模块环境 console.log(this) // {} console.log(this === global) // false 模块内部的顶层变量，不会自动成为global和this的属性。\n1 2 3 4 // 模块环境 var foo = \u0026#34;bar\u0026#34;; console.log(this.foo); // undefined console.log(global.foo); // undefined 上面代码中，顶层变量foo并不会生成this.foo和global.foo两个属性。这是因为foo是模块内部的变量，不是全局有效，因此不是global的属性，而this是当前的模块对象，this.foo代表模块实例的属性，这跟变量foo是两回事情。\n另外，如果声明变量的时候，不使用var命令，而是直接赋值，那么该变量在 REPL 环境下将成为global和this的属性，在模块环境将只成为 global 的属性。\n1 2 3 4 5 6 7 8 9 10 11 // REPL 环境 \u0026gt; foo = \u0026#34;bar\u0026#34;; \u0026gt; global.foo bar \u0026gt; this.foo bar // 模块环境 foo = \u0026#34;bar\u0026#34;; console.log(this.foo); // undefined console.log(global.foo); // bar 函数内部的 this 直接执行一个函数（不使用new命令），函数内部的this指向global，REPL 环境和模块环境都是如此。\n1 2 3 4 5 6 7 8 9 foo = \u0026#34;bar\u0026#34;; function testThis () { this.foo = \u0026#34;foo\u0026#34;; } console.log(global.foo); // bar testThis(); console.log(global.foo); // foo 如果是严格模式，函数内部的this返回undefined。\n1 2 3 4 5 6 7 8 9 foo = \u0026#34;bar\u0026#34;; function testThis() { \u0026#34;use strict\u0026#34;; this.foo = \u0026#34;foo\u0026#34;; } console.log(this.foo); // \u0026#34;bar\u0026#34; testThis(); // TypeError: Cannot set property \u0026#39;foo\u0026#39; of undefined 如果使用new命令调用某个函数，该函数就变成了构造函数，函数内部的this指向新建的实例对象。\n","permalink":"https://WFUing.github.io/posts/tech/language/nodejs/module/this/","summary":"this 变量 Node 应用的顶层变量是global，对应浏览器的window变量。\n顶层的 this 在 REPL 环境，顶层的this就指向global。\n1 2 \u0026gt; global === this true 顶层变量是global和this的属性。\n1 2 3 4 5 \u0026gt; var foo = \u0026#34;bar\u0026#34;; \u0026gt; this.foo bar \u0026gt; global.foo bar 上面代码中，foo是一个顶层变量，自动生成了this.foo和global.foo两个属性。\n在模块环境，顶层的this指向当前模块，即module.exports，默认是一个空对象，与global不是同一个对象。\n1 2 3 // 模块环境 console.log(this) // {} console.log(this === global) // false 模块内部的顶层变量，不会自动成为global和this的属性。\n1 2 3 4 // 模块环境 var foo = \u0026#34;bar\u0026#34;; console.log(this.foo); // undefined console.log(global.foo); // undefined 上面代码中，顶层变量foo并不会生成this.foo和global.foo两个属性。这是因为foo是模块内部的变量，不是全局有效，因此不是global的属性，而this是当前的模块对象，this.foo代表模块实例的属性，这跟变量foo是两回事情。\n另外，如果声明变量的时候，不使用var命令，而是直接赋值，那么该变量在 REPL 环境下将成为global和this的属性，在模块环境将只成为 global 的属性。","title":"this.md"},{"content":"Resources 使用控制台创建一个事件函数 使用 Serverless Cloud Framework 创建函数 API实践 想要了解各API的用法，可先在腾讯云官方文档寻找：云函数 API 概览-API 中心-腾讯云 (tencent.com)\n腾讯云官方推荐API Explorer调试API和生成代码，它提供了在线调用、签名验证、SDK 代码生成和快速检索接口等能力：\n总结使用API步骤：\n在文档中找到想要的API，了解API的功能和用法； 在API Explorer中下载代码或调试； 安装代码所需要的对应依赖，并将参数（如秘钥等）替换成自己腾讯云账号的，密钥可前往官网控制台进行获取； 为了项目的可维护性，参数可设置成环境变量或配置文件，并根据实际项目需要修改代码。 重要API整理 公共参数 云函数 公共参数-调用方式-API 中心-腾讯云 (tencent.com)\n使用Postman或者Curl直接发送请求时需要带上这些公共参数，下面是使用Curl发送请求的一个示例（由API Explorer生成）：\n1 curl -X POST https://scf.tencentcloudapi.com -H \u0026#34;Authorization: TC3-HMAC-SHA256 Credential=AKIDntdFc3Qo12WwlvVaRtFeoF2s75BvoPiwIL8UvOXenQ-Ll8Le5SfIpM4jjLXyUGXX/2023-05-30/scf/tc3_request, SignedHeaders=content-type;host, Signature=08e82782ba555a81a8864c0ad57e0defbd27d0034eb5c8b1e5ccf60202fc1c2b\u0026#34; -H \u0026#34;Content-Type: application/json\u0026#34; -H \u0026#34;Host: scf.tencentcloudapi.com\u0026#34; -H \u0026#34;X-TC-Action: ListFunctions\u0026#34; -H \u0026#34;X-TC-Timestamp: 1685434170\u0026#34; -H \u0026#34;X-TC-Version: 2018-04-16\u0026#34; -H \u0026#34;X-TC-Language: zh-CN\u0026#34; -H \u0026#34;X-TC-Token: 8HVPWbJ4b60AFSi6IGd41mG7pXaNSxOa607adae527ed98cca05322893420aec9TaLLoQIydU0_J99sP40grvLXfat-hSb2ysPTMqHotagIIy8UJzTWestfbmhKd0nxBQuJhT6cM3ew1ii_Ug47velPmhuzQMIN9CvG0jw084q450d1mqEFSjdm2k64wpNgzTIFEn-633R2hPqlO_09jJY_AxdDsmpX80Z7PurEqGOHACiRFGCqVavLck2SVMVLkM7WBg_13IOkp12TSi3cOA\u0026#34; -d \u0026#39;{}\u0026#39; 而使用各种语言的SDK调用这些API则不需要管这些公共参数，仅需配置秘钥即可。\n下面是一些重要的API，腾讯云官方的API文档已经很详细易用，了解更具体的用法可查看它。\n函数相关API 获取函数列表 https://cloud.tencent.com/document/api/583/18582\n创建函数 函数需要打包成.zip文件并采用BASE64编码转换成字符串在code的zipFile参数中，或先上传到腾讯云CosBucket对象存储桶中。\nhttps://cloud.tencent.com/document/api/583/18586\n删除函数 需要函数名。\nhttps://cloud.tencent.com/document/api/583/18585\n运行函数 需要函数名。\nhttps://cloud.tencent.com/document/api/583/17243\n获取函数详细信息 需要函数名。\nhttps://cloud.tencent.com/document/api/583/18584\n触发器相关API 设置函数触发方式 即创建触发器，需要触发器的名称、类型（ cos 、cmq、 timer 定时触发器、 ckafka、apigw API网关）、名字、[描述](云函数 触发器配置描述-触发器-文档中心-腾讯云 (tencent.com))。触发器描述中指定触发器的配置。\nhttps://cloud.tencent.com/document/api/583/18589\n删除触发器 需要函数名、触发器名称、类型。\nhttps://cloud.tencent.com/document/api/583/18588\n更新触发器状态 开关触发器，需要函数名、触发器类型、触发器名、开或关。apigw类触发器无法开关。\nhttps://cloud.tencent.com/document/api/583/89800\n获取函数触发器列表 需要函数名。\nhttps://cloud.tencent.com/document/api/583/44268\n","permalink":"https://WFUing.github.io/posts/tech/architecture/serverless/tencentyun-serverless-api/","summary":"腾讯云官方推荐并提供了使用控制台和使用Serverless 组件（Tencent Serverless Cloud Framework）两种方式用于管理云函数，分别在浏览器中和本地CLI中进行开发","title":"Tencentyun Serverless Api"},{"content":"Resources https://www.npmjs.com/package/@alicloud/fc-open20210406/v/2.0.9 CreateService 重要参数 参数名 描述 类型 是否必填 serviceName 服务的名称 string 是 description 服务的描述信息 string 否 internetAccess 是否允许公网访问 boolean 否 role 服务所使用的角色 string 是 vpcConfig 服务的VPC配置 dict 否 logConfig 服务的日志配置 dict 否 nasConfig 服务的NAS配置 dict 否 vpcConfig 字典包含以下键值：\n键名 描述 类型 是否必填 VpcId VPC的ID string 是 VSwitchIds VSwitch的ID列表 list 是 logConfig 字典包含以下键值：\n键名 描述 类型 是否必填 Project 日志服务的项目名称 string 是 Logstore 日志服务的日志库名称 string 是 nasConfig 字典包含以下键值：\n键名 描述 类型 是否必填 MountPoints NAS挂载点列表 list 是 UserId 用于访问NAS的用户ID string 是 GroupId 用于访问NAS的用户组ID string 是 GetService 重要参数 参数名 描述 类型 是否必填 serviceName 服务的名称 string 是 CreateFunction 重要参数 参数名 描述 类型 是否必填 serviceName 函数所属的服务名称 string 是 functionName 函数的名称 string 是 description 函数的描述信息 string 否 runtime 函数的运行环境 string 是 handler 函数的处理程序 string 是 initializer 函数的初始化程序 string 否 customContainerConfig 函数的自定义容器配置 dict 否 caPort 函数容器的端口号（仅适用于自定义容器） int 否 environmentVariables 函数的环境变量 dict 否 vpcConfig 函数的VPC配置 dict 否 logConfig 函数的日志配置 dict 否 nasConfig 函数的NAS配置 dict 否 mountPoints 函数的NAS挂载点列表 list[dict] 否 code 函数的代码 dict 是 layers 函数的Layer列表 list[string] 否 caEnable 是否开启自定义容器功能（仅适用于自定义容器） boolean 否 caFiles 自定义容器的CA证书文件列表（仅适用于自定义容器） list[dict] 否 runtime参数 runtime参数用于指定函数的运行环境。它决定了函数在何种语言和框架下执行。以下是runtime参数的常见取值及其对应的运行环境：\nruntime取值 运行环境 python2.7 Python 2.7 python3.6 Python 3.6 python3.7 Python 3.7 python3.8 Python 3.8 python3.9 Python 3.9 nodejs6 Node.js 6.x nodejs8 Node.js 8.x nodejs10 Node.js 10.x nodejs12 Node.js 12.x nodejs14 Node.js 14.x nodejs16 Node.js 16.x java8 Java 8 java11 Java 11 php7.2 PHP 7.2 dotnetcore2.1 .NET Core 2.1 dotnetcore3.1 .NET Core 3.1 custom 自定义运行时环境 对于大多数常用的编程语言和框架，可以直接选择相应的runtime取值。\n对于自定义运行时环境，可以选择\u0026quot;custom\u0026quot;作为runtime的取值，并提供自定义的运行时环境。自定义运行时环境需要提供相应的配置和执行文件，以便在函数中正确运行。\ncode参数 code参数用于指定函数的代码内容或代码存储位置。根据函数的具体需求和使用情况，code参数可以采用不同的设置方式。以下是对code参数的详细介绍：\n代码内容：可以直接将函数的代码内容作为字符串传递给code参数。这适用于函数代码比较简单且较短小的情况。将代码内容作为字符串传递给code参数时，通常需要指定runtime参数来指定函数的运行环境。\n代码存储位置：可以将函数的代码存储在指定的位置，例如对象存储（如OSS）或代码仓库（如GitHub），然后通过code参数提供相关的配置信息来引用这些存储位置的代码。具体的设置方式会根据不同的云服务提供商和平台而有所不同，通常需要提供存储位置的信息（如存储桶名称、对象键或代码仓库地址等）。\n对于直接传递代码内容的方式，阿里云提供了使用Base64编码的zip包方式。您可以将函数代码打包成zip包，并使用Base64编码将其转换为字符串，然后将该字符串作为zipFile字段的值传递给code参数。\n对于代码存储位置的情况，您需要提供相应的配置信息，例如存储位置的访问密钥、存储桶名称、对象键等。具体的设置方式会因云服务提供商和平台而有所不同。例如，在使用对象存储（如OSS）存储位置的情况下，可以提供如下配置：\n1 2 3 4 5 6 7 8 code = { \u0026#34;ossBucketName\u0026#34;: \u0026#34;my-bucket\u0026#34;, \u0026#34;ossObjectName\u0026#34;: \u0026#34;my-function.zip\u0026#34;, \u0026#34;ossAccessKeyId\u0026#34;: \u0026#34;my-access-key-id\u0026#34;, \u0026#34;ossAccessKeySecret\u0026#34;: \u0026#34;my-access-key-secret\u0026#34; } CreateFunction(serviceName=\u0026#34;my-service\u0026#34;, functionName=\u0026#34;my-function\u0026#34;, code=code, ...) customContainerConfig参数 参数 描述 image 指定要使用的容器镜像的名称。 command 指定容器启动时要执行的命令。 args 指定传递给容器启动命令的额外参数。 accelerationType 是否开启镜像加速。 webServerMode 镜像运行是否为Web Server模式。取值为true表示需要在容器镜像中实现Web Server来监听端口并处理请求。取值为false表示需要容器运行后主动退出进程，并且ExitCode需要为0。 GetFunction 重要参数 以下是GetFunction接口的参数列表，包括参数名、参数类型、是否必填和参数描述：\n参数名 参数类型 是否必填 参数描述 serviceName 字符串 是 函数所属的服务名称。 functionName 字符串 是 要获取的函数名称。 qualifier 字符串 否 函数版本或别名。如果未提供，则返回函数最新版本的信息。 CreateTrigger 重要参数 CreateTrigger函数是用于创建触发器的阿里云函数计算接口。通过该接口，您可以为函数关联不同类型的触发器，例如定时触发器、API网关触发器、对象存储（OSS）触发器等。\n以下是CreateTrigger函数的使用方式：\n首先，确保已经创建了需要触发的函数（使用CreateFunction函数创建）。\n构造CreateTrigger函数的请求参数，包括以下必填字段：\nserviceName：函数所属的服务名称。 functionName：要创建触发器的函数名称。 triggerName：触发器的名称，用于在函数中唯一标识触发器。 triggerType：触发器的类型，例如Timer（定时触发器）、OSS（对象存储触发器）、HTTP（HTTP触发器）等。 triggerConfig：触发器的配置信息，根据不同类型的触发器有所不同。 根据需要，可以设置CreateTrigger函数的其他可选参数，例如qualifier（函数版本或别名）等。\n调用CreateTrigger函数，传递请求参数，并获取返回结果。返回结果将包含触发器的相关信息，如触发器ID、触发器状态等。\n阿里云触发器类型 CreateTrigger函数支持多种触发器类型，您可以根据具体的需求选择适合的触发器类型。以下是一些常见的触发器类型及其简要介绍：\n定时触发器（Timer）：根据预设的时间表达式，周期性地触发函数的执行，例如每小时、每天、每周等。可以设置函数在特定时间点或时间间隔内触发。\n对象存储触发器（OSS）：当阿里云对象存储（OSS）上的文件发生变化时触发函数执行，例如文件上传、删除等事件。\nAPI网关触发器（HTTP）：将函数作为后端服务与阿里云API网关结合，实现基于HTTP请求的触发，例如接收API请求并进行处理。\n日志服务触发器（Log）：当日志服务中有新的日志产生时触发函数执行，例如实时处理日志、触发告警等。\nTable Store触发器（TableStore）：当阿里云Table Store中的数据发生变化时触发函数执行，例如数据更新、插入等操作。\n参考网址：阿里云触发器简介\nTimer触发器 以下是一个定时触发器配置信息的例子，包括时间表达式和其他可选参数：\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;serviceName\u0026#34;: \u0026#34;my-service\u0026#34;, \u0026#34;functionName\u0026#34;: \u0026#34;my-function\u0026#34;, \u0026#34;triggerName\u0026#34;: \u0026#34;my-timer-trigger\u0026#34;, \u0026#34;triggerType\u0026#34;: \u0026#34;Timer\u0026#34;, \u0026#34;triggerConfig\u0026#34;: { \u0026#34;cronExpression\u0026#34;: \u0026#34;0 0 9 * * ?\u0026#34;, // 每天上午9点触发 \u0026#34;enable\u0026#34;: true, \u0026#34;payload\u0026#34;: \u0026#34;{\\\u0026#34;key\\\u0026#34;: \\\u0026#34;value\\\u0026#34;}\u0026#34; }, \u0026#34;qualifier\u0026#34;: \u0026#34;LATEST\u0026#34; } 在上述例子中，配置信息的各个字段的含义如下：\nserviceName：函数所属的服务名称。 functionName：要关联定时触发器的函数名称。 triggerName：定时触发器的名称。 triggerType：指定为\u0026quot;Timer\u0026quot;，表示创建定时触发器。 triggerConfig：包含触发器的具体配置信息。 cronExpression：时间表达式，指定触发器的触发时间。在此例中，表示每天的上午9点触发。 enable：是否启用触发器。 payload：可选的触发器参数，作为函数调用时传递的输入参数。在此例中，使用JSON字符串作为示例。 qualifier：可选参数，指定函数版本或别名。在此例中，设置为\u0026quot;LATEST\u0026quot;，表示使用最新版本的函数。 HTTP触发器 以下是一个HTTP触发器的配置信息示例：\n1 2 3 4 5 6 7 8 9 10 11 12 { \u0026#34;serviceName\u0026#34;: \u0026#34;my-service\u0026#34;, \u0026#34;functionName\u0026#34;: \u0026#34;my-function\u0026#34;, \u0026#34;triggerName\u0026#34;: \u0026#34;my-http-trigger\u0026#34;, \u0026#34;triggerType\u0026#34;: \u0026#34;HTTP\u0026#34;, \u0026#34;triggerConfig\u0026#34;: { \u0026#34;authType\u0026#34;: \u0026#34;ANONYMOUS\u0026#34;, \u0026#34;methods\u0026#34;: [\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;], \u0026#34;url\u0026#34;: \u0026#34;/my-endpoint\u0026#34; }, \u0026#34;qualifier\u0026#34;: \u0026#34;LATEST\u0026#34; } 在上述例子中，配置信息的各个字段的含义如下：\nserviceName：函数所属的服务名称。 functionName：要关联HTTP触发器的函数名称。 triggerName：HTTP触发器的名称。 triggerType：指定为\u0026quot;HTTP\u0026quot;，表示创建HTTP触发器。 triggerConfig：包含触发器的具体配置信息。 authType：HTTP触发器的认证类型，可以选择\u0026quot;ANONYMOUS\u0026quot;（匿名访问）或\u0026quot;CUSTOM\u0026quot;（自定义认证）。 methods：允许的HTTP请求方法列表。在此例中，允许GET和POST请求。 url：定义触发器的URL路径。在此例中，设置为\u0026quot;/my-endpoint\u0026quot;。 qualifier：可选参数，指定函数版本或别名。在此例中，设置为\u0026quot;LATEST\u0026quot;，表示使用最新版本的函数。 GetTrigger 重要参数 以下是GetTrigger接口的参数列表，包括参数名、参数类型、是否必填和参数描述：\n参数名 参数类型 是否必填 参数描述 serviceName 字符串 是 触发器所属的服务名称。 functionName 字符串 是 触发器所属的函数名称。 triggerName 字符串 是 要获取的触发器名称。 InvokeFunction 重要参数 以下是InvokeFunction接口的参数列表，包括参数名、参数类型、是否必填和参数描述：\n参数名 参数类型 是否必填 参数描述 serviceName 字符串 是 函数所属的服务名称。 functionName 字符串 是 要调用的函数名称。 payload 字符串 否 调用函数时传递的输入参数。可以是字符串形式的JSON数据。 qualifier 字符串 否 函数版本或别名。如果未提供，则使用函数的最新版本。 X-Fc-Invocation-Type 字符串 否 函数调用的方式。可选值包括 \u0026ldquo;Sync\u0026rdquo;（同步）和 \u0026ldquo;Async\u0026rdquo;（异步）。默认为 \u0026ldquo;Sync\u0026rdquo;。 X-Fc-Log-Type 字符串 否 函数调用的日志类型。可选值包括 \u0026ldquo;None\u0026rdquo;（无日志）和 \u0026ldquo;Tail\u0026rdquo;（返回完整日志）。默认为 \u0026ldquo;None\u0026rdquo;。 ","permalink":"https://WFUing.github.io/posts/tech/architecture/serverless/alicloud-fc-api/","summary":"函数计算（Function Compute）是一个事件驱动的全托管 Serverless 计算服务，您无需管理服务器等基础设施，只需编写代码并上传，函数计算会为您准备好计算资源，并以弹性、可靠的方式运行您的代码。","title":"Alicloud Function Compute API"},{"content":"Git 简介 Git 是什么 Git 是一个开源的分布式版本控制系统。\nGit 和其它版本控制系统（包括 Subversion 和近似工具）的主要差别在于 Git 对待数据的方式。 从概念上来说，其它大部分系统以文件变更列表的方式存储信息，而 Git 是把数据看作是对小型文件系统的一系列快照。\n什么是版本控制 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。\n集中化的版本控制系统 介绍分布式版本控制系统前，有必要先了解一下传统的集中式版本控制系统。\n集中化的版本控制系统，诸如 CVS，Subversion 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录。\n分布式版本控制系统 分布式版本控制系统的客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。\n为什么使用 Git Git 是分布式的。这是 Git 和其它非分布式的版本控制系统（例如 svn，cvs 等），最核心的区别。分布式带来以下好处：\n工作时不需要联网 - 首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件 A，你的同事也在他的电脑上改了文件 A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 更加安全 集中式版本控制系统，一旦中央服务器出了问题，所有人都无法工作。 分布式版本控制系统，每个人电脑中都有完整的版本库，所以某人的机器挂了，并不影响其它人。 Git 的工作原理 个人认为，对于 Git 这个版本工具，再不了解原理的情况下，直接去学习命令行，可能会一头雾水。所以，本文特意将原理放在命令使用章节之前讲解。\n版本库 当你一个项目到本地或创建一个 git 项目，项目目录下会有一个隐藏的 .git 子目录。这个目录是 git 用来跟踪管理版本库的，如果不熟悉其工作机制，千万不要手动修改。\nhooks 目录：包含客户端或服务端的钩子脚本（hook scripts） info 目录：包含一个全局性排除（global exclude）文件， 用以放置那些不希望被记录在 .gitignore 文件中的忽略模式（ignored patterns）。 objects 目录：存储所有数据内容。 refs 目录：存储指向数据（分支、远程仓库和标签等）的提交对象的指针 HEAD 文件：指向目前被检出的分支。 index 文件保存暂存区信息。 config 文件：包含项目特有的配置选项。 description 文件：description 文件仅供 GitWeb 程序使用，我们无需关心。 哈希值 Git 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能构筑在 Git 底层，是 Git 的关键组件。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。\nGit 计算校验和的使用 SHA-1 哈希算法。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希值看起来是这样：\n1 24b9da6552252987aa493b52f8696cd6d3b00373 Git 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。\n文件状态 在 GIt 中，你的文件可能会处于三种状态之一：\n已修改（modified） - 已修改表示修改了文件，但还没保存到数据库中。 已暂存（staged） - 已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 已提交（committed） - 已提交表示数据已经安全的保存在本地数据库中。 工作区域 与文件状态对应的，不同状态的文件在 Git 中处于不同的工作区域。\n工作区（working） - 当你 git clone 一个项目到本地，相当于在本地克隆了项目的一个副本。工作区是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。 暂存区（staging） - 暂存区是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索引’\u0026rsquo;，不过一般说法还是叫暂存区。 本地仓库（local） - 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 本地仓库。 远程仓库（remote） - 以上几个工作区都是在本地。为了让别人可以看到你的修改，你需要将你的更新推送到远程仓库。同理，如果你想同步别人的修改，你需要从远程仓库拉取更新。 分支管理 Git Flow Git Flow 应该是目前流传最广的 Git 分支管理策略。Git Flow 围绕的核心点是版本发布（release），它适用于迭代版本较长的项目。\n详细内容，可以参考这篇文章：Git 在团队中的最佳实践\u0026ndash;如何正确使用 Git Flow\nGit Flow 常用分支：\nmaster - 主线分支 develop - 开发分支 feature - 特性分支 release - 发布分支 hotfix - 问题修复分支 Git Flow 工作流程\n2.1. 主干分支 主干分支有两个，它们是伴随着项目生命周期长期存在的分支。\nmaster - 这个分支对应发布到生产环境的代码。这个分支只允许从其他分支合入代码，不能在这个分支直接修改。所有在 master 分支上的 Commit 都应该打 Tag。 develop - 这个分支包含所有要发布到下一个 release 的代码，这个分支主要是从其他分支合入代码，比如 feature 分支。 2.2. feature 分支 这个分支主要是用来开发一个新的功能，一旦开发完成，我们合并回 develop 分支进入下一个 release。feature 分支开发结束后，必须合并回 develop 分支, 合并完分支后一般会删点这个 feature 分支，但是我们也可以保留。\n2.3. release 分支 release 分支基于 develop 分支创建，创建后，我们可以在这个 release 分支上进行测试，修复 Bug 等工作。同时，其它开发人员可以基于它开发新的 feature (记住：一旦创建了 release 分支之后不要从 develop 分支上合并新的改动到 release 分支)。\n发布 release 分支时，合并 release 到 master 和 develop， 同时在 master 分支上打个 Tag 记住 release 版本号，然后可以删除 release 分支了。\n2.4. hotfix 分支 当出现线上 bug 时，也意味着 master 存在 Bug。这时，我们需要基于 master 创建一个 hotfix 分支，在此分支上完成 bug 修复。修复后，我们应该将此分支合并回 master 和 develop 分支，同时在 master 上打一个 tag。所以，hotfix 的改动会进入下一个 release。\n2.5. 如何应用 Git Flow 在实际开发中，如何具体落地 Git Flow 流程呢？\ngit 提供了 git flow 命令来手动管理，但是比较麻烦，所以还是建议使用 Git Flow 的 GUI 工具。比如：SourceTree、VScode 的 GitFlow 插件、Intellij 的 GitFlow 插件等。\n想了解更详细的 Git Flow 介绍，可以参考：\nA Successful Git Branching Model\nGit 在团队中的最佳实践\u0026ndash;如何正确使用 Git Flow\nGithub Flow 对于简单且迭代频繁的项目来说，Git Flow 可能有些太复杂了。这时，可以考虑 Github Flow。\n在 Github Flow 策略中，所有分支都是基于 master 创建。在 Feature 或 Bugfix 分支中完成工作后，将其合入 master，然后继续迭代。\n想了解更详细的 Github Flow 介绍，可以参考：GitHub Flow\nGit Commit 规范 Git 每次提交代码，都要写 Commit message（提交说明），否则就不允许提交。\n好的 Commit message 可以让人一眼就明白提交者修改了什么内容，有什么影响；而不好的 Commit message 写了和没写一样，甚至还可能误导别人。\n先来看下图中不好的 Commit message 范例，从提交信息完全看不出来修改了什么。\n再来一张较好的 Commit message 范例，每次提交的是什么内容，做了什么一目了然。\nCommit message 的作用 从前面，我们不难看出，完善的 Commit message 非常有利于项目维护。即时是个人维护的项目，时间久了，可能也会忘记当初自己改了什么。\nCommit message 的作用还不仅仅是理解历史信息，它的主要作用如下：\n（1）提供易于理解的历史信息，方便检索\n（2）可以过滤某些 commit（比如文档改动），便于快速查找信息。\n（3）可以直接从 commit 生成 Change log。\nCommit message 的规范 开源社区有很多 Commit message 的规范，个人推荐使用 Angular Git Commit 规范，这是目前使用最广的写法，比较合理和系统化，并且有配套的工具。\n它主要有以下组成部分：\n标题行：必填, 描述主要修改类型和内容 主题内容：描述为什么修改, 做了什么样的修改, 以及开发的思路等等 页脚注释：放 Breaking Changes 或 Closed Issues 常用的修改项\ntype：commit 的类型 feat：新特性 fix：修改问题 refactor：代码重构 docs：文档修改 style：代码格式修改, 注意不是 css 修改 test：测试用例修改 chore：其他修改, 比如构建流程, 依赖管理. scope：commit 影响的范围, 比如：route, component, utils, build\u0026hellip; subject：commit 的概述 body：commit 具体修改内容, 可以分为多行 footer：一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接 生成 Change log 如果你的所有 Commit 都符合 Angular Git Commit 规范，那么发布新版本时，就可以用脚本自动生成 Change log。\n生成的文档包括以下三个部分。\nNew features Bug fixes Breaking changes. 每个部分都会罗列相关的 commit ，并且有指向这些 commit 的链接。当然，生成的文档允许手动修改，所以发布前，你还可以添加其他内容。\nconventional-changelog 就是生成 Change log 的工具，运行下面的命令即可。\n1 2 3 $ npm install -g conventional-changelog $ cd my-project $ conventional-changelog -p angular -i CHANGELOG.md -w 上面命令不会覆盖以前的 Change log，只会在CHANGELOG.md的头部加上自从上次发布以来的变动。\n如果你想生成所有发布的 Change log，要改为运行下面的命令。\n1 $ conventional-changelog -p angular -i CHANGELOG.md -w -r 0 为了方便使用，可以将其写入package.json的scripts字段。\n1 2 3 4 5 { \u0026#34;scripts\u0026#34;: { \u0026#34;changelog\u0026#34;: \u0026#34;conventional-changelog -p angular -i CHANGELOG.md -w -r 0\u0026#34; } } 以后，直接运行下面的命令即可。\n1 $ npm run changelog Git 奇技淫巧 生成 SSH 公钥 许多 Git 服务器都使用 SSH 公钥进行认证。 为了向 Git 服务器提供 SSH 公钥，如果某系统用户尚未拥有密钥，必须事先为其生成一份。 这个过程在所有操作系统上都是相似的。 首先，你需要确认自己是否已经拥有密钥。 默认情况下，用户的 SSH 密钥存储在其 ~/.ssh 目录下。 进入该目录并列出其中内容，你便可以快速确认自己是否已拥有密钥：\n1 2 3 4 $ cd ~/.ssh $ ls authorized_keys2 id_dsa known_hosts config id_dsa.pub 我们需要寻找一对以 id_dsa 或 id_rsa 命名的文件，其中一个带有 .pub 扩展名。 .pub 文件是你的公钥，另一个则是私钥。 如果找不到这样的文件（或者根本没有 .ssh 目录），你可以通过运行 ssh-keygen 程序来创建它们。在 Linux/Mac 系统中，ssh-keygen 随 SSH 软件包提供；在 Windows 上，该程序包含于 MSysGit 软件包中。\n1 2 3 4 5 6 7 8 9 10 $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/schacon/.ssh/id_rsa): Created directory \u0026#39;/home/schacon/.ssh\u0026#39;. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/schacon/.ssh/id_rsa. Your public key has been saved in /home/schacon/.ssh/id_rsa.pub. The key fingerprint is: d0:82:24:8e:d7:f1:bb:9b:33:53:96:93:49:da:9b:e3 schacon@mylaptop.local 首先 ssh-keygen 会确认密钥的存储位置（默认是 .ssh/id_rsa），然后它会要求你输入两次密钥口令。如果你不想在使用密钥时输入口令，将其留空即可。\n现在，进行了上述操作的用户需要将各自的公钥发送给任意一个 Git 服务器管理员（假设服务器正在使用基于公钥的 SSH 验证设置）。 他们所要做的就是复制各自的 .pub 文件内容，并将其通过邮件发送。 公钥看起来是这样的：\n1 2 3 4 5 6 7 $ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@mylaptop.local 在你的 Github 账户中，依次点击 Settings \u0026gt; SSH and GPG keys \u0026gt; New SSH key\n然后，将上面生成的公钥内容粘贴到 Key 编辑框并保存。至此大功告成。\n后面，你在克隆你的 Github 项目时使用 SSH 方式即可。\n如果觉得我的讲解还不够细致，可以参考：adding-a-new-ssh-key-to-your-github-account\n使用 .gitignore 忽略不必提交内容 .gitignore 文件可能从字面含义也不难猜出：这个文件里配置的文件或目录，会自动被 git 所忽略，不纳入版本控制。\n在日常开发中，我们的项目经常会产生一些临时文件，如编译 Java 产生的 *.class 文件，又或是 IDE 自动生成的隐藏目录（Intellij 的 .idea 目录、Eclipse 的 .settings 目录等）等等。这些文件或目录实在没必要纳入版本管理。在这种场景下，你就需要用到 .gitignore 配置来过滤这些文件或目录。\n.gitignore 配置的规则很简单，也没什么可说的，看几个例子，自然就明白了。\n【示例】一份 Java 的 .gitignore\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Compiled class file *.class # Log file *.log # BlueJ files *.ctxt # Mobile Tools for Java (J2ME) .mtj.tmp/ # Package Files # *.jar *.war *.nar *.ear *.zip *.tar.gz *.rar # virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml hs_err_pid* 【推荐】这里推荐一个 Github 的开源项目：gitignore，在这里，你可以找到很多常用的 .gitignore 模板，如：Java、Nodejs、C++ 的 .gitignore 模板等等。\n使用 .gitattributes 解决 LF 和 CRLF 问题 你有没有在和多人协同开发时遇到过以下烦恼？\n开发者们分别使用不同的操作系统进行开发，有的人用 Windows，有的人用 Linux/MacOS。众所周知，不同操作系统默认的文件结尾行是不同的：在 Windows 上默认的是回车换行（Carriage Return Line Feed, CRLF），然而，在 Linux/MacOS 上则是换行（Line Feed, LF）。这就可能导致这种情况：明明文件内容一模一样，但是版本比对时仍然存在版本差异。\n那么如何解决这个问题呢？Git 提供了 .gitattributes 配置文件，它允许使用者指定由 git 使用的文件和路径的属性。\n在 Git 库中，一个普通文本文件的行尾默认是 LF。对于工作目录，除了 text 属性之外，还可以设置 eol 属性或 core.eol 配置变量。\n.gitattributes 文件中，可以用 text 属性指定某类文件或目录下的文件，控制它的行结束标准化。当一个文本文件被标准化时，它的行尾将在存储库中转换为 LF。要控制工作目录中使用的行结束风格，请使用单个文件的eol属性和所有文本文件的 core.eol 配置变量。\n【示例】一份 .gitattributes 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 * text=auto eol=lf *.txt text *.java text *.scala text *.groovy text *.gradle text *.properties text # unix style *.sh text eol=lf # win style *.bat text eol=crlf # binary *.jar binary *.war binary *.zip binary *.tar binary *.tar.gz binary *.gz binary *.apk binary *.bin binary *.exe binary 【推荐】这里推荐一个 Github 的开源项目：gitignore，在这里，你可以找到很多常用的 .gitignore 模板，如：Java、Nodejs、C++ 的 .gitignore 模板等等。\n同时提交代码到不同的远程仓库 如果，你在不同的 Git 远程仓库中维护同一个项目，你可能会有这样的需求：能不能一次提交，同时 push 到多个远程仓库中呢？\n这个可以有，解决方案如下：\n比如，我有一个 blog 项目，同时维护在 Github 和 Gitee 上。\n（1）首先，在 Github 和 Gitee 上配置本地的 ssh 公钥（如果是 Gitlab，也同样如此），这样中央仓库就能识别本地。\n生成 SSH 公钥的方法，请参考上文的 “生成 SSH 公钥” 章节。\n（2）进入 git 项目的隐藏目录 .git，打开 config 文件，参考下面配置进行编辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true [remote \u0026#34;origin\u0026#34;] url = git@github.com:dunwu/blog.git url = git@gitee.com:turnon/blog.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \u0026#34;master\u0026#34;] remote = origin merge = refs/heads/master [user] name = dunwu email = forbreak@163.com 重点在于 remote \u0026quot;origin\u0026quot;，同时配置了两个 url。配置后，一旦触发 push 远程仓库的动作，就会同时推送提交记录到配置的远程仓库。\nGithub Issue 和 Gitlab Issue 开发软件，Bug 再所难免，出现问题不可怕，可怕的是放任不管；所以，优秀的软件项目，都应该管理好问题追踪。软件的使用者，在使用中，可能会遇到形形色色的问题，难以解决，需要向维护者寻求帮助。\n问题追踪如此重要，所以各种代码托管平台都会提供 Issue 维护机制，如 Github Issue 和 Gitlab Issue。\n如果一个项目的开源社区很活跃，在没有任何约束的前提下，提问肯定是五花八门的，让维护者难以招架。\n其实，提问也是一门艺术，如果提问者的问题长篇大幅，言不达意，让别人难以理解，就很难得到有效帮助。关于如何高效的提问，推荐参考 提问的智慧 这篇文章，作者整理的非常好。\n作为开发者，你不能期望所有提问者都是训练有素的提问者。所以，使用规范化的 Issue 模板来引导提问者提问，可以大大减轻开发者的负担。\nGithub Issue 模板 如何在 Github Issue 平台上创建 Issue 模板呢？方法如下：\n（1）在仓库根目录创建新目录 .github\n（2）在 .github 目录中添加 ISSUE_TEMPLATE 目录，在其中添加的 md 文件都会被 Github 自动识，并将其作为 issue 的默认模板。\n示例，下面是携程 apollo 的一个 Issue 模板，要求提问者填充 bug 描述、复现步骤、期望、截图、日志等细节。\n更多模板：Github issue_templates 模板\nGitlab Issue 模板 如何在 Gitlab Issue 平台上创建 Issue 模板呢？方法如下：\n（1）在仓库根目录创建新目录 .gitlab\n（2）在 .gitlab 目录中添加 issue_templates 目录，在其中添加的 md 文件都会被 Gitlab 自动识，并将其作为 issue 的默认模板。\n更多模板：Gitlab 官方 issue_templates 模板\nGit Hook 在执行提交代码（git commit），推送代码（git push）等行为时，我们可能希望做一些代码检查性工作，例如：代码 lint 检查、代码格式化等。当检查发现代码存在问题时，就拒绝代码提交，从而保证项目质量。\nGit 提供了 Git Hook 机制，允许使用者在特定的重要动作发生时触发自定义脚本。有两类钩子：客户端钩子和服务器端钩子。客户端钩子由诸如提交和合并等操作所触发调用，而服务器端钩子作用于诸如接收被推送的提交这样的联网操作。钩子都被存储在 Git 项目目录下的 .git/hooks 子目录中。Git 在这个目录下放置了一些示例，这些示例的名字都是以 .sample 结尾，如果想启用它们，得先移除这个后缀。\n常用的客户端钩子：\npre-commit 钩子：在提交信息前运行。 它用于检查即将提交的快照，例如，检查是否有所遗漏，确保测试运行，以及核查代码。 如果该钩子以非零值退出，Git 将放弃此次提交，不过你可以用 git commit --no-verify 来绕过这个环节。 你可以利用该钩子，来检查代码风格是否一致（运行类似 lint 的程序）、尾随空白字符是否存在（自带的钩子就是这么做的），或新方法的文档是否适当。 prepare-commit-msg 钩子：在启动提交信息编辑器之前，默认信息被创建之后运行。 它允许你编辑提交者所看到的默认信息。 该钩子接收一些选项：存有当前提交信息的文件的路径、提交类型和修补提交的提交的 SHA-1 校验。 它对一般的提交来说并没有什么用；然而对那些会自动产生默认信息的提交，如提交信息模板、合并提交、压缩提交和修订提交等非常实用。 你可以结合提交模板来使用它，动态地插入信息。 commit-msg 钩子：接收一个参数，此参数即上文提到的，存有当前提交信息的临时文件的路径。 如果该钩子脚本以非零值退出，Git 将放弃提交，因此，可以用来在提交通过前验证项目状态或提交信息。 在本章的最后一节，我们将展示如何使用该钩子来核对提交信息是否遵循指定的模板。 post-commit 钩子：在整个提交过程完成后运行。它不接收任何参数，但你可以很容易地通过运行 git log -1 HEAD 来获得最后一次的提交信息。 该钩子一般用于通知之类的事情。 pre-push 钩子：会在 git push 运行期间， 更新了远程引用但尚未传送对象时被调用。 它接受远程分支的名字和位置作为参数，同时从标准输入中读取一系列待更新的引用。 你可以在推送开始之前，用它验证对引用的更新操作（一个非零的退出码将终止推送过程）。 Javascript 应用 Git Hook 想在 JavaScript 应用中使用 Git Hook，推荐使用 husky ，可以很方便的编写钩子处理命令。\n使用方法很简单，先安装 husky\n1 npm i -D husky 然后，在 package.json 中添加配置：\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;husky\u0026#34;: { \u0026#34;hooks\u0026#34;: { \u0026#34;pre-commit\u0026#34;: \u0026#34;lint-staged\u0026#34; } }, \u0026#34;lint-staged\u0026#34;: { \u0026#34;src/**/*.{js,vue}\u0026#34;: [ \u0026#34;eslint --fix\u0026#34;, \u0026#34;git add\u0026#34; ] }, 以上配置的作用是，当提交代码前（ pre-commit ），先执行 lint-staged；\nlint-staged 中执行的动作是，对 src 目录的所有 js、vue 文件进行 eslint 检查，并尝试修复。如果修复后没有问题，就 git add 添加修改后的文件；如果修复失败，则拒绝提交代码。\n参考资料 官方资源 Git 官网 Git Github Github 官方教程 模板 gitignore 模板 - .gitignore 文件模板 gitattributes 模板 - .gitattributes 文件模板 github-cheat-sheet - git 命令简略图表 Git 教程 Learn Git branching - 交互式教程 Git 官方推荐教程 - Scott Chacon 的 Git 书。 git-flight-rules git-tips Git 中文教程 廖雪峰的 Git 教程 有关 git 的学习资源 文章 Git Cookbook Git 奇技淫巧 Git 风格指南 Git 在团队中的最佳实践\u0026ndash;如何正确使用 Git Flow Commit message 和 Change log 编写指南 Git 工具 guis - Git 官网展示的客户端工具列表。 gogs - 极易搭建的自助 Git 服务。 gitflow - 应用 fit-flow 模型的工具。 firstaidgit.io 一个可搜索的最常被问到的 Git 的问题 git-extra-commands - 一堆有用的额外的 Git 脚本 git-extras - GIT 工具集 \u0026ndash; repo summary, repl, changelog population, author commit percentages and more git-fire - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。 git-tips - Git 小提示 git-town - 通用，高级 Git 工作流支持！ GUI 客户端 GitKraken - 豪华的 Git 客户端 Windows, Mac \u0026amp; Linux git-cola - 另外一个 Git 客户端 Windows \u0026amp; OS X GitUp - 一个新的 Git 客户端，在处理 Git 的复杂性上有自己的特点 gitx-dev - 图形化的 Git 客户端 OS X Source Tree - 免费的图形化 Git 客户端 Windows \u0026amp; OS X Tower - 图形化 Git 客户端 OS X(付费) git cheat sheet github-git-cheat-sheet ","permalink":"https://WFUing.github.io/posts/tech/architecture/git/git-principle/","summary":"Git 和其它版本控制系统（包括 Subversion 和近似工具）的主要差别在于 Git 对待数据的方式。 从概念上来说，其它大部分系统以文件变更列表的方式存储信息，而 Git 是把数据看作是对小型文件系统的一系列快照。","title":"Git Principle"},{"content":"Git 帮助手册 国外网友制作了一张 Git Cheat Sheet，总结很精炼，各位不妨收藏一下。\n本节选择性介绍 git 中比较常用的命令行场景。\n安装 （1）Debian/Ubuntu 环境安装\n如果你使用的系统是 Debian/Ubuntu ， 安装命令为：\n1 2 3 4 5 $ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ \u0026gt; libz-dev libssl-dev $ apt-get install git-core $ git --version git version 1.8.1.2 （2）Centos/RedHat 环境安装\n如果你使用的系统是 Centos/RedHat ，安装命令为：\n1 2 3 4 5 $ yum install curl-devel expat-devel gettext-devel \\ \u0026gt; openssl-devel zlib-devel $ yum -y install git-core $ git --version git version 1.7.1 （3）Windows 环境安装\n在Git 官方下载地址下载 exe 安装包。按照安装向导安装即可。\n建议安装 Git Bash 这个 git 的命令行工具。\n（4）Mac 环境安装\n在Git 官方下载地址下载 mac 安装包。按照安装向导安装即可。\n配置 Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。 ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。 每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users\\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。\n配置用户信息 当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改：\n1 2 git config --global user.name \u0026#34;John Doe\u0026#34; git config --global user.email johndoe@example.com 再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。\n很多 GUI 工具都会在第一次运行时帮助你配置这些信息。\n给 Git 命令添加别名 在 OS X 和 Linux 下, 你的 Git 的配置文件储存在 ~/.gitconfig。我在[alias] 部分添加了一些快捷别名(和一些我容易拼写错误的)，如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [alias] a = add amend = commit --amend c = commit ca = commit --amend ci = commit -a co = checkout d = diff dc = diff --changed ds = diff --staged f = fetch loll = log --graph --decorate --pretty=oneline --abbrev-commit m = merge one = log --pretty=oneline outstanding = rebase -i @{u} s = status unpushed = log @{u} wc = whatchanged wip = rebase -i @{u} zap = fetch -p 缓存一个仓库的用户名和密码 你可能有一个仓库需要授权，这时你可以缓存用户名和密码，而不用每次推/拉(push/pull)的时候都输入，Credential helper 能帮你。\n1 2 git config --global credential.helper cache ## Set git to use the credential memory cache 1 2 git config --global credential.helper \u0026#39;cache --timeout=3600\u0026#39; ## Set the cache to timeout after 1 hour (setting is in seconds) 仓库 初始化仓库 1 $ git init 克隆仓库 1 2 3 4 # 通过 SSH $ git clone ssh://user@domain.com/repo.git # 通过 HTTP $ git clone http://domain.com/user/repo.git 储藏 有时，我们需要在同一个项目的不同分支上工作。当需要切换分支时，偏偏本地的工作还没有完成，此时，提交修改显得不严谨，但是不提交代码又无法切换分支。这时，你可以使用 git stash 将本地的修改内容作为草稿储藏起来。\n官方称之为储藏，但我个人更喜欢称之为存草稿。\n1 2 3 4 5 6 7 8 9 10 11 12 # 1. 将修改作为当前分支的草稿保存 $ git stash # 2. 查看草稿列表 $ git stash list stash@{0}: WIP on master: 6fae349 :memo: Writing docs. # 3.1 删除草稿 $ git stash drop stash@{0} # 3.2 读取草稿 $ git stash apply stash@{0} 暂存 git add 命令用于将修改添加到暂存区。\n暂存指定文件 1 git add xxx 暂存当前目录下所有修改 1 git add . 暂存所有修改 1 git add -A 暂存文件部分内容 暂存文件部分内容\n1 git add --patch filename.x -p 简写。这会打开交互模式， 你将能够用 s 选项来分隔提交(commit)；\n然而, 如果这个文件是新的, 会没有这个选择， 添加一个新文件时，这样做:\n1 git add -N filename.x 然后, 你需要用 e 选项来手动选择需要添加的行，执行 git diff --cached 将会显示哪些行暂存了哪些行只是保存在本地了。\n把暂存的内容变成未暂存，把未暂存的内容暂存起来 这个有点困难， 我能想到的最好的方法是先 stash 未暂存的内容， 然后重置(reset)，再 pop 第一步 stashed 的内容, 最后再 add 它们。\n1 2 3 4 git stash -k git reset --hard git stash pop git add -A 提交 git commit 命令用于将修改保存到到本地仓库。\n查看最近一次提交 1 git show 或者\n1 git log -n1 -p 提交本地的所有修改 1 git commit -a 提交暂存的修改 1 git commit 把暂存的内容添加到上一次的提交 1 git commit --amend 附加消息提交 1 git commit -m \u0026#39;commit message\u0026#39; 修改提交信息 如果你的提交信息写错了且这次提交（commit）还没有推送（push），可以使用以下命令修改：\n1 git commit --amend 或者\n1 git commit --amend -m \u0026#39;xxxxxxx\u0026#39; 修改提交信息中的用户名和邮箱 1 git commit --amend --author \u0026#34;New Authorname \u0026lt;authoremail@mydomain.com\u0026gt;\u0026#34; 从提交中移除一个文件 1 2 3 git checkout HEAD^ myfile git add -A git commit --amend 删除最后一次提交 如果你需要删除推了的提交(pushed commits)，你可以使用下面的方法。可是，这会不可逆的改变你的历史，也会搞乱那些已经从该仓库拉取(pulled)了的人的历史。简而言之，如果你不是很确定，千万不要这么做。\n1 2 git reset HEAD^ --hard git push -f [remote] [branch] 如果你还没有推到远程, 把 Git 重置(reset)到你最后一次提交前的状态就可以了(同时保存暂存的变化):\n1 (my-branch*)$ git reset --soft HEAD@{1} 这只能在没有推送之前有用. 如果你已经推了, 唯一安全能做的是 git revert SHAofBadCommit， 那会创建一个新的提交(commit)用于撤消前一个提交的所有变化(changes)； 或者, 如果你推的这个分支是 rebase-safe 的 (例如： 其它开发者不会从这个分支拉), 只需要使用 git push -f； 更多, 请参考 the above section。\n删除任意提交 同样的警告：不到万不得已的时候不要这么做.\n1 2 git rebase --onto SHA1_OF_BAD_COMMIT^ SHA1_OF_BAD_COMMIT git push -f [remote] [branch] 或者做一个 交互式 rebase 删除那些你想要删除的提交(commit)里所对应的行。\n我尝试推一个修正后的提交(amended commit)到远程，但是报错 1 2 3 4 5 6 7 To https://github.com/yourusername/repo.git ! [rejected] mybranch -\u0026gt; mybranch (non-fast-forward) error: failed to push some refs to \u0026#39;https://github.com/tanay1337/webmaker.org.git\u0026#39; hint: Updates were rejected because the tip of your current branch is behind hint: its remote counterpart. Integrate the remote changes (e.g. hint: \u0026#39;git pull ...\u0026#39;) before pushing again. hint: See the \u0026#39;Note about fast-forwards\u0026#39; in \u0026#39;git push --help\u0026#39; for details. 注意, rebasing(见下面)和修正(amending)会用一个新的提交(commit)代替旧的, 所以如果之前你已经往远程仓库上推过一次修正前的提交(commit)，那你现在就必须强推(force push) (-f)。 注意 – 总是 确保你指明一个分支!\n1 (my-branch)$ git push origin mybranch -f 一般来说, 要避免强推. 最好是创建和推(push)一个新的提交(commit)，而不是强推一个修正后的提交。后者会使那些与该分支或该分支的子分支工作的开发者，在源历史中产生冲突。\n不小心强制重置，想找回内容 如果你意外的做了 git reset --hard, 你通常能找回你的提交(commit), 因为 Git 对每件事都会有日志，且都会保存几天。\n1 (master)$ git reflog 你将会看到一个你过去提交(commit)的列表, 和一个重置的提交。 选择你想要回到的提交(commit)的 SHA，再重置一次:\n1 (master)$ git reset --hard SHA1234 这样就完成了。\n重置 撤销本地修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 移除缓存区的所有文件（i.e. 撤销上次git add） $ git reset HEAD # 将HEAD重置到上一次提交的版本，并将之后的修改标记为未添加到缓存区的修改 $ git reset \u0026lt;commit\u0026gt; # 将HEAD重置到上一次提交的版本，并保留未提交的本地修改 $ git reset --keep \u0026lt;commit\u0026gt; # 放弃工作目录下的所有修改 $ git reset --hard HEAD # 将HEAD重置到指定的版本，并抛弃该版本之后的所有修改 $ git reset --hard \u0026lt;commit-hash\u0026gt; # 用远端分支强制覆盖本地分支 $ git reset --hard \u0026lt;remote/branch\u0026gt; e.g., upstream/master, origin/my-feature # 放弃某个文件的所有本地修改 $ git checkout HEAD \u0026lt;file\u0026gt; 删除添加.gitignore文件前错误提交的文件：\n1 2 3 4 # 提交一条 git 记录，提交信息为 remove xyz file $ git rm -r --cached . $ git add . $ git commit -m \u0026#34;remove xyz file\u0026#34; 撤销远程修改（创建一个新的提交，并回滚到指定版本）：\n1 2 # revert 哈希号为 commit-hash 的记录 $ git revert \u0026lt;commit-hash\u0026gt; 彻底删除指定版本：\n1 2 3 # 执行下面命令后，commit-hash 提交后的记录都会被彻底删除，使用需谨慎 $ git reset --hard \u0026lt;commit-hash\u0026gt; $ git push -f 更新 1 2 3 4 5 6 7 8 # 下载远程端版本，但不合并到HEAD中 $ git fetch \u0026lt;remote\u0026gt; # 将远程端版本合并到本地版本中 $ git pull origin master # 以rebase方式将远端分支与本地合并 $ git pull --rebase \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; 推送 推送提交到远程仓库 1 git push remote \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; 发布标签 1 git push --tags 未暂存 未暂存(Unstaged)的内容\n把未暂存的内容移动到一个新分支 git checkout -b my-branch 我想把未暂存的内容移动到另一个已存在的分支 1 2 3 git stash git checkout my-branch git stash pop 丢弃本地未提交的变化 如果你只是想重置源(origin)和你本地(local)之间的一些提交(commit)，你可以：\n1 2 3 4 5 6 7 8 ## one commit $ git reset --hard HEAD^ ## two commits $ git reset --hard HEAD^^ ## four commits $ git reset --hard HEAD~4 ## or $ git checkout -f 重置某个特殊的文件, 你可以用文件名做为参数:\n1 git reset filename 我想丢弃某些未暂存的内容 如果你想丢弃工作拷贝中的一部分内容，而不是全部。\n签出(checkout)不需要的内容，保留需要的。\n1 2 $ git checkout -p ## Answer y to all of the snippets you want to drop 另外一个方法是使用 stash， Stash 所有要保留下的内容, 重置工作拷贝, 重新应用保留的部分。\n1 2 3 4 $ git stash -p ## Select all of the snippets you want to save $ git reset --hard $ git stash pop 或者, stash 你不需要的部分, 然后 stash drop。\n1 2 3 $ git stash -p ## Select all of the snippets you don\u0026#39;t want to save $ git stash drop 分支 分支(Branches)\n列出所有的分支 1 git branch 列出所有的远端分支 1 git branch -r 基于当前分支创建新分支 1 git branch \u0026lt;new-branch\u0026gt; 基于远程分支创建新分支 1 git branch --track \u0026lt;new-branch\u0026gt; \u0026lt;remote-branch\u0026gt; 删除本地分支 1 git branch -d \u0026lt;branch\u0026gt; 强制删除本地分支 注意：强制删除本地分支，将会丢失未合并的修改\n1 git branch -D \u0026lt;branch\u0026gt; 删除远程分支 1 2 git push \u0026lt;remote\u0026gt; :\u0026lt;branch\u0026gt; (since Git v1.5.0) git push \u0026lt;remote\u0026gt; --delete \u0026lt;branch\u0026gt; (since Git v1.7.0) 切换分支 1 git checkout \u0026lt;branch\u0026gt; 创建并切换到新分支 1 git checkout -b \u0026lt;branch\u0026gt; 我从错误的分支拉取了内容，或把内容拉取到了错误的分支 这是另外一种使用 git reflog 情况，找到在这次错误拉(pull) 之前 HEAD 的指向。\n1 2 3 (master)$ git reflog ab7555f HEAD@{0}: pull origin wrong-branch: Fast-forward c5bc55a HEAD@{1}: checkout: checkout message goes here 重置分支到你所需的提交(desired commit):\n1 git reset --hard c5bc55a 完成。\n我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 先确认你没有推(push)你的内容到远程。\ngit status 会显示你领先(ahead)源(origin)多少个提交:\n1 2 3 4 5 (my-branch)$ git status ## On branch my-branch ## Your branch is ahead of \u0026#39;origin/my-branch\u0026#39; by 2 commits. ## (use \u0026#34;git push\u0026#34; to publish your local commits) # 一种方法是:\n1 (master)$ git reset --hard origin/my-branch 我需要提交到一个新分支，但错误的提交到了 master 在 master 下创建一个新分支，不切换到新分支,仍在 master 下:\n1 (master)$ git branch my-branch 把 master 分支重置到前一个提交:\n1 (master)$ git reset --hard HEAD^ HEAD^ 是 HEAD^1 的简写，你可以通过指定要设置的HEAD来进一步重置。\n或者, 如果你不想使用 HEAD^, 找到你想重置到的提交(commit)的 hash(git log 能够完成)， 然后重置到这个 hash。 使用git push 同步内容到远程。\n例如, master 分支想重置到的提交的 hash 为a13b85e:\n1 2 (master)$ git reset --hard a13b85e HEAD is now at a13b85e 签出(checkout)刚才新建的分支继续工作:\n1 (master)$ git checkout my-branch 我想保留来自另外一个 ref-ish 的整个文件 假设你正在做一个原型方案(原文为 working spike (see note)), 有成百的内容，每个都工作得很好。现在, 你提交到了一个分支，保存工作内容:\n1 (solution)$ git add -A \u0026amp;\u0026amp; git commit -m \u0026#34;Adding all changes from this spike into one big commit.\u0026#34; 当你想要把它放到一个分支里 (可能是feature, 或者 develop), 你关心是保持整个文件的完整，你想要一个大的提交分隔成比较小。\n假设你有:\n分支 solution, 拥有原型方案， 领先 develop 分支。 分支 develop, 在这里你应用原型方案的一些内容。 我去可以通过把内容拿到你的分支里，来解决这个问题:\n1 (develop)$ git checkout solution -- file1.txt 这会把这个文件内容从分支 solution 拿到分支 develop 里来:\n1 2 3 4 5 6 ## On branch develop ## Your branch is up-to-date with \u0026#39;origin/develop\u0026#39;. ## Changes to be committed: ## (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) # ## modified: file1.txt 然后, 正常提交。\nNote: Spike solutions are made to analyze or solve the problem. These solutions are used for estimation and discarded once everyone gets clear visualization of the problem. ~ Wikipedia.\n我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 假设你有一个master分支， 执行git log, 你看到你做过两次提交:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 (master)$ git log commit e3851e817c451cc36f2e6f3049db528415e3c114 Author: Alex Lee \u0026lt;alexlee@example.com\u0026gt; Date: Tue Jul 22 15:39:27 2014 -0400 Bug #21 - Added CSRF protection commit 5ea51731d150f7ddc4a365437931cd8be3bf3131 Author: Alex Lee \u0026lt;alexlee@example.com\u0026gt; Date: Tue Jul 22 15:39:12 2014 -0400 Bug #14 - Fixed spacing on title commit a13b85e984171c6e2a1729bb061994525f626d14 Author: Aki Rose \u0026lt;akirose@example.com\u0026gt; Date: Tue Jul 21 01:12:48 2014 -0400 First commit 让我们用提交 hash(commit hash)标记 bug (e3851e8 for #21, 5ea5173 for #14).\n首先, 我们把master分支重置到正确的提交(a13b85e):\n1 2 (master)$ git reset --hard a13b85e HEAD is now at a13b85e 现在, 我们对 bug #21 创建一个新的分支:\n1 2 (master)$ git checkout -b 21 (21)$ 接着, 我们用 cherry-pick 把对 bug #21 的提交放入当前分支。 这意味着我们将应用(apply)这个提交(commit)，仅仅这一个提交(commit)，直接在 HEAD 上面。\n1 (21)$ git cherry-pick e3851e8 这时候, 这里可能会产生冲突， 参见交互式 rebasing 章 冲突节 解决冲突.\n再者， 我们为 bug #14 创建一个新的分支, 也基于master分支\n1 2 3 (21)$ git checkout master (master)$ git checkout -b 14 (14)$ 最后, 为 bug #14 执行 cherry-pick:\n1 (14)$ git cherry-pick 5ea5173 我想删除上游(upstream)分支被删除了的本地分支 一旦你在 github 上面合并(merge)了一个 pull request, 你就可以删除你 fork 里被合并的分支。 如果你不准备继续在这个分支里工作, 删除这个分支的本地拷贝会更干净，使你不会陷入工作分支和一堆陈旧分支的混乱之中。\n1 git fetch -p 我不小心删除了我的分支 如果你定期推送到远程, 多数情况下应该是安全的，但有些时候还是可能删除了还没有推到远程的分支。 让我们先创建一个分支和一个新的文件:\n1 2 3 4 5 (master)$ git checkout -b my-branch (my-branch)$ git branch (my-branch)$ touch foo.txt (my-branch)$ ls README.md foo.txt 添加文件并做一次提交\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 (my-branch)$ git add . (my-branch)$ git commit -m \u0026#39;foo.txt added\u0026#39; (my-branch)$ foo.txt added 1 files changed, 1 insertions(+) create mode 100644 foo.txt (my-branch)$ git log commit 4e3cd85a670ced7cc17a2b5d8d3d809ac88d5012 Author: siemiatj \u0026lt;siemiatj@example.com\u0026gt; Date: Wed Jul 30 00:34:10 2014 +0200 foo.txt added commit 69204cdf0acbab201619d95ad8295928e7f411d5 Author: Kate Hudson \u0026lt;katehudson@example.com\u0026gt; Date: Tue Jul 29 13:14:46 2014 -0400 Fixes #6: Force pushing after amending commits 现在我们切回到主(master)分支，‘不小心的’删除my-branch分支\n1 2 3 4 5 6 7 (my-branch)$ git checkout master Switched to branch \u0026#39;master\u0026#39; Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. (master)$ git branch -D my-branch Deleted branch my-branch (was 4e3cd85). (master)$ echo oh noes, deleted my branch! oh noes, deleted my branch! 在这时候你应该想起了reflog, 一个升级版的日志，它存储了仓库(repo)里面所有动作的历史。\n1 2 3 4 (master)$ git reflog 69204cd HEAD@{0}: checkout: moving from my-branch to master 4e3cd85 HEAD@{1}: commit: foo.txt added 69204cd HEAD@{2}: checkout: moving from master to my-branch 正如你所见，我们有一个来自删除分支的提交 hash(commit hash)，接下来看看是否能恢复删除了的分支。\n1 2 3 4 5 6 (master)$ git checkout -b my-branch-help Switched to a new branch \u0026#39;my-branch-help\u0026#39; (my-branch-help)$ git reset --hard 4e3cd85 HEAD is now at 4e3cd85 foo.txt added (my-branch-help)$ ls README.md foo.txt 看! 我们把删除的文件找回来了。 Git 的 reflog 在 rebasing 出错的时候也是同样有用的。\n我想删除一个分支 删除一个远程分支:\n1 (master)$ git push origin --delete my-branch 你也可以:\n1 (master)$ git push origin :my-branch 删除一个本地分支:\n1 (master)$ git branch -D my-branch 我想从别人正在工作的远程分支签出(checkout)一个分支 首先, 从远程拉取(fetch) 所有分支:\n1 (master)$ git fetch --all 假设你想要从远程的daves分支签出到本地的daves\n1 2 3 (master)$ git checkout --track origin/daves Branch daves set up to track remote branch daves from origin. Switched to a new branch \u0026#39;daves\u0026#39; (--track 是 git checkout -b [branch] [remotename]/[branch] 的简写)\n这样就得到了一个daves分支的本地拷贝, 任何推过(pushed)的更新，远程都能看到.\n标签 添加标签 1 $ git tag \u0026lt;tag-name\u0026gt; 添加标签并附加消息 1 $ git tag -a \u0026lt;tag-name\u0026gt; 删除标签 1 2 git tag -d \u0026lt;tag_name\u0026gt; git push \u0026lt;remote\u0026gt; :refs/tags/\u0026lt;tag_name\u0026gt; 恢复已删除标签 如果你想恢复一个已删除标签(tag), 可以按照下面的步骤: 首先, 需要找到无法访问的标签(unreachable tag):\n1 git fsck --unreachable | grep tag 记下这个标签(tag)的 hash，然后用 Git 的 update-ref:\n1 git update-ref refs/tags/\u0026lt;tag_name\u0026gt; \u0026lt;hash\u0026gt; 这时你的标签(tag)应该已经恢复了。\nRebase 和 Merge merge 与 rebase 虽然是 git 常用功能，但是强烈建议不要使用 git 命令来完成这项工作。\n因为如果出现代码冲突，在没有代码比对工具的情况下，实在太艰难了。\n你可以考虑使用各种 Git GUI 工具。\n将分支合并到当前 HEAD 中 1 git merge \u0026lt;branch\u0026gt; 将当前 HEAD 版本重置到分支中 1 git rebase \u0026lt;branch\u0026gt; 撤销 rebase/merge 你可以合并(merge)或 rebase 了一个错误的分支, 或者完成不了一个进行中的 rebase/merge。 Git 在进行危险操作的时候会把原始的 HEAD 保存在一个叫 ORIG_HEAD 的变量里, 所以要把分支恢复到 rebase/merge 前的状态是很容易的。\n1 (my-branch)$ git reset --hard ORIG_HEAD 我已经 rebase 过, 但是我不想强推(force push) 不幸的是，如果你想把这些变化(changes)反应到远程分支上，你就必须得强推(force push)。 是因你快进(Fast forward)了提交，改变了 Git 历史, 远程分支不会接受变化(changes)，除非强推(force push)。这就是许多人使用 merge 工作流, 而不是 rebasing 工作流的主要原因之一， 开发者的强推(force push)会使大的团队陷入麻烦。使用时需要注意，一种安全使用 rebase 的方法是，不要把你的变化(changes)反映到远程分支上, 而是按下面的做:\n1 2 3 4 (master)$ git checkout my-branch (my-branch)$ git rebase -i master (my-branch)$ git checkout master (master)$ git merge --ff-only my-branch 更多, 参见 this SO thread.\n我需要组合(combine)几个提交(commit) 假设你的工作分支将会做对于 master 的 pull-request。 一般情况下你不关心提交(commit)的时间戳，只想组合 所有 提交(commit) 到一个单独的里面, 然后重置(reset)重提交(recommit)。 确保主(master)分支是最新的和你的变化都已经提交了, 然后:\n1 2 (my-branch)$ git reset --soft master (my-branch)$ git commit -am \u0026#34;New awesome feature\u0026#34; 如果你想要更多的控制, 想要保留时间戳, 你需要做交互式 rebase (interactive rebase):\n1 (my-branch)$ git rebase -i master 如果没有相对的其它分支， 你将不得不相对自己的HEAD 进行 rebase。 例如：你想组合最近的两次提交(commit), 你将相对于HEAD\\~2 进行 rebase， 组合最近 3 次提交(commit), 相对于HEAD\\~3, 等等。\n1 (master)$ git rebase -i HEAD~2 在你执行了交互式 rebase 的命令(interactive rebase command)后, 你将在你的编辑器里看到类似下面的内容:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature pick b729ad5 fixup pick e3851e8 another fix ## Rebase 8074d12..b729ad5 onto 8074d12 # ## Commands: ## p, pick = use commit ## r, reword = use commit, but edit the commit message ## e, edit = use commit, but stop for amending ## s, squash = use commit, but meld into previous commit ## f, fixup = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message ## x, exec = run command (the rest of the line) using shell # ## These lines can be re-ordered; they are executed from top to bottom. # ## If you remove a line here THAT COMMIT WILL BE LOST. # ## However, if you remove everything, the rebase will be aborted. # ## Note that empty commits are commented out 所有以 # 开头的行都是注释, 不会影响 rebase.\n然后，你可以用任何上面命令列表的命令替换 pick, 你也可以通过删除对应的行来删除一个提交(commit)。\n例如, 如果你想 单独保留最旧(first)的提交(commit),组合所有剩下的到第二个里面, 你就应该编辑第二个提交(commit)后面的每个提交(commit) 前的单词为 f:\n1 2 3 4 pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature f b729ad5 fixup f e3851e8 another fix 如果你想组合这些提交(commit) 并重命名这个提交(commit), 你应该在第二个提交(commit)旁边添加一个r，或者更简单的用s 替代 f:\n1 2 3 4 pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature s b729ad5 fixup s e3851e8 another fix 你可以在接下来弹出的文本提示框里重命名提交(commit)。\n1 2 3 4 5 6 7 8 9 10 Newer, awesomer features ## Please enter the commit message for your changes. Lines starting ## with \u0026#39;#\u0026#39; will be ignored, and an empty message aborts the commit. ## rebase in progress; onto 8074d12 ## You are currently editing a commit while rebasing branch \u0026#39;master\u0026#39; on \u0026#39;8074d12\u0026#39;. # ## Changes to be committed: # modified: README.md # 如果成功了, 你应该看到类似下面的内容:\n1 (master)$ Successfully rebased and updated refs/heads/master. 安全合并(merging)策略 --no-commit 执行合并(merge)但不自动提交, 给用户在做提交前检查和修改的机会。 no-ff 会为特性分支(feature branch)的存在过留下证据, 保持项目历史一致。\n1 (master)$ git merge --no-ff --no-commit my-branch 我需要将一个分支合并成一个提交(commit) 1 (master)$ git merge --squash my-branch 我只想组合(combine)未推的提交(unpushed commit) 有时候，在将数据推向上游之前，你有几个正在进行的工作提交(commit)。这时候不希望把已经推(push)过的组合进来，因为其他人可能已经有提交(commit)引用它们了。\n1 (master)$ git rebase -i @{u} 这会产生一次交互式的 rebase(interactive rebase), 只会列出没有推(push)的提交(commit)， 在这个列表时进行 reorder/fix/squash 都是安全的。\n检查是否分支上的所有提交(commit)都合并(merge)过了 检查一个分支上的所有提交(commit)是否都已经合并(merge)到了其它分支, 你应该在这些分支的 head(或任何 commits)之间做一次 diff:\n1 (master)$ git log --graph --left-right --cherry-pick --oneline HEAD...feature/120-on-scroll 这会告诉你在一个分支里有而另一个分支没有的所有提交(commit), 和分支之间不共享的提交(commit)的列表。 另一个做法可以是:\n1 (master)$ git log master ^feature/120-on-scroll --no-merges 交互式 rebase(interactive rebase)可能出现的问题 这个 rebase 编辑屏幕出现\u0026rsquo;noop' 如果你看到的是这样:\n1 noop 这意味着你 rebase 的分支和当前分支在同一个提交(commit)上, 或者 领先(ahead) 当前分支。 你可以尝试:\n检查确保主(master)分支没有问题 rebase HEAD\\~2 或者更早 有冲突的情况 如果你不能成功的完成 rebase, 你可能必须要解决冲突。\n首先执行 git status 找出哪些文件有冲突:\n1 2 3 4 5 6 7 (my-branch)$ git status On branch my-branch Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: README.md 在这个例子里面, README.md 有冲突。 打开这个文件找到类似下面的内容:\n1 2 3 4 5 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD some code ========= some code \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; new-commit 你需要解决新提交的代码(示例里, 从中间==线到new-commit的地方)与HEAD 之间不一样的地方.\n有时候这些合并非常复杂，你应该使用可视化的差异编辑器(visual diff editor):\n1 (master*)$ git mergetool -t opendiff 在你解决完所有冲突和测试过后, git add 变化了的(changed)文件, 然后用git rebase --continue 继续 rebase。\n1 2 (my-branch)$ git add README.md (my-branch)$ git rebase --continue 如果在解决完所有的冲突过后，得到了与提交前一样的结果, 可以执行git rebase --skip。\n任何时候你想结束整个 rebase 过程，回来 rebase 前的分支状态, 你可以做:\n1 (my-branch)$ git rebase --abort 查看信息 显示工作路径下已修改的文件：git status\n显示与上次提交版本文件的不同：git diff\n显示提交历史：\n1 2 3 4 5 6 7 8 # 从最新提交开始，显示所有的提交记录（显示hash， 作者信息，提交的标题和时间） $ git log # 显示某个用户的所有提交 $ git log --author=\u0026#34;username\u0026#34; # 显示某个文件的所有修改 $ git log -p \u0026lt;file\u0026gt; 显示搜索内容：\n1 2 3 4 5 # 从当前目录的所有文件中查找文本内容 $ git grep \u0026#34;Hello\u0026#34; # 在某一版本中搜索文本 $ git grep \u0026#34;Hello\u0026#34; v2.5 其他 克隆所有子模块 1 git clone --recursive git://github.com/foo/bar.git 如果已经克隆了:\n1 git submodule update --init --recursive 已删除补丁(patch) 如果某人在 GitHub 上给你发了一个 pull request, 但是然后他删除了他自己的原始 fork, 你将没法克隆他们的提交(commit)或使用 git am。在这种情况下, 最好手动的查看他们的提交(commit)，并把它们拷贝到一个本地新分支，然后做提交。\n做完提交后, 再修改作者，参见变更作者。 然后, 应用变化, 再发起一个新的 pull request。\n跟踪文件(Tracking Files) 我只想改变一个文件名字的大小写，而不修改内容 1 (master)$ git mv --force myfile MyFile 我想从 Git 删除一个文件，但保留该文件 1 (master)$ git rm --cached log.txt Fork 项目 GitHub 中 Fork 是 服务端的代码仓库克隆（即 新克隆出来的代码仓库在远程服务端），包含了原来的仓库（即 upstream repository，上游仓库）所有内容，如分支、Tag、提交。代码托管服务（如 Github、BitBucket）提供了方便的完成 Fork 操作的功能（在仓库页面点一下 Fork 按钮）。这样有了一个你自己的可以自由提交的远程仓库，然后可以通过的 Pull Request 把你的提交贡献回 原仓库。而对于原仓库 Owner 来说，鼓励别人 Fork 自己的仓库，通过 Pull Request 给自己的仓库做贡献，也能提高了自己仓库的知名度。\n参考：Fork a repo\n（1）执行 git remote -v，您将看到当前为 fork 配置的远程存储库。\n（2）添加上游项目的仓库地址\n1 git remote add upstream \u0026lt;github仓库地址\u0026gt; （3）确认是否添加成功，再次键入 git remote -v。\n（4）获取上游项目更新，可以执行 git fetch upstream\n（5）同步上游项目的代码到新仓库\n1 2 3 4 # merge git merge upstream/master # rebase git rebase upstream/master origin/master 我不知道我做错了些什么 你把事情搞砸了：你 重置(reset) 了一些东西, 或者你合并了错误的分支, 亦或你强推了后找不到你自己的提交(commit)了。有些时候, 你一直都做得很好, 但你想回到以前的某个状态。\n这就是 git reflog 的目的， reflog 记录对分支顶端(the tip of a branch)的任何改变, 即使那个顶端没有被任何分支或标签引用。基本上, 每次 HEAD 的改变, 一条新的记录就会增加到reflog。遗憾的是，这只对本地分支起作用，且它只跟踪动作 (例如，不会跟踪一个没有被记录的文件的任何改变)。\n1 2 3 4 (master)$ git reflog 0a2e358 HEAD@{0}: reset: moving to HEAD\\~2 0254ea7 HEAD@{1}: checkout: moving from 2.2 to master c10f740 HEAD@{2}: checkout: moving from master to 2.2 上面的 reflog 展示了从 master 分支签出(checkout)到 2.2 分支，然后再签回。 那里，还有一个硬重置(hard reset)到一个较旧的提交。最新的动作出现在最上面以 HEAD@{0}标识.\n如果事实证明你不小心回移(move back)了提交(commit), reflog 会包含你不小心回移前 master 上指向的提交(0254ea7)。\n1 git reset --hard 0254ea7 然后使用 git reset 就可以把 master 改回到之前的 commit，这提供了一个在历史被意外更改情况下的安全网。\n📚 资料 官方资源 Git 官网 Git Github Github 官方教程 模板 gitignore 模板 - .gitignore 文件模板 gitattributes 模板 - .gitattributes 文件模板 github-cheat-sheet - git 命令简略图表 Git 教程 Learn Git branching - 交互式教程 Git 官方推荐教程 - Scott Chacon 的 Git 书。 git-flight-rules git-tips Git 中文教程 廖雪峰的 Git 教程 有关 git 的学习资源 文章 Git Cookbook Git 奇技淫巧 Git 风格指南 Git 在团队中的最佳实践\u0026ndash;如何正确使用 Git Flow Commit message 和 Change log 编写指南 Git 工具 guis - Git 官网展示的客户端工具列表。 gogs - 极易搭建的自助 Git 服务。 gitflow - 应用 fit-flow 模型的工具。 firstaidgit.io 一个可搜索的最常被问到的 Git 的问题 git-extra-commands - 一堆有用的额外的 Git 脚本 git-extras - GIT 工具集 \u0026ndash; repo summary, repl, changelog population, author commit percentages and more git-fire - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。 git-tips - Git 小提示 git-town - 通用，高级 Git 工作流支持！ GUI 客户端 GitKraken - 豪华的 Git 客户端 Windows, Mac \u0026amp; Linux git-cola - 另外一个 Git 客户端 Windows \u0026amp; OS X GitUp - 一个新的 Git 客户端，在处理 Git 的复杂性上有自己的特点 gitx-dev - 图形化的 Git 客户端 OS X Source Tree - 免费的图形化 Git 客户端 Windows \u0026amp; OS X Tower - 图形化 Git 客户端 OS X(付费) git cheat sheet github-git-cheat-sheet ","permalink":"https://WFUing.github.io/posts/tech/architecture/git/git-tutorial/","summary":"Git 帮助手册 国外网友制作了一张 Git Cheat Sheet，总结很精炼，各位不妨收藏一下。\n本节选择性介绍 git 中比较常用的命令行场景。\n安装 （1）Debian/Ubuntu 环境安装\n如果你使用的系统是 Debian/Ubuntu ， 安装命令为：\n1 2 3 4 5 $ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ \u0026gt; libz-dev libssl-dev $ apt-get install git-core $ git --version git version 1.8.1.2 （2）Centos/RedHat 环境安装\n如果你使用的系统是 Centos/RedHat ，安装命令为：\n1 2 3 4 5 $ yum install curl-devel expat-devel gettext-devel \\ \u0026gt; openssl-devel zlib-devel $ yum -y install git-core $ git --version git version 1.","title":"Git Tutorial"},{"content":" 由于 bash 是 Linux 标准默认的 shell 解释器，可以说 bash 是 shell 编程的基础。\n本文主要介绍 bash 的语法，对于 linux 指令不做任何介绍。\n1 2 3 4 5 ███████╗██╗ ██╗███████╗██╗ ██╗ ██╔════╝██║ ██║██╔════╝██║ ██║ ███████╗███████║█████╗ ██║ ██║ ╚════██║██╔══██║██╔══╝ ██║ ██║ ███████║██║ ██║███████╗███████╗███████╗ 简介 什么是 shell Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。 Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问 Linux 内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。\n什么是 shell 脚本 Shell 脚本（shell script），是一种为 shell 编写的脚本程序，一般文件后缀为 .sh。\n业界所说的 shell 通常都是指 shell 脚本，但 shell 和 shell script 是两个不同的概念。\nShell 环境 Shell 编程跟 java、php 编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。\nShell 的解释器种类众多，常见的有：\nsh - 即 Bourne Shell。sh 是 Unix 标准默认的 shell。 bash - 即 Bourne Again Shell。bash 是 Linux 标准默认的 shell。 fish - 智能和用户友好的命令行 shell。 xiki - 使 shell 控制台更友好，更强大。 zsh - 功能强大的 shell 与脚本语言。 指定脚本解释器 在 shell 脚本，#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 解释器。#! 被称作shebang（也称为 Hashbang ）。\n所以，你应该会在 shell 中，见到诸如以下的注释：\n指定 sh 解释器 1 #!/bin/sh 指定 bash 解释器 1 #!/bin/bash 注意\n上面的指定解释器的方式是比较常见的，但有时候，你可能也会看到下面的方式：\n1 #!/usr/bin/env bash 这样做的好处是，系统会自动在 PATH 环境变量中查找你指定的程序（本例中的bash）。相比第一种写法，你应该尽量用这种写法，因为程序的路径是不确定的。这样写还有一个好处，操作系统的PATH变量有可能被配置为指向程序的另一个版本。比如，安装完新版本的bash，我们可能将其路径添加到PATH中，来\u0026quot;隐藏\u0026quot;老版本。如果直接用#!/bin/bash，那么系统会选择老版本的bash来执行脚本，如果用#!/usr/bin/env bash，则会使用新版本。\n模式 shell 有交互和非交互两种模式。\n交互模式 简单来说，你可以将 shell 的交互模式理解为执行命令行。\n看到形如下面的东西，说明 shell 处于交互模式下：\n1 user@host:~$ 接着，便可以输入一系列 Linux 命令，比如 ls，grep，cd，mkdir，rm 等等。\n非交互模式 简单来说，你可以将 shell 的非交互模式理解为执行 shell 脚本。\n在非交互模式下，shell 从文件或者管道中读取命令并执行。\n当 shell 解释器执行完文件中的最后一个命令，shell 进程终止，并回到父进程。\n可以使用下面的命令让 shell 以非交互模式运行：\n1 2 3 4 sh /path/to/script.sh bash /path/to/script.sh source /path/to/script.sh ./path/to/script.sh 上面的例子中，script.sh是一个包含 shell 解释器可以识别并执行的命令的普通文本文件，sh和bash是 shell 解释器程序。你可以使用任何喜欢的编辑器创建script.sh（vim，nano，Sublime Text, Atom 等等）。\n其中，source /path/to/script.sh 和 ./path/to/script.sh 是等价的。\n除此之外，你还可以通过chmod命令给文件添加可执行的权限，来直接执行脚本文件：\n1 2 chmod +x /path/to/script.sh #使脚本具有执行权限 /path/to/test.sh 这种方式要求脚本文件的第一行必须指明运行该脚本的程序，比如：\n💻 『示例源码』\n1 2 #!/usr/bin/env bash echo \u0026#34;Hello, world!\u0026#34; 上面的例子中，我们使用了一个很有用的命令echo来输出字符串到屏幕上。\n基本语法 解释器 前面虽然两次提到了#! ，但是本着重要的事情说三遍的精神，这里再强调一遍：\n在 shell 脚本，#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 解释器。#! 被称作shebang（也称为 Hashbang ）。\n#! 决定了脚本可以像一个独立的可执行文件一样执行，而不用在终端之前输入sh, bash, python, php等。\n1 2 3 # 以下两种方式都可以指定 shell 解释器为 bash，第二种方式更好 #!/bin/bash #!/usr/bin/env bash 注释 注释可以说明你的代码是什么作用，以及为什么这样写。\nshell 语法中，注释是特殊的语句，会被 shell 解释器忽略。\n单行注释 - 以 # 开头，到行尾结束。 多行注释 - 以 :\u0026lt;\u0026lt;EOF 开头，到 EOF 结束。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #-------------------------------------------- # shell 注释示例 # author：zp #-------------------------------------------- # echo \u0026#39;这是单行注释\u0026#39; ########## 这是分割线 ########## :\u0026lt;\u0026lt;EOF echo \u0026#39;这是多行注释\u0026#39; echo \u0026#39;这是多行注释\u0026#39; echo \u0026#39;这是多行注释\u0026#39; EOF echo echo 用于字符串的输出。\n输出普通字符串：\n1 2 echo \u0026#34;hello, world\u0026#34; # Output: hello, world 输出含变量的字符串：\n1 2 echo \u0026#34;hello, \\\u0026#34;zp\\\u0026#34;\u0026#34; # Output: hello, \u0026#34;zp\u0026#34; 输出含变量的字符串：\n1 2 3 name=zp echo \u0026#34;hello, \\\u0026#34;${name}\\\u0026#34;\u0026#34; # Output: hello, \u0026#34;zp\u0026#34; 输出含换行符的字符串：\n1 2 3 4 5 6 7 8 # 输出含换行符的字符串 echo \u0026#34;YES\\nNO\u0026#34; # Output: YES\\nNO echo -e \u0026#34;YES\\nNO\u0026#34; # -e 开启转义 # Output: # YES # NO 输出含不换行符的字符串：\n1 2 3 4 5 6 7 8 9 10 echo \u0026#34;YES\u0026#34; echo \u0026#34;NO\u0026#34; # Output: # YES # NO echo -e \u0026#34;YES\\c\u0026#34; # -e 开启转义 \\c 不换行 echo \u0026#34;NO\u0026#34; # Output: # YESNO 输出重定向至文件\n1 echo \u0026#34;test\u0026#34; \u0026gt; test.txt 输出执行结果\n1 2 echo `pwd` # Output:(当前目录路径) 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #!/usr/bin/env bash # 输出普通字符串 echo \u0026#34;hello, world\u0026#34; # Output: hello, world # 输出含变量的字符串 echo \u0026#34;hello, \\\u0026#34;zp\\\u0026#34;\u0026#34; # Output: hello, \u0026#34;zp\u0026#34; # 输出含变量的字符串 name=zp echo \u0026#34;hello, \\\u0026#34;${name}\\\u0026#34;\u0026#34; # Output: hello, \u0026#34;zp\u0026#34; # 输出含换行符的字符串 echo \u0026#34;YES\\nNO\u0026#34; # Output: YES\\nNO echo -e \u0026#34;YES\\nNO\u0026#34; # -e 开启转义 # Output: # YES # NO # 输出含不换行符的字符串 echo \u0026#34;YES\u0026#34; echo \u0026#34;NO\u0026#34; # Output: # YES # NO echo -e \u0026#34;YES\\c\u0026#34; # -e 开启转义 \\c 不换行 echo \u0026#34;NO\u0026#34; # Output: # YESNO # 输出内容定向至文件 echo \u0026#34;test\u0026#34; \u0026gt; test.txt # 输出执行结果 echo `pwd` # Output:(当前目录路径) printf printf 用于格式化输出字符串。\n默认，printf 不会像 echo 一样自动添加换行符，如果需要换行可以手动添加 \\n。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 单引号 printf \u0026#39;%d %s\\n\u0026#39; 1 \u0026#34;abc\u0026#34; # Output:1 abc # 双引号 printf \u0026#34;%d %s\\n\u0026#34; 1 \u0026#34;abc\u0026#34; # Output:1 abc # 无引号 printf %s abcdef # Output: abcdef(并不会换行) # 格式只指定了一个参数，但多出的参数仍然会按照该格式输出 printf \u0026#34;%s\\n\u0026#34; abc def # Output: # abc # def printf \u0026#34;%s %s %s\\n\u0026#34; a b c d e f g h i j # Output: # a b c # d e f # g h i # j # 如果没有参数，那么 %s 用 NULL 代替，%d 用 0 代替 printf \u0026#34;%s and %d \\n\u0026#34; # Output: # and 0 # 格式化输出 printf \u0026#34;%-10s %-8s %-4s\\n\u0026#34; 姓名 性别 体重kg printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 郭靖 男 66.1234 printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 杨过 男 48.6543 printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 郭芙 女 47.9876 # Output: # 姓名 性别 体重kg # 郭靖 男 66.12 # 杨过 男 48.65 # 郭芙 女 47.99 printf 的转义符 序列 说明 \\a 警告字符，通常为 ASCII 的 BEL 字符 \\b 后退 \\c 抑制（不显示）输出结果中任何结尾的换行字符（只在%b 格式指示符控制下的参数字符串中有效），而且，任何留在参数里的字符、任何接下来的参数以及任何留在格式字符串中的字符，都被忽略 \\f 换页（formfeed） \\n 换行 \\r 回车（Carriage return） \\t 水平制表符 \\v 垂直制表符 \\\\ 一个字面上的反斜杠字符 \\ddd 表示 1 到 3 位数八进制值的字符。仅在格式字符串中有效 \\0ddd 表示 1 到 3 位的八进制值字符 变量 跟许多程序设计语言一样，你可以在 bash 中创建变量。\nBash 中没有数据类型，bash 中的变量可以保存一个数字、一个字符、一个字符串等等。同时无需提前声明变量，给变量赋值会直接创建变量。\n变量命名原则 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用 bash 里的关键字（可用 help 命令查看保留关键字）。 声明变量 访问变量的语法形式为：${var} 和 $var 。\n变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界，所以推荐加花括号。\n1 2 3 word=\u0026#34;hello\u0026#34; echo ${word} # Output: hello 只读变量 使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。\n1 2 3 4 rword=\u0026#34;hello\u0026#34; echo ${rword} readonly rword # rword=\u0026#34;bye\u0026#34; # 如果放开注释，执行时会报错 删除变量 使用 unset 命令可以删除变量。变量被删除后不能再次使用。unset 命令不能删除只读变量。\n1 2 3 4 5 6 7 dword=\u0026#34;hello\u0026#34; # 声明变量 echo ${dword} # 输出变量值 # Output: hello unset dword # 删除变量 echo ${dword} # Output: （空） 变量类型 局部变量 - 局部变量是仅在某个脚本内部有效的变量。它们不能被其他的程序和脚本访问。 环境变量 - 环境变量是对当前 shell 会话内所有的程序或脚本都可见的变量。创建它们跟创建局部变量类似，但使用的是 export 关键字，shell 脚本也可以定义环境变量。 常见的环境变量：\n变量 描述 $HOME 当前用户的用户目录 $PATH 用分号分隔的目录列表，shell 会到这些目录中查找命令 $PWD 当前工作目录 $RANDOM 0 到 32767 之间的整数 $UID 数值类型，当前用户的用户 ID $PS1 主要系统输入提示符 $PS2 次要系统输入提示符 这里 有一张更全面的 Bash 环境变量列表。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #!/usr/bin/env bash ################### 声明变量 ################### name=\u0026#34;world\u0026#34; echo \u0026#34;hello ${name}\u0026#34; # Output: hello world ################### 输出变量 ################### folder=$(pwd) echo \u0026#34;current path: ${folder}\u0026#34; ################### 只读变量 ################### rword=\u0026#34;hello\u0026#34; echo ${rword} # Output: hello readonly rword # rword=\u0026#34;bye\u0026#34; # 如果放开注释，执行时会报错 ################### 删除变量 ################### dword=\u0026#34;hello\u0026#34; # 声明变量 echo ${dword} # 输出变量值 # Output: hello unset dword # 删除变量 echo ${dword} # Output: （空） ################### 系统变量 ################### echo \u0026#34;UID:$UID\u0026#34; echo LOGNAME:$LOGNAME echo User:$USER echo HOME:$HOME echo PATH:$PATH echo HOSTNAME:$HOSTNAME echo SHELL:$SHELL echo LANG:$LANG ################### 自定义变量 ################### days=10 user=\u0026#34;admin\u0026#34; echo \u0026#34;$user logged in $days days age\u0026#34; days=5 user=\u0026#34;root\u0026#34; echo \u0026#34;$user logged in $days days age\u0026#34; # Output: # admin logged in 10 days age # root logged in 5 days age ################### 从变量读取列表 ################### colors=\u0026#34;Red Yellow Blue\u0026#34; colors=$colors\u0026#34; White Black\u0026#34; for color in $colors do echo \u0026#34; $color\u0026#34; done 字符串 单引号和双引号 shell 字符串可以用单引号 ''，也可以用双引号 “”，也可以不用引号。\n单引号的特点 单引号里不识别变量 单引号里不能出现单独的单引号（使用转义符也不行），但可成对出现，作为字符串拼接使用。 双引号的特点 双引号里识别变量 双引号里可以出现转义字符 综上，推荐使用双引号。\n拼接字符串 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 使用单引号拼接 name1=\u0026#39;white\u0026#39; str1=\u0026#39;hello, \u0026#39;${name1}\u0026#39;\u0026#39; str2=\u0026#39;hello, ${name1}\u0026#39; echo ${str1}_${str2} # Output: # hello, white_hello, ${name1} # 使用双引号拼接 name2=\u0026#34;black\u0026#34; str3=\u0026#34;hello, \u0026#34;${name2}\u0026#34;\u0026#34; str4=\u0026#34;hello, ${name2}\u0026#34; echo ${str3}_${str4} # Output: # hello, black_hello, black 获取字符串长度 1 2 3 4 text=\u0026#34;12345\u0026#34; echo ${#text} # Output: # 5 截取子字符串 1 2 3 4 text=\u0026#34;12345\u0026#34; echo ${text:2:2} # Output: # 34 从第 3 个字符开始，截取 2 个字符\n查找子字符串 1 2 3 4 5 6 7 8 #!/usr/bin/env bash text=\u0026#34;hello\u0026#34; echo `expr index \u0026#34;${text}\u0026#34; ll` # Execute: ./str-demo5.sh # Output: # 3 查找 ll 子字符在 hello 字符串中的起始位置。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 #!/usr/bin/env bash ################### 使用单引号拼接字符串 ################### name1=\u0026#39;white\u0026#39; str1=\u0026#39;hello, \u0026#39;${name1}\u0026#39;\u0026#39; str2=\u0026#39;hello, ${name1}\u0026#39; echo ${str1}_${str2} # Output: # hello, white_hello, ${name1} ################### 使用双引号拼接字符串 ################### name2=\u0026#34;black\u0026#34; str3=\u0026#34;hello, \u0026#34;${name2}\u0026#34;\u0026#34; str4=\u0026#34;hello, ${name2}\u0026#34; echo ${str3}_${str4} # Output: # hello, black_hello, black ################### 获取字符串长度 ################### text=\u0026#34;12345\u0026#34; echo \u0026#34;${text} length is: ${#text}\u0026#34; # Output: # 12345 length is: 5 # 获取子字符串 text=\u0026#34;12345\u0026#34; echo ${text:2:2} # Output: # 34 ################### 查找子字符串 ################### text=\u0026#34;hello\u0026#34; echo `expr index \u0026#34;${text}\u0026#34; ll` # Output: # 3 ################### 判断字符串中是否包含子字符串 ################### result=$(echo \u0026#34;${str}\u0026#34; | grep \u0026#34;feature/\u0026#34;) if [[ \u0026#34;$result\u0026#34; != \u0026#34;\u0026#34; ]]; then echo \u0026#34;feature/ 是 ${str} 的子字符串\u0026#34; else echo \u0026#34;feature/ 不是 ${str} 的子字符串\u0026#34; fi ################### 截取关键字左边内容 ################### full_branch=\u0026#34;feature/1.0.0\u0026#34; branch=`echo ${full_branch#feature/}` echo \u0026#34;branch is ${branch}\u0026#34; ################### 截取关键字右边内容 ################### full_version=\u0026#34;0.0.1-SNAPSHOT\u0026#34; version=`echo ${full_version%-SNAPSHOT}` echo \u0026#34;version is ${version}\u0026#34; ################### 字符串分割成数组 ################### str=\u0026#34;0.0.0.1\u0026#34; OLD_IFS=\u0026#34;$IFS\u0026#34; IFS=\u0026#34;.\u0026#34; array=( ${str} ) IFS=\u0026#34;$OLD_IFS\u0026#34; size=${#array[*]} lastIndex=`expr ${size} - 1` echo \u0026#34;数组长度：${size}\u0026#34; echo \u0026#34;最后一个数组元素：${array[${lastIndex}]}\u0026#34; for item in ${array[@]} do echo \u0026#34;$item\u0026#34; done ################### 判断字符串是否为空 ################### #-n 判断长度是否非零 #-z 判断长度是否为零 str=testing str2=\u0026#39;\u0026#39; if [[ -n \u0026#34;$str\u0026#34; ]] then echo \u0026#34;The string $str is not empty\u0026#34; else echo \u0026#34;The string $str is empty\u0026#34; fi if [[ -n \u0026#34;$str2\u0026#34; ]] then echo \u0026#34;The string $str2 is not empty\u0026#34; else echo \u0026#34;The string $str2 is empty\u0026#34; fi #\tOutput: #\tThe string testing is not empty #\tThe string is empty ################### 字符串比较 ################### str=hello str2=world if [[ $str = \u0026#34;hello\u0026#34; ]]; then echo \u0026#34;str equals hello\u0026#34; else echo \u0026#34;str not equals hello\u0026#34; fi if [[ $str2 = \u0026#34;hello\u0026#34; ]]; then echo \u0026#34;str2 equals hello\u0026#34; else echo \u0026#34;str2 not equals hello\u0026#34; fi 数组 bash 只支持一维数组。\n数组下标从 0 开始，下标可以是整数或算术表达式，其值应大于或等于 0。\n创建数组 1 2 3 # 创建数组的不同方式 nums=([2]=2 [0]=0 [1]=1) colors=(red yellow \u0026#34;dark blue\u0026#34;) 访问数组元素 访问数组的单个元素： 1 2 echo ${nums[1]} # Output: 1 访问数组的所有元素： 1 2 3 4 5 echo ${colors[*]} # Output: red yellow dark blue echo ${colors[@]} # Output: red yellow dark blue 上面两行有很重要（也很微妙）的区别：\n为了将数组中每个元素单独一行输出，我们用 printf 命令：\n1 2 3 4 5 6 printf \u0026#34;+ %s\\n\u0026#34; ${colors[*]} # Output: # + red # + yellow # + dark # + blue 为什么dark和blue各占了一行？尝试用引号包起来：\n1 2 3 printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;${colors[*]}\u0026#34; # Output: # + red yellow dark blue 现在所有的元素都在一行输出 —— 这不是我们想要的！让我们试试${colors[@]}\n1 2 3 4 5 printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;${colors[@]}\u0026#34; # Output: # + red # + yellow # + dark blue 在引号内，${colors[@]}将数组中的每个元素扩展为一个单独的参数；数组元素中的空格得以保留。\n访问数组的部分元素： 1 2 3 echo ${nums[@]:0:2} # Output: # 0 1 在上面的例子中，${array[@]} 扩展为整个数组，:0:2取出了数组中从 0 开始，长度为 2 的元素。\n访问数组长度 1 2 3 echo ${#nums[*]} # Output: # 3 向数组中添加元素 向数组中添加元素也非常简单：\n1 2 3 4 colors=(white \u0026#34;${colors[@]}\u0026#34; green black) echo ${colors[@]} # Output: # white red yellow dark blue green black 上面的例子中，${colors[@]} 扩展为整个数组，并被置换到复合赋值语句中，接着，对数组colors的赋值覆盖了它原来的值。\n从数组中删除元素 用unset命令来从数组中删除一个元素：\n1 2 3 4 unset nums[0] echo ${nums[@]} # Output: # 1 2 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #!/usr/bin/env bash ################### 创建数组 ################### nums=( [ 2 ] = 2 [ 0 ] = 0 [ 1 ] = 1 ) colors=( red yellow \u0026#34;dark blue\u0026#34; ) ################### 访问数组的单个元素 ################### echo ${nums[1]} # Output: 1 ################### 访问数组的所有元素 ################### echo ${colors[*]} # Output: red yellow dark blue echo ${colors[@]} # Output: red yellow dark blue printf \u0026#34;+ %s\\n\u0026#34; ${colors[*]} # Output: # + red # + yellow # + dark # + blue printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;${colors[*]}\u0026#34; # Output: # + red yellow dark blue printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;${colors[@]}\u0026#34; # Output: # + red # + yellow # + dark blue ################### 访问数组的部分元素 ################### echo ${nums[@]:0:2} # Output: # 0 1 ################### 获取数组长度 ################### echo ${#nums[*]} # Output: # 3 ################### 向数组中添加元素 ################### colors=( white \u0026#34;${colors[@]}\u0026#34; green black ) echo ${colors[@]} # Output: # white red yellow dark blue green black ################### 从数组中删除元素 ################### unset nums[ 0 ] echo ${nums[@]} # Output: # 1 2 运算符 算术运算符 下表列出了常用的算术运算符，假定变量 x 为 10，变量 y 为 20：\n运算符 说明 举例 + 加法 expr $x + $y 结果为 30。 - 减法 expr $x - $y 结果为 -10。 * 乘法 expr $x * $y 结果为 200。 / 除法 expr $y / $x 结果为 2。 % 取余 expr $y % $x 结果为 0。 = 赋值 x=$y 将把变量 y 的值赋给 x。 == 相等。用于比较两个数字，相同则返回 true。 [ $x == $y ] 返回 false。 != 不相等。用于比较两个数字，不相同则返回 true。 [ $x != $y ] 返回 true。 **注意：**条件表达式要放在方括号之间，并且要有空格，例如: [$x==$y] 是错误的，必须写成 [ $x == $y ]。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 x=10 y=20 echo \u0026#34;x=${x}, y=${y}\u0026#34; val=`expr ${x} + ${y}` echo \u0026#34;${x} + ${y} = $val\u0026#34; val=`expr ${x} - ${y}` echo \u0026#34;${x} - ${y} = $val\u0026#34; val=`expr ${x} \\* ${y}` echo \u0026#34;${x} * ${y} = $val\u0026#34; val=`expr ${y} / ${x}` echo \u0026#34;${y} / ${x} = $val\u0026#34; val=`expr ${y} % ${x}` echo \u0026#34;${y} % ${x} = $val\u0026#34; if [[ ${x} == ${y} ]] then echo \u0026#34;${x} = ${y}\u0026#34; fi if [[ ${x} != ${y} ]] then echo \u0026#34;${x} != ${y}\u0026#34; fi # Output: # x=10, y=20 # 10 + 20 = 30 # 10 - 20 = -10 # 10 * 20 = 200 # 20 / 10 = 2 # 20 % 10 = 0 # 10 != 20 关系运算符 关系运算符只支持数字，不支持字符串，除非字符串的值是数字。\n下表列出了常用的关系运算符，假定变量 x 为 10，变量 y 为 20：\n运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ]返回 false。 -ne 检测两个数是否相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ]返回 true。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 x=10 y=20 echo \u0026#34;x=${x}, y=${y}\u0026#34; if [[ ${x} -eq ${y} ]]; then echo \u0026#34;${x} -eq ${y} : x 等于 y\u0026#34; else echo \u0026#34;${x} -eq ${y}: x 不等于 y\u0026#34; fi if [[ ${x} -ne ${y} ]]; then echo \u0026#34;${x} -ne ${y}: x 不等于 y\u0026#34; else echo \u0026#34;${x} -ne ${y}: x 等于 y\u0026#34; fi if [[ ${x} -gt ${y} ]]; then echo \u0026#34;${x} -gt ${y}: x 大于 y\u0026#34; else echo \u0026#34;${x} -gt ${y}: x 不大于 y\u0026#34; fi if [[ ${x} -lt ${y} ]]; then echo \u0026#34;${x} -lt ${y}: x 小于 y\u0026#34; else echo \u0026#34;${x} -lt ${y}: x 不小于 y\u0026#34; fi if [[ ${x} -ge ${y} ]]; then echo \u0026#34;${x} -ge ${y}: x 大于或等于 y\u0026#34; else echo \u0026#34;${x} -ge ${y}: x 小于 y\u0026#34; fi if [[ ${x} -le ${y} ]]; then echo \u0026#34;${x} -le ${y}: x 小于或等于 y\u0026#34; else echo \u0026#34;${x} -le ${y}: x 大于 y\u0026#34; fi # Output: # x=10, y=20 # 10 -eq 20: x 不等于 y # 10 -ne 20: x 不等于 y # 10 -gt 20: x 不大于 y # 10 -lt 20: x 小于 y # 10 -ge 20: x 小于 y # 10 -le 20: x 小于或等于 y 布尔运算符 下表列出了常用的布尔运算符，假定变量 x 为 10，变量 y 为 20：\n运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 x=10 y=20 echo \u0026#34;x=${x}, y=${y}\u0026#34; if [[ ${x} != ${y} ]]; then echo \u0026#34;${x} != ${y} : x 不等于 y\u0026#34; else echo \u0026#34;${x} != ${y}: x 等于 y\u0026#34; fi if [[ ${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 15 ]]; then echo \u0026#34;${x} 小于 100 且 ${y} 大于 15 : 返回 true\u0026#34; else echo \u0026#34;${x} 小于 100 且 ${y} 大于 15 : 返回 false\u0026#34; fi if [[ ${x} -lt 100 || ${y} -gt 100 ]]; then echo \u0026#34;${x} 小于 100 或 ${y} 大于 100 : 返回 true\u0026#34; else echo \u0026#34;${x} 小于 100 或 ${y} 大于 100 : 返回 false\u0026#34; fi if [[ ${x} -lt 5 || ${y} -gt 100 ]]; then echo \u0026#34;${x} 小于 5 或 ${y} 大于 100 : 返回 true\u0026#34; else echo \u0026#34;${x} 小于 5 或 ${y} 大于 100 : 返回 false\u0026#34; fi # Output: # x=10, y=20 # 10 != 20 : x 不等于 y # 10 小于 100 且 20 大于 15 : 返回 true # 10 小于 100 或 20 大于 100 : 返回 true # 10 小于 5 或 20 大于 100 : 返回 false 逻辑运算符 以下介绍 Shell 的逻辑运算符，假定变量 x 为 10，变量 y 为 20:\n运算符 说明 举例 \u0026amp;\u0026amp; 逻辑的 AND [[ ${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 100 ]] 返回 false ` ` 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 x=10 y=20 echo \u0026#34;x=${x}, y=${y}\u0026#34; if [[ ${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 100 ]] then echo \u0026#34;${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 100 返回 true\u0026#34; else echo \u0026#34;${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 100 返回 false\u0026#34; fi if [[ ${x} -lt 100 || ${y} -gt 100 ]] then echo \u0026#34;${x} -lt 100 || ${y} -gt 100 返回 true\u0026#34; else echo \u0026#34;${x} -lt 100 || ${y} -gt 100 返回 false\u0026#34; fi # Output: # x=10, y=20 # 10 -lt 100 \u0026amp;\u0026amp; 20 -gt 100 返回 false # 10 -lt 100 || 20 -gt 100 返回 true 字符串运算符 下表列出了常用的字符串运算符，假定变量 a 为 \u0026ldquo;abc\u0026rdquo;，变量 b 为 \u0026ldquo;efg\u0026rdquo;：\n运算符 说明 举例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为 0，为 0 返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否为 0，不为 0 返回 true。 [ -n $a ] 返回 true。 str 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 x=\u0026#34;abc\u0026#34; y=\u0026#34;xyz\u0026#34; echo \u0026#34;x=${x}, y=${y}\u0026#34; if [[ ${x} = ${y} ]]; then echo \u0026#34;${x} = ${y} : x 等于 y\u0026#34; else echo \u0026#34;${x} = ${y}: x 不等于 y\u0026#34; fi if [[ ${x} != ${y} ]]; then echo \u0026#34;${x} != ${y} : x 不等于 y\u0026#34; else echo \u0026#34;${x} != ${y}: x 等于 y\u0026#34; fi if [[ -z ${x} ]]; then echo \u0026#34;-z ${x} : 字符串长度为 0\u0026#34; else echo \u0026#34;-z ${x} : 字符串长度不为 0\u0026#34; fi if [[ -n \u0026#34;${x}\u0026#34; ]]; then echo \u0026#34;-n ${x} : 字符串长度不为 0\u0026#34; else echo \u0026#34;-n ${x} : 字符串长度为 0\u0026#34; fi if [[ ${x} ]]; then echo \u0026#34;${x} : 字符串不为空\u0026#34; else echo \u0026#34;${x} : 字符串为空\u0026#34; fi # Output: # x=abc, y=xyz # abc = xyz: x 不等于 y # abc != xyz : x 不等于 y # -z abc : 字符串长度不为 0 # -n abc : 字符串长度不为 0 # abc : 字符串不为空 文件测试运算符 文件测试运算符用于检测 Unix 文件的各种属性。\n属性检测描述如下：\n操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ]返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于 0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 file=\u0026#34;/etc/hosts\u0026#34; if [[ -r ${file} ]]; then echo \u0026#34;${file} 文件可读\u0026#34; else echo \u0026#34;${file} 文件不可读\u0026#34; fi if [[ -w ${file} ]]; then echo \u0026#34;${file} 文件可写\u0026#34; else echo \u0026#34;${file} 文件不可写\u0026#34; fi if [[ -x ${file} ]]; then echo \u0026#34;${file} 文件可执行\u0026#34; else echo \u0026#34;${file} 文件不可执行\u0026#34; fi if [[ -f ${file} ]]; then echo \u0026#34;${file} 文件为普通文件\u0026#34; else echo \u0026#34;${file} 文件为特殊文件\u0026#34; fi if [[ -d ${file} ]]; then echo \u0026#34;${file} 文件是个目录\u0026#34; else echo \u0026#34;${file} 文件不是个目录\u0026#34; fi if [[ -s ${file} ]]; then echo \u0026#34;${file} 文件不为空\u0026#34; else echo \u0026#34;${file} 文件为空\u0026#34; fi if [[ -e ${file} ]]; then echo \u0026#34;${file} 文件存在\u0026#34; else echo \u0026#34;${file} 文件不存在\u0026#34; fi # Output:(根据文件的实际情况，输出结果可能不同) # /etc/hosts 文件可读 # /etc/hosts 文件可写 # /etc/hosts 文件不可执行 # /etc/hosts 文件为普通文件 # /etc/hosts 文件不是个目录 # /etc/hosts 文件不为空 # /etc/hosts 文件存在 控制语句 条件语句 跟其它程序设计语言一样，Bash 中的条件语句让我们可以决定一个操作是否被执行。结果取决于一个包在 $[[ ]]$ 里的表达式。\n由 $[[ ]]$ （sh中是[ ]）包起来的表达式被称作 检测命令 或 基元。这些表达式帮助我们检测一个条件的结果。这里可以找到有关bash 中单双中括号区别的答案。\n共有两个不同的条件表达式：if和case。\nif （1）if 语句\nif在使用上跟其它语言相同。如果中括号里的表达式为真，那么then和fi之间的代码会被执行。fi标志着条件代码块的结束。\n1 2 3 4 5 6 7 8 9 10 # 写成一行 if [[ 1 -eq 1 ]]; then echo \u0026#34;1 -eq 1 result is: true\u0026#34;; fi # Output: 1 -eq 1 result is: true # 写成多行 if [[ \u0026#34;abc\u0026#34; -eq \u0026#34;abc\u0026#34; ]] then echo \u0026#34;\u0026#34;abc\u0026#34; -eq \u0026#34;abc\u0026#34; result is: true\u0026#34; fi # Output: abc -eq abc result is: true （2）if else 语句\n同样，我们可以使用if..else语句，例如：\n1 2 3 4 5 6 if [[ 2 -ne 1 ]]; then echo \u0026#34;true\u0026#34; else echo \u0026#34;false\u0026#34; fi # Output: true （3）if elif else 语句\n有些时候，if..else不能满足我们的要求。别忘了if..elif..else，使用起来也很方便。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 x=10 y=20 if [[ ${x} \u0026gt; ${y} ]]; then echo \u0026#34;${x} \u0026gt; ${y}\u0026#34; elif [[ ${x} \u0026lt; ${y} ]]; then echo \u0026#34;${x} \u0026lt; ${y}\u0026#34; else echo \u0026#34;${x} = ${y}\u0026#34; fi # Output: 10 \u0026lt; 20 case 如果你需要面对很多情况，分别要采取不同的措施，那么使用case会比嵌套的if更有用。使用case来解决复杂的条件判断，看起来像下面这样：\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 exec case ${oper} in \u0026#34;+\u0026#34;) val=`expr ${x} + ${y}` echo \u0026#34;${x} + ${y} = ${val}\u0026#34; ;; \u0026#34;-\u0026#34;) val=`expr ${x} - ${y}` echo \u0026#34;${x} - ${y} = ${val}\u0026#34; ;; \u0026#34;*\u0026#34;) val=`expr ${x} \\* ${y}` echo \u0026#34;${x} * ${y} = ${val}\u0026#34; ;; \u0026#34;/\u0026#34;) val=`expr ${x} / ${y}` echo \u0026#34;${x} / ${y} = ${val}\u0026#34; ;; *) echo \u0026#34;Unknown oper!\u0026#34; ;; esac 每种情况都是匹配了某个模式的表达式。|用来分割多个模式，)用来结束一个模式序列。第一个匹配上的模式对应的命令将会被执行。*代表任何不匹配以上给定模式的模式。命令块儿之间要用;;分隔。\n循环语句 循环其实不足为奇。跟其它程序设计语言一样，bash 中的循环也是只要控制条件为真就一直迭代执行的代码块。\nBash 中有四种循环：for，while，until和select。\nfor循环 for与它在 C 语言中的姊妹非常像。看起来是这样：\n1 2 3 4 for arg in elem1 elem2 ... elemN do ### 语句 done 在每次循环的过程中，arg依次被赋值为从elem1到elemN。这些值还可以是通配符或者大括号扩展。\n当然，我们还可以把for循环写在一行，但这要求do之前要有一个分号，就像下面这样：\n1 for i in {1..5}; do echo $i; done 还有，如果你觉得for..in..do对你来说有点奇怪，那么你也可以像 C 语言那样使用for，比如：\n1 2 3 for (( i = 0; i \u0026lt; 10; i++ )); do echo $i done 当我们想对一个目录下的所有文件做同样的操作时，for就很方便了。举个例子，如果我们想把所有的.bash文件移动到script文件夹中，并给它们可执行权限，我们的脚本可以这样写：\n💻 『示例源码』\n1 2 3 4 5 DIR=/home/zp for FILE in ${DIR}/*.sh; do mv \u0026#34;$FILE\u0026#34; \u0026#34;${DIR}/scripts\u0026#34; done # 将 /home/zp 目录下所有 sh 文件拷贝到 /home/zp/scripts while循环 while循环检测一个条件，只要这个条件为 真，就执行一段命令。被检测的条件跟if..then中使用的基元并无二异。因此一个while循环看起来会是这样：\n1 2 3 4 while [[ condition ]] do ### 语句 done 跟for循环一样，如果我们把do和被检测的条件写到一行，那么必须要在do之前加一个分号。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ### 0到9之间每个数的平方 x=0 while [[ ${x} -lt 10 ]]; do echo $((x * x)) x=$((x + 1)) done # Output: # 0 # 1 # 4 # 9 # 16 # 25 # 36 # 49 # 64 # 81 until循环 until循环跟while循环正好相反。它跟while一样也需要检测一个测试条件，但不同的是，只要该条件为 假 就一直执行循环：\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 x=0 until [[ ${x} -ge 5 ]]; do echo ${x} x=`expr ${x} + 1` done # Output: # 0 # 1 # 2 # 3 # 4 select循环 select循环帮助我们组织一个用户菜单。它的语法几乎跟for循环一致：\n1 2 3 4 select answer in elem1 elem2 ... elemN do ### 语句 done select会打印elem1..elemN以及它们的序列号到屏幕上，之后会提示用户输入。通常看到的是$?（PS3变量）。用户的选择结果会被保存到answer中。如果answer是一个在1..N之间的数字，那么语句会被执行，紧接着会进行下一次迭代 —— 如果不想这样的话我们可以使用break语句。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/usr/bin/env bash PS3=\u0026#34;Choose the package manager: \u0026#34; select ITEM in bower npm gem pip do echo -n \u0026#34;Enter the package name: \u0026#34; \u0026amp;\u0026amp; read PACKAGE case ${ITEM} in bower) bower install ${PACKAGE} ;; npm) npm install ${PACKAGE} ;; gem) gem install ${PACKAGE} ;; pip) pip install ${PACKAGE} ;; esac break # 避免无限循环 done 这个例子，先询问用户他想使用什么包管理器。接着，又询问了想安装什么包，最后执行安装操作。\n运行这个脚本，会得到如下输出：\n1 2 3 4 5 6 7 $ ./my_script 1) bower 2) npm 3) gem 4) pip Choose the package manager: 2 Enter the package name: gitbook-cli break 和 continue 如果想提前结束一个循环或跳过某次循环执行，可以使用 shell 的break和continue语句来实现。它们可以在任何循环中使用。\nbreak语句用来提前结束当前循环。\ncontinue语句用来跳过某次迭代。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 # 查找 10 以内第一个能整除 2 和 3 的正整数 i=1 while [[ ${i} -lt 10 ]]; do if [[ $((i % 3)) -eq 0 ]] \u0026amp;\u0026amp; [[ $((i % 2)) -eq 0 ]]; then echo ${i} break; fi i=`expr ${i} + 1` done # Output: 6 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 打印10以内的奇数 for (( i = 0; i \u0026lt; 10; i ++ )); do if [[ $((i % 2)) -eq 0 ]]; then continue; fi echo ${i} done # Output: # 1 # 3 # 5 # 7 # 9 函数 bash 函数定义语法如下：\n1 2 3 4 [ function ] funname [()] { action; [return int;] } 💡 说明：\n函数定义时，function 关键字可有可无。 函数返回值 - return 返回函数返回值，返回值类型只能为整数（0-255）。如果不加 return 语句，shell 默认将以最后一条命令的运行结果，作为函数返回值。 函数返回值在调用该函数后通过 $? 来获得。 所有函数在使用前必须定义。这意味着必须将函数放在脚本开始部分，直至 shell 解释器首次发现它时，才可以使用。调用函数仅使用其函数名即可。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #!/usr/bin/env bash calc(){ PS3=\u0026#34;choose the oper: \u0026#34; select oper in + - \\* / # 生成操作符选择菜单 do echo -n \u0026#34;enter first num: \u0026#34; \u0026amp;\u0026amp; read x # 读取输入参数 echo -n \u0026#34;enter second num: \u0026#34; \u0026amp;\u0026amp; read y # 读取输入参数 exec case ${oper} in \u0026#34;+\u0026#34;) return $((${x} + ${y})) ;; \u0026#34;-\u0026#34;) return $((${x} - ${y})) ;; \u0026#34;*\u0026#34;) return $((${x} * ${y})) ;; \u0026#34;/\u0026#34;) return $((${x} / ${y})) ;; *) echo \u0026#34;${oper} is not support!\u0026#34; return 0 ;; esac break done } calc echo \u0026#34;the result is: $?\u0026#34; # $? 获取 calc 函数返回值 执行结果：\n1 2 3 4 5 6 7 8 9 $ ./function-demo.sh 1) + 2) - 3) * 4) / choose the oper: 3 enter first num: 10 enter second num: 10 the result is: 100 位置参数 位置参数是在调用一个函数并传给它参数时创建的变量。\n位置参数变量表：\n变量 描述 $0 脚本名称 $1 … $9 第 1 个到第 9 个参数列表 ${10} … ${N} 第 10 个到 N 个参数列表 $* or $@ 除了$0外的所有位置参数 $# 不包括$0在内的位置参数的个数 $FUNCNAME 函数名称（仅在函数内部有值） 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/usr/bin/env bash x=0 if [[ -n $1 ]]; then echo \u0026#34;第一个参数为：$1\u0026#34; x=$1 else echo \u0026#34;第一个参数为空\u0026#34; fi y=0 if [[ -n $2 ]]; then echo \u0026#34;第二个参数为：$2\u0026#34; y=$2 else echo \u0026#34;第二个参数为空\u0026#34; fi paramsFunction(){ echo \u0026#34;函数第一个入参：$1\u0026#34; echo \u0026#34;函数第二个入参：$2\u0026#34; } paramsFunction ${x} ${y} 执行结果：\n1 2 3 4 5 6 7 8 9 10 11 $ ./function-demo2.sh 第一个参数为空 第二个参数为空 函数第一个入参：0 函数第二个入参：0 $ ./function-demo2.sh 10 20 第一个参数为：10 第二个参数为：20 函数第一个入参：10 函数第二个入参：20 执行 ./variable-demo4.sh hello world ，然后在脚本中通过 $1、$2 \u0026hellip; 读取第 1 个参数、第 2 个参数。。。\n函数处理参数 另外，还有几个特殊字符用来处理参数：\n参数处理 说明 $# 返回参数个数 $* 返回所有参数 $$ 脚本运行的当前进程 ID 号 $! 后台运行的最后一个进程的 ID 号 $@ 返回所有参数 $- 返回 Shell 使用的当前选项，与 set 命令功能相同。 $? 函数返回值 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 runner() { return 0 } name=zp paramsFunction(){ echo \u0026#34;函数第一个入参：$1\u0026#34; echo \u0026#34;函数第二个入参：$2\u0026#34; echo \u0026#34;传递到脚本的参数个数：$#\u0026#34; echo \u0026#34;所有参数：\u0026#34; printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;$*\u0026#34; echo \u0026#34;脚本运行的当前进程 ID 号：$$\u0026#34; echo \u0026#34;后台运行的最后一个进程的 ID 号：$!\u0026#34; echo \u0026#34;所有参数：\u0026#34; printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;$@\u0026#34; echo \u0026#34;Shell 使用的当前选项：$-\u0026#34; runner echo \u0026#34;runner 函数的返回值：$?\u0026#34; } paramsFunction 1 \u0026#34;abc\u0026#34; \u0026#34;hello, \\\u0026#34;zp\\\u0026#34;\u0026#34; # Output: # 函数第一个入参：1 # 函数第二个入参：abc # 传递到脚本的参数个数：3 # 所有参数： # + 1 abc hello, \u0026#34;zp\u0026#34; # 脚本运行的当前进程 ID 号：26400 # 后台运行的最后一个进程的 ID 号： # 所有参数： # + 1 # + abc # + hello, \u0026#34;zp\u0026#34; # Shell 使用的当前选项：hB # runner 函数的返回值：0 Shell 扩展 扩展 发生在一行命令被分成一个个的 记号（tokens） 之后。换言之，扩展是一种执行数学运算的机制，还可以用来保存命令的执行结果，等等。\n感兴趣的话可以阅读关于 shell 扩展的更多细节。\n大括号扩展 大括号扩展让生成任意的字符串成为可能。它跟 文件名扩展 很类似，举个例子：\n1 echo beg{i,a,u}n ### begin began begun 大括号扩展还可以用来创建一个可被循环迭代的区间。\n1 2 echo {0..5} ### 0 1 2 3 4 5 echo {00..8..2} ### 00 02 04 06 08 命令置换 命令置换允许我们对一个命令求值，并将其值置换到另一个命令或者变量赋值表达式中。当一个命令被``或$()包围时，命令置换将会执行。举个例子：\n1 2 3 4 5 now=`date +%T` ### or now=$(date +%T) echo $now ### 19:08:26 算数扩展 在 bash 中，执行算数运算是非常方便的。算数表达式必须包在$(( ))中。算数扩展的格式为：\n1 2 result=$(( ((10 + 5*3) - 7) / 2 )) echo $result ### 9 在算数表达式中，使用变量无需带上$前缀：\n1 2 3 4 5 x=4 y=7 echo $(( x + y )) ### 11 echo $(( ++x + y++ )) ### 12 echo $(( x + y )) ### 13 单引号和双引号 单引号和双引号之间有很重要的区别。在双引号中，变量引用或者命令置换是会被展开的。在单引号中是不会的。举个例子：\n1 2 echo \u0026#34;Your home: $HOME\u0026#34; ### Your home: /Users/\u0026lt;username\u0026gt; echo \u0026#39;Your home: $HOME\u0026#39; ### Your home: $HOME 当局部变量和环境变量包含空格时，它们在引号中的扩展要格外注意。随便举个例子，假如我们用echo来输出用户的输入：\n1 2 3 INPUT=\u0026#34;A string with strange whitespace.\u0026#34; echo $INPUT ### A string with strange whitespace. echo \u0026#34;$INPUT\u0026#34; ### A string with strange whitespace. 调用第一个echo时给了它 5 个单独的参数 —— $INPUT 被分成了单独的词，echo在每个词之间打印了一个空格。第二种情况，调用echo时只给了它一个参数（整个$INPUT 的值，包括其中的空格）。\n来看一个更严肃的例子：\n1 2 3 FILE=\u0026#34;Favorite Things.txt\u0026#34; cat $FILE ### 尝试输出两个文件: `Favorite` 和 `Things.txt` cat \u0026#34;$FILE\u0026#34; ### 输出一个文件: `Favorite Things.txt` 尽管这个问题可以通过把 FILE 重命名成Favorite-Things.txt来解决，但是，假如这个值来自某个环境变量，来自一个位置参数，或者来自其它命令（find, cat, 等等）呢。因此，如果输入 可能 包含空格，务必要用引号把表达式包起来。\n流和重定向 Bash 有很强大的工具来处理程序之间的协同工作。使用流，我们能将一个程序的输出发送到另一个程序或文件，因此，我们能方便地记录日志或做一些其它我们想做的事。\n管道给了我们创建传送带的机会，控制程序的执行成为可能。\n学习如何使用这些强大的、高级的工具是非常非常重要的。\n输入、输出流 Bash 接收输入，并以字符序列或 字符流 的形式产生输出。这些流能被重定向到文件或另一个流中。\n有三个文件描述符：\n代码 描述符 描述 0 stdin 标准输入 1 stdout 标准输出 2 stderr 标准错误输出 重定向 重定向让我们可以控制一个命令的输入来自哪里，输出结果到什么地方。这些运算符在控制流的重定向时会被用到：\nOperator Description \u0026gt; 重定向输出 \u0026amp;\u0026gt; 重定向输出和错误输出 \u0026amp;\u0026gt;\u0026gt; 以附加的形式重定向输出和错误输出 \u0026lt; 重定向输入 \u0026lt;\u0026lt; Here 文档 语法 \u0026lt;\u0026lt;\u0026lt; Here 字符串 以下是一些使用重定向的例子：\n1 2 3 4 5 6 7 8 9 10 11 ### ls的结果将会被写到list.txt中 ls -l \u0026gt; list.txt ### 将输出附加到list.txt中 ls -a \u0026gt;\u0026gt; list.txt ### 所有的错误信息会被写到errors.txt中 grep da * 2\u0026gt; errors.txt ### 从errors.txt中读取输入 less \u0026lt; errors.txt /dev/null 文件 如果希望执行某个命令，但又不希望在屏幕上显示输出结果，那么可以将输出重定向到 /dev/null：\n1 $ command \u0026gt; /dev/null /dev/null 是一个特殊的文件，写入到它的内容都会被丢弃；如果尝试从该文件读取内容，那么什么也读不到。但是 /dev/null 文件非常有用，将命令的输出重定向到它，会起到\u0026quot;禁止输出\u0026quot;的效果。\n如果希望屏蔽 stdout 和 stderr，可以这样写：\n1 $ command \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 Debug shell 提供了用于 debug 脚本的工具。\n如果想采用 debug 模式运行某脚本，可以在其 shebang 中使用一个特殊的选项：\n1 #!/bin/bash options options 是一些可以改变 shell 行为的选项。下表是一些可能对你有用的选项：\nShort Name Description -f noglob 禁止文件名展开（globbing） -i interactive 让脚本以 交互 模式运行 -n noexec 读取命令，但不执行（语法检查） -t — 执行完第一条命令后退出 -v verbose 在执行每条命令前，向stderr输出该命令 -x xtrace 在执行每条命令前，向stderr输出该命令以及该命令的扩展参数 举个例子，如果我们在脚本中指定了-x例如：\n1 2 3 4 5 #!/bin/bash -x for (( i = 0; i \u0026lt; 3; i++ )); do echo $i done 这会向stdout打印出变量的值和一些其它有用的信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ ./my_script + (( i = 0 )) + (( i \u0026lt; 3 )) + echo 0 0 + (( i++ )) + (( i \u0026lt; 3 )) + echo 1 1 + (( i++ )) + (( i \u0026lt; 3 )) + echo 2 2 + (( i++ )) + (( i \u0026lt; 3 )) 有时我们值需要 debug 脚本的一部分。这种情况下，使用set命令会很方便。这个命令可以启用或禁用选项。使用-启用选项，+禁用选项：\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 开启 debug set -x for (( i = 0; i \u0026lt; 3; i++ )); do printf ${i} done # 关闭 debug set +x # Output: # + (( i = 0 )) # + (( i \u0026lt; 3 )) # + printf 0 # 0+ (( i++ )) # + (( i \u0026lt; 3 )) # + printf 1 # 1+ (( i++ )) # + (( i \u0026lt; 3 )) # + printf 2 # 2+ (( i++ )) # + (( i \u0026lt; 3 )) # + set +x for i in {1..5}; do printf ${i}; done printf \u0026#34;\\n\u0026#34; # Output: 12345 参考资料 awesome-shell - shell 资源列表 awesome-bash - bash 资源列表 bash-handbook bash-guide - bash 基本用法指南 bash-it - 为你日常使用、开发以及维护 shell 脚本和自定义命令提供了一个可靠的框架 dotfiles.github.io - 上面有 bash 和其它 shell 的各种 dotfiles 集合以及 shell 框架的链接 Runoob Shell 教程 shellcheck - 一个静态 shell 脚本分析工具，本质上是 bash／sh／zsh 的 lint。 最后，Stack Overflow 上 bash 标签下有很多你可以学习的问题，当你遇到问题时，也是一个提问的好地方。\n","permalink":"https://WFUing.github.io/posts/tech/architecture/shell/","summary":"Shell 是一个用 C 语言编写的程序，是用户使用 Linux 的桥梁，它既是一种命令语言，又是一种程序设计语言。","title":"Shell 简介"},{"content":"我们将注意力转向过程抽象，这是一种将复杂程序分解成 functions (也称为 procedures 或 subroutines 。这些术语在不同语境中的用法有细微差别，但就我们的目的而言，我们将把它们视为同义词) 形式的较小代码片段的策略。函数将某些计算封装在一个接口之后，与任何抽象概念一样，函数的用户只需知道函数做了什么，而不需要知道函数是如何完成计算的。函数还通过接收影响其计算的参数来概括计算。计算的结果就是函数的返回值。\n在本单元中，我们首先介绍 Lisp 家族中的函数式语言 Scheme。然后，我们将讨论与所有 procedural languages 相关的函数方面的问题，然后再仔细研究 functional programming，这是一种以数学函数为计算模型的编程范式。\nIntroduction to Scheme R5RS Scheme 语言采用了与 Python 非常相似的计算模型，但只使用 expressions (不使用statements)，擅长 symbolic computation。\nScheme 是 Lisp 的一种方言，Lisp 是当今仍在广泛使用的第二古老的编程语言（仅次于 Fortran）。几十年来，Lisp 程序员社区一直在蓬勃发展，而新的 Lisp 方言（如 Clojure）也是所有现代编程语言中开发者社区发展最快的。要跟上本文的示例，可以下载 Scheme 解释器或使用在线解释器。\nExpressions Scheme 程序由 expressions 组成，expressions 可以是简单表达式，也可以是列表形式的组合。简单表达式由一个文字或符号组成。组合表达式是一种 compound expression，由一个运算符表达式和零个或多个操作数子表达式组成。运算符和操作数都包含在括号中：\n1 2 \u0026gt; (quotient 10 2) 5 Scheme 只使用前缀符号。操作符通常是符号，如 + 和 *。复合表达式可以嵌套，也可以跨一行以上：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; (+ (* 3 5) (- 10 6)) 19 \u0026gt; (+ (* 3 (+ (* 2 4) (+ 3 5) ) ) (+ (- 10 7) 6 ) ) 57 对组合进行求值时，首先需要检查运算符是否代表 special form，因为 special form 有自己的求值程序。如果运算符不是 special form，那么运算符和操作数表达式将按照任意顺序进行求值。然后，作为运算符值的函数将应用于作为操作数值的参数。\n在 Scheme 中，if 表达式是特殊形式的一个例子。虽然它在语法上看起来与调用表达式相似，但它的评估过程却与调用表达式不同。if 表达式的一般形式是\n1 (if \u0026lt;predicate\u0026gt; \u0026lt;consequent\u0026gt; \u0026lt;alternative\u0026gt;) 要对 if 表达式进行求值，解释器首先会对表达式的 \u0026lt;predicate\u0026gt; 部分进行求值。如果 \u0026lt;predicate\u0026gt; 求值为 true，解释器将求值 \u0026lt;consequent\u0026gt; 并返回其值。否则，解释器将求值 \u0026lt;alternative\u0026gt;，并返回其值，\u0026lt;alternative\u0026gt;可省略。\nNumerical values 可以使用熟悉的比较运算符进行比较，但在这种情况下也使用 prefix notation：\n1 2 \u0026gt; (\u0026gt;= 2 1) #t 在 Scheme 中，真值 (包括布尔值 #t 表示真， #f 表示假) 可以与布尔特殊形式相结合，它们的求值过程如下：\n(and \u0026lt;e1\u0026gt; ... \u0026lt;en\u0026gt;) 解释器按从左到右的顺序逐次求值表达式 \u0026lt;e\u0026gt;。如果任何 \u0026lt;e\u0026gt; 的值为 false，则 and 表达式的值就是该 false，其余 \u0026lt;e\u0026gt; 的值不予求值。如果所有 \u0026lt;e\u0026gt; 的值都为 true，那么 and 表达式的值就是最后一个 \u0026lt;e\u0026gt; 的值。 (or \u0026lt;e1\u0026gt; ... \u0026lt;en\u0026gt;) 解释器按从左到右的顺序，一次评估一个 \u0026lt;e\u0026gt; 表达式。如果任何 \u0026lt;e\u0026gt; 的值为 true，该值将作为 or 表达式的值返回，其余的 \u0026lt;e\u0026gt; 将不被求值。如果所有 \u0026lt;e\u0026gt; 的值都为 false，则 or 表达式的值就是最后一个 \u0026lt;e\u0026gt; 的值。 true 也可以用 not 程序来处理：\n(not \u0026lt;e\u0026gt;) 当表达式 \u0026lt;e\u0026gt; 的值为假值时，not 表达式的值为 #t，否则为 #f。 Definitions 可以使用 define 特殊形式对值进行命名：\n1 2 3 \u0026gt; (define pi 3.14) \u0026gt; (* pi 2) 6.28 新函数（在 Scheme 中通常称为 procedures）可以使用 define 特殊形式的第二个版本来定义。例如，要定义平方，我们可以写下\n1 (define (square x) (* x x)) 程序定义的一般形式是\n1 (define (\u0026lt;name\u0026gt; \u0026lt;formal parameters\u0026gt;) \u0026lt;body\u0026gt;) \u0026lt;name\u0026gt; 是与环境中存储过程定义相关联的符号。 \u0026lt;formal parameters\u0026gt; 是存储过程正文中使用的名称，用于指代存储过程的相应参数。 \u0026lt;body\u0026gt; 是一个表达式，当形式参数被存储过程的实际参数替换时，它将产生存储过程应用的值。 \u0026lt;name\u0026gt; 和 \u0026lt;formal parameters\u0026gt; 放在括号中，就像在实际调用存储过程时一样。 定义了 square 之后，我们就可以在调用表达式中使用它了:\n1 2 3 4 5 6 7 8 \u0026gt; (square 21) 441 \u0026gt; (square (+ 2 5)) 49 \u0026gt; (square (square 3)) 81 用户自定义函数可以接受多个参数，并在函数体中包含特殊形式：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; (define (average x y) (/ (+ x y) 2)) \u0026gt; (average 1 3) 2 \u0026gt; (define (abs x) (if (\u0026lt; x 0) (- x) x ) ) \u0026gt; (abs -3) 3 Scheme 支持具有 static scope 的局部函数定义。我们将推迟到讨论高阶函数时再讨论这个问题。\n匿名函数也称为 lambda 函数，是使用 lambda 特殊形式创建的。使用 lambda 创建存储过程的方法与定义相同，只是不指定存储过程的名称：\n1 (lambda (\u0026lt;formal-parameters\u0026gt;) \u0026lt;body\u0026gt;) 由此产生的存储过程与使用 define 创建的存储过程一样。唯一不同的是，它没有与环境中的任何名称相关联。事实上，下面的表达式是等价的：\n1 2 \u0026gt; (define (plus4 x) (+ x 4)) \u0026gt; (define plus4 (lambda (x) (+ x 4))) 与任何以 procedure 为值的表达式一样，lambda 表达式也可以用作 call expression 中的操作符：\n1 2 \u0026gt; ((lambda (x y z) (+ x y (square z))) 1 2 3) 12 Compound Values Pairs 是内置于 Scheme 语言中的。由于历史原因，Pairs 使用 cons 内置函数创建，因此，Pairs 也被称为 cons 单元，Pairs 中的元素使用 car 和 cdr 访问：\n1 2 3 4 5 6 7 \u0026gt; (define x (cons 1 2)) \u0026gt; x (1 . 2) \u0026gt; (car x) 1 \u0026gt; (cdr x) 2 A pair consisting of the elements 1 and 2 该语言还使用成对的方式建立 Recursive lists 。用 '() 表示的特殊值代表 empty list。递归列表值的呈现方式是将其元素放在括号内，中间用空格隔开：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026gt; (cons 1 (cons 2 (cons 3 (cons 4 \u0026#39;()) ) ) ) (1 2 3 4) \u0026gt; (list 1 2 3 4) (1 2 3 4) \u0026gt; (define one-through-four (list 1 2 3 4)) \u0026gt; (car one-through-four) 1 \u0026gt; (cdr one-through-four) (2 3 4) \u0026gt; (car (cdr one-through-four)) 2 \u0026gt; (cons 10 one-through-four) (10 1 2 3 4) \u0026gt; (cons 5 one-through-four) (5 1 2 3 4) 下图为文本表示为 (1 2 3 4) 的列表对应的结构由一连串的对组成，以空列表在图中表示为包含符号 $\\emptyset$：\nA list containing the elements 1, 2, 3, and 4 以空列表以外的其他元素结束的数对序列称为 improper list。如上面的 (cons 1 2) 的结果就是一个例子，它只包含序列中的 pair。下面演示的是一个更复杂的序列：\n1 2 3 4 5 6 \u0026gt; (cons 1 (cons 2 (cons 3 4) ) ) (1 2 3 . 4) An improper list containing the elements 1, 2, and 3, and terminated by 4 rather than the empty list 证明了 pairs 和其他 compound objects 具有引用语义 \u0026ndash; 配对的 cdr 部分存储了对序列中下一对配对的引用。下面的代码通过变量进一步演示了这些引用语义：\n1 2 3 4 5 6 7 \u0026gt; (define x (cons 1 2)) \u0026gt; (define y x) \u0026gt; (eqv? x y) #t \u0026gt; (set-car! y 7) \u0026gt; x (7 . 2) 在这里，定义 (define y x) 的结果是 x 和 y 指向同一个数据 pair object。只有当两个参数指向同一个对象对时，存储过程 eqv? 才会返回 true（而 equal? 则从结构上对对象对进行比较）。此外，当我们使用 set-car! 变量修改 y 所引用的配对的第一个项目时，我们可以看到 x 引用了同一个配对，因为它也显示了修改。\n一个对象是否为空列表，可以使用原始的 null? 。利用它，我们可以定义用于计算适当列表长度和选择元素的标准序列操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; (define (list-length items) (if (null? items) 0 (+ 1 (list-length (cdr items))) ) ) \u0026gt; (define (getitem items n) (if (= n 0) (car items) (getitem (cdr items) (- n 1)) ) ) \u0026gt; (define squares (list 1 4 9 16 25)) \u0026gt; (length squares) 5 \u0026gt; (getitem squares 3) 16 内置的 length 和 list-ref 程序提供了与这里的 list-length 和 getitem 相同的功能。\nSymbolic Data 我们迄今为止使用过的所有复合数据对象最终都是由数字构建的。使用任意符号作为数据是 Scheme 的优势之一。\n为了操作符号，我们需要在语言中加入一个新元素：引用数据对象的能力。假设我们要构造列表 (a b)。我们不能用 (list a b) 来实现这个目的，因为这个表达式构造的是一个包含 a 和 b 值的列表，而不是符号本身。在 Scheme 中，我们会在符号 a 和 b 之前加上单引号，来指代它们，而不是它们的值：\n1 2 3 4 5 6 7 8 \u0026gt; (define a 1) \u0026gt; (define b 2) \u0026gt; (list a b) (1 2) \u0026gt; (list \u0026#39;a \u0026#39;b) (a b) \u0026gt; (list \u0026#39;a b) (a 2) 在 Scheme 中，任何未被求值的表达式都被称为 quoted。引号的概念源于一个经典的哲学，即一个事物，如到处乱跑并吠叫的狗与 \u0026ldquo;狗\u0026rdquo; 这个词之间的区别，\u0026ldquo;狗\u0026rdquo; 这个词是用于指定此类事物的语言结构。当我们使用带引号的 \u0026ldquo;狗\u0026rdquo; 时，我们指的并不是某只狗，而是一个词。在语言中，引号允许我们谈论语言本身，在 Scheme 中也是如此：\n1 2 \u0026gt; (list \u0026#39;define \u0026#39;list) (define list) 引号还允许我们使用传统的列表打印表示法键入复合对象。我们已经看到，'() 表示空列表。下面是其他例子：\n1 2 3 4 5 \u0026gt; (car \u0026#39;(a b c)) a \u0026gt; (cdr \u0026#39;(a b c)) (b c) Scheme 中的引号与字符串不同，后者表示字符格式的原始、非结构化数据，而前者表示结构化数据。\n1 2 3 4 5 6 7 8 9 10 \u0026gt; \u0026#34;(- 3)\u0026#34; ; a string containing the characters #\\( #\\- #\\space #\\3 #\\) \u0026#34;(- 3)\u0026#34; \u0026gt; \u0026#39;(- 3) ; produces a list containing the symbol - and number 3 (- 3) \u0026gt; (car \u0026#39;(- 3)) - \u0026gt; (cdr \u0026#39;(- 3)) (3) \u0026gt; (- 3) ; calls the - procedure on the number 3 -3 在上面的示例中，字符串字面形式 \u0026quot;(- 3)\u0026quot; 的值为其本身，带引号的表达式 '(- 3) 求值为一个列表，列表的第一个元素是符号 -，第二个元素是数字 3。最后一个示例对符号 - 进行求值以获得相应的存储过程，将数字 3 求值为自身，然后在数字 3 上调用存储过程 -，得到 -3。换句话说，字符串字面量中的数据仍然是字符数据，既不会被求值，也不会被解析。带引号表达式会被解析，但不会被求值，而是产生数据的结构化表示。未加引号的表达式会被解释器解析和求值。\n完整的 Scheme 语言还包含其他功能，如 mutation operations、vectors 和 maps。不过，我们迄今为止介绍的子集提供了一种丰富的函数式编程语言，能够实现我们迄今为止讨论过的许多想法。\nFunctions 我们首先要考虑的是以参数形式向函数传递数据的各种方案。我们将出现在函数定义中的参数，也称为 formal parameters，与调用函数时传递给函数的实际值区分开来，后者通常被称为 actual parameter。\n本文将使用 argument 一词来指代 actual parameter， 用 parameter 一词指代 formal parameters。 Keyword Arguments 有些语言允许甚至要求在调用函数时提供参数名，这种策略称为 named parameters 或 keyword arguments。\n关键字参数通常允许以不同于函数参数列表的顺序提供参数。例如，在 Python 中，keyword argument 可以用于任何参数。请看下面的代码：\n1 2 def foo(x, y): print(x, y) 调用不带关键字参数的 foo() 时，第一个参数会作为第一个参数传递，第二个参数会作为第二个参数传递：\n1 2 \u0026gt;\u0026gt;\u0026gt; foo(1, 2) 1 2 不过，参数可以使用参数名重新排序：\n1 2 \u0026gt;\u0026gt;\u0026gt; foo(y = 1, x = 2) 2 1 Python 还提供了将参数定义为 positional-only 或 keyword-only 的机制，但我们不会在这里讨论这些机制。\n有少数语言要求默认为所有或大部分参数提供名称，并要求以与参数相同的顺序提供参数。下面是 Swift 3 中的一个示例：\n1 2 3 4 5 func greet(name: String, withGreeting: String) { print(withGreeting + \u0026#34; \u0026#34; + name) } greet(name: \u0026#34;world\u0026#34;, withGreeting: \u0026#34;hello\u0026#34;) 以相反的参数顺序调用 greet() 是错误的。\nSwift 允许为一个参数指定不同的参数名和参数名，这一点也很罕见。这意味着调用函数时为参数提供的名称可能与函数主体中使用的参数内部名称不同。\nDefault Arguments 在某些语言中，函数声明或定义可能会提供一个 default argument，允许在没有该参数的情况下调用函数。这可以替代重载，即编写单独的函数定义来处理存在或缺少参数的情况。\n下面是一个 Python 示例：\n1 2 def power(base, exponent=2): return base ** exponent power() 函数可以调用一个参数，在这种情况下，默认参数 2 用于计算数字的平方。也可以使用两个参数来计算任意幂：\n1 2 3 4 \u0026gt;\u0026gt;\u0026gt; power(3) 9 \u0026gt;\u0026gt;\u0026gt; power(3, 4) 81 有 default arguments 一般必须出现在参数列表的末尾。对于何时以及在哪种环境下评估默认参数，不同语言的做法各不相同。最常见的策略是每次调用函数时都评估缺省参数，但在定义 environment (static scope) 中进行。Python 的罕见之处在于，它只在函数定义语句执行时评估一次缺省参数。这意味着，如果在函数中修改了参数值，那么对同一函数的后续调用可能会对同一参数使用不同的缺省值。例如\n1 2 3 4 5 6 7 8 9 10 def test(x=[]): x.append(1) print(x) test() test() // output [1] [1, 1] C 和 C++ 有许多关于缺省参数的规则，这是因为一个实体可以声明多次。默认参数既可以在独立声明中提供，也可以在定义中提供。但是，同一实体的多个可见声明为同一参数提供默认参数是非法的，即使提供的值是相同的。缺省参数集是同一作用域内所有可见声明的集合，只有在前面和当前声明已为所有后续参数提供缺省参数的情况下，声明才能为参数引入缺省参数。缺省参数中使用的名称在声明时进行解析，但参数表达式在调用函数时进行求值。\n下面是 C++ 中多重声明的一个合法示例：\n1 2 3 4 int foo(int x, int y = 4); int foo(int x = 3, int y) { return x + y; } 除函数参数外，C++ 还允许模板参数使用默认参数，其有效性规则与此类似。\nVariadic Functions 一种语言可能会提供一种机制，让函数在调用时可以使用数量可变的参数。这种特性通常被称为 varargs，使用这种特性的函数被称为变量函数 (variadic)。这种机制可能提供类型安全，也可能允许不安全的使用，从而导致错误或未定义的行为。可变参数一般必须出现在参数列表的末尾，它匹配的是非可变参数匹配后剩余的参数。通常只允许使用一个变量参数。\n在提供安全变量函数的语言中，一种常见的机制是自动将变量参数打包到一个 container 中，例如 array 或 tuple。例如，下面的 Python 函数计算其参数的乘积：\n1 2 3 4 5 def product(*args): result = 1 for i in args: result *= i return result 参数名前面的 * 表示变量参数，变量参数以绑定到参数名的元组形式传递。上述函数遍历元组中的元素，更新总乘积。要调用 product()，必须提供 0 个或更多参数：\n1 2 3 4 \u0026gt;\u0026gt;\u0026gt; product() 1 \u0026gt;\u0026gt;\u0026gt; product(1, 2, 3) 6 Python 还提供了可变关键字参数，这些参数被打包成一个字典。在参数前面加上 ** 表示它是一个可变关键字参数，并且这样的参数必须是最后一个。例如，下面的函数同时包含一个非关键字可变参数和一个可变关键字参数，打印出前者对应的元组和后者对应的字典：\n1 2 3 def print_args(*args, **kwargs): print(args) print(kwargs) 1 2 3 \u0026gt;\u0026gt;\u0026gt; print_args(3, 4, x = 5, y = 6) (3, 4) {\u0026#39;x\u0026#39;: 5, \u0026#39;y\u0026#39;: 6} 最后，Python 允许使用 * 或 ** 操作符对序列或字典进行 \u0026ldquo;解包\u0026rdquo;，从而将解包后的值用于需要值列表的地方。例如，下面的代码将一个列表解包，以调用 product()：\n1 2 product(*[1, 2, 3]) 6 此外，Scheme 还支持可变参数。一个存储过程可以使用一个不恰当的列表作为参数列表，并以一个符号而不是空列表结束，这样就可以定义一个存储过程来接受可变参数。可变参数与任意数量的参数绑定，并打包成一个列表：\n1 2 3 4 5 6 7 \u0026gt; (define (func . args) args ) \u0026gt; (func) () \u0026gt; (func 1 2 3) (1 2 3) 存储过程 func 可以接收任意数量的参数，并返回包含这些参数的 list。因此，它的行为与内置的 list 存储过程相同。我们还可以定义一个存储过程，同时接收必参数和可变参数，例如下面的 average 定义：\n1 2 3 4 5 6 7 8 9 10 11 \u0026gt; (define (average x . nums) (/ (apply + x nums) (+ 1 (length nums)) ) ) \u0026gt; (average 1) 1 \u0026gt; (average 1 3) 2 \u0026gt; (average 1 3 5 7) 4 procedure 接收一个或多个参数，其中第一个参数与参数 x 绑定，其余参数封装在一个与变量 nums 参数绑定的列表中。我们可以使用 apply 来转发变量参数，它接收一个存储过程、任意数量的常规参数，最后是一个包含其余参数的列表。例如，(apply + 1 2 '(3 4)) 相当于调用 (+ 1 2 3 4)。在上面第一个使用 average 的示例中，nums 在调用 (average 1) 时绑定为一个空列表，而 (apply + x nums) 相当于 (apply + 1 '()) ，后者本身相当于 (+ 1)。在第三个例子中，nums 绑定到一个列表 (3 5 7)，因此 (apply + x nums) 等价于 (apply + 1 '(3 5 7))，而 (apply + 1 '(3 5 7)) 又等价于 (+ 1 3 5 7)。\n在 Python 和 Scheme 中，可变参数可以匹配任何类型的参数，因为这两种语言都是动态类型的。然而，在静态类型语言中，可变参数通常被限制为单一类型，尽管该类型可能是多态的。例如，下面是 Java 中的一个变量方法：\n1 2 3 4 5 public static void print_all(String... args) { for (String s : args) { System.out.println(s); } } print_all() 的参数必须是字符串，并将它们打包成一个字符串数组。Java 也允许将单个字符串数组作为参数传递：\n1 2 print_all(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;); print_all(new String[] { \u0026#34;good\u0026#34;, \u0026#34;bye\u0026#34; }); C 和 C++ 也有一种可变参数机制，但它存在严重的安全问题。尤其是，它无法向被调用的函数提供关于参数个数及其类型的信息。下面是一个返回参数之和的函数示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;stdarg.h\u0026gt; int sum(int count, ...) { va_list args; int total = 0; int i; va_start(args, count); for (i = 0; i \u0026lt; count; i++) { total += va_arg(args, int); } va_end(args); return total; } 在该函数中，第一个参数被假定为其余参数的个数，而后一个参数被假定为 int 类型。如果违反其中任何一个条件，都会产生未定义的行为。另一种策略是使用格式字符串来确定参数的数量和类型，如 printf() 和类似函数中使用的方法。可变参数缺乏安全性，会导致格式字符串攻击等漏洞。\nC++11 提供了类型安全的 variadic templates。\nParameter Passing 语言的另一个不同之处在于函数与其调用者之间传递参数的 semantics 和 mechanism。函数参数可以是单向的，仅用于向函数传递输入或仅用于从函数向调用者传递输出，也可以是双向的。这些情况被称为 input、output 和 input/output 参数。一种语言不必支持所有三种参数类别。\n各种语言使用不同的参数传递技术或调用模式。这些技术会影响参数和参数的语义以及支持的参数类别。以下是不同语言使用的具体调用模式：\nCall by value，参数代表函数调用框架中的一个新变量。参数值被复制到与新变量相关的存储空间中。按值调用参数只为函数提供输入，如下面的 C++ 示例：\n1 2 3 4 5 6 7 8 9 10 void foo(int x) { x++; cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; endl; } int main() { int y = 3; foo(y); // prints 4 cout \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; // prints 3 } 即使 foo() 修改了输入值，修改后的值也不会传回 caller。\nCall by reference，参数必须传递一个 l-value，因为参数 aliases 了传递进来的对象。对参数的任何修改都会反映在参数对象中。因此，引用调用参数同时提供输入和输出。在 C++ 中，引用参数提供了引用调用，并且可以通过声明 const 将其限制为仅提供输入。下面的 C++ 示例使用引用调用交换了两个对象的值：\n1 2 3 4 5 6 7 8 9 10 11 void swap(int \u0026amp;x, int \u0026amp;y) { int tmp = x; x = y; y = tmp; } int main() { int x = 3, y = 4; swap(x, y); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; // prints 4 3 } 引用调用有时用来指使用指针间接传递对象。下面的 C/C++ 函数使用指针交换对象值：\n1 2 3 4 5 6 7 8 9 10 11 void swap(int *x, int *y) { int tmp = *x; *x = *y; *y = tmp; } int main() { int x = 3, y = 4; swap(\u0026amp;x, \u0026amp;y); printf(\u0026#34;%d %d\\n\u0026#34;, x, y); // prints 4 3 } 但从技术上讲，参数和参量是独立的指针对象，通过值传递。尽管如此，这种效果模拟了引用调用，使输入和输出都能通过一个参数来实现。\nCall by result，在这种模式下，参数代表一个新变量，调用者不对其进行初始化。相反，调用者会为参数指定一个 l-value，当函数调用结束时，参数的最终值会被复制到 l-value 中。因此，按结果调用只提供输出参数。下面是一个使用类似 C 的语法、按结果调用的示例：\n1 2 3 4 5 6 7 8 void foo(result int x) { x = 3; x++; // x is now 4 } int y = 5; foo(y); // y is now 4 print(y); // prints 4 Call by value-result，这是 Call by value 和 Call by result 的组合。参数值被复制到与参数相对应的新变量中，然后从函数返回时，参数值又被复制到调用者提供的 l-value 值中。这与引用调用的不同之处在于，在进入和退出函数时都会进行复制。可以通过将相同的 l-value 传递给多个参数来说明这一点，例如在下面的示例中使用了类似于 C 语言的语法，即按 Call by value-result：\n1 2 3 4 5 6 7 8 int foo(value-result int x, value-result int y) { x++; return x - y; } int z = 3; print(foo(z, z)); // prints 1 print(z); // prints 3 or 4, depending on the semantics 在这段代码中，x 和 y 是新变量，它们被初始化为 z 的值，即 3。x 的增量不会影响 y，因为它们是独立的变量，所以调用 foo() 返回 1。因此，1 会被打印出来。z 的最终值取决于从 x 还是从 y 复制的语言语义。如果使用引用调用，那么 x 和 y 将 alias 为同一个对象，调用 foo() 将返回 0。\nCall by name，在这种模式下，可以提供一个完整的表达式作为参数，但在调用函数时不会对其进行求值。相反，在函数中出现参数名的地方，参数名会被表达式替换，而表达式会在主体中遇到时进行求值。这是一种 lazy evaluation，即在需要时才计算值。下面是一个使用 C-like syntax、按名称调用的示例：\n1 2 3 4 5 6 7 8 9 void foo(name int a, name int b) { print(b); // becomes print(++y) print(b); // becomes print(++y) } int x = -1, y = 3; foo(++x, ++y); // prints 4, then 4 or 5 depending on the exact // language semantics; y is now 4 or 5 print(x); // prints -1 -- x is unchanged 在本例中，参数表达式 ++x 从未被求值，因为相应的逐名调用参数 a 从未被使用。另一方面，表达式 ++y 被计算，因为相应的参数 b 确实被使用了。根据语言语义的不同，表达式可能只被求值一次，其值被缓存以备后续使用，也可能在每次使用参数时都被求值。\n按名称调用会产生一个微妙的问题。请看下面这段代码，它使用了 C-like syntax 和按名称调用：\n1 2 3 4 5 6 7 void bar(name int x) { int y = 3; print(x + y); } int y = 1; bar(y + 1); 如果我们用参数表达式替换 bar() 中出现的参数 x，就会得到 y + 1 + y 作为 print() 的参数。如果在 bar() 的环境中求值，结果将是 7。这是不可取的，因为这意味着局部声明 y 的实现细节改变了函数的行为。\n相反，参数表达式应在调用者的环境中进行评估。这就要求在函数调用时同时传递参数及其环境。使用名称调用的语言通常使用编译器生成的局部函数，称为 thunk ，来封装参数表达式及其环境。然后将 thunk 传递给被调用的函数，当遇到参数时，就会调用 thunk。\n在某些语言中，与 call-by-name parameter 相对应的表达式仅在首次引用该参数时进行评估，并缓存评估结果。缓存的结果将用于随后每次出现的参数。\ncall by value 是大多数现代语言使用的调用模式，包括 C、C++（用于非引用参数）、Java、Scheme 和 Python。程序员经常误以为后三种语言使用 call by reference，但实际上，它们将 call by value 与 call by reference 语义结合在一起。这种组合有时被称为 object reference 。下面的示例说明 Python 使用的是 call by value：\n1 2 3 4 def swap(x, y): tmp = x x = y y = tmp 1 2 3 4 \u0026gt;\u0026gt;\u0026gt; x, y = 1, 2 \u0026gt;\u0026gt;\u0026gt; swap(x, y) \u0026gt;\u0026gt;\u0026gt; x, y (1, 2) 错误的 swap() 函数只是改变了局部变量的值，从而改变了它们所引用的对象，而没有影响作为参数的变量。这表明全局 x 和 y 的存储空间与参数的存储空间是不同的，因此 Python 没有使用引用调用。事实上，Python 甚至不能像 C 和 C++ 指针那样模拟引用调用。\nl-value and r-value l-value 和 r-value 是 C++ 表达式的基础。简单地说，l-value 是对象引用，r-value 是值。l-value 和 r-value 之间的区别在表达式的编写和理解中起着重要作用。\nl-value 是产生对象引用的表达式，例如变量名、数组下标引用、取消引用指针或返回引用的函数调用。l-value 总是有一个定义的存储区域，因此可以获取其地址。 r-value 是指不是 l-value 的表达式。r-value 的例子包括字面量、大多数运算符的结果以及返回非引用的函数调用。r-value 不一定与任何存储空间相关联。 严格来说，函数是一个 l-value，但它的唯一用途是用于调用函数或确定函数的地址。大多数情况下，l-value 指的是对象 l-value。\nEvaluation of Function Calls 下面我们总结一下函数调用的实现过程：\n第一步是确定嵌套函数调用的非本地环境。在使用嵌套函数和静态作用域的语言中，当执行嵌套函数定义本身时，非本地环境的引用会存储在关联的函数对象中。在具有深绑定的动态作用域下，非本地环境是在函数名称被引用时确定的。最后，在浅绑定的动态作用域中，非本地环境是函数被调用时处于活动状态的环境。\n下一步是使用新创建的函数调用激活记录将参数传递给函数。参数在现有环境中进行评估，并按如下方式传递给被调用者：\nCall by value and call by value-result : 对参数进行评估以获得其 r-value。r-value 将被复制到新激活记录中相应参数的存储空间。 Call by reference : 参数的 l-value。相应的参数会绑定到与 l-value 相关的对象上。 Call by result : 参数进行评估，以获得其 l-value 。在新的激活记录中，存储空间会被分配，但不会被初始化。 Call by name : 参数表达式会被打包到一个包含当前环境的 thunk 中。参数绑定到 thunk 的引用上。 一旦参数被传递，调用者的执行就会暂停，而被调用者的主体将在一个由新创建的激活记录和被调用者的非本地环境组成的环境中执行。对于 call by name，根据语言的语义，call by name 参数的出现会在参数第一次被指名或每次被指名时调用相应的 thunk。\n当被调用的函数返回时，其返回值（如果有的话）会被放置在指定的存储位置，通常是在调用者的激活记录中。对于 call-by-result 或 call-by-value-result 参数，参数的当前 r-value 会被复制到与相应函数调用参数的 l-value 相关联的对象中。然后，被调用者的激活记录将被销毁，调用者将在函数调用后恢复执行。函数调用本身的评估结果就是函数的返回值。\nRecursion Recursion 是一种利用函数和函数应用进行重复的机制。它涉及函数直接或间接地调用自身，通常使用在某种意义上比前一个参数 \u0026ldquo;小 \u0026ldquo;的参数。递归计算在达到基数时终止，基数是指无需进行任何递归调用即可直接计算出结果的输入。\n一种语言要想达到图灵完备性，只需提供 recursion 和 conditionals 即可。\nActivation Records 在机器上，递归之所以起作用，是因为函数的每次调用都有自己的激活记录，将局部变量映射为值。请看下面的阶乘递归定义：\n1 2 3 4 def factorial(n): if n == 0: return 1 return n * factorial(n - 1) 调用 factorial(4) 会导致五次调用 factorial()，参数从 4 到 0，每次都有自己的激活记录和参数 n 的绑定：\n1 2 3 4 5 factorial(4): n --\u0026gt; 4 factorial(3): n --\u0026gt; 3 factorial(2): n --\u0026gt; 2 factorial(1): n --\u0026gt; 1 factorial(0): n --\u0026gt; 0 Activation records used to compute factorial(4) 在执行 factorial() 主体时查找 n，每次调用都会获得自己的 n 值，而不会受到其他激活记录的影响。\n要使函数调用生效，激活记录需要的不仅仅是参数和局部变量的存储空间。临时值也需要存储在某个地方，由于每个调用都需要自己的临时值存储空间，因此这些临时值通常也要放在激活记录中。调用还需要知道在哪里存储其返回值，通常是在调用者框架中的临时存储区。最后，函数需要知道如何将执行返回给调用者。具体细节不在本文讨论范围之内，但这些信息包括调用者函数调用后的指令地址和调用者激活记录的地址。\n临时对象集可以通过静态方式保守地确定，因此激活记录的大小以及对象在其中的位置都可以在编译时确定。对于上面的 factor()，需要临时存储 n - 1 以及递归调用 factorial() 的结果。递归调用会使用后者在调用程序中的位置来存储其返回值。根据不同的实现，调用 factorial(0) 的激活记录中可能仍然有这些临时对象的空间，即使它们不会被使用。\nTail Recursion 递归计算对函数的每次调用都使用单独的激活记录。存储这些记录所需的空间与激活函数调用的次数成正比。在上面的 factorial(n) 中，当计算达到 factorial(0) 时，所有 n + 1 次调用都同时激活，需要的空间为 O(n)。与之相比，下面的迭代实现使用的空间是恒定的：\n1 2 3 4 5 6 def factorial_iter(n): result = 1 while n \u0026gt; 0: result *= n n -= 1 return result 然而，递归版本的 factorial() 所需的空间并不是使用递归的内在原因，而是函数编写方式的结果。事实上，由于在递归调用之后还需要完成调用的工作，因此在递归调用期间必须保留其激活记录，这就导致了线性空间需求。\n考虑另一种阶乘递推计算方法：\n1 2 3 4 def factorial_tail(n, partial_result = 1): if n == 0: return partial_result return factorial_tail(n - 1, n * partial_result) 请注意，在完成递归调用后，factorial_tail() 函数不做任何工作。这意味着在进行递归调用时，它不再需要存储参数、局部变量或临时对象。此外，由于 factorial(n, k) 直接返回递归调用 factorial(n - 1, n * k) 的结果，因此后者可以将其返回值存储在 factorial(n, k) 的调用者中用于存放 factorial(n, k) 返回值的位置，并直接将执行返回给该调用者。因此，优化后的实现可以为 factorial_tail(n - 1, n * k) 重用 factorial_tail(n, k) 的激活记录空间，因为前者不再需要激活记录。\n这个过程可以推广到任何函数调用，而不仅仅是递归调用。如果函数的调用者直接返回调用值，而不执行任何额外的计算，那么该函数调用就是尾调用。如果一个函数的所有递归调用都是尾调用，那么这个函数就是尾递归函数。因此，factorial_tail() 是尾部递归函数。\n尾递归计算只使用固定数量的激活记录，因此其空间使用量与等效的迭代计算相当。事实上，许多函数式语言并不提供迭代的构造，因为它们可以等效地使用尾递归来表达。这些语言通常要求实现执行尾调用优化，尽可能重复使用激活记录的空间。\n由于尾调用要求在返回后不执行任何计算，因此在语法上看似尾调用的调用可能不是尾调用，因为隐式计算可能发生在函数的末尾。这方面的一个具体例子是基于作用域的资源管理，如下例所示：\n1 2 3 4 5 6 int sum(vector\u0026lt;int\u0026gt; values, int index, int partial_result = 0) { if (values.size() == index) { return 0; } return sum(values, index + 1, partial_result + values[index]) } 虽然这段代码在递归调用后似乎没有进行计算，但本地 vector\u0026lt;int\u0026gt; 对象有一个析构函数，必须在递归调用完成后运行。因此，对 sum() 的递归调用不是尾部调用，该计算也不是尾部递归计算。\n另一种阻碍尾调用优化的情况是，在使用静态作用域并支持高阶函数全部功能的语言中，函数内部包含一个函数定义。嵌套函数需要访问其定义环境，因此如果嵌套函数可以在其外层函数调用完成后或在尾调用中使用，则必须保留该环境。\nHigher-Order Functions first-class entity 是一种支持对语言中的其他 entities 进行操作的 entity，包括作为参数传递、从函数返回和动态创建。\n在 functions 是 first-class entity 的语言中，可以编写 higher-order functions，将另一个 function 作为参数传递或返回一个 function。 其他语言也可能支持 higher-order functions，但是在这些语言中 function 不是可以在运行时动态创建的 entity 。 Function Objects 在某些语言中，可以定义本身不是函数但提供与函数相同接口的对象。这些对象被称为函数对象或函数器。一般来说，语言通过允许重载函数调用操作符来编写函数器。请看下面的 C++ 示例：\n1 2 3 4 5 6 7 8 9 10 11 class Counter { public: Counter : count(0) {} int operator()() { return count++; } private: int count; }; Counter 类实现了一个函数，可以返回它被调用的次数。可以同时存在多个 Counter 对象，每个对象都有自己的计数：\n1 2 3 4 5 6 7 Counter counter1, counter2; cout \u0026lt;\u0026lt; counter1() \u0026lt;\u0026lt; endl; // prints 0 cout \u0026lt;\u0026lt; counter1() \u0026lt;\u0026lt; endl; // prints 1 cout \u0026lt;\u0026lt; counter1() \u0026lt;\u0026lt; endl; // prints 2 cout \u0026lt;\u0026lt; counter2() \u0026lt;\u0026lt; endl; // prints 0 cout \u0026lt;\u0026lt; counter2() \u0026lt;\u0026lt; endl; // prints 1 cout \u0026lt;\u0026lt; counter1() \u0026lt;\u0026lt; endl; // prints 3 函数允许 function-like object 存在多个实例，每个实例都有自己的状态，并在函数的生命周期内持续存在。这与 function 截然不同，function 中的自动对象不会在单次调用后持续存在，而静态对象则会在整个程序执行过程中持续存在。\nPython 还允许通过定义特殊的 __call__ 方法来编写函数：\n1 2 3 4 5 6 7 class Counter: def __init__(self): self.count = 0 def __call__(self): self.count += 1 return self.count - 1 一般来说，在重载函数调用操作符时，可以指定额外的参数，以模拟可以接收这些参数的函数。\n有些语言不允许重载函数调用操作符本身，但规定了允许定义和使用类函数对象的约定。例如，下面是 Counter 在 Java 中使用 Supplier\u0026lt;T\u0026gt; 接口的实现，该接口指定了一个产生 T 的零参数方法：\n1 2 3 4 5 6 7 class Counter implements Supplier\u0026lt;Integer\u0026gt; { public Integer get() { return count++; } private int count = 0; } 然后通过明确调用 get() 方法来调用这个类函数对象：\n1 2 3 4 5 6 7 8 Supplier\u0026lt;Integer\u0026gt; counter1 = new Counter(); Supplier\u0026lt;Integer\u0026gt; counter2 = new Counter(); System.out.println(counter1.get()); // prints 0 System.out.println(counter1.get()); // prints 1 System.out.println(counter1.get()); // prints 2 System.out.println(counter2.get()); // prints 0 System.out.println(counter2.get()); // prints 1 System.out.println(counter1.get()); // prints 3 再比如，Java 中的 Predicate 接口是通过 functor-like objects 实现的，这些对象接收一个参数并返回一个布尔值：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 interface Predicate\u0026lt;T\u0026gt; { boolean test(T t); ... } class GreaterThan implements Predicate\u0026lt;Integer\u0026gt; { public GreaterThan(int threshold) { this.threshold = threshold; } public boolean test(Integer i) { return i \u0026gt; threshold; } private int threshold; } 使用这些 functor-like objects 的代码会调用 test() 方法，而不是直接调用对象：\n1 2 3 GreaterThan gt3 = new GreaterThan(3); System.out.println(gt3.test(2)); // prints out false System.out.println(gt3.test(20)); // prints out true java.util.function 函数库包中为常见模式提供了单独的接口。\nFunctions as Parameters higher-order function 可以将另一个函数作为参数。我们首先研究那些只有 top-level functions 并允许将函数指针或引用作为参数传递的语言。然后，我们将研究将函数作为参数传递会如何影响函数代码的执行环境。\nFunction Pointers 在某些语言中，函数可以作为参数或返回值传递，但不能在另一个函数的上下文中创建。在这些语言中，所有函数都是在顶层定义的，只有指向函数的指针或引用才能作为值使用。下面是 C 语言中的一个例子，C 语言提供了函数指针：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void apply(int *array, size_t size, int (*func)(int)) { for (; size \u0026gt; 0; --size, ++array) { *array = func(*array); } } int add_one(int x) { return x + 1; } int main() { int A[5] = { 1, 2, 3, 4, 5 }; apply(A, 5, add_one); printf(\u0026#34;%d, %d, %d, %d, %d\\n\u0026#34;, A[0], A[1], A[2], A[3], A[4]); return 0; } apply() 函数接收数组、数组大小和一个指向接收 int 并返回 int 的 function pointer。它将函数应用于数组中的每个元素，并用结果替换原值。add_one() 函数作为参数传递给 apply()，C 语言会自动将函数转换为函数指针，其结果是 A 中的每个元素都被递增。\nBinding Policy 在上面的代码中，有三个环境与 add_one() 函数相关联：定义环境、在 main() 中引用环境和在 apply() 中调用环境。根据语言的语义，这三个环境中的任何一个都可能是 add_one() 主体执行环境的组成部分。\n在静态作用域中，函数中的代码可以访问其定义环境中的名称，而在动态作用域中，它可以访问其使用环境中的名称。考虑到动态作用域，函数的非本地环境是函数被引用的环境还是函数被调用的环境？下面是一个与这种区别有关的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 int foo(int (*bar)()) { int x = 3; return bar(); } int baz() { return x; } int main() { int x = 4; print(foo(baz)); } 在动态作用域中，函数可以访问其使用环境。然而，在上面的示例中，根据 baz() 的使用环境是函数被引用的地方还是被调用的地方，结果是不同的。\n函数被引用的地方的情况下，baz() 的非本地环境是 main() 的环境，baz() 主体中的 x 将引用 main() 中定义的 x。这就是所谓的深度绑定。 函数被调用的地方的情况下，baz() 的非本地环境是 foo() 的环境，baz() 中的 x 将引用 foo() 中定义的 x。这就是所谓的浅绑定。这两种方法都是有效的，语言的绑定策略决定了使用哪种方法。 使用静态作用域时，绑定策略也会对递归函数内部本地定义的函数产生影响。然而，在使用静态作用域的语言中，深度绑定被普遍使用，因此函数定义时所建立的环境就是函数所能访问的环境。\nNested Functions 函数式编程的一个主要特点是可以在另一个函数中定义一个函数，从而动态创建一个函数。在具有静态作用域的语言中，这种嵌套函数可以访问其定义环境，函数与其定义环境的组合称为 closure。嵌套函数中使用但在外层环境中定义的变量被称为 closure 所捕获。如果嵌套函数从外层函数中返回或泄漏，外层函数的环境通常必须在函数返回后继续存在，因为嵌套函数可能会访问其中的绑定。\n举例来说，请看下面这个返回嵌套函数的 Python higher-order function：\n1 2 3 4 5 def make_greater_than(threshold): def greater_than(x): return x \u0026gt; threshold return greater_than make_greater_than() 函数接收一个阈值，并构造一个嵌套函数来判断其输入是否大于阈值。threshold 变量位于 make_greater_than() 的激活记录中，但被 greater_than() 捕获。由于后者会返回阈值，因此激活记录必须持续存在，这样 greater_than() 的调用才能访问 threshold 的绑定。\n请注意，每次调用 make_greater_than()，都会创建一个不同的 greater_than() 实例，并拥有自己的外层环境。因此，不同的 make_greater_than() 调用会产生不同的函数：\n1 2 3 4 5 6 7 8 9 10 \u0026gt;\u0026gt;\u0026gt; gt3 = make_greater_than(3) \u0026gt;\u0026gt;\u0026gt; gt30 = make_greater_than(30) \u0026gt;\u0026gt;\u0026gt; gt3(2) False \u0026gt;\u0026gt;\u0026gt; gt3(20) True \u0026gt;\u0026gt;\u0026gt; gt30(20) False \u0026gt;\u0026gt;\u0026gt; gt30(200) True Environment for multiple instances of a nested function 调用的父框架是 threshold 绑定为 3 的框架，因此 x \u0026gt; threshold 的值为 false。\n非纯函数式语言可能允许修改捕获的变量。例如，下面使用嵌套函数定义了一个银行账户的数据抽象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def make_account(balance): def deposit(amount): nonlocal balance balance += amount return balance def withdraw(amount): nonlocal balance if 0 \u0026lt;= amount \u0026lt;= balance: balance -= amount return amount else: return 0 return deposit, withdraw Python 需要 nonlocal ，因为它默认赋值给本地变量。然后，我们可以如下使用创建的函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt;\u0026gt;\u0026gt; deposit, withdraw = make_account(100) \u0026gt;\u0026gt;\u0026gt; withdraw(10) 10 \u0026gt;\u0026gt;\u0026gt; deposit(0) 90 \u0026gt;\u0026gt;\u0026gt; withdraw(20) 20 \u0026gt;\u0026gt;\u0026gt; deposit(0) 70 \u0026gt;\u0026gt;\u0026gt; deposit(10) 80 \u0026gt;\u0026gt;\u0026gt; withdraw(100) 0 \u0026gt;\u0026gt;\u0026gt; deposit(0) 80 Decorators Python 中的一种常见模式是通过应用高阶函数来转换函数或类。这样的高阶函数被称为 decorator，Python 有专门的语法来装饰函数：\n1 2 3 @\u0026lt;decorator\u0026gt; def \u0026lt;name\u0026gt;(\u0026lt;parameters\u0026gt;): \u0026lt;body\u0026gt; 这在很大程度上相当于\n1 2 3 4 def \u0026lt;name\u0026gt;(\u0026lt;parameters\u0026gt;): \u0026lt;body\u0026gt; \u0026lt;name\u0026gt; = \u0026lt;decorator\u0026gt;(\u0026lt;name\u0026gt;) 被装饰函数的定义被正常执行，然后在函数上调用装饰器。调用的结果与函数名称绑定。\n举个例子，假设我们想通过打印函数名称及其参数来跟踪函数被调用的时间。我们可以定义一个高阶函数，接收一个函数并返回一个新的嵌套函数，该函数首先打印出原始函数的名称及其参数，然后调用该函数：\n1 2 3 4 5 6 7 def trace(fn): def tracer(*args): args_string = \u0026#39;, \u0026#39;.join(repr(arg) for arg in args) print(f\u0026#39;{fn.__name__}({args_string})\u0026#39;) return fn(*args) return tracer 在这里，我们使用变量参数为原始函数传递任意数量的参数。为了简单起见，我们忽略了关键字参数。然后，我们可以使用装饰器语法将其应用到函数中：\n1 2 3 @trace def factorial(n): return 1 if n == 0 else n * factorial(n - 1) 现在，只要调用 factorial()，我们就能得到参数的打印输出：\n1 2 3 4 5 6 7 8 \u0026gt;\u0026gt;\u0026gt; factorial(5) factorial(5) factorial(4) factorial(3) factorial(2) factorial(1) factorial(0) 120 请注意，递归调用也会调用转换后的函数。这是因为在 factorial() 的外层环境中，factorial 这个名称现在与嵌套的跟踪函数绑定在一起，因此查找这个名称时，会调用跟踪函数，而不是原来的函数。这样做的一个副作用是产生了相互递归，即一组函数通过彼此间接地进行递归调用。\nMutual recursion resulting from decorating a recursive function Lambda Functions 嵌套函数定义允许在运行时构造函数，从而满足了函数成为 first-class entity 的要求之一。不过，到目前为止，我们只看到了嵌套函数定义的命名，即在定义环境中引入了绑定。这与其他一流实体，如数据值，形成了鲜明对比，后者可以在不绑定名称的情况下创建。就像构造不带名称的值很有用一样，比如将其作为参数传递或返回时，构造不带名称的函数也很有用。这些函数被称为匿名函数或 lambda 函数。\nlambda 函数在函数式语言中无处不在，但许多常用的命令式语言也提供某种形式的 lambda 函数。不同语言的语法和功能各不相同，我们将研究几个具有代表性的示例。\nScheme 在以函数式为主的 Lisp 系列语言中，lambda 是一种常见的构造，Scheme 也不例外。lambda 特殊形式构造了一个匿名函数：\n1 (lambda (\u0026lt;parameters\u0026gt;) \u0026lt;body\u0026gt;) 使用 define 形式的函数定义可视为变量定义和 lambda 的简写：\n1 2 3 (define (\u0026lt;name\u0026gt; \u0026lt;parameters\u0026gt;) \u0026lt;body\u0026gt;) --\u0026gt; (define \u0026lt;name\u0026gt; (lambda (\u0026lt;parameters\u0026gt;) \u0026lt;body\u0026gt;)) 例如，下面的函数创建并返回一个匿名函数，该函数将给定的数字添加到参数中：\n1 2 3 4 5 (define (make-adder n) (lambda (x) (+ x n) ) ) 这比只使用 define 的等价定义更简单、更恰当：\n1 2 3 4 5 6 (define (make-adder n) (define (adder x) (+ x n) ) adder ) 然后，我们就可以在各个参数上调用 make-adder 的结果：\n1 2 3 4 5 6 7 \u0026gt; (define add3 (make-adder 3)) \u0026gt; (add3 4) 7 \u0026gt; (add3 5) 8 \u0026gt; ((make-adder 4) 5) 9 Scheme 中的嵌套函数使用静态作用域，因此匿名函数可以访问其定义环境中的变量 n。然后，它将自己的参数 x 与 n 相加，返回总和。\nScheme 并非纯函数式，它允许变量和复合数据的变异。嵌套函数，无论是否匿名，都可以修改其非本地环境中的变量。下面的函数创建了一个计数器函数，返回它被调用的次数：\n1 2 3 4 5 6 7 8 (define (make-counter) (let ((count 0)) (lambda () (set! count (+ count 1)) (- count 1) ) ) ) set! 将变量变为给定值。这样，我们就可以使用 make-counter 函数了：\n1 2 3 4 5 6 7 \u0026gt; (define counter (make-counter)) \u0026gt; (counter) 0 \u0026gt; (counter) 1 \u0026gt; (counter) 2 Resources https://eecs390.github.io/notes/functional.html ","permalink":"https://WFUing.github.io/posts/tech/language/functional-programming/","summary":"我们将注意力转向过程抽象，这是一种将复杂程序分解成 functions (也称为 procedures 或 subroutines 。这些术语在不同语境中的用法有细微差别，但就我们的目的而言，我们将把它们视为同义词) 形式的较小代码片段的策略。函数将某些计算封装在一个接口之后，与任何抽象概念一样，函数的用户只需知道函数做了什么，而不需要知道函数是如何完成计算的。函数还通过接收影响其计算的参数来概括计算。计算的结果就是函数的返回值。\n在本单元中，我们首先介绍 Lisp 家族中的函数式语言 Scheme。然后，我们将讨论与所有 procedural languages 相关的函数方面的问题，然后再仔细研究 functional programming，这是一种以数学函数为计算模型的编程范式。\nIntroduction to Scheme R5RS Scheme 语言采用了与 Python 非常相似的计算模型，但只使用 expressions (不使用statements)，擅长 symbolic computation。\nScheme 是 Lisp 的一种方言，Lisp 是当今仍在广泛使用的第二古老的编程语言（仅次于 Fortran）。几十年来，Lisp 程序员社区一直在蓬勃发展，而新的 Lisp 方言（如 Clojure）也是所有现代编程语言中开发者社区发展最快的。要跟上本文的示例，可以下载 Scheme 解释器或使用在线解释器。\nExpressions Scheme 程序由 expressions 组成，expressions 可以是简单表达式，也可以是列表形式的组合。简单表达式由一个文字或符号组成。组合表达式是一种 compound expression，由一个运算符表达式和零个或多个操作数子表达式组成。运算符和操作数都包含在括号中：\n1 2 \u0026gt; (quotient 10 2) 5 Scheme 只使用前缀符号。操作符通常是符号，如 + 和 *。复合表达式可以嵌套，也可以跨一行以上：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; (+ (* 3 5) (- 10 6)) 19 \u0026gt; (+ (* 3 (+ (* 2 4) (+ 3 5) ) ) (+ (- 10 7) 6 ) ) 57 对组合进行求值时，首先需要检查运算符是否代表 special form，因为 special form 有自己的求值程序。如果运算符不是 special form，那么运算符和操作数表达式将按照任意顺序进行求值。然后，作为运算符值的函数将应用于作为操作数值的参数。","title":"Functional Programming"},{"content":"Serverless Devs 是一个开源开放的 Serverless 开发者平台，致力于为开发者提供强大的工具链体系。通过该平台，开发者不仅可以一键体验多云 Serverless 产品，极速部署 Serverless 项目，还可以在 Serverless 应用全生命周期进行项目的管理，并且非常简单快速的将 Serverless Devs 与其他工具/平台进行结合，进一步提升研发、运维效能。\n平台/产品支持 目前 Serverless Devs 项目已经支持的 FaaS 平台/产品：\nHosted 阿里云函数计算（FC）: 项目仓库 AWS Lambda: 项目仓库 百度智能云函数计算（CFC）: 项目仓库 华为云函数工作流（FG）: 项目仓库 腾讯云云函数（SCF）: 项目仓库 Installable OpenFunction（ofn）: 项目仓库 Laf: 开发中\u0026hellip; 项目期望 Serverless Devs 希望可以为 Serverless 开发者们提供一款可以无厂商锁定的，可以在 Serverless 应用全生命周期发挥作用的 Serverless 开发者工具； Serverless Registry 希望可以为 Serverless 生态提供一套完整的包管理规范，与 Python 中的 pypi， Nodejs 中的 npm 等类似，将以此来开放和分享 Serverless Package，建设 Serverless 生态； Serverless Developer Meetup 希望可以打造最符合 Serverless 开发者的社区活动，通过这个活动，希望更多人可以一起交流、学习 Serverless 相关的产品； 快速上手 本快速上手案例以 阿里云函数计算 为例的快速上手 Serverless Devs\n工具安装 第一步：安装 Node.js(\u0026gt;=12.0.0) 与 NPM 包管理工具； 第二步：安装 Serverless Devs 开发者工具； 1 $ npm install @serverless-devs/s -g 第三步：可以通过s -v判断工具是否安装成功，如果安装成功可以看到相对应的版本信息，例如： 1 @serverless-devs/s: 2.1.2, core: 0.1.41, s-home: /Users/xxx/.s, darwin-x64, node-v17.7.1 密钥配置 以阿里云密钥配置为例：\n获取密钥页面：https://usercenter.console.aliyun.com/#/manage/ak 打开 获取密钥页面 获取密钥信息 ：\n执行s config add，并选择Alibaba Cloud (alibaba)：\n1 2 3 4 $ s config add ? Please select a provider: Alibaba Cloud (alibaba) 🧭 Refer to the document for alibaba key: http://config.devsapp.net/account/alibaba ? AccessKeyID: 此时，可以按照引导，进行密钥的配置：\n1 2 3 4 5 6 7 8 9 10 11 12 ? Please select a template: Alibaba Cloud (alibaba) 🧭 Refer to the document for alibaba key: http://config.devsapp.net/account/alibaba ? AccessKeyID 此处填写AccessKeyID ? AccessKeySecret 此处填写AccessKeySecret ? Please create alias for key pair. If not, please enter to skip alibaba-access Alias: alibaba-access AccountID: 自动获取AccountID AccessKeyID: 此处填写AccessKeyID AccessKeySecret: 此处填写AccessKeySecret ✔ Configuration successful 为了验证密钥是否正确配置，可以通过s config get -a alibaba-access进行指定密钥的查看：\n1 2 3 4 5 $ s config get -a alibaba-access alibaba-access: AccountID: 此处填*******tID AccessKeyID: 此处填*********yID AccessKeySecret: 此处填*************ret 上手体验 Serverless：Hello World 执行s命令：\n1 2 $ s ? No Serverless-Devs project is currently detected. Do you want to create a new project? (Y/n) 填写y，并按回车，可以进入到创建引导部分：\n1 2 3 4 5 6 7 8 9 🚀 More applications: https://registry.serverless-devs.com ? Hello Serverless for Cloud Vendors (Use arrow keys or type to search) ❯ Alibaba Cloud Serverless AWS Cloud Serverless Baidu Cloud Serverless Huawei Cloud Serverless Tencent Cloud Serverless Dev Template for Serverless Devs 此时只需要选择对应的选项，按照引导进行操作，即可。例如选择Alibaba Cloud Serverless，就可以看到阿里云Serverless产品下的应用模板分类:\n1 2 3 4 5 6 ? Hello, serverlesser. Which template do you like? (Use arrow keys or type to search) ❯ Quick start [Deploy a Hello World function to FaaS] Container example [Deploy function to FaaS with custom-container] Web Framework [Deploy a web framework to FaaS] Static website [Deploy a static website] Best practice [Experience serverless project] 此时可以继续选择某分类下的具体应用进行初始化，例如选择Quick start之后，可以看到该分类下的具体模板应用：\n1 2 3 4 5 6 7 8 9 ? Which template do you like? (Use arrow keys or type to search) ❯ [HTTP] Node.js 14 - 快速部署一个 nodejs14 http函数 [HTTP] Python3 - 快速部署一个 python3 http函数 [HTTP] Java8 - 快速部署一个 java8 http函数 [HTTP] PHP7 - 快速部署一个 php http函数 [HTTP] C++ (custom)- 快速部署一个 C++ http函数 [Event] Node.js 14 - 快速部署一个 nodejs14 event函数 [Event] Python3 - 快速部署一个 python3 event函数 ... ... 选择[HTTP] Node.js 14即可完成创建，在引导的过程中，可能会出现填写项目名称以及选择密钥的过程：\n项目名称可以是：start-fc-http-nodejs14 地域可以是：cn-hangzhou 服务名可以是： hello-world-service 函数名可以是： start-fc-http-nodejs14 密钥可以选择我们上文中创建过的：alibaba-access 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 🚀 More applications: https://registry.serverless-devs.com ? Hello Serverless for Cloud Vendors Alibaba Cloud Serverless ? Hello, serverlesser. Which template do you like? Quick start [Deploy a Hello World function to FaaS] ? Which template do you like? [HTTP] Node.js 14 😋 Create application command: [s init devsapp/start-fc-http-nodejs14] ? Please input your project name (init dir) start-fc-http-nodejs14 ✔ file decompression completed Serverless Devs Application Case Cloud services required： - FC : https://fc.console.aliyun.com/ Tips： - FC Component: https://www.serverless-devs.com/fc/readme 创建应用所在的地区 ? 地域 cn-hangzhou 服务名称，只能包含字母、数字、下划线和中划线。不能以数字、中划线开头。长度在 1-128 之间 ? 服务名 hello-world-service 函数名称，只能包含字母、数字、下划线和中划线。不能以数字、中划线开头。长度在 1-64 之间 ? 函数名 start-fc-http-nodejs14 ? please select credential alias alibaba-access * Before using, please check whether the actions command in Yaml file is available * Carefully reading the notes in s.yaml is helpful for the use of the tool * If need help in the use process, please apply to join the Dingtalk Group: 33947367 🏄‍ Thanks for using Serverless-Devs 👉 You could [cd /Users/nanxuanli/work/demo/devs/start-fc-http-nodejs14] and enjoy your serverless journey! 🧭️ If you need help for this example, you can use [s -h] after you enter folder. 💞 Document ❤ Star: https://github.com/Serverless-Devs/Serverless-Devs 🚀 More applications: https://registry.serverless-devs.com ? Do you want to deploy the project immediately? (Y/n) 可以看到，系统在最后有一个提醒，是否要部署该项目，此时可以输入y，直接进行项目的部署，稍等片刻，可以看到部署结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 helloworld: region: cn-hangzhou service: name: hello-world-service function: name: start-fc-http-nodejs14 runtime: nodejs14 handler: index.handler memorySize: 128 timeout: 60 url: system_url: https://start-fp-nodejs-hello-w-service-uxcvfbhdii.cn-hangzhou.fcapp.run custom_domain: - domain: http://start-fc-http-nodejs14.hello-world-service.1816647648916833.cn-hangzhou.fc.devsapp.net triggers: - type: http name: httpTrigger 此时可以打开domain返回给我们的域名，进行测试。\n人工智能：目标检测 初始化一个已有的人工智能目标检测项目：s init devsapp/image-prediction-app，初始化过程中可能会出现填写项目名称以及选择密钥的过程：\n项目名称可以是：image-prediction-app 密钥可以选择我们上文中创建过的：alibaba-access 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 $ s init devsapp/image-prediction-app 🚀 Serverless Awesome: https://github.com/Serverless-Devs/package-awesome ? Please input your project name (init dir) image-prediction-app ✔ file decompression completed ? please select credential alias alibaba-access ___ __ __ _______ _______ _______ | | | |_| || _ || || | | | | || |_| || ___|| ___| | | | || || | __ | |___ | | | || || || || ___| | | | ||_|| || _ || |_| || |___ |___| |_| |_||__| |__||_______||_______| Welcome to the image-prediction-app application This application requires to open these services: FC : https://fc.console.aliyun.com/ This application can help you quickly deploy the image-prediction-app project. The application uses FC component：https://github.com/devsapp/fc The application homepage: https://github.com/devsapp/image-prediction-app 🏄‍ Thanks for using Serverless-Devs 👉 You could [cd /Users/jiangyu/start-application/image-prediction-app] and enjoy your serverless journey! 🧭️ If you need help for this example, you can use [s -h] after you enter folder. 💞 Document ❤ Star：https://github.com/Serverless-Devs/Serverless-Devs 进入项目目录：cd image-prediction-app\n通过deploy命令进行项目的部署：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Tips for next step ====================== * Display information of the deployed resource: s info * Display metrics: s metrics * Display logs: s logs * Invoke remote function: s invoke * Remove Service: s remove service * Remove Function: s remove function * Remove Trigger: s remove trigger * Remove CustomDomain: s remove domain imageAi: region: cn-hangzhou url: custom_domain: - domain: http://server.ai-cv-image-prediction.1583208943291465.cn-hangzhou.fc.devsapp.net 此时可以打开系统分配的测试域名，并上传一张图片进行测试。\n传统框架：基于Django的博客项目 初始化一个已有的基于Django的博客项目：s init django-blog，初始化过程中可能会出现填写项目名称以及选择密钥的过程：\n项目名称可以是：django-blog 密钥可以选择我们上文中创建过的：alibaba-access 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 $ s init django-blog 🚀 Serverless Awesome: https://github.com/Serverless-Devs/package-awesome ? Please input your project name (init dir) django-blog ✔ file decompression completed ? please select credential alias alibaba-access ______ ___ _______ __ _ _______ _______ _______ ___ _______ _______ | | | || _ || | | || || || _ || | | || | | _ | | || |_| || |_| || ___|| _ || |_| || | | _ || ___| | | | | | || || || | __ | | | || || | | | | || | __ | |_| | ___| || || _ || || || |_| || _ | | |___ | |_| || || | | || || _ || | | || |_| || || |_| || || || |_| | |______| |_______||__| |__||_| |__||_______||_______||_______||_______||_______||_______| Welcome to the django-blog application This application requires to open these services: FC : https://fc.console.aliyun.com/ This application can help you quickly deploy the django-blog project. The application uses Django component：https://github.com/devsapp/django The application homepage: https://github.com/devsapp/django-blog * Python 3.7 is recommended; * If the version is greater than Python 3.7: * Operation error: ImportError: cannot import name \u0026#39;metadata\u0026#39; from \u0026#39;importlib\u0026#39;, you can refer to: https://stackoverflow.com/questions/59216175/importerror-cannot-import-name-metadata-from-importlib * Default information: * Admin：/admin * Default Admin Username: blog * Default Admin Password: myblog12345! 🏄‍ Thanks for using Serverless-Devs 👉 You could [cd /Users/jiangyu/django-blog] and enjoy your serverless journey! 🧭️ If you need help for this example, you can use [s -h] after you enter folder. 💞 Document ❤ Star：https://github.com/Serverless-Devs/Serverless-Devs 进入项目目录：cd django-blog\n通过deploy命令进行项目的部署：\n1 2 3 4 5 6 7 8 9 10 Tips for next step ====================== * Invoke remote function: s invoke ✔ Try container acceleration djangoBlog: region: cn-shenzhen serviceName: serverless-devs-django functionName: django customDomains: - http://django.serverless-devs-django.1583208943291465.cn-shenzhen.fc.devsapp.net Resources Github: https://github.com/Serverless-Devs/Serverless-Devs ","permalink":"https://WFUing.github.io/posts/tech/architecture/serverless/serverless-dev/","summary":"Serverless Devs 是一个开源开放的 Serverless 开发者平台，致力于为开发者提供强大的工具链体系。通过该平台，开发者不仅可以一键体验多云 Serverless 产品，极速部署 Serverless 项目，还可以在 Serverless 应用全生命周期进行项目的管理，并且非常简单快速的将 Serverless Devs 与其他工具/平台进行结合，进一步提升研发、运维效能。\n平台/产品支持 目前 Serverless Devs 项目已经支持的 FaaS 平台/产品：\nHosted 阿里云函数计算（FC）: 项目仓库 AWS Lambda: 项目仓库 百度智能云函数计算（CFC）: 项目仓库 华为云函数工作流（FG）: 项目仓库 腾讯云云函数（SCF）: 项目仓库 Installable OpenFunction（ofn）: 项目仓库 Laf: 开发中\u0026hellip; 项目期望 Serverless Devs 希望可以为 Serverless 开发者们提供一款可以无厂商锁定的，可以在 Serverless 应用全生命周期发挥作用的 Serverless 开发者工具； Serverless Registry 希望可以为 Serverless 生态提供一套完整的包管理规范，与 Python 中的 pypi， Nodejs 中的 npm 等类似，将以此来开放和分享 Serverless Package，建设 Serverless 生态； Serverless Developer Meetup 希望可以打造最符合 Serverless 开发者的社区活动，通过这个活动，希望更多人可以一起交流、学习 Serverless 相关的产品； 快速上手 本快速上手案例以 阿里云函数计算 为例的快速上手 Serverless Devs","title":"Serverless Dev"},{"content":"Serverless 是一种计算模型，它使得开发者能够在无需管理服务器和基础架构的情况下运行代码（或称函数）。使用无服务器计算，开发者可以将代码上传到云平台，平台会在需要时根据流量自动进行资源分配和处理。\nServerless 的特点\n按需分配 无服务器计算基于事件驱动和按需调用，只在需要时才会进行计算资源的分配和管理 弹性伸缩 无服务器计算平台会自动根据负载量的变化进行资源的动态分配和优化，无需手动干预 简化开发与部署 开发者专注于编写核心业务逻辑代码，简化应用开发以及部署流程 Concept Models Serverless 核心资源 Service\n阿里云提供服务这一抽象 服务是函数计算资源管理的单位，同一服务下的所有函数共享一些设置，如服务授权和日志配置 一个应用可拆分为多个服务，一个服务可由多个函数组成 Function\n云函数，云函数由代码和运行环境描述组成 云函数可能依赖于其他云函数，或者外部服务，如对象存储，API 网关，消息队列 Trigger\n触发器，用于在满足某些条件时，触发 Function 的执行 基于事件驱动 常见的触发器类型 定时触发器 Cron Trigger API 网关触发器 HTTP Trigger 消息队列触发器 MQ Trigger External Service\n云函数在运行过程中，可能调用外部的服务完成任务，如调用 Redis 或 RDBMS 存储状态 Function 表示 Serverless 函数\nFunction 基本信息\n包括函数的代码 URI，运行时，处理函数名称等\nFunction 资源需求\n指定函数运行时所需的计算资源，如内存，CPU 等\nFunction 触发器\n1 2 3 4 5 6 7 8 9 export interface Function { runtime: string; codeDir: string; // source code directory to bundle resource: { memory: string; cpu: string; }; triggers: {}[]; } Trigger 函数触发器，基于事件驱动机制触发函数执行\n1 2 3 4 5 export interface Trigger { name: string; type: string; props: unknown; } Application Application 表示当前部署的 Serverless 应用\n一个 Application 可能包含多个 Function\nApplication 需要指定默认的部署参数，比如使用的 Provider\n1 2 3 4 5 6 7 export interface Application { provider: { name: string; props: {}; }; functions: Function[]; } 执行器会解析入口模块的 Application，并执行实际的部署\nFunction 部署过程涉及到的阶段 函数部署会涉及以下阶段\n状态查询：向集群查询部署状态，判断是否已有部署 构建：打包用户代码和依赖，执行构建，生成 Artifact 上传：将构建好的 Artifact 上传到指定的存储服务 执行部署：调用 Provider 提供的 API，创建函数资源 对于基于 Kubernetes 的 Serverless 平台，如 OpenFaas，OpenWhisk 和 Knative。函数的运行基本单位为 POD，产物为 Docker 镜像。\n对于腾讯云，阿里云等公有云厂商，产物为构建好的二进制文件，打包为 zip，并需要上传至 OSS\n","permalink":"https://WFUing.github.io/posts/tech/architecture/serverless/serverless-concept-models/","summary":"Serverless 是一种计算模型，它使得开发者能够在无需管理服务器和基础架构的情况下运行代码（或称函数）。使用无服务器计算，开发者可以将代码上传到云平台，平台会在需要时根据流量自动进行资源分配和处理。\nServerless 的特点\n按需分配 无服务器计算基于事件驱动和按需调用，只在需要时才会进行计算资源的分配和管理 弹性伸缩 无服务器计算平台会自动根据负载量的变化进行资源的动态分配和优化，无需手动干预 简化开发与部署 开发者专注于编写核心业务逻辑代码，简化应用开发以及部署流程 Concept Models Serverless 核心资源 Service\n阿里云提供服务这一抽象 服务是函数计算资源管理的单位，同一服务下的所有函数共享一些设置，如服务授权和日志配置 一个应用可拆分为多个服务，一个服务可由多个函数组成 Function\n云函数，云函数由代码和运行环境描述组成 云函数可能依赖于其他云函数，或者外部服务，如对象存储，API 网关，消息队列 Trigger\n触发器，用于在满足某些条件时，触发 Function 的执行 基于事件驱动 常见的触发器类型 定时触发器 Cron Trigger API 网关触发器 HTTP Trigger 消息队列触发器 MQ Trigger External Service\n云函数在运行过程中，可能调用外部的服务完成任务，如调用 Redis 或 RDBMS 存储状态 Function 表示 Serverless 函数\nFunction 基本信息\n包括函数的代码 URI，运行时，处理函数名称等\nFunction 资源需求\n指定函数运行时所需的计算资源，如内存，CPU 等\nFunction 触发器\n1 2 3 4 5 6 7 8 9 export interface Function { runtime: string; codeDir: string; // source code directory to bundle resource: { memory: string; cpu: string; }; triggers: {}[]; } Trigger 函数触发器，基于事件驱动机制触发函数执行","title":"Serverless Concept Models"},{"content":"元编程是编写可在其他程序上运行的计算机程序的技术。诸如编译器和程序分析器之类的系统可以被视为元程序，因为它们将其他程序作为输入。我们将在这里讨论的元编程形式特别关注生成要作为程序一部分包含的代码。从某种意义上说，它们可以被认为是初级编译器。\nMacros and Code Generation macro 是将输入序列转换为某种替换输出序列的规则。这个翻译过程称为 macro expansion，一些语言提供宏作为其规范的一部分。宏设施可以被实现为 preprocessing step，其中宏扩展发生在 lexical and syntactic analysis 之前，或者它可以被合并为 syntax analysis 或 a later translation step。\n使用最广泛的 macro systems 之一是 C 预处理器（CPP），它作为处理程序的第一步被包含在 C 和 C++ 中。预处理器指令以散列符号开头，包括 #include、#define、#if 等。例如，下面定义了一个类似函数的 macro 来交换两个项目：\n1 #define SWAP(a, b) { auto tmp = b; b = a; a = tmp; } 然后，我们可以如下使用宏：\n1 2 3 4 5 6 7 8 9 int main() { int x = 3; int y = 4; SWAP(x, y); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; } // output 4 3 通过向 g++ 传递 -E 标志，可以获得宏扩展的结果：\n1 $ g++ -E \u0026lt;source\u0026gt; 不过，如果使用 #includes 指令，结果可能会非常混乱，因为该指令会从给定文件中调入代码。\nCPP macros perform text 替换，因此上述代码等同于：\n1 2 3 4 5 6 int main() { int x = 3; int y = 4; { auto tmp = y; y = x; x = tmp; }; cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; } 使用 SWAP 宏后的分号仍然保留，表示空语句。不过，在需要使用单一语句的情况下，例如一个没有被 block 括住的条件分支，这就会造成问题：\n1 2 3 4 if (x \u0026lt; y) SWAP(x, y); else cout \u0026lt;\u0026lt; \u0026#34;no swap\u0026#34; \u0026lt;\u0026lt; endl; 避免这一问题的常用方法是将 macro 的扩展代码放在 do/while 中：\n1 2 3 4 5 #define SWAP(a, b) do { \\ auto tmp = b; \\ b = a; \\ a = tmp; \\ } while (false) 在这里，我们在一行的末尾添加了一个 \\，表示下一行应被视为上一行的继续。do/while 循环在语法上以分号结束，因此 SWAP(x, y); 中的分号在语法上是 do/while 循环的一部分。因此，扩展代码的语法是正确的：\n1 2 3 4 if (x \u0026lt; y) do { auto tmp = b; b = a; a = tmp; } while (false); else cout \u0026lt;\u0026lt; \u0026#34;no swap\u0026#34; \u0026lt;\u0026lt; endl; 虽然 textual replacement 很有用，但它也有缺点，因为虽然宏在语法上类似函数，但它们的行为却不像函数。具体来说，它们不把参数作为自己的实体，也不引入独立的作用域。请看下面的例子：\n1 2 3 4 5 6 7 8 9 10 int main() { int x = 3; int y = 4; int z = 5; SWAP(x \u0026lt; y ? x : y, z); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; endl; } // output 3 4 3 使用 g++ -E，我们可以看到预处理后的代码。只看 main() 的输出，我们会发现\n1 2 3 4 5 6 7 8 9 10 11 int main() { int x = 3; int y = 4; int z = 5; do { auto tmp = z; z = x \u0026lt; y ? x : y; x \u0026lt; y ? x : y = tmp; } while (false); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; endl; } 在这里，我们手动添加了换行符和空格，以使输出更易读；而预处理器本身会将宏输出放在一行中。罪魁祸首是最后生成的语句：\n1 x \u0026lt; y ? x : y = tmp; 在 C++ 中，条件运算符 ? : 和赋值运算符 = 具有相同的优先级，并且从右向左关联，因此这等同于\n1 x \u0026lt; y ? x : (y = tmp); 由于 x \u0026lt; y，这里没有赋值。因此，x 的值保持不变。\n我们可以在每次使用 macro argument 时加上括号来解决这个问题：\n1 2 3 4 5 #define SWAP(a, b) do { \\ auto tmp = (b); \\ (b) = (a); \\ (a) = tmp; \\ } while (false) Ranking the Operator Precedence in C\u0026#43;\u0026#43; 现在会产生预期的结果，因为括号明确地将这些操作联系起来：\n1 2 3 4 5 6 7 8 9 10 11 int main() { int x = 3; int y = 4; int z = 5; do { auto tmp = (z); (z) = (x \u0026lt; y ? x : y); (x \u0026lt; y ? x : y) = tmp; } while (false); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; endl; } 然而，第二个问题并不那么容易解决。考虑一下当我们将 SWAP 宏应用于名为 tmp 的变量时会发生什么：\n1 2 3 4 5 6 7 8 9 int main() { int x = 3; int tmp = 4; SWAP(tmp, x); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; tmp \u0026lt;\u0026lt; endl; } // output 3 4 没有发生交换！再次使用 g++ -E 检查输出，我们可以看到（模数间隔）\n1 2 3 4 5 6 7 8 9 10 int main() { int x = 3; int tmp = 4; do { auto tmp = (x); (x) = (tmp); (tmp) = tmp; } while (false); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; tmp \u0026lt;\u0026lt; endl; } 由于 SWAP 使用的临时变量与参数同名，因此临时变量会捕获生成代码中出现的参数。这是因为宏只是执行文本替换，并不能确保名称被解析到适当的作用域。因此，宏实际上并不使用按名称调用，而按名称调用可确保参数中的名称解析到适当的作用域。对文本替换的依赖使 CPP 成为一个不卫生的宏系统。其他系统（如 Scheme 的系统）是卫生的，它们为宏引入的名称创建了单独的作用域，并确保参数不会被捕获。\nScheme Macros 作为 R5RS Scheme 规范的一部分，宏系统是卫生的。宏由 define-syntax、let-syntax 或 letrec-syntax 中的一种形式引入，并将给定的名称与宏绑定。例如，下面是 let 作为宏的定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 (define-syntax let (syntax-rules () ((let ((name val) ...) body1 body2 ... ) ((lambda (name ...) body1 body2 ... ) val ... ) ) ) ) syntax-rules 指定了宏转换的规则。第一个参数是规则模式与输入之间必须匹配的字面形式列表。例如，cond 形式中的 else 标识符。但在这种情况下，没有字面意义。syntax-rules 的其余参数指定了转换。转换的第一项是输入模式，第二项是输出模式。...的作用类似于克莱因星，将前一项与输入中出现的零次或多次相匹配。输入模式中出现但不在字面量列表中的名称，除了作为宏名称的第一项，都是与输入元素相匹配的卫生变量。这些变量可以在输出模式中引用，以指定如何构造输出。\n在全局环境中评估上述表达式时，会将 let 名称与一个转换为 lambda 的宏绑定。\n宏主体引入的标识符保证避免与其他标识符冲突，解释器通常会重命名标识符以避免冲突。下面是 swap 宏的定义：\n1 2 3 4 5 6 7 8 9 10 (define-syntax swap (syntax-rules () ((swap a b) (let ((tmp b)) (set! b a) (set! a tmp) ) ) ) ) 这就将 swap 的使用转化为一个表达式，通过临时变量 tmp 交换两个参数。因此\n1 2 3 4 5 6 7 \u0026gt; (define x 3) \u0026gt; (define y 4) \u0026gt; (swap x y) \u0026gt; x 4 \u0026gt; y 3 不过，与 CPP 宏不同的是，swap 宏引入的 tmp 与其他任何 tmp 都是不同的：\n1 2 3 4 5 6 \u0026gt; (define tmp 5) \u0026gt; (swap x tmp) \u0026gt; x 5 \u0026gt; tmp 4 因为宏在 Scheme 中是卫生的，所以我们会得到预期的行为。\n为了支持宏，Scheme 解释器的评估过程会像往常一样评估列表中的第一个项目。如果评估结果是一个宏，那么解释器将对列表的其余部分执行宏扩展，而不会首先评估参数。扩展引入的任何名称都与其他名称置于不同的作用域。扩展后，解释器会对扩展结果重复求值过程，因此，如果最终结果是一个 let 表达式 (如上文 swap 中的表达式)，就会对该表达式进行求值。\n一个宏定义可以指定多个模式规则。再加上扩展的结果会被求值，这使得宏定义可以递归，如下面的 let* 定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 (define-syntax let* (syntax-rules () ((let* () body1 body2 ... ) (let () body1 body2 ... ) ) ((let* ((name1 val1) (name2 val2) ...) body1 body2 ... ) (let ((name1 val1)) (let* ((name2 val2) ...) body1 body2 ... ) ) ) ) ) 当 let* 没有绑定时，有一种基本模式，在这种情况下，它直接转化为一个 let。当至少有一个绑定时，也有一个递归模式，在这种情况下，let* 会转化为一个嵌套在 let 中的更简单的 let*。宏定义中的省略号 (...) 类似于正则表达式中的 Kleene 星号 (*)，表示前一项可以匹配零次或多次。因此，具有单一绑定的 let* 与上述第二条模式规则相匹配，其中 (name2 val2) 匹配次数为零。\nCPP Macros 我们再来看看 CPP 宏。尽管宏不卫生，但在涉及元编程的任务中却非常有用。\nCPP 允许我们使用 #define 来定义两种类型的 macro，即 object-like macro 和 function-like macro。object-like macro 是一种简单的文本替换，用一个文本序列替换另一个文本序列。在历史上，定义常量是一种常用的方法：\n1 2 3 4 5 6 #define PI 3.1415926535 int main() { cout \u0026lt;\u0026lt; \u0026#34;pi = \u0026#34; \u0026lt;\u0026lt; PI \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;tau = \u0026#34; \u0026lt;\u0026lt; PI * 2 \u0026lt;\u0026lt; endl; } 在 C++ 中，更好的做法是使用 const 或 constexpr 定义常量。\nfunction-like macro 接受参数 (如上文的 SWAP)，并能将参数文本替换到替换文本中的特定位置。\n使用 function-like macro 的一个更复杂的例子是对遵循相同模式的多段代码进行抽象定义。请看表示复数的类型定义：\n1 2 3 4 5 6 7 8 struct Complex { double real; double imag; }; ostream \u0026amp;operator\u0026lt;\u0026lt;(ostream \u0026amp;os, Complex c) { return os \u0026lt;\u0026lt; \u0026#34;(\u0026#34; \u0026lt;\u0026lt; c.real \u0026lt;\u0026lt; \u0026#34;+\u0026#34; \u0026lt;\u0026lt; c.imag \u0026lt;\u0026lt; \u0026#34;i)\u0026#34;; } 假设除了上述重载的流插入操作符之外，我们还希望支持算术运算 +、- 和 *。这些运算的基本形式相同：\n1 2 3 Complex operator \u0026lt;op\u0026gt;(Complex a, Complex b) { return Complex{ \u0026lt;expression for real\u0026gt;, \u0026lt;expression for imag\u0026gt; }; } 在这里，我们使用了 uniform initialization syntax 来初始化一个含有其成员值的 Complex。然后，我们可以编写一个 function-like macro 来抽象这个结构：\n1 2 3 4 #define COMPLEX_OP(op, real_part, imag_part) \\ Complex operator op(Complex a, Complex b) { \\ return Complex{ real_part, imag_part }; \\ } 该 macro 的参数包括运算符、计算实部的表达式和计算虚部的表达式。我们可以使用下面的宏来定义运算：\n1 2 3 4 COMPLEX_OP(+, a.real+b.real, a.imag+b.imag); COMPLEX_OP(-, a.real-b.real, a.imag-b.imag); COMPLEX_OP(*, a.real*b.real - a.imag*b.imag, a.imag*b.real + a.real*b.imag); 与我们最初的 SWAP 实现一样，尾部的分号是多余的，但却提高了可读性以及与语法高亮程序的交互性。使用 g++ -E 在预处理器中运行代码，我们可以得到（修改间距）：\n1 2 3 4 5 6 7 8 9 10 Complex operator +(Complex a, Complex b) { return Complex{ a.real+b.real, a.imag+b.imag }; }; Complex operator -(Complex a, Complex b) { return Complex{ a.real-b.real, a.imag-b.imag }; }; Complex operator *(Complex a, Complex b) { return Complex{ a.real*b.real - a.imag*b.imag, a.imag*b.real + a.real*b.imag }; }; 接下来，我们可以定义 Complex 和 double 之间的运算。我们再次发现，这种操作具有特定的模式：\n1 2 3 Complex operator \u0026lt;op\u0026gt;(\u0026lt;type1\u0026gt; a, \u0026lt;type2\u0026gt; b) { return \u0026lt;expr1\u0026gt; \u0026lt;op\u0026gt; \u0026lt;expr2\u0026gt;; } 这里，\u0026lt;exprN\u0026gt; 是转换为 Complex 表示的相应参数。我们可以使用宏对其进行抽象：\n1 2 3 4 #define REAL_OP(op, typeA, typeB, argA, argB) \\ Complex operator op(typeA a, typeB b) { \\ return argA op argB; \\ } 我们还可以定义一个宏，将 double 转换为 Complex：\n1 2 #define CONVERT(a) \\ (Complex{ a, 0 }) 这样，我们就可以对操作进行如下定义：\n1 2 3 4 5 6 REAL_OP(+, Complex, double, a, CONVERT(b)); REAL_OP(+, double, Complex, CONVERT(a), b); REAL_OP(-, Complex, double, a, CONVERT(b)); REAL_OP(-, double, Complex, CONVERT(a), b); REAL_OP(*, Complex, double, a, CONVERT(b)); REAL_OP(*, double, Complex, CONVERT(a), b); 通过预处理器运行，我们可以得到\n1 2 3 4 5 6 Complex operator +(Complex a, double b) { return a + (Complex{ b, 0 }); }; Complex operator +(double a, Complex b) { return (Complex{ a, 0 }) + b; }; Complex operator -(Complex a, double b) { return a - (Complex{ b, 0 }); }; Complex operator -(double a, Complex b) { return (Complex{ a, 0 }) - b; }; Complex operator *(Complex a, double b) { return a * (Complex{ b, 0 }); }; Complex operator *(double a, Complex b) { return (Complex{ a, 0 }) * b; }; 现在我们可以如下使用复数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int main() { Complex c1{ 3, 4 }; Complex c2{ -1, 2 }; double d = 0.5; cout \u0026lt;\u0026lt; c1 + c2 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 - c2 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 * c2 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 + d \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 - d \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 * d \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; d + c1 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; d - c1 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; d * c1 \u0026lt;\u0026lt; endl; } 1 2 3 4 5 6 7 8 9 (2+6i) (4+2i) (-11+2i) (3.5+4i) (2.5+4i) (1.5+2i) (3.5+4i) (-2.5+-4i) (1.5+2i) Stringification and Concatenation 在使用宏时，将宏参数转换为字符串或将其与其他标记连接起来可能很有用。例如，假设我们要编写一个交互式应用程序，读取用户的输入并执行相应的操作。对于复数，目标函数可能如下：\n1 2 3 4 5 6 7 8 Complex Complex_conjugate(Complex c) { return Complex{ c.real, -c.imag }; } string Complex_polar(Complex c) { return \u0026#34;(\u0026#34; + to_string(sqrt(pow(c.real, 2) + pow(c.imag, 2))) + \u0026#34;,\u0026#34; + to_string(atan(c.imag / c.real)) + \u0026#34;)\u0026#34;; } 应用程序会将用户输入与代表操作的字符串进行比较，调用相应的函数，并打印出结果。这就是常见的模式：\n1 2 if (\u0026lt;input\u0026gt; == \u0026#34;\u0026lt;action\u0026gt;\u0026#34;) cout \u0026lt;\u0026lt; Complex_\u0026lt;action\u0026gt;(\u0026lt;value\u0026gt;) \u0026lt;\u0026lt; endl; 在这里，我们既需要动作的字符串表示法，也需要将 Complex_ 标记与动作标记本身连接起来的能力。我们可以为这种模式定义如下宏：\n1 2 3 #define ACTION(str, name, arg) \\ if (str == #name) \\ cout \u0026lt;\u0026lt; Complex_ ## name(arg) \u0026lt;\u0026lt; endl 标记前的 ## 是字符串化运算符，将标记转换为字符串。Complex_ 和 name 之间的 ## 是标记粘贴操作符，用于连接两边的标记。\n这样，我们就可以编写如下应用代码：\n1 2 3 4 5 6 Complex c1 { 3, 4 }; string s; while (cin \u0026gt;\u0026gt; s) { ACTION(s, conjugate, c1); ACTION(s, polar, c1); } 通过预处理器运行这个程序，我们就能得到想要的结果：\n1 2 3 4 5 6 Complex c1 { 3, 4 }; string s; while (cin \u0026gt;\u0026gt; s) { if (s == \u0026#34;conjugate\u0026#34;) cout \u0026lt;\u0026lt; Complex_conjugate(c1) \u0026lt;\u0026lt; endl; if (s == \u0026#34;polar\u0026#34;) cout \u0026lt;\u0026lt; Complex_polar(c1) \u0026lt;\u0026lt; endl; } The Macro Namespace 使用 CPP 宏的一个缺陷是，它们不包含在任何特定的命名空间中。事实上，只要定义了宏，它就能替换任何符合条件的标识符，无论该标识符位于何处。因此，定义一个宏就相当于让一个特定的标识符充当保留关键字，程序员无法使用。这也是为什么常量通常最好定义为变量，限定为 const 或 constexpr，而不是类似对象的宏的原因之一。\n为避免污染全局命名空间，使用了几种约定。\n第一种是在所有宏的前缀加上定义宏的库所特有的字符，以避免与其他库发生冲突。例如，我们的复数宏可以用 COMPLEX_ 作为前缀，以避免与其他宏或标识符冲突。 第二种策略是在不再需要宏时，使用 #undef 预处理器指令取消对宏的定义。例如，在库代码的末尾，我们可能有如下代码： 1 2 3 4 #undef COMPLEX_OP #undef REAL_OP #undef CONVERT #undef ACTION 这样，标识符就可以在以后的代码中用于其他目的。\nCode Generation 虽然 macros 允许我们使用一种语言提供的宏设施生成代码，但在某些情况下，这种设施无法使用或不足以满足我们的目的。在这种情况下，在外部程序中用同一种语言或另一种语言编写代码生成器可能会比较方便。这种技术也称为 automatic programming。\n例如，R5RS Scheme 规范要求实现提供 car 和 cdr 的组合，最深可达四层。例如，(caar x) 应等同于 (car (car x))，(caddar x) 应等同于 (car (cdr (cdr (car x))))。除了 car 和 cdr 本身外，还需要提供 28 种组合，手工编写既繁琐又容易出错。相反，我们可以定义下面的 Python 脚本来生成一个 Scheme 库文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 import itertools def cadrify(seq): if len(seq): return \u0026#39;(c{0}r {1})\u0026#39;.format(seq[0], cadrify(seq[1:])) return \u0026#39;x\u0026#39; def defun(seq): return \u0026#39;(define (c{0}r x) {1})\u0026#39;.format(\u0026#39;\u0026#39;.join(seq), cadrify(seq)) for i in range(2, 5): for seq in itertools.product((\u0026#39;a\u0026#39;, \u0026#39;d\u0026#39;), repeat=i): print(defun(seq)) cadrify() 函数是一个递归函数，它接收一个序列，如 ('a','d','a')，并使用第一个项目和序列其余部分的递归结果构造一个调用。在本例中，后者是 (cdr (car x))，因此结果是 (car (cdr (car x)))。基本情况是序列为空，只产生 x。\ndefun() 函数接收一个序列，并用它为相应的组合构建定义。它调用 cadrify() 构建正文。对于序列 ('a','d','a')，结果是\n1 (define (cadar x) (car (cdr (car x)))) 最后，循环结束时会产生每个长度的 a 和 d 的所有组合。它使用函数库中的 itertools.product() 函数来获得一个序列，该序列是元组 ('a','d') 的第 i 次幂。对于每个组合，它都会调用 defun() 生成该组合的函数。\n1 2 3 4 5 6 7 8 9 (define (caar x) (car (car x))) (define (cadr x) (car (cdr x))) (define (cdar x) (cdr (car x))) (define (cddr x) (cdr (cdr x))) (define (caaar x) (car (car (car x)))) (define (caadr x) (car (car (cdr x)))) ... (define (cdddar x) (cdr (cdr (cdr (car x))))) (define (cddddr x) (cdr (cdr (cdr (cdr x))))) 我们可以将生成的代码放入标准库中，由 Scheme 解释器加载。\nTemplate Metaprogramming Template metaprogramming 是一种在编译时使用模板生成源代码的技术，然后将源代码与程序的其他代码一起编译。它通常是指利用语言的模板实例化规则进行编译时执行的一种形式。Template metaprogramming 在 C++ 中最为常见，但也有少数其他语言可以使用。\nC++ 中模板元编程的关键是 template specialization，它允许编写专门的定义来实例化带有特定参数的模板。例如，考虑一个包含静态值域的类模板，如果模板参数为 int，该值域为 true，否则为 false。我们可以如下编写通用模板：\n1 2 3 4 template \u0026lt;class T\u0026gt; struct is_int { static const bool value = false; }; 现在我们可以定义当参数为 int 时该模板的特殊化：\n1 2 3 4 template \u0026lt;\u0026gt; struct is_int\u0026lt;int\u0026gt; { static const bool value = true; }; 特化中的模板参数列表包含非特化参数。在上面的例子中，没有任何参数，所以是空的。然后，在模板名称之后，我们提供了实例化的全部参数集，在本例中只有 int。然后，我们提供实例化的其余定义。\n现在，当我们使用模板时，如果模板参数与特化兼容，编译器就会使用特化，否则就会使用通用模板：\n1 2 3 4 5 cout \u0026lt;\u0026lt; is_int\u0026lt;double\u0026gt;::value \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; is_int\u0026lt;int\u0026gt;::value \u0026lt;\u0026lt; endl; // output 0 1 模板特化使我们能够编写以模板参数为条件的代码。与递归实例化相结合，这使得模板实例化具有图灵完备性。模板不对可变变量进行编码，因此模板元编程实际上是函数式编程的一种形式。\nPairs 举个更复杂的例子，让我们定义可在编译时操作的 pairs 和 lists。这些结构中存储的元素将是任意类型。\n在开始定义 pairs 之前，我们先构建一个报告机制，以便在编译时检查结果。我们将在编译器生成的错误信息中包含相关信息：\n1 2 3 4 template \u0026lt;class A, int I\u0026gt; struct report { static_assert(I \u0026lt; 0, \u0026#34;report\u0026#34;); }; 为了简单起见，我们使用了一个 integer 模板参数，当然也可以使用类型对数字进行编码。在实例化 report 模板时，如果模板参数 I 为非负，static_assert 会引发错误。请看下面的内容：\n1 report\u0026lt;int, 5\u0026gt; foo; 编译器会报错，指出是哪个实例导致 static_assert 失败。在 Clang 中，我们会得到类似下面的错误：\n1 2 3 4 5 6 pair.cpp:64:3: error: static_assert failed \u0026#34;report\u0026#34; static_assert(I \u0026lt; 0, \u0026#34;report\u0026#34;); ^ ~~~~~ pair.cpp:67:16: note: in instantiation of template class \u0026#39;report\u0026lt;int, 5\u0026gt;\u0026#39; requested here report\u0026lt;int, 5\u0026gt; foo; 使用 GCC，错误如下：\n1 2 3 4 5 pair.cpp: In instantiation of \u0026#39;struct report\u0026lt;int, 5\u0026gt;\u0026#39;: pair.cpp:67:16: required from here main.cpp:64:3: error: static assertion failed: report static_assert(I \u0026lt; 0, \u0026#34;report\u0026#34;); ^ 两个编译器都报告了相关信息，即报告模板的参数是 int 和 5。\n这样，我们就可以定义 pair 模板如下：\n1 2 3 4 5 template \u0026lt;class First, class Second\u0026gt; struct pair { using car = First; using cdr = Second; }; 在 template 中，我们定义了类型别名 car 和 cdr，用于指代配对的第一项和第二项。因此，pair\u0026lt;int, double\u0026gt;::car 是 int 的别名，而 pair\u0026lt;int, double\u0026gt;::cdr 是 double 的别名。\n我们还可以定义类型别名，以便从数据对中提取第一项和第二项：\n1 2 3 4 template \u0026lt;class Pair\u0026gt; using car_t = typename Pair::car; template \u0026lt;class Pair\u0026gt; using cdr_t = typename Pair::cdr; 在 Pair::car 和 Pair::cdr 之前需要使用 typename 关键字，因为我们使用的是嵌套类型，其外层类型依赖于模板参数。在这种情况下，C++ 无法确定我们命名的是一个类型而不是一个值，因此 typename 关键字明确表示这是一个类型。使用上述别名，car_t\u0026lt;pair\u0026lt;int, double\u0026gt;\u0026gt; 是 int 的别名，而 cdr_t\u0026lt;pair\u0026lt;int, double\u0026gt;\u0026gt; 是 double 的别名。\n为了表示递归列表，我们需要一个空列表的表示方法：\n1 2 struct nil { }; 现在我们可以定义一个模板来判断一个列表是否为空，这个列表可以用空列表 nil 或以 nil 结尾的对序列来表示。我们定义了一个通用模板，然后针对以 nil 作为参数的情况定义了一个特殊化模板：\n1 2 3 4 5 6 7 8 9 template \u0026lt;class List\u0026gt; struct is_empty { static const bool value = false; }; template \u0026lt;\u0026gt; struct is_empty\u0026lt;nil\u0026gt; { static const bool value = true; }; 为了在编译时使用 value，它必须是一个 compile-time constant，我们可以将其设置为 static 和 const，并使用编译时常量对其进行初始化。在 C++14 中，我们还可以定义全局变量模板（global variable templates）来编码 list 的长度：\n1 2 template \u0026lt;class List\u0026gt; const bool is_empty_v = is_empty\u0026lt;List\u0026gt;::value; is_empty_v\u0026lt;nil\u0026gt; 的值为 true，而 is_empty\u0026lt;pair\u0026lt;int, nil\u0026gt;\u0026gt; 的值为 false。这样，我们就可以在编译时确定列表是否为空：\n1 2 3 4 5 6 using x = pair\u0026lt;char, pair\u0026lt;int, pair\u0026lt;double, nil\u0026gt;\u0026gt;\u0026gt;; using y = pair\u0026lt;float, pair\u0026lt;bool, nil\u0026gt;\u0026gt;; using z = nil; report\u0026lt;x, is_empty_v\u0026lt;x\u0026gt;\u0026gt; a; report\u0026lt;y, is_empty_v\u0026lt;y\u0026gt;\u0026gt; b; report\u0026lt;z, is_empty_v\u0026lt;z\u0026gt;\u0026gt; c; 在这里，我们为列表引入了类型别名，作为编译时不可变的变量。然后，我们用类型和是否为空实例化报告。这样，GCC 会给出以下错误信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 pair.cpp: In instantiation of \u0026#39;struct report\u0026lt;pair\u0026lt;char, pair\u0026lt;int, pair\u0026lt;double, nil\u0026gt; \u0026gt; \u0026gt;, 0\u0026gt;\u0026#39;: pair.cpp:82:28: required from here pair.cpp:73:3: error: static assertion failed: report static_assert(I \u0026lt; 0, \u0026#34;report\u0026#34;); ^~~~~~~~~~~~~ pair.cpp: In instantiation of \u0026#39;struct report\u0026lt;pair\u0026lt;float, pair\u0026lt;bool, nil\u0026gt; \u0026gt;, 0\u0026gt;\u0026#39;: pair.cpp:83:28: required from here pair.cpp:73:3: error: static assertion failed: report pair.cpp: In instantiation of \u0026#39;struct report\u0026lt;nil, 1\u0026gt;\u0026#39;: pair.cpp:84:28: required from here pair.cpp:73:3: error: static assertion failed: report 检查报告的整数参数，我们会发现列表 pair\u0026lt;char、pair\u0026lt;int、pair\u0026lt;double、nil\u0026gt;\u0026gt; 和 pair\u0026lt;float、pair\u0026lt;bool、nil\u0026gt;\u0026gt; 不是空的，但列表 nil 是空的。\n我们可以使用递归计算列表的长度：\n1 2 3 4 5 6 7 8 9 10 11 12 template \u0026lt;class List\u0026gt; struct length { static const int value = length\u0026lt;cdr_t\u0026lt;List\u0026gt;\u0026gt;::value + 1; }; template \u0026lt;\u0026gt; struct length\u0026lt;nil\u0026gt; { static const int value = 0; }; template \u0026lt;class List\u0026gt; const int length_v = length\u0026lt;List\u0026gt;::value; 在这里，我们使用的是 length 结构递归实例化的值。由于 value 是通过由编译时常量之间的运算组成的表达式初始化的，因此它也是一个编译时常量。与 is_empty_v 一样，我们定义了一个变量模板 length_v 来对结果进行编码。我们可以计算并报告 x 类型别名的长度：\n1 report\u0026lt;x, length_v\u0026lt;x\u0026gt;\u0026gt; d; 报告的第一个参数是任意的，因为我们只关心第二个参数，所以我们只传递 x 本身。我们得到：\n1 2 3 4 pair.cpp: In instantiation of \u0026#39;struct report\u0026lt;pair\u0026lt;char, pair\u0026lt;int, pair\u0026lt;double, nil\u0026gt; \u0026gt; \u0026gt;, 3\u0026gt;\u0026#39;: pair.cpp:85:26: required from here pair.cpp:73:3: error: static assertion failed: report 相关信息是长度为 3。\n我们还可以定义更复杂的列表操作。例如，我们可以将列表倒转如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 template \u0026lt;class List, class SoFar\u0026gt; struct reverse_helper { using type = typename reverse_helper\u0026lt;cdr_t\u0026lt;List\u0026gt;, pair\u0026lt;car_t\u0026lt;List\u0026gt;, SoFar\u0026gt;\u0026gt;::type; }; template \u0026lt;class SoFar\u0026gt; struct reverse_helper\u0026lt;nil, SoFar\u0026gt; { using type = SoFar; }; template \u0026lt;class List\u0026gt; using reverse_t = typename reverse_helper\u0026lt;List, nil\u0026gt;::type; 在这里，我们使用一个辅助模板来执行反转，其中第一个模板参数是剩余列表，第二个模板参数是到目前为止的反转列表。在每一步中，我们以 pair\u0026lt;car_t\u0026lt;List\u0026gt;, SoFar\u0026gt; 的形式计算新的部分结果，将剩余列表中的第一个项目添加到前一个部分结果的前面。然后 cdr_t\u0026lt;List\u0026gt; 是除去第一个项目的剩余列表。\n递归的基本情况是剩余列表为 nil，在这种情况下，最终结果与部分结果相同。我们使用部分类模板特化来实现这一点，它允许我们只特化类模板的部分参数。在 reverse_helper 中，我们对第一个参数进行了特殊化，这样，任何第一个参数为 nil 的 reverse_helper 实例都将使用特殊化。特化保留了一个模板参数，该参数包含在参数列表中。完整的参数列表会出现在模板名称之后，包括特化和未特化的参数。\nRESOURCES https://eecs390.github.io/notes/metaprogramming.html http://philo.top/2021/03/14/metaprogramming/ ","permalink":"https://WFUing.github.io/posts/tech/language/metaprogramming/","summary":"元编程是编写可在其他程序上运行的计算机程序的技术。诸如编译器和程序分析器之类的系统可以被视为元程序，因为它们将其他程序作为输入。我们将在这里讨论的元编程形式特别关注生成要作为程序一部分包含的代码。从某种意义上说，它们可以被认为是初级编译器。\nMacros and Code Generation macro 是将输入序列转换为某种替换输出序列的规则。这个翻译过程称为 macro expansion，一些语言提供宏作为其规范的一部分。宏设施可以被实现为 preprocessing step，其中宏扩展发生在 lexical and syntactic analysis 之前，或者它可以被合并为 syntax analysis 或 a later translation step。\n使用最广泛的 macro systems 之一是 C 预处理器（CPP），它作为处理程序的第一步被包含在 C 和 C++ 中。预处理器指令以散列符号开头，包括 #include、#define、#if 等。例如，下面定义了一个类似函数的 macro 来交换两个项目：\n1 #define SWAP(a, b) { auto tmp = b; b = a; a = tmp; } 然后，我们可以如下使用宏：\n1 2 3 4 5 6 7 8 9 int main() { int x = 3; int y = 4; SWAP(x, y); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; } // output 4 3 通过向 g++ 传递 -E 标志，可以获得宏扩展的结果：","title":"meta-programming"},{"content":"Introduction 有限状态机 (finite-state machine, FSM) 是一种抽象机器，在任何给定时间内都可以处于有限个状态中的一个状态。FSM 可以根据某些外部输入从一种状态转换到另一种状态，从一种状态转换到另一种状态称为转换。FSM 是由其状态列表、初始状态和每个转换的条件定义的。\n状态是对等待执行转换的系统状态的描述。\nExample 下面是一个简单状态机的直观描述。 这是一个简单的开关模型。\nA simple on/off switch with two states 它由 \u0026ldquo;开 \u0026ldquo;和 \u0026ldquo;关 \u0026ldquo;两种状态组成。因此，这台机器在任何时刻都可以处于这两种状态中的一种。换句话说，状态之间的转换是瞬时的。flick 事件会导致机器在不同状态间转换。 当机器进入 on 状态时，会产生一个副作用。一盏灯被打开。 当机器退出 on 状态时，会产生另一个副作用。一盏灯被关闭。 这个简单的状态机就相当于一个布尔变量，来控制某件事情的 on 与 off。 What is state anyway? 程序状态是程序中所有变量及其在任意时间点上的值的集合 Wikipedia 。\n一个程序或软件组件有五个独立变量，每个变量都可能为真或假，那么理论上它可以处于 $2^5=32$ 种状态中的任何一种。然而，程序经常会出现 invalid 状态，而在传统软件中，变量都会经过仔细检查和处理，以避免出现这些 invalid 状态。\nRelationship with statecharts 理解状态机几乎等同于理解 statecharts。 在许多方面，statecharts是状态机的 \u0026ldquo;大哥\u0026rdquo;，旨在克服状态机的一些局限性。statecharts 本质上是一种状态机，它允许任何状态以分层的方式包含更多的状态机。这是为了克服状态机固有的一些局限性。\nAbstract machine vs run-time 抽象机器本身（如状态机的绘制或代码）与特定抽象机器更具体的运行时执行之间必须作出重要区分。这种区别类似于类（抽象定义）和对象（具体实例化）之间的区别。同样，对于单个抽象机器来说，可能有许多执行，就像任何特定类往往有许多实例一样。\n术语 \u0026ldquo;statechart\u0026rdquo;、\u0026ldquo;state machine \u0026ldquo;和 \u0026ldquo;FSM \u0026ldquo;通常既指抽象形式，也指运行时形式，尽管运行时形式有时带有限定词 \u0026ldquo;run\u0026rdquo; 或 \u0026ldquo;execution\u0026rdquo;，如 \u0026ldquo;state machine execution\u0026rdquo; 或 \u0026ldquo;statetchart run\u0026rdquo;。\nabstract state machine 是一种软件组件，它定义了一组有限的状态：\n有一种状态被定义为 initial state。当机器开始执行时，它会自动进入这种状态。 每个状态都可以定义机器进入或退出该状态时发生的操作。操作通常会产生 side effects。 每个状态都能定义触发转换的 transition。 transition 定义了机器如何对事件做出反应，即退出一种状态并进入另一种状态。 transition 可以定义过渡发生时的 actions。动作通常会产生 side effects。 在运行状态机时，会执行这个抽象状态机。首先，状态机进入initial state。 然后，一旦有事件发生，就会立即传递给状态机。 当事件发生时\n将根据当前状态的转换对事件进行检查 如果某个转场与事件相匹配，该转场就会发生 由于 transition 发生，状态 exited 或 entered，并执行相关操作 机器立即进入新状态，准备处理下一个事件。 Resources Wikipedia defines a finite-state machine statecharts ","permalink":"https://WFUing.github.io/posts/tech/architecture/iot/state-machine/","summary":"有限状态机 (finite-state machine, FSM) 是一种抽象机器，在任何给定时间内都可以处于有限个状态中的一个状态。FSM 可以根据某些外部输入从一种状态转换到另一种状态，从一种状态转换到另一种状态称为转换。","title":"State Machine"},{"content":"简介 ANTLR 是 ANother Tool for Language Recognition 的缩写，是一个功能强大的解析器生成器框架，用于从语法文件中构建语言识别器、编译器和翻译器，语法文件中包含从源语言到目标语言的每个语句所要执行的操作。\n使用编译器设计的概念来定义每种现代编程语言的写作风格。这是一套典型的步骤，首先是 Lexical, Syntactical 和 Semantic Analysis，确定语言的基本编写方式，以便识别。接下来是一系列非常有趣的步骤：中间代码生成、优化和目标代码生成。\n目前的版本为 4.7，它提供了一种方便的、对开发人员友好的方式来定义自己的规则集（又称语法），它由一系列标记和操作组成，这些标记和操作定义了语句在源语言中的书写方式，从而可以正确识别和解析语句。更有趣的是，它还能让用户对代码进行操作，并将其生成目标代码，所有这一切都可以用您选择的语言来实现。\n那么，谁在使用 ANTLR 呢？\n编程语言：Boo、Groovy、Mantra、Nemerle、XRuby 等。 其他工具、框架：Apache Spark、Hibernate、Intellij IDEA、Jazillian、JBoss Rules、Keynote(Apple)、WebLogic（Oracle）等。 The Basics 1 2 def sum(a, b): return a + b 考虑到上面 Python 的例子，这些编译器设计步骤从识别 Python 中编写的每条语句（源代码）的基本单元开始，并将其分解为 a stream of tokens，每个标记都被识别或映射为特定类型，也就是 Lexical Analysis。\nLexical Analysis of the python function yielding a stream of tokens 然后，根据这些标记出现的顺序来确定书面语句的上下文，并通过语义分析构建一棵树（或 Abstract Syntax Tree）来检查其正确性，同时提供使用现有树遍历方法之一进行遍历的能力。\nSyntax tree after Semantic analysis TLDR 概念 Lexer : converts a stream of characters to a stream of tokens. Parser : processes of tokens, possibly creating AST. Abstract Syntax Tree(AST): an intermediate tree representation of the parsed input that is simpler to process than the stream of tokens. Tree Parser: It processes an AST. String Template: a library that supports using templates with placeholders for outputting text (something very specific to ANTLR). ANTLR 是一种 LL parser（Left-to-right, Leftmost derivation），是一种自顶向下的剖析器，适用于无上下文语言的子集。它从左到右解析输入，对句子进行 Leftmost derivation。它简化了许多步骤，使创建语言识别器和解析器变得更容易、更方便。\nSyntax tree after Semantic analysis Example1 下面是我为解析 python 函数而编写的解析器的一个快速示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 grammar PythonParserExample; tokens { INDENT, DEDENT, LINE_BREAK } statement : (single_input)? EOF ; single_input : LINE_BREAK | simple_stmt | complex_stmt (LINE_BREAK)? EOF ; complex_stmt: funcdef; simple_stmt : small_stmt (SEMI_COLON small_stmt)* SEMI_COLON? (LINE_BREAK)? EOF ; stmt : simple_stmt | complex_stmt ; funcdef : ASYNC? DEF name OPEN_PAREN typedargslist? CLOSE_PAREN (ARROW name)? COLON \u0026#39;\\n\u0026#39;? funcbody ; typedargslist : (def_parameters COMMA)? (args (COMMA def_parameters)? ) COMMA? | def_parameters COMMA? ; funcbody : simple_stmt | LINE_BREAK INDENT stmt+ DEDENT ; args : STAR name ; def_parameters : def_parameter (COMMA def_parameter)* ; small_stmt : RETURN expression #return_stmt ; def_parameter : name | STAR ; expression: name op=OPERATOR name ; name: NAME; DEF : D E F; SEMI_COLON : \u0026#39;;\u0026#39;; STAR : \u0026#39;*\u0026#39;; OPERATOR : STAR|\u0026#39;+\u0026#39;|\u0026#39;/\u0026#39;|\u0026#39;**\u0026#39;|\u0026#39;-\u0026#39;; RETURN : R E T U R N; ASYNC : A S Y N C; COMMA : \u0026#39;,\u0026#39;; OPEN_PAREN : \u0026#39;(\u0026#39;; CLOSE_PAREN : \u0026#39;)\u0026#39;; ARROW : \u0026#39;-\u0026gt;\u0026#39;; COLON : \u0026#39;:\u0026#39;; NAME : ID_START ID_CONTINUE*; WS : [ \\t]+ {HandleSpaces();} -\u0026gt; channel(HIDDEN); 它的一个主要优点是，用户可以使用相同的 syntax 进行 lexing 和 parsing。然而，在语法层面上，这里的区别在于命名约定:\n以大写字母开头的规则是 lexer rules 其他的都是 parse rules ANTLR plugin (on Intellij IDEA) output for the above python function parsing 一旦定义完毕，complete ANLTR jar 文件就会提供一个选项，将其生成一组文件，并使用您喜欢的编程语言代码，也就是一个 parser。\n1 java -Xmx500M -cp \u0026lt;path to ANTLR complete JAR\u0026gt; org.antlr.v4.Tool -Dlanguage=\u0026lt;target_language\u0026gt; PythonParserExample.g4 由于我使用 Python3 作为生成解析器的目标，ANTLR 的配置会生成 3 个 python 文件，这些文件可以作为代码翻译过程的一部分，用于将一种语言的源代码转换为另一种语言。\nANTLR plugin (on Intellij IDEA) output for the above python function parsing Setting up an ANTLR Project ANTLR plugin for VSCode 这里使用的设置将是在 VSCode 上创建的 Java-Maven 项目。\nANTLR plugin for VSCode 提供了各种选项（甚至比 Intellij 还多）来调试语法文件，并创建了美观的 parse trees，以便轻松调试用户输入语句的特定配置。\nANTLR plugin (on Intellij IDEA) output for the above python function parsing 要生成这些可视化效果，需要使用 vscode 的 ANTLR 启动配置在调试模式下运行语法文件，并为语法指定输入文件。下面是 VS Code 上 ANTLR 的 launch.json 配置文件：\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;name\u0026#34;: \u0026#34;Debug ANTLR4 grammar\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;antlr-debug\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;input\u0026#34;: \u0026#34;input.txt\u0026#34;, \u0026#34;grammar\u0026#34;: \u0026#34;BooleanExprParser.g4\u0026#34;, \u0026#34;startRule\u0026#34;: \u0026#34;parse\u0026#34;, \u0026#34;printParseTree\u0026#34;: true, \u0026#34;visualParseTree\u0026#34;: true } Grammar 让我们先为解析器创建一个基本语法或 BooleanExpr.g4 文件。\n1 2 3 4 grammar BooleanExpr; @header { package antlrsource; } 请注意 parser file 是如何以 grammar BooleanExpr; 开始的。这可以通过将 Lexer tokens (大写字母表示) 和 parser tokens (所有其他标记) 保存在两个不同的文件中来分解：\n1 2 3 4 lexer grammar BooleanExprLexer; @header { package antlrsource; } 1 2 3 4 parser grammar BooleanExprParser; @header { package antlrsource; } 一个用于 parser，另一个用于 lexer，这样更便于维护。接下来，我们先定义一个头文件和软件包名称，放在生成的解析器类的开头。这将允许我们指定一个包，以便在 Java 代码中导入。\n从 Lexer 开始，我们将 IDENTIFIER 定义为 lexer rule，并提供与之匹配的描述：\n1 2 3 IDENTIFIER : [a-zA-Z_] [a-zA-Z_0-9]* ; Lexer rules 总是以大写字母开头。这些规则是 parser 的基本构件，重点是构建 parser rules 的基础。对正则表达式稍有接触的人来说，这应该有点熟悉。\n这里，A-Z 表示 A 和 Z 之间的字母，而 a-z 表示 a 和 z 之间的字母。同样，0-9 表示数字 0 和 9 之间的数字。由于规则可能包含也可能不包含这些字母的多次出现，因此可以用 (*/+) 运算符作为后缀，表示这些字母出现的频率。这里，* 表示可能完全不出现（0 次或更多次）。这意味着，我们的 IDENTIFIER 规则将匹配大写字母、小写字母（总是以大写/小写字母开头）和整数字符的任意组合，但不匹配空字符。\n一般来说，所有空白都会被词法识别器标记化。因此，您必须在解析器规则中定义空格以及所有可能使用空格的地方。不过，由于我们的源布尔表达式在某些地方不需要对空格敏感，因此我们可以编写一条词法规则来处理这个问题。\n1 WS: [ \\r\\t\\u000C\\n]+ -\u0026gt; skip; 请注意留白标记的定义是如何编写的，以识别一个或多个空格、制表符和换行符，并让 ANTLR 跳过它们。箭头（-\u0026gt;）运算符定义了遇到标记时要执行的操作（本例中为跳过操作）。接下来是为布尔表达式定义标记，其中包括多个运算符和操作数。这包括以下标记：\n1 2 3 4 5 6 7 8 9 10 11 12 13 AND: A N D; OR: O R; NOT: N O T; TRUE: \u0026#39;True\u0026#39;; FALSE: \u0026#39;False\u0026#39;; GT: G T {setText(\u0026#34; \u0026gt; \u0026#34;);}; GE: G E {setText(\u0026#34; \u0026gt;= \u0026#34;);}; LT: L T {setText(\u0026#34; \u0026lt; \u0026#34;);}; LE: L E {setText(\u0026#34; \u0026lt;= \u0026#34;);}; EQ: E Q {setText(\u0026#34; == \u0026#34;);}; LPARENTHESIS: \u0026#39;(\u0026#39;; RPARENTHESIS: \u0026#39;)\u0026#39;; DECIMAL_NUMBER: \u0026#39;-\u0026#39;? [0-9]+ ( \u0026#39;.\u0026#39; [0-9]+)?; Embedding Actions 规则 GT、GE、LT、LE 和 EQ 包含代码块，允许它们在遇到各自的标记时执行某些动作。这样就可以在语法文件中定义某些动作，但需要注意的是，只能定义简单的小动作，而不能定义复杂的代码块。\n如果我们不希望产生构建解析树的开销，我们可以在解析过程中即时计算值或打印内容。另一方面，这意味着要在表达式语法中嵌入任意代码，这就比较困难；我们必须了解这些操作对解析器的影响，以及这些操作的位置。 The Definitive ANTLR 4 Reference\n请注意，每条规则都由用空格隔开的字母组成。这些被称为 fragments。它们的主要目的是减少每个标记的杂乱定义，这基本上需要处理对大小写敏感的用例。这样，用户就不必为识别同一个 token 而写下所有可能的文本组合。其定义如下\n1 2 3 4 fragment A : [aA]; // match either an \u0026#39;a\u0026#39; or \u0026#39;A\u0026#39; fragment B : [bB]; ... fragment Z : [zZ]; 虽然大多数字母数字令牌都可以通过使用片段来创建，但其他令牌则可以通过自定义正则表达式定义或使用引号括起来的纯字符串（如 LPARENTHESIS 和 DECIMAL_NUMBER）来创建。\n而 parser rules（所有其他规则）则以小写字母开头。这些规则的主要目的是在 DSL 中定义布尔表达式的上下文，并帮助从生成的词法标记中构建解析树或抽象语法树。\nBasic Building Blocks 让我们开始定义规则。首先，我们定义根节点（或通常所说的解析节点），它本身只能指向一条规则（此处为 basicBooleanExpression）。首先是一个返回语句，其中包含它应该返回的变量（可选，但在我们的例子中是必需的）及其返回类型。\n这条规则指向另一条名为 basicBooleanExpression 的规则，该规则后跟有 EOF（或文件结束）字符。不包含该字符实质上意味着您正试图解析整个输入内容，而只解析部分输入内容是可以接受的，这将避免任何语法错误。\n1 2 3 4 parse returns[String str] @init {$str=\u0026#34;\u0026#34;;}: basicBooleanExpression {$str=$basicBooleanExpression.str;} EOF; 使用 EOF character 的原因是，如果在解析 basicbooleanExpression 规则时出现语法错误，那么解析规则将尝试恢复语法错误并报告收集到的语法错误，然后继续解析，因为 EOF 是完成规则所必需的，而且解析器尚未到达 EOF。\n由于我们已经定义了语法并将其分成了两个独立的文件，因此我们可以选择在解析器文件中将词法作为定义规则的词汇:\n1 2 3 options { tokenVocab = BooleanExprLexer; } 回到我们的解析器，\n第一条规则或 basicBooleanExpresion 规则定义了三个选项，在我们的 python 目标代码评估中应始终返回一个布尔值。第一种是后两种规则的组合，即两个布尔表达式与一个逻辑和/或运算符的组合； 第二种是另一种三元表达式，即使用比较器（如、小于或 LT）比较两个基本表达式彼此返回的某个值； 最后，第三种是单元表达式（只有一个布尔值，如 True 或 False）。 这些规则由运算符 | 分隔。这意味着，basicBooleanExpression 在识别输入字符串时，可以根据从左到右的文本识别，递归地引用其子规则中的任一规则。\n1 2 3 4 5 basicBooleanExpression returns[String str]: left = basicBooleanExpression op = logicalOperator right = basicBooleanExpression {$str=$left.str +\u0026#34; \u0026#34;+$op.text+\u0026#34; \u0026#34;+$right.str;} # logicalExpression | left = expression op = comparator right = expression {$str=\u0026#34;(\u0026#34;+$left.text +\u0026#34; \u0026#34;+$op.text+\u0026#34; \u0026#34;+$right.text+\u0026#34;)\u0026#34;;} # comparisonExpression | bool {$str=$bool.str;} # booleanExpression; basicBooleanExpression 中的每条规则都分配给一个变量名，如 left、right（表达式中的左右操作数）和 op（操作数的缩写），或者是一条单标记规则。$str 变量用于分配当前表达式解析的结果，并使用规则开头的 [String str] 返回值返回。\n# 用于标记每条规则，使其在目标语言解析器（在我们的例子中是 Java 解析器类）中有专门的监听器方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 lexer grammar BooleanExprLexer; @header { package antlrsource; } AND: A N D; OR: O R; NOT: N O T; TRUE: \u0026#39;True\u0026#39;; FALSE: \u0026#39;False\u0026#39;; GT: G T {setText(\u0026#34; \u0026gt; \u0026#34;);}; GE: G E {setText(\u0026#34; \u0026gt;= \u0026#34;);}; LT: L T {setText(\u0026#34; \u0026lt; \u0026#34;);}; LE: L E {setText(\u0026#34; \u0026lt;= \u0026#34;);}; EQ: E Q {setText(\u0026#34; == \u0026#34;);}; LPARENTHESIS: \u0026#39;(\u0026#39;; RPARENTHESIS: \u0026#39;)\u0026#39;; DECIMAL_NUMBER: \u0026#39;-\u0026#39;? [0-9]+ ( \u0026#39;.\u0026#39; [0-9]+)?; IDENTIFIER: [a-zA-Z_] [a-zA-Z_0-9]*; WS: [ \\r\\t\\u000C\\n]+ -\u0026gt; skip; fragment A : [aA]; // match either an \u0026#39;a\u0026#39; or \u0026#39;A\u0026#39; fragment B : [bB]; fragment C : [cC]; fragment D : [dD]; fragment E : [eE]; fragment F : [fF]; fragment G : [gG]; fragment H : [hH]; fragment I : [iI]; fragment J : [jJ]; fragment K : [kK]; fragment L : [lL]; fragment M : [mM]; fragment N : [nN]; fragment O : [oO]; fragment P : [pP]; fragment Q : [qQ]; fragment R : [rR]; fragment S : [sS]; fragment T : [tT]; fragment U : [uU]; fragment V : [vV]; fragment W : [wW]; fragment X : [xX]; fragment Y : [yY]; fragment Z : [zZ]; BooleanExprLexer.g4\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 parser grammar BooleanExprParser; @header { package antlrsource; } options { tokenVocab = BooleanExprLexer; } parse returns[String str] @init {$str=\u0026#34;\u0026#34;;}: basicBooleanExpression {$str=$basicBooleanExpression.str;} EOF; basicBooleanExpression returns[String str]: left = basicBooleanExpression op = logicalOperator right = basicBooleanExpression\t{$str=$left.str +\u0026#34; \u0026#34;+$op.text+\u0026#34; \u0026#34;+$right.str;} # logicalExpression | left = expression op = comparator right = expression {$str=\u0026#34;(\u0026#34;+$left.text +\u0026#34; \u0026#34;+$op.text+\u0026#34; \u0026#34;+$right.text+\u0026#34;)\u0026#34;;}\t# comparisonExpression | bool\t{$str=$bool.str;}\t# booleanExpression; expression returns[String str]: LPARENTHESIS expression RPARENTHESIS\t# parenthesisExpression | NOT expression\t# notExpression | bool\t# unaryboolExpression | IDENTIFIER\t# identifierExpression | DECIMAL_NUMBER\t# decimalExpression ; comparator returns[String str]: GT | GE | LT | LE | EQ; logicalOperator returns[String str]: AND | OR; bool returns[String str]: TRUE | FALSE; BooleanExprParser.g4\n1 2 a gt b and c gt d a eq b input demo\nMaven Configuration 现在，让我们继续生成解析器文件。这次，我将使用 maven 配置和 VS Code 的 ANTLR 插件来生成这些文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.antlr\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;antlr4-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8-1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;antlr\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;libDirectory\u0026gt;${basedir}/src/main/antlr\u0026lt;/libDirectory\u0026gt; \u0026lt;sourceDirectory\u0026gt;${basedir}/src/main/antlr\u0026lt;/sourceDirectory\u0026gt;\u0026lt;outputDirectory\u0026gt;${basedir}/src/main/java/antlrsource\u0026lt;/outputDirectory\u0026gt; \u0026lt;visitor\u0026gt;false\u0026lt;/visitor\u0026gt; \u0026lt;listener\u0026gt;true\u0026lt;/listener\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;antlr4\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 每个标签都定义了 ANTLR 在生成解析器类时应使用的目录或需要或不需要生成的文件。例如，监听器和访问者标签的定义都是为了根据它们的布尔值生成相应的 java classes/interfaces。\nThe set of target language parser files Traversal Patterns 让我们深入了解 Listener vs Visitor traversal patterns ，并探索 BooleanExprParserBaseListener class 的功能。\nANTLR4 提供了两种遍历语法树的方法：\nListener(default)：listener pattern 是一种事件驱动方法，用于遍历每个解析器规则类型的语法树。为每个解析器规则提供一个包含进入和退出事件方法的接口。 Visitor：这使得用户也可以控制解析树的遍历。解析树中的节点（解析器规则）将使用提供的访问方法明确遍历或访问。 根据使用环境的不同，Listener 和 Visitor 模式各有利弊。\n相同点\n两种实现方式的规则语法规则完全相同。 两种实现方式的解析器输出也完全相同。 不同点\n由于 Listener pattern 依赖于用户来定义其遍历序列，因此它使用调用堆栈来管理这些遍历，这意味着大量输入可能会导致溢出，而在已分配堆上使用堆栈的监听器则不会出现这种问题。 Listener pattern 和 Visitor pattern 的最大区别在于，监听器方法是由 ANTLR 提供的行走器对象独立调用的，而访问者方法必须通过显式访问调用来行走其子节点。如果忘记在节点的子节点上调用访问者方法，就意味着这些子树不会被访问。\n跳回到我们生成的 Listener\nListener Implementation Listener Interface 接口类的实现只针对某些语言，一般来说，implementing class/module 是在目标语言中定义的。请注意，interface 和 implementation 中都定义了根（或解析）节点监听器方法。所有方法都有相应的上下文对象，该对象由生成的解析器类提供。这样就可以在遍历解析树时对该规则的上下文进行操作。\n让我们创建与解析器的第一次 interaction ，并生成一个简单表达式的输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // Creates a lexer for the input string to generate the tokens BooleanExprLexer lexer = new BooleanExprLexer(CharStreams.fromString(\u0026#34;a eq b\u0026#34;)); // Stores the tokens generated by the lexer for the input string CommonTokenStream tokens = new CommonTokenStream(lexer); /** Creates a parser for generation of an Abstract Syntax tree from the stream of tokens to identify context */ BooleanExprParser parser = new BooleanExprParser(tokens); /** Creates a parse tree for generating the output string and manipulation of the parser and lexer tokens in the parse tree. The tree is create considering the parse rule in the grammar as the root node. This tree will be used later for listener. */ ParseTree tree = parser.parse(); /** Convert the root node\u0026#39;s output to it\u0026#39;s rule context and use its attribute for printing the parser\u0026#39;s output string. */ ParseContext context = (ParseContext) tree; System.out.println(context.str); 由于我们已经在语法文件中添加了将基本运算符转换为 python 对应运算符的操作，因此解析器的输出表达式已经是解析形式。例如，一个简单的比较表达式，如 a eq b，将转换为 python 表达式 a == b 。\n现在，我们已经转换了表达式，可以使用监听器文件中的某些更改将其转换为函数，并使用 template 将该表达式替换为 placeholder function text，用于多个类似表达式：\n1 2 def \u0026lt;function_name\u0026gt;(\u0026lt;list_of_parameters\u0026gt;): return a == b parsed expression 可以很容易地替换成上面的表达式。不用担心替换部分，我们稍后会讲到。现在，为了从每个表达式中提取参数列表，我们将添加一个列表，以便在每次触发标识符类型（解析器规则）的输入事件监听器方法时捕获每个标识符名称。\n让我们定义一个字符串列表作为实例变量，在无参数构造函数中对其进行初始化，定义其 getter 方法，并添加一个方法来清除该列表，以便每次表达式解析和替换完成后都能清除该列表。\n1 2 3 4 5 6 public class BooleanExprParserBaseListener implements BooleanExprParserListener { private List\u0026lt;String\u0026gt; identifiersList; public BooleanExprParserBaseListener(){ identifiersList= new ArrayList\u0026lt;\u0026gt;(); } ... 让我们把上下文 getText 方法中的标识符名称添加到我们为 identifierExpression 每次触发输入事件时创建的列表中：\n1 2 3 4 5 6 7 8 9 public void clearIdentifiers() { identifiersList.clear(); } public List\u0026lt;String\u0026gt; getIdentifiersList() { return identifiersList; } @Override public void enterIdentifierExpression(BooleanExprParser.IdentifierExpressionContext ctx) { identifiersList.add(ctx.getText()); } 最后，我们需要在树上遍历，以触发这些事件，从而收集表达式的所有参数。ANTLR 为此提供了 ParseTreeWalker 类。顾名思义，该类允许在走过解析树时同时使用监听器和访问者实现类。让我们使用监听器来遍历上面定义的解析树：\n1 2 3 4 5 BooleanExprParserBaseListener booleanExprBaseListener = new BooleanExprParserBaseListener(); ParseTreeWalker walker = new ParseTreeWalker(); walker.walk(booleanExprBaseListener, tree); List\u0026lt;String\u0026gt; identifiers = booleanExprBaseListener.getIdentifiersList(); booleanExprBaseListener.clearIdentifiers(); 请注意，这里的 walk 方法使用 listener 来监听在解析树上行走时触发的事件。接下来，我们使用 getter 方法获取解析表达式时获取的所有标识符名称列表。\nGenerate Code A gist of what the process looks like so far 将使用上一部分 generated expression 或 the output of intermediate code generation，并将其替换为模板组文件(templating engine 使用的东西)，这样我们就可以将渲染的函数串写入 python 文件。\ntemplating engine 将以我们的目标语言（即 Python）生成实际可用的代码，从而实现代码生成的目标。\n提到 templating engine ，你首先想到的就是 web frameworks。几乎所有的现代 web frameworks 都有一个共同的目标，那就是使用模板引擎生成动态的、业务就绪的网页。每个模板引擎的最终目标都是将获取的输出结果替换为模板文件，以便即时显示给最终用户。\ntemplating engines compared side-by-side\nStringTemplate 我将使用一个名为 StringTemplate 的类似模板引擎。它被广泛用于网页模板化，但也支持用于创建目标语言代码文件的基本模板操作。\n\u0026lt;attribute\u0026gt; 如果存在，则求值为属性的字符串值，否则为空字符串。 例如，在使用 Java 中的 StringTemplate 对象时，\u0026lt;expression\u0026gt; 将以 key expression 表示。因此，如果用户在 expression 键上输入任何值，它就会在模板中被称为 expression 属性。 对于模板内的自定义或用户定义对象，请使用 \u0026lt;attribute.property\u0026gt; ，将属性作为属性查找，然后使用 getProperty() 或 isProperty() 或 hasProperty() 等访问器方法。 \u0026lt;attribute:t1(argument-list)：... :tN(argument-list)\u0026gt; 迭代同一个模板替换的对象列表。从左到右依次应用多个模板。在多值属性上应用模板的结果是另一个多值属性。整个表达式的求值结果是所有模板元素的连接结果 \u0026lt;! comment !\u0026gt; StringTemplate 会忽略已定义的注释。 模板定义看起来就像带有未键入参数的函数定义： templateName(arg1, arg2, ..., argN) ::= \u0026quot;single-line template\u0026quot; templateName(arg1, arg2, ..., argN) ::= \u0026lt;\u0026lt;multi-line template\u0026gt;\u0026gt; templateName(arg1, arg2, ..., argN) ::= \u0026lt;%multi-line template that ignores indentation and newlines%\u0026gt; 下面我们来看看 Python StringTemplateExample.stg 文件的示例：\n1 2 3 4 5 6 7 \u0026lt;! StringTemplateExample.stg !\u0026gt; templateExample(functions) ::= \u0026lt;\u0026lt; \u0026lt;functions :{function | def \u0026lt;function.function_name\u0026gt;(\u0026lt;function.params_list\u0026gt;) return \u0026lt;function.expression\u0026gt; }\u0026gt; \u0026gt;\u0026gt; 请注意，为了保持缩进和两行间隙，我使用了上面基础示例中的第二种模板类型，因为这需要遵循 Python PEP8 的规则，即在 Python 方法之间有两行间隙。下面我们来看看该模板在 Java 中的用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 List\u0026lt;String\u0026gt; lines = reader.lines().collect(Collectors.toList()); String functionName = \u0026#34;generated_function_%1$s\u0026#34;; List\u0026lt;Map\u0026gt; functions = new ArrayList\u0026lt;\u0026gt;(); Map \u0026lt;String,String\u0026gt; function; for (int i = 0; i \u0026lt; lines.size(); i++) { BooleanExprLexer lexer = new BooleanExprLexer(CharStreams.fromString(lines.get(i))); CommonTokenStream tokens = new CommonTokenStream(lexer); BooleanExprParser parser = new BooleanExprParser(tokens); ParseTree tree = parser.parse(); ParseContext context = (ParseContext) tree; System.out.println(context.str); BooleanExprParserBaseListener booleanExprBaseListener = new BooleanExprParserBaseListener(); ParseTreeWalker walker = new ParseTreeWalker(); walker.walk(booleanExprBaseListener, tree); List\u0026lt;String\u0026gt; identifiers = booleanExprBaseListener.getIdentifiersList(); function = new HashMap\u0026lt;\u0026gt;(); function.put(\u0026#34;function_name\u0026#34;, String.format(functionName, i)); function.put(\u0026#34;expression\u0026#34;, context.str); function.put(\u0026#34;params_list\u0026#34;, identifiers.stream().collect(Collectors.joining(\u0026#34;, \u0026#34;))); functions.add(function); booleanExprBaseListener.clearIdentifiers(); } stringTemplateExample.add(\u0026#34;functions\u0026#34;, functions); System.out.println(stringTemplateExample.render()); INPUT\n1 2 a gt b and c gt d a eq b Output\n1 2 3 4 5 def generated_function_0(a, b, c, d) return (a \u0026gt; b) and (c \u0026gt; d) def generated_function_1(a, b) return (a == b) Resources repo : https://github.com/WFUing/BooleanParser https://medium.com/analytics-vidhya/antlr-and-code-generation-a71ead442005 https://medium.com/analytics-vidhya/python-from-expressions-the-antlr-series-part-1-3d7696c3a01c https://medium.com/analytics-vidhya/python-from-expressions-the-antlr-series-part-2-5436ef00bcf https://medium.com/analytics-vidhya/python-from-expressions-the-antlr-series-part-3-7ac541a1d08c ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/antlr-code-generation/","summary":"ANTLR 是 \u003cstrong\u003eAN\u003c/strong\u003eother \u003cstrong\u003eT\u003c/strong\u003eool for \u003cstrong\u003eL\u003c/strong\u003eanguage \u003cstrong\u003eR\u003c/strong\u003eecognition 的缩写，是一个功能强大的解析器生成器框架，用于从语法文件中构建语言识别器、编译器和翻译器，语法文件中包含从源语言到目标语言的每个语句所要执行的操作。","title":"Antlr Code Generation"},{"content":"下面列出了所有类型的编程语言的完整分类列表。编程语言没有严格的分类方案。因此，我们可以将一种语言视为不止一种编程语言的示例。\n让我们一一理解这些编程语言。由于列表很大，因此不可能详细讨论所有这些内容。在这里，我正在用所有这些各种编程语言的示例编写简短的介绍。\n编程语言流行度排名 编译语言 编译语言是一种编程语言，其中我们使用编译器来编译和执行代码。编译器通常是从我们的书面源代码生成机器级代码的翻译器。\nC\nC ++\nC＃\nALGOL\nCobol\nFortran\nJava\nVisual Basic\nSmalltalk\n解释语言 解释语言是一种编程语言，在其中，无需将程序编译为机器语言的指令，我们就可以直接自由地执行指令。解释器逐行执行程序。语言解释为编译后的实现（如平台独立性，动态范围，动态类型等）提供了更多的灵活性。\nPython\nRuby\nPerl\nPascal\nLisp\nBASIC\nAPL\n脚本语言 脚本语言是控制应用程序的编程语言。可以在任何其他应用程序上独立执行的脚本。它们被广泛应用于它们所控制的应用中，并被用于自动化领域。\nPHP\nVBScript\nWindows PowerShell\nF-Script\nBeanShell\nAutoIt\nR\nGame Maker Language\n标记语言 标记语言是一种人工语言，用于对文档进行注释，以便在语法上与文本（可定义文本显示方式的文本）区分开。\nHTML\nXML\nXHTML\nSGML\nCurl\n程序语言 程序（命令式）编程意味着指定程序达到预期状态应采取的步骤。过程不过是一组可以通过过程调用引用的指令。这有助于代码的重用。这种类型的编程使程序结构化并易于跟踪程序流。\nHyperTalk\nGo\nPL/C\nPL/I\nMATLAB\nCurl\nMathematica\nMATLAB\n函数式语言 函数式编程语言将每次计算都定义为数学评估。他们专注于函数的应用。一些函数式编程语言是纯函数式语言，但是许多所谓的函数式语言是不纯净的，包含命令式功能，它们不是纯函数式语言。\nPure Functional\nAgda\nSAC\nSASL\nCuneiform\nCurry\nFuthark\nHaskell\n不纯功能语言 APL\nC++ (since C++11)\nC#\nVB.NET\nCeylon\nKotlin\nLisp\nClojure\nJScript\nPHP\nPython\n基于逻辑的编程语言 逻辑编程是一种编程范例，主要基于形式逻辑。基于逻辑的编程是一组逻辑形式的语句，这些语句表达有关问题域的事实和规则。\nProlog\nROOP\nALF\nAlma-0\nCurry\nFril\nJanus\n面向对象的语言 面向对象的编程（OOP）是基于对象概念的高级编程范例，该对象可能包含字段形式的数据，通常称为属性。在OOP中，计算机程序将相关数据和功能绑定到对象中，并实现对象及其相关过程以创建软件程序。\nScala\nC++\nJava\nPython\nC#\nRuby\nScala\n数据流语言 数据流编程语言依赖于表示数据流。在数据流语言中，数据流从一条指令传递到另一条指令以执行。条件执行会跳转数据，并在过程调用中将数据路由到其他位置。\nAnalytica\nBMDFM\nHartmann pipelines\nLucid\nMax\nOz\nPrograph\nPure Data\n嵌入式语言 主要是动态脚本和编程语言。它也可以用作独立于平台的通用编程语言。嵌入式语言有两种类型：\n服务端 : 服务器端嵌入式语言更加灵活。动态生成附加标记是拥有服务器端代码片段的主要目的。服务该页面时，嵌入在网页中的服务器端是自动丢弃的代码，并由输出替换。 客户端 : 客户端嵌入式语言旨在为网页提供动态特性，从而减少重新连接服务器的开销。 服务器端\nPHP\nVBScript\nSMX\nTcl\nWebDNA\n客户端\nActionScript\nJavaScript\nVBScript\n机器语言 这些语言可由计算中央处理器直接执行。机器语言通常以八进制或十六进制形式的位模式编码。\nARM\nDEC\nx86\nIBM System/360\nMIPS\nSun, Oracle SPARC\n系统语言 这些语言用于内存管理或任务管理中使用的低级语言。与应用软件相比，通常用于系统编程的系统编程语言（例如，用于编写系统软件的语言）通常需要不同的开发方法。\nAda\nNim\nRust\nSwift\nESPOL\n并发语言 这些语言是为了在消息传递语言中并发而构造的。例如，Java显示共享内存并发。\nGo\nJava\nJulia\nclojure\nScala\n范式语言 这些类型的语言支持多种编程语言或编程范式。多范式语言允许使用多种编程风格。没有一种特定的语言能够以最简单或有效的方式解决所有问题，这就是我们使用Multiparadigm语言的原因。\nAda\nAPL\nBETA\nC++\nC#\nCobra\n扩展语言 这些语言用作其他语言的扩展。扩展编程语言嵌入到另一个程序中，并用于在扩展脚本中利用其功能。\nAutoLISP\nBeanShell\nPerl\nPike\nRuby\n迭代语言 这些语言围绕生成器提供或提供生成器。\nAldor\nAlphard\nPHP\nCLU\nCobra\n硬件描述语言 这些编程语言用于电子产品，硬件描述语言或HDL用于描述电子电路或数字逻辑电路的结构，设计和操作。Verilog和VHDL在工业中使用的各种最流行和得到良好支持的HDL品种中。\n模拟电路的HDL：\nVerilog-AMS\nVHDL-AMS\n数字电路的HDL：\nAdvanced Boolean Expression Language(ABEL)\nAltera Hardware Description Language(AHDL)\nBluespec\nLava\nELLA\n视觉语言 在Viual Languages中，用户可以以二维或多种方式指定程序，而不能使用视觉语言中的一维（文本字符串）来指定程序，我们使用图形元素和图形来开发程序。\nAnalytica\nBlockly\nDRAKON\nFabrik\nScratch\nSimulink\nSpreadsheets\n基于列表的语言 列表的语言基于列表数据结构。\n例：\nLisp\nArc\nClojure\nR\nDylan\nJoy\n同步语言 这些编程语言用于对反应系统进行编程。编程反应系统是被中断并立即响应的系统。这些系统中的一些也称为实时系统，并且被广泛使用。\nArgus\nAverest\nEsterel\nLustre\nSignal\n宏语言 这些语言用于将一个源代码文件转换为另一个。宏是一小段文本，可以扩展为更大的文本。宏语言通常用于预处理源代码。预处理程序提供文件包含等功能。\ncpp (the C preprocessor)\nm4\nML/I (general purpose macro processor)\n查询语言 数据库和信息系统中使用这些语言进行查询。\nSQL\nXPath\nAQL\nPQL\nXQuery\n元编程语言 元编程语言是编写程序，该程序编写或操纵其他程序（包括其自身）作为数据，或者完成在编译时在运行时执行的部分工作。\nC++\nCWIC\nCurl\nD\neC\nEmacs Lisp\nElixir\nF#\n基于规则的语言 当被一组数据中的条件激活时，基于规则的语言实例化规则。将选择某些集合，并执行属于那些规则的语句。\nawk\nCLIPS\nConstraint Handling Rules\nDrools\nJess\nOPS5\nProlog\n数值分析语言 在数值分析中，我们分析和实现用于数值解的算法，以解决涉及连续变量的现实数学模型的巨大问题。我们在数值分析中使用以下编程语言。\nMathematica\nMATLAB\nPROSE\nR\n语法处理语言 这些语言可帮助生成词法分析器和解析器以实现上下文无关的语法。\nANTLR\nCoco/R (EBNF with semantics)\nGNU bison (FSF\u0026rsquo;s version of Yacc)\nGNU Flex (FSF version of Lex)\nlex (Lexical Analysis, from Bell Labs)\nParsing expression grammar (PEG)\n非基于英语的语言 有几种编程语言，它们是用英语以外的其他语言开发的。在这种情况下，语言不是障碍。\nChinese BASIC - Chinese\nFjölnir - Icelandic\nLanguage Symbolique d\u0026rsquo;Enseignement - French\nLexico - Spanish\nRapira - Russian\nChaScript-Bengali\nezhil-Tamil\n基于XML的语言 这些语言用于将XML文档转换为人类可读的格式。\nAnt\nC?\nXPath\nXQuery\nXProc\n","permalink":"https://WFUing.github.io/posts/tech/language/programming-language-pool/","summary":"下面列出了所有类型的编程语言的完整分类列表。编程语言没有严格的分类方案。因此，我们可以将一种语言视为不止一种编程语言的示例。\n让我们一一理解这些编程语言。由于列表很大，因此不可能详细讨论所有这些内容。在这里，我正在用所有这些各种编程语言的示例编写简短的介绍。\n编程语言流行度排名 编译语言 编译语言是一种编程语言，其中我们使用编译器来编译和执行代码。编译器通常是从我们的书面源代码生成机器级代码的翻译器。\nC\nC ++\nC＃\nALGOL\nCobol\nFortran\nJava\nVisual Basic\nSmalltalk\n解释语言 解释语言是一种编程语言，在其中，无需将程序编译为机器语言的指令，我们就可以直接自由地执行指令。解释器逐行执行程序。语言解释为编译后的实现（如平台独立性，动态范围，动态类型等）提供了更多的灵活性。\nPython\nRuby\nPerl\nPascal\nLisp\nBASIC\nAPL\n脚本语言 脚本语言是控制应用程序的编程语言。可以在任何其他应用程序上独立执行的脚本。它们被广泛应用于它们所控制的应用中，并被用于自动化领域。\nPHP\nVBScript\nWindows PowerShell\nF-Script\nBeanShell\nAutoIt\nR\nGame Maker Language\n标记语言 标记语言是一种人工语言，用于对文档进行注释，以便在语法上与文本（可定义文本显示方式的文本）区分开。\nHTML\nXML\nXHTML\nSGML\nCurl\n程序语言 程序（命令式）编程意味着指定程序达到预期状态应采取的步骤。过程不过是一组可以通过过程调用引用的指令。这有助于代码的重用。这种类型的编程使程序结构化并易于跟踪程序流。\nHyperTalk\nGo\nPL/C\nPL/I\nMATLAB\nCurl\nMathematica\nMATLAB\n函数式语言 函数式编程语言将每次计算都定义为数学评估。他们专注于函数的应用。一些函数式编程语言是纯函数式语言，但是许多所谓的函数式语言是不纯净的，包含命令式功能，它们不是纯函数式语言。\nPure Functional\nAgda\nSAC\nSASL\nCuneiform\nCurry\nFuthark\nHaskell\n不纯功能语言 APL\nC++ (since C++11)","title":"Programming Language List"},{"content":"Resources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 博客 ZooKeeper源码阅读心得分享+源码基本结构+源码环境搭建 手摸手教你阅读和调试大型开源项目 ZooKeeper ","permalink":"https://WFUing.github.io/posts/tech/architecture/distributed/zookeeper/zookeeper-code/","summary":"Resources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 博客 ZooKeeper源码阅读心得分享+源码基本结构+源码环境搭建 手摸手教你阅读和调试大型开源项目 ZooKeeper ","title":"Zookeeper Code"},{"content":"ZooKeeper 简介 ZooKeeper 是什么 ZooKeeper 是 Apache 的顶级项目。ZooKeeper 为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名服务、配置管理和分布式锁等分布式的基础服务。在解决分布式数据一致性方面，ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。\nZooKeeper 主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是 ZooKeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控存储数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。\n很多大名鼎鼎的框架都基于 ZooKeeper 来实现分布式高可用，如：Dubbo、Kafka 等。\nZooKeeper 官方支持 Java 和 C 的 Client API。ZooKeeper 社区为大多数语言（.NET，python 等）提供非官方 API。\nZooKeeper 的应用场景 配置管理 集群节点可以通过中心源获取启动配置 更简单的部署 分布式集群管理 节点加入/离开 节点的实时状态 命名服务，如：DNS 分布式同步：如锁、栅栏、队列 分布式系统的选主 中心化和高可靠的数据注册 ZooKeeper 的特性 ZooKeeper 具有以下特性：\n顺序一致性 - 所有客户端看到的服务端数据模型都是一致的。从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。具体的实现可见：原子广播 原子性 - 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 实现方式可见：事务 单一视图 - 无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 高性能 - ZooKeeper 将数据全量存储在内存中，所以其性能很高。需要注意的是：由于 ZooKeeper 的所有更新和删除都是基于事务的，因此 ZooKeeper 在读多写少的应用场景中有性能表现较好，如果写操作频繁，性能会大大下滑。 高可用 - ZooKeeper 的高可用是基于副本机制实现的，此外 ZooKeeper 支持故障恢复，可见：选举 Leader ZooKeeper 的设计目标 简单的数据模型：ZooKeeper 的数据模型是一个树形结构的文件系统，树中的节点被称为 znode。 可以构建集群：ZooKeeper 支持集群模式，可以通过伸缩性，来控制集群的吞吐量。需要注意的是：由于 ZooKeeper 采用一主多从架构，所以其写性能是有上限的，比较适合于读多写少的场景。 顺序访问：对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事务请求的先后顺序。 高性能、高可用：ZooKeeper 将数据存全量储在内存中以保持高性能，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是基于事务的，所以其在读多写少的应用场景中有着很高的性能表现。 ZooKeeper 核心概念 服务 Zookeeper 服务是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。\n客户端只会连接一个 ZooKeeper 服务器节点，并维持 TCP 连接。\n数据模型 ZooKeeper 的数据模型是一个树形结构的文件系统。\n树中的节点被称为 znode，其中根节点为 /，每个节点上都会保存自己的数据和节点信息。znode 可以用于存储数据，并且有一个与之相关联的 ACL（详情可见 ACL）。ZooKeeper 的设计目标是实现协调服务，而不是真的作为一个文件存储，因此 znode 存储数据的大小被限制在 1MB 以内。\n数据模型 ZooKeeper 的数据访问具有原子性。其读写操作都是要么全部成功，要么全部失败。\nznode 通过路径被引用。znode 节点路径必须是绝对路径。\nznode 有两种类型：\n临时的（ EPHEMERAL ） - 户端会话结束时，ZooKeeper 就会删除临时的 znode。不允许有子节点。 持久的（PERSISTENT ） - 除非客户端主动执行删除操作，否则 ZooKeeper 不会删除持久的 znode。 节点信息 znode 上有一个顺序标志（ SEQUENTIAL ）。如果在创建 znode 时，设置了顺序标志（ SEQUENTIAL ），那么 ZooKeeper 会使用计数器为 znode 添加一个单调递增的数值，即 zxid。ZooKeeper 正是利用 zxid 实现了严格的顺序访问控制能力。\n每个 znode 节点在存储数据的同时，都会维护一个叫做 Stat 的数据结构，里面存储了关于该节点的全部状态信息。如下：\n状态属性 说明 czxid 数据节点创建时的事务 ID ctime 数据节点创建时的时间 mzxid 数据节点最后一次更新时的事务 ID mtime 数据节点最后一次更新时的时间 pzxid 数据节点的子节点最后一次被修改时的事务 ID cversion 子节点的更改次数 version 节点数据的更改次数 aversion 节点的 ACL 的更改次数 ephemeralOwner 如果节点是临时节点，则表示创建该节点的会话的 SessionID；如果节点是持久节点，则该属性值为 0 dataLength 数据内容的长度 numChildren 数据节点当前的子节点个数 集群角色 Zookeeper 集群是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。此外，每个服务器节点承担如下三种角色中的一种：\nLeader - 它负责 发起并维护与各 Follwer 及 Observer 间的心跳。所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader。 Follower - 它会响应 Leader 的心跳。Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，并且负责在 Leader 处理写请求时对请求进行投票。一个 Zookeeper 集群可能同时存在多个 Follower。 Observer - 角色与 Follower 类似，但是无投票权。 客户端可以从任意 ZooKeeper 服务器节点读取数据，但只能通过 Leader 服务写数据并需要半数以上 Follower 的 ACK，才算写入成功。记住这个重要的知识点，下文会详细讲述。\nACL ZooKeeper 采用 ACL（Access Control Lists）策略来进行权限控制。\n每个 znode 创建时都会带有一个 ACL 列表，用于决定谁可以对它执行何种操作。\nACL 依赖于 ZooKeeper 的客户端认证机制。ZooKeeper 提供了以下几种认证方式：\ndigest - 用户名和密码 来识别客户端 sasl - 通过 kerberos 来识别客户端 ip - 通过 IP 来识别客户端 ZooKeeper 定义了如下五种权限：\nCREATE - 允许创建子节点； READ - 允许从节点获取数据并列出其子节点； WRITE - 允许为节点设置数据； DELETE - 允许删除子节点； ADMIN - 允许为节点设置权限。 ZooKeeper 工作原理 读操作 Leader/Follower/Observer 都可直接处理读请求，从本地内存中读取数据并返回给客户端即可。\n由于处理读请求不需要服务器之间的交互，Follower/Observer 越多，整体系统的读请求吞吐量越大，也即读性能越好。\n写操作 所有的写请求实际上都要交给 Leader 处理。Leader 将写请求以事务形式发给所有 Follower 并等待 ACK，一旦收到半数以上 Follower 的 ACK，即认为写操作成功。\n写 Leader 由上图可见，通过 Leader 进行写操作，主要分为五步：\n客户端向 Leader 发起写请求 Leader 将写请求以事务 Proposal 的形式发给所有 Follower 并等待 ACK Follower 收到 Leader 的事务 Proposal 后返回 ACK Leader 得到过半数的 ACK（Leader 对自己默认有一个 ACK）后向所有的 Follower 和 Observer 发送 Commmit Leader 将处理结果返回给客户端 注意\nLeader 不需要得到 Observer 的 ACK，即 Observer 无投票权 Leader 不需要得到所有 Follower 的 ACK，只要收到过半的 ACK 即可，同时 Leader 本身对自己有一个 ACK。上图中有 4 个 Follower，只需其中两个返回 ACK 即可，因为 $$\\frac{2+1}{4+1} \u0026gt; \\frac{1}{2}$$ Observer 虽然无投票权，但仍须同步 Leader 的数据从而在处理读请求时可以返回尽可能新的数据 写 Follower/Observer Follower/Observer 均可接受写请求，但不能直接处理，而需要将写请求转发给 Leader 处理。 除了多了一步请求转发，其它流程与直接写 Leader 无任何区别。 事务 对于来自客户端的每个更新请求，ZooKeeper 具备严格的顺序访问控制能力。\n为了保证事务的顺序一致性，ZooKeeper 采用了递增的事务 id 号（zxid）来标识事务。\nLeader 服务会为每一个 Follower 服务器分配一个单独的队列，然后将事务 Proposal 依次放入队列中，并根据 FIFO(先进先出) 的策略进行消息发送。Follower 服务在接收到 Proposal 后，会将其以事务日志的形式写入本地磁盘中，并在写入成功后反馈给 Leader 一个 Ack 响应。当 Leader 接收到超过半数 Follower 的 Ack 响应后，就会广播一个 Commit 消息给所有的 Follower 以通知其进行事务提交，之后 Leader 自身也会完成对事务的提交。而每一个 Follower 则在接收到 Commit 消息后，完成事务的提交。\n所有的提议（proposal）都在被提出的时候加上了 zxid。zxid 是一个 64 位的数字，它的高 32 位是 epoch 用来标识 Leader 关系是否改变，每次一个 Leader 被选出来，它都会有一个新的 epoch，标识当前属于那个 leader 的统治时期。低 32 位用于递增计数。\n详细过程如下：\nLeader 等待 Server 连接； Follower 连接 Leader，将最大的 zxid 发送给 Leader； Leader 根据 Follower 的 zxid 确定同步点； 完成同步后通知 follower 已经成为 uptodate 状态； Follower 收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了。 观察 ZooKeeper 允许客户端监听它关心的 znode，当 znode 状态发生变化（数据变化、子节点增减变化）时，ZooKeeper 服务会通知客户端。\n客户端和服务端保持连接一般有两种形式：\n客户端向服务端不断轮询 服务端向客户端推送状态 Zookeeper 的选择是服务端主动推送状态，也就是观察机制（ Watch ）。\nZooKeeper 的观察机制允许用户在指定节点上针对感兴趣的事件注册监听，当事件发生时，监听器会被触发，并将事件信息推送到客户端。\n监听器实时触发 监听器总是有序的 创建新的 znode 数据前，客户端就能收到监听事件。 客户端使用 getData 等接口获取 znode 状态时传入了一个用于处理节点变更的回调，那么服务端就会主动向客户端推送节点的变更：\n1 public byte[] getData(final String path, Watcher watcher, Stat stat) 从这个方法中传入的 Watcher 对象实现了相应的 process 方法，每次对应节点出现了状态的改变，WatchManager 都会通过以下的方式调用传入 Watcher 的方法：\n1 2 3 4 5 6 7 8 9 10 11 Set\u0026lt;Watcher\u0026gt; triggerWatch(String path, EventType type, Set\u0026lt;Watcher\u0026gt; supress) { WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); Set\u0026lt;Watcher\u0026gt; watchers; synchronized (this) { watchers = watchTable.remove(path); } for (Watcher w : watchers) { w.process(e); } return watchers; } Zookeeper 中的所有数据其实都是由一个名为 DataTree 的数据结构管理的，所有的读写数据的请求最终都会改变这颗树的内容，在发出读请求时可能会传入 Watcher 注册一个回调函数，而写请求就可能会触发相应的回调，由 WatchManager 通知客户端数据的变化。\n通知机制的实现其实还是比较简单的，通过读请求设置 Watcher 监听事件，写请求在触发事件时就能将通知发送给指定的客户端。\n会话 ZooKeeper 客户端通过 TCP 长连接连接到 ZooKeeper 服务集群。会话 (Session) 从第一次连接开始就已经建立，之后通过心跳检测机制来保持有效的会话状态。通过这个连接，客户端可以发送请求并接收响应，同时也可以接收到 Watch 事件的通知。\n每个 ZooKeeper 客户端配置中都配置了 ZooKeeper 服务器集群列表。启动时，客户端会遍历列表去尝试建立连接。如果失败，它会尝试连接下一个服务器，依次类推。\n一旦一台客户端与一台服务器建立连接，这台服务器会为这个客户端创建一个新的会话。每个会话都会有一个超时时间，若服务器在超时时间内没有收到任何请求，则相应会话被视为过期。一旦会话过期，就无法再重新打开，且任何与该会话相关的临时 znode 都会被删除。\n通常来说，会话应该长期存在，而这需要由客户端来保证。客户端可以通过心跳方式（ping）来保持会话不过期。\nZooKeeper 的会话具有四个属性：\nsessionID - 会话 ID，唯一标识一个会话，每次客户端创建新的会话时，Zookeeper 都会为其分配一个全局唯一的 sessionID。 TimeOut - 会话超时时间，客户端在构造 Zookeeper 实例时，会配置 sessionTimeout 参数用于指定会话的超时时间，Zookeeper 客户端向服务端发送这个超时时间后，服务端会根据自己的超时时间限制最终确定会话的超时时间。 TickTime - 下次会话超时时间点，为了便于 Zookeeper 对会话实行分桶策略管理，同时为了高效低耗地实现会话的超时检查与清理，Zookeeper 会为每个会话标记一个下次会话超时时间点，其值大致等于当前时间加上 TimeOut。 isClosing - 标记一个会话是否已经被关闭，当服务端检测到会话已经超时失效时，会将该会话的 isClosing 标记为已关闭，这样就能确保不再处理来自该会话的心情求了。 Zookeeper 的会话管理主要是通过 SessionTracker 来负责，其采用了分桶策略（将类似的会话放在同一区块中进行管理）进行管理，以便 Zookeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。\nZAB 协议 ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。ZAB 协议不是 Paxos 算法，只是比较类似，二者在操作上并不相同。Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。而 ZooKeeper 需要确保操作的顺序性。\nZAB 协议是 Zookeeper 专门设计的一种支持崩溃恢复的原子广播协议。\nZAB 协议是 ZooKeeper 的数据一致性和高可用解决方案。\nZAB 协议定义了两个可以无限循环的流程：\n选举 Leader - 用于故障恢复，从而保证高可用。 原子广播 - 用于主从同步，从而保证数据一致性。 选举 Leader ZooKeeper 的故障恢复\nZooKeeper 集群采用一主（称为 Leader）多从（称为 Follower）模式，主从节点通过副本机制保证数据一致。\n如果 Follower 节点挂了 - ZooKeeper 集群中的每个节点都会单独在内存中维护自身的状态，并且各节点之间都保持着通讯，只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务。 如果 Leader 节点挂了 - 如果 Leader 节点挂了，系统就不能正常工作了。此时，需要通过 ZAB 协议的选举 Leader 机制来进行故障恢复。 ZAB 协议的选举 Leader 机制简单来说，就是：基于过半选举机制产生新的 Leader，之后其他机器将从新的 Leader 上同步状态，当有过半机器完成状态同步后，就退出选举 Leader 模式，进入原子广播模式。\n术语 myid - 每个 Zookeeper 服务器，都需要在数据文件夹下创建一个名为 myid 的文件，该文件包含整个 Zookeeper 集群唯一的 ID（整数）。 zxid - 类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal ID。为了保证顺序性，该 zxid 必须单调递增。因此 Zookeeper 使用一个 64 位的数来表示，高 32 位是 Leader 的 epoch，从 1 开始，每次选出新的 Leader，epoch 加一。低 32 位为该 epoch 内的序号，每次 epoch 变化，都将低 32 位的序号重置。这样保证了 zxid 的全局递增性。 服务器状态 LOOKING - 不确定 Leader 状态。该状态下的服务器认为当前集群中没有 Leader，会发起 Leader 选举 FOLLOWING - 跟随者状态。表明当前服务器角色是 Follower，并且它知道 Leader 是谁 LEADING - 领导者状态。表明当前服务器角色是 Leader，它会维护与 Follower 间的心跳 OBSERVING - 观察者状态。表明当前服务器角色是 Observer，与 Folower 唯一的不同在于不参与选举，也不参与集群写操作时的投票 选票数据结构 每个服务器在进行领导选举时，会发送如下关键信息\nlogicClock - 每个服务器会维护一个自增的整数，名为 logicClock，它表示这是该服务器发起的第多少轮投票 state - 当前服务器的状态 self_id - 当前服务器的 myid self_zxid - 当前服务器上所保存的数据的最大 zxid vote_id - 被推举的服务器的 myid vote_zxid - 被推举的服务器上所保存的数据的最大 zxid 投票流程 自增选举轮次 - Zookeeper 规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作。 初始化选票 - 每个服务器在广播自己的选票前，会将自己的投票箱清空。该投票箱记录了所收到的选票。例：服务器 2 投票给服务器 3，服务器 3 投票给服务器 1，则服务器 1 的投票箱为(2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。 发送初始化选票 - 每个服务器最开始都是通过广播把票投给自己。 接收外部投票 - 服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。 判断选举轮次 - 收到外部投票后，首先会根据投票信息中所包含的 logicClock 来进行不同处理 外部投票的 logicClock 大于自己的 logicClock。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的 logicClock 更新为收到的 logicClock，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。 外部投票的 logicClock 小于自己的 logicClock。当前服务器直接忽略该投票，继续处理下一个投票。 外部投票的 logickClock 与自己的相等。当时进行选票 PK。 选票 PK - 选票 PK 是基于(self_id, self_zxid) 与 (vote_id, vote_zxid) 的对比 外部投票的 logicClock 大于自己的 logicClock，则将自己的 logicClock 及自己的选票的 logicClock 变更为收到的 logicClock 若 logicClock 一致，则对比二者的 vote_zxid，若外部投票的 vote_zxid 比较大，则将自己的票中的 vote_zxid 与 vote_myid 更新为收到的票中的 vote_zxid 与 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖 若二者 vote_zxid 一致，则比较二者的 vote_myid，若外部投票的 vote_myid 比较大，则将自己的票中的 vote_myid 更新为收到的票中的 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱 统计选票 - 如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。 更新服务器状态 - 投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为 LEADING，否则将自己的状态更新为 FOLLOWING 通过以上流程分析，我们不难看出：要使 Leader 获得多数 Server 的支持，则 ZooKeeper 集群节点数必须是奇数。且存活的节点数目不得少于 N + 1 。\n每个 Server 启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。\n原子广播（Atomic Broadcast） ZooKeeper 通过副本机制来实现高可用。\n那么，ZooKeeper 是如何实现副本机制的呢？答案是：ZAB 协议的原子广播。\nZAB 协议的原子广播要求：\n所有的写请求都会被转发给 Leader，Leader 会以原子广播的方式通知 Follow。当半数以上的 Follow 已经更新状态持久化后，Leader 才会提交这个更新，然后客户端才会收到一个更新成功的响应。这有些类似数据库中的两阶段提交协议。\n在整个消息的广播过程中，Leader 服务器会每个事务请求生成对应的 Proposal，并为其分配一个全局唯一的递增的事务 ID(ZXID)，之后再对其进行广播。\nZAB 是通过一切以领导者为准的强领导者模型和严格按照顺序提交日志，来实现操作的顺序性的，这一点和 Raft 是一样的。\nZooKeeper 应用 ZooKeeper 可以用于发布/订阅、负载均衡、命令服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能 。\n命名服务 在分布式系统中，通常需要一个全局唯一的名字，如生成全局唯一的订单号等，ZooKeeper 可以通过顺序节点的特性来生成全局唯一 ID，从而可以对分布式系统提供命名服务。\n配置管理 利用 ZooKeeper 的观察机制，可以将其作为一个高可用的配置存储器，允许分布式应用的参与者检索和更新配置文件。\n分布式锁 可以通过 ZooKeeper 的临时节点和 Watcher 机制来实现分布式排它锁。\n举例来说，有一个分布式系统，有三个节点 A、B、C，试图通过 ZooKeeper 获取分布式锁。\n（1）访问 /lock （这个目录路径由程序自己决定），创建 带序列号的临时节点（EPHEMERAL） 。\n（2）每个节点尝试获取锁时，拿到 /locks节点下的所有子节点（id_0000,id_0001,id_0002），判断自己创建的节点是不是序列号最小的\n如果序列号是最小的，则成功获取到锁。 释放锁：执行完操作后，把创建的节点给删掉。 如果不是，则监听比自己要小 1 的节点变化。 （3）释放锁，即删除自己创建的节点。\n图中，NodeA 删除自己创建的节点 id_0000，NodeB 监听到变化，发现自己的节点已经是最小节点，即可获取到锁。\n集群管理 ZooKeeper 还能解决大多数分布式系统中的问题：\n如可以通过创建临时节点来建立心跳检测机制。如果分布式系统的某个服务节点宕机了，则其持有的会话会超时，此时该临时节点会被删除，相应的监听事件就会被触发。 分布式系统的每个服务节点还可以将自己的节点状态写入临时节点，从而完成状态报告或节点工作进度汇报。 通过数据的订阅和发布功能，ZooKeeper 还能对分布式系统进行模块的解耦和任务的调度。 通过监听机制，还能对分布式系统的服务节点进行动态上下线，从而实现服务的动态扩容。 选举 Leader 节点 分布式系统一个重要的模式就是主从模式 (Master/Salves)，ZooKeeper 可以用于该模式下的 Matser 选举。可以让所有服务节点去竞争性地创建同一个 ZNode，由于 ZooKeeper 不能有路径相同的 ZNode，必然只有一个服务节点能够创建成功，这样该服务节点就可以成为 Master 节点。\n队列管理 ZooKeeper 可以处理两种类型的队列：\n当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队列。 队列按照 FIFO 方式进行入队和出队操作，例如实现生产者和消费者模型。 同步队列用 ZooKeeper 实现的实现思路如下：\n创建一个父目录 /synchronizing，每个成员都监控标志（Set Watch）位目录 /synchronizing/start 是否存在，然后每个成员都加入这个队列，加入队列的方式就是创建 /synchronizing/member_i 的临时目录节点，然后每个成员获取 /synchronizing 目录的所有目录节点，也就是 member_i。判断 i 的值是否已经是成员的个数，如果小于成员个数等待 /synchronizing/start 的出现，如果已经相等就创建 /synchronizing/start。\nZooKeeper 的缺点 ZooKeeper 的监听是一次性的。\nZooKeeper 不是为高可用性设计的 生产环境中常常需要通过多机房部署来容灾。出于成本考虑，一般多机房都是同时提供服务的，即一个机房撑不住所有流量。ZooKeeper 集群只能有一个 Leader，一旦机房之间连接出现故障，那么只有 Leader 所在的机房可以正常工作，其他机房只能停摆。于是所有流量集中到 Leader 所在的机房，由于处理不过来而导致崩溃。\n即使是在同一个机房里面，由于网段的不同，在调整机房交换机的时候偶尔也会发生网段隔离的情况。实际上机房每个月基本上都会发生短暂的网络隔离之类的子网段调整。在那个时刻 ZooKeeper 将处于不可用状态。如果业务系统重度依赖 ZooKeeper（比如用 Dubbo 作为 RPC，且使用 ZooKeeper 作为注册中心），则系统的可用性将非常脆弱。\n由于 ZooKeeper 对于网络隔离的极度敏感，导致 ZooKeeper 对于网络的任何风吹草动都会做出激烈反应。这使得 ZooKeeper 的不可用时间比较多。我们不能让 ZooKeeper 的不可用，变成系统的不可用。\nZooKeeper 的选举过程速度很慢 互联网环境中，网络不稳定几乎是必然的，而 ZooKeeper 网络隔离非常敏感。一旦出现网络隔离，zookeeper 就要发起选举流程。\nZooKeeper 的选举流程通常耗时 30 到 120 秒，期间 ZooKeeper 由于没有 Leader，都是不可用的。\n对于网络里面偶尔出现的，比如半秒一秒的网络隔离，ZooKeeper 会由于选举过程，而把不可用时间放大几十倍。\nZooKeeper 的性能是有限的 典型的 ZooKeeper 的 TPS 大概是一万多，无法支撑每天动辄几十亿次的调用。因此，每次请求都去 ZooKeeper 获取业务系统信息是不可能的。\n为此，ZooKeeper 的 client 必须自己缓存业务系统的信息。这就导致 ZooKeeper 提供的强一致性实际上是做不到的。如果我们需要强一致性，还需要其他机制来进行保障：比如用自动化脚本把业务系统的 old master 给 kill 掉，但是这可能会引发很多其他问题。\nZooKeeper 无法进行有效的权限控制 ZooKeeper 的权限控制非常弱。在大型的复杂系统里面，使用 ZooKeeper 必须自己再额外的开发一套权限控制系统，通过那套权限控制系统再访问 ZooKeeper。\n额外的权限控制系统不但增加了系统复杂性和维护成本，而且降低了系统的总体性能。\n即使有了 ZooKeeper 也很难避免业务系统的数据不一致 由于 ZooKeeper 的性能限制，我们无法让每次系统内部调用都走 ZooKeeper，因此总有某些时刻，业务系统会存在两份数据（业务系统 client 那边缓存的业务系统信息是定时从 ZooKeeper 更新的，因此会有更新不同步的问题）。\n如果要保持数据的强一致性，唯一的方法是先 kill 掉当前 Leader，再在 ZooKeeper 上更新 Leader 信息。是否要 kill 掉当前 Leader 这个问题上，程序是无法完全自动决定的（因为网络隔离的时候 ZooKeeper 已经不可用了，自动脚本没有全局信息，不管怎么做都可能是错的，什么都不做也可能是错的。当网络故障的时候，只有运维人员才有全局信息，程序是无法得知其他机房的情况的）。因此系统无法自动的保障数据一致性，必须要人工介入。而人工介入的典型时间是半个小时以上，我们不能让系统这么长时间不可用。因此我们必须在某个方向上进行妥协，最常见的妥协方式是放弃强一致性，而接受最终一致性。\n如果我们需要人工介入才能保证可靠的强一致性，那么 ZooKeeper 的价值就大打折扣。\nResources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 书籍 《Hadoop 权威指南（第四版）》 《从 Paxos 到 Zookeeper 分布式一致性原理与实践》 文章 分布式服务框架 ZooKeeper \u0026ndash; 管理分布式环境中的数据 ZooKeeper 的功能以及工作原理 ZooKeeper 简介及核心概念 详解分布式协调服务 ZooKeeper 深入浅出 Zookeeper（一） Zookeeper 架构及 FastLeaderElection 机制 Introduction to Apache ZooKeeper Zookeeper 的优缺点 ","permalink":"https://WFUing.github.io/posts/tech/architecture/distributed/zookeeper/zookeeper-theory/","summary":"ZooKeeper 简介 ZooKeeper 是什么 ZooKeeper 是 Apache 的顶级项目。ZooKeeper 为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名服务、配置管理和分布式锁等分布式的基础服务。在解决分布式数据一致性方面，ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。\nZooKeeper 主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是 ZooKeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控存储数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。\n很多大名鼎鼎的框架都基于 ZooKeeper 来实现分布式高可用，如：Dubbo、Kafka 等。\nZooKeeper 官方支持 Java 和 C 的 Client API。ZooKeeper 社区为大多数语言（.NET，python 等）提供非官方 API。\nZooKeeper 的应用场景 配置管理 集群节点可以通过中心源获取启动配置 更简单的部署 分布式集群管理 节点加入/离开 节点的实时状态 命名服务，如：DNS 分布式同步：如锁、栅栏、队列 分布式系统的选主 中心化和高可靠的数据注册 ZooKeeper 的特性 ZooKeeper 具有以下特性：\n顺序一致性 - 所有客户端看到的服务端数据模型都是一致的。从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。具体的实现可见：原子广播 原子性 - 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 实现方式可见：事务 单一视图 - 无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 高性能 - ZooKeeper 将数据全量存储在内存中，所以其性能很高。需要注意的是：由于 ZooKeeper 的所有更新和删除都是基于事务的，因此 ZooKeeper 在读多写少的应用场景中有性能表现较好，如果写操作频繁，性能会大大下滑。 高可用 - ZooKeeper 的高可用是基于副本机制实现的，此外 ZooKeeper 支持故障恢复，可见：选举 Leader ZooKeeper 的设计目标 简单的数据模型：ZooKeeper 的数据模型是一个树形结构的文件系统，树中的节点被称为 znode。 可以构建集群：ZooKeeper 支持集群模式，可以通过伸缩性，来控制集群的吞吐量。需要注意的是：由于 ZooKeeper 采用一主多从架构，所以其写性能是有上限的，比较适合于读多写少的场景。 顺序访问：对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事务请求的先后顺序。 高性能、高可用：ZooKeeper 将数据存全量储在内存中以保持高性能，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是基于事务的，所以其在读多写少的应用场景中有着很高的性能表现。 ZooKeeper 核心概念 服务 Zookeeper 服务是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。","title":"Zookeeper 原理"},{"content":"什么是分布式系统 将硬件或软件组件(服务)分布在不同的网络计算机上，并且通过消息传递进行通信和协调。\n特点\n分布性 对等性 平等: 无主从之分 独立: 拥有自己的CPU和内存，独立处理数据 并发性 外部: 承载多个客户端的并发访问 内部: 作业(Job)被分解成多个任务(Task)，并发运行在不同的节点上 故障独立性 部分节点出现故障不影响整个系统的正常使用 split-brain 问题 对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房。正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，但机房之间无法通信。如果不考虑过半机制，那么就会出现每个机房内部都将选出一个Leader。这就相当于原本一个集群，被分成了两个集群，出现了两个大脑，这就是脑裂。\n脑裂 对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。\nCAP定理 C(Consistency，一致性) 含义: 同一时刻，数据在不同节点的多个副本是否具有完全相同的值 类型 强一致性: 数据更新完成后，同一时刻，不同的读操作都能获得最新的值 弱一致性: 数据更新完成后，同一时刻，不同的读操作不一定都能获得最新的值，也无法保证多长时间之后可以获得最新的值 A(Availability，可用性) 含义: 对于每一次请求，系统是否都能在有限(指定)的时间内做出响应 P(Partition Tolerance，分区容错性) 含义: 当发生网络分区时，系统仍能对外提供满足 一致性C 和 可用性A 的服务 CAP定理 分布式系统在同一时间片段内，不可能同时满足一致性C、可用性A和分区容错性P，最多只能满足其中的两项。\n满足意味着100%， 满足C -\u0026gt; 满足强一致性 满足A -\u0026gt; 满足绝对可用性 对分布式系统而言，网络分区无法避免，满足P是前提条件，所以不可能选择CA架构，只能选择CP或AP架构 例如: 发生网络分区时，某个节点正在进行写操作 如果为了保证C，必须禁止其他节点的读写操作，那就与A冲突了 如果为了保证A，其他节点正常读写，那就与C冲突了 选择CP或AP架构，关键在业务场景 例如: 对于必须确保强一致性的银行业务，只能选择CP BASE理论 BA(Basically Availability，基本可用性) 当系统发生故障时，在确保核心功能和指标有效的提前下，允许损失部分可用性，包括响应时间上的损失、非核心功能上的损失等 S(Soft State，软状态) 允许数据存在中间状态(暂时未更新)，且该状态不会影响整体可用性 允许不同节点上的数据副本的同步过程存在一定延时 EC(Eventually Consistency，最终一致性) 分布在不同节点上的数据副本，在经过一定时间的同步后，最终达到一致状态 例如: Zookeeper、HDFS QJM写事务的过半策略 弱一致性的升级版 BASE定理 分布式系统在满足分区容错性P的同时，允许数据软状态S的存在，并实现基本可用性BA和最终一致性EC\n在满足P的前提下，对CAP中的强一致性A和绝对可用性C进行适度妥协 A -\u0026gt; BA ，C -\u0026gt; EC 通过容忍部分数据的暂时不一致(软状态)，即牺牲数据的强一致性(确保最终一致性)，以确保系统的核心功能和指标有效(基本可用) CAP定理的延伸，CAP的 C+P / A+P -\u0026gt; BASE的EC+BA+P 对大规模互联网系统分布式实践的总结 ","permalink":"https://WFUing.github.io/posts/tech/architecture/distributed/overview/","summary":"什么是分布式系统 将硬件或软件组件(服务)分布在不同的网络计算机上，并且通过消息传递进行通信和协调。\n特点\n分布性 对等性 平等: 无主从之分 独立: 拥有自己的CPU和内存，独立处理数据 并发性 外部: 承载多个客户端的并发访问 内部: 作业(Job)被分解成多个任务(Task)，并发运行在不同的节点上 故障独立性 部分节点出现故障不影响整个系统的正常使用 split-brain 问题 对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房。正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，但机房之间无法通信。如果不考虑过半机制，那么就会出现每个机房内部都将选出一个Leader。这就相当于原本一个集群，被分成了两个集群，出现了两个大脑，这就是脑裂。\n脑裂 对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。\nCAP定理 C(Consistency，一致性) 含义: 同一时刻，数据在不同节点的多个副本是否具有完全相同的值 类型 强一致性: 数据更新完成后，同一时刻，不同的读操作都能获得最新的值 弱一致性: 数据更新完成后，同一时刻，不同的读操作不一定都能获得最新的值，也无法保证多长时间之后可以获得最新的值 A(Availability，可用性) 含义: 对于每一次请求，系统是否都能在有限(指定)的时间内做出响应 P(Partition Tolerance，分区容错性) 含义: 当发生网络分区时，系统仍能对外提供满足 一致性C 和 可用性A 的服务 CAP定理 分布式系统在同一时间片段内，不可能同时满足一致性C、可用性A和分区容错性P，最多只能满足其中的两项。\n满足意味着100%， 满足C -\u0026gt; 满足强一致性 满足A -\u0026gt; 满足绝对可用性 对分布式系统而言，网络分区无法避免，满足P是前提条件，所以不可能选择CA架构，只能选择CP或AP架构 例如: 发生网络分区时，某个节点正在进行写操作 如果为了保证C，必须禁止其他节点的读写操作，那就与A冲突了 如果为了保证A，其他节点正常读写，那就与C冲突了 选择CP或AP架构，关键在业务场景 例如: 对于必须确保强一致性的银行业务，只能选择CP BASE理论 BA(Basically Availability，基本可用性) 当系统发生故障时，在确保核心功能和指标有效的提前下，允许损失部分可用性，包括响应时间上的损失、非核心功能上的损失等 S(Soft State，软状态) 允许数据存在中间状态(暂时未更新)，且该状态不会影响整体可用性 允许不同节点上的数据副本的同步过程存在一定延时 EC(Eventually Consistency，最终一致性) 分布在不同节点上的数据副本，在经过一定时间的同步后，最终达到一致状态 例如: Zookeeper、HDFS QJM写事务的过半策略 弱一致性的升级版 BASE定理 分布式系统在满足分区容错性P的同时，允许数据软状态S的存在，并实现基本可用性BA和最终一致性EC","title":"分布式系统概述"},{"content":"Background IIoT（工业物联网）架构通常是分布式和异步的，通信由事件驱动，如消息的发布（和相应的订阅）。这些异步架构提高了可扩展性和对变化的耐受性，但也引发了互操作性问题，因为架构各元素之间对消息内部结构及其分类（主题）的明确知识被稀释了。\n事实上，这也是 REST 应用程序接口面临的一个问题，直到业界联合起来，提出了一种定义同步应用程序接口结构和模式的标准方法：OpenAPI（源自 Swagger）。\nIntroduction 对于异步架构，受 OpenAPI 的启发，AsyncAPI 的出现解决了这一问题：\nAsyncAPI 提供了一种规范，允许您以机器可读的格式定义消息驱动的 API。它与协议无关，因此可以用于通过 Kafka、MQTT、AMQP、WebSockets、STOMP 等工作的 API。该规范与 OpenAPI/Swagger 非常相似，所以如果你熟悉它，AsyncAPI 对你来说应该很容易。\n在 AsyncAPI 中，API 的规格可以用 YAML 或 JSON 定义，例如可以指定消息代理、感兴趣的主题或与每个主题相关的不同消息格式等。不过，AsyncAPI 还处于开发的早期阶段，AsyncAPI 工具市场还不发达，主要局限于生成供人类使用的文档。\nAsyncAPI 最初的贡献就是上图中展示的方法。\nAsyncAPI Toolkit 如上图所示，AsyncAPI 团队扩展了这一初始框架。基于 AsyncAPI 规范在 Xtext 中开发 AsyncAPI JSON 语法的，该语法可验证符合 AsyncAPI 规范的消息驱动 API 定义。同样，根据该语法，Xtext 会自动生成相应的 AsyncAPI 元模型和所有工具（带内容辅助功能的编辑器、解析器等），以便轻松创建 AsyncAPI JSON 定义并将其转换为符合 AsyncAPI 元模型的 AsyncAPI 模型。\n有了 AsyncAPI 元模型和作为符合模型的应用程序接口规范，就可以通过执行 M2T 转换（生成内部 DSL）来继续工作流程。目前，AsyncAPI Toolkit 支持 Java 语言，并生成一个库，通过提供流畅的 API 来协助开发人员创建、发布和接收格式良好的消息。\n值得注意的是，由于这些架构都是基于 message 的，因此数据建模起着至关重要的作用。因此，我们在上述工作流程中使用了另一种（图形化）具体语法，重点是对要交换的消息进行建模。这可用于引导 AsyncAPI JSON 定义，随后可对其进行手动完善。\nImporting / Modeling an AsyncAPI 规范 首先，基于 AsyncAPI 规范，我们创建了一个 Xtext 语法。根据该语法，我们自动生成了一个 Ecore metamodel，以及一套编辑器和基于 Eclipse 的工具。这些编辑器允许使用 AsyncAPI 创建基于 JSON 的消息驱动 API 规范。使用这些编辑器创建的规范会被自动解析并重新整合为 AsyncAPI 元模型的实例。\n生成代码，轻松处理 AsyncAPI 规范中的信息 此外，原型还能生成 Java 代码，支持根据建模的 AsyncAPI（包括嵌套 JSON 对象）创建和序列化基于 JSON 的消息有效载荷。但目前还不支持数组。下面的节选显示了原型支持的 AsyncAPI 规范示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 { \u0026#34;asyncapi\u0026#34;: \u0026#34;1.2.0\u0026#34;, \u0026#34;info\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Sample AsyncAPI specification\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, }, \u0026#34;servers\u0026#34;: [ { \u0026#34;url\u0026#34;: \u0026#34;broker.url:{port}\u0026#34;, \u0026#34;scheme\u0026#34;: \u0026#34;mqtt\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;This is an example description\u0026#34;, \u0026#34;variables\u0026#34;: { \u0026#34;port\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;1883\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;1883\u0026#34;, \u0026#34;8883\u0026#34; ] } } } ], \u0026#34;topics\u0026#34;: { \u0026#34;messages/device2controller\u0026#34;: { \u0026#34;publish\u0026#34;: { \u0026#34;$ref\u0026#34; : \u0026#34;#/components/messages/request\u0026#34; } } } }, \u0026#34;components\u0026#34;: { \u0026#34;schemas\u0026#34;: { \u0026#34;protocol_version\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Protocol version\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;, \u0026#34;default\u0026#34;: 2, \u0026#34;x-friendly-name\u0026#34;: \u0026#34;ProtocolVersion\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ID\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;XXXXXX YY ZZZZZZ W\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Status\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;OK\u0026#34;, \u0026#34;ERROR\u0026#34;], \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Status\u0026#34; }, \u0026#34;environment\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Environment\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;DEV\u0026#34;, \u0026#34;STAG\u0026#34;,\u0026#34;PROD\u0026#34; ], \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Environment\u0026#34; } }, \u0026#34;messages\u0026#34; : { \u0026#34;request\u0026#34; : { \u0026#34;summary\u0026#34; : \u0026#34;Request connectivity.\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Request connectivity when status changes\u0026#34;, \u0026#34;payload\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;P\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/protocol_version\u0026#34; }, \u0026#34;ID\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/id\u0026#34; }, \u0026#34;E\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/environment\u0026#34; }, \u0026#34;M\u0026#34;: { \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Message\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;S\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/status\u0026#34; }, \u0026#34;C\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Content\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;x-friendly-name\u0026#34;: \u0026#34;Content\u0026#34; } } } } } } } } 根据上述规范，可以生成如下信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package tests; import messages.device2controller.Request; import messages.device2controller.Request.Payload.Environment; import messages.device2controller.Request.Payload.Message; import messages.device2controller.Request.Payload.PayloadBuilder; import messages.device2controller.Request.Payload.Message.Status; public class Test { public static void main(String[] args) { PayloadBuilder builder = Request.payloadBuilder(); Request.Payload payload = builder .withProtocolVersion(2) .withEnvironment(Environment.DEV) .withID(\u0026#34;id\u0026#34;) .withMessage( Message.newBuilder() .withStatus(Status.OK) .withContent(\u0026#34;Content\u0026#34;) .build() ).build(); System.out.println(payload.toJson(true)); System.out.println(Request.Payload.fromJson(payload.toJson()).toJson(true)); } } 从 Ecore 模型生成新的 AsyncAPI 在此之前，我们假设您要么已经有一个 AsyncAPI 文件要导入，要么您将使用我们的 AsyncAPI 编辑器创建一个文件。事实上，还有第三种选择：使用现有的 Ecore 模型，并从中生成一个骨架 AsyncAPI 规范。\n生成器将为每个领域类创建一个可重复使用的 JSON 模式。通道将由注释过的 EClasses 创建。此外，还可通过 EAnnotations 指定主机信息。\n除了其局限性外，获得基于 JSON 的 Ecore 模型表示法还有几个优点：\n允许开发人员和架构师创建一个可用的 AsyncAPI 定义，而无需深入了解规范， 同时保持建模环境的简单性和可管理性； 以及让不熟悉建模的人也能遵守 AsyncAPI 规范还能让有经验的开发人员和架构师完善和完成无法用 Ecore 轻松捕获的架构细节 为了在建议的开发工作流程中集成数据模型，定义了 Ecore 到 AsyncAPI 的模型到模型（M2M）和 AsyncAPI 到 JSON 的 M2T 转换。\n例子\nResources tutorial: https://modeling-languages.com/asyncapi-modeling-editor-code-generator/ A model-based approach for developing event-driven architectures with AsyncAPI Model-driven development of asynchronous message-driven architectures with AsyncAPI Grammar 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 grammar io.github.abelgomez.asyncapi.AsyncApi hidden(WS) generate asyncApi \u0026#34;http://io.github.abelgomez/asyncapi/AsyncApi\u0026#34; import \u0026#34;http://www.eclipse.org/emf/2002/Ecore\u0026#34; as ecore AsyncAPI: {AsyncAPI} \u0026#39;{\u0026#39;\t( ( \u0026#39;\u0026#34;asyncapi\u0026#34;\u0026#39; \u0026#39;:\u0026#39; version=VersionNumber \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;info\u0026#34;\u0026#39; \u0026#39;:\u0026#39; info=Info \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;servers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; servers+=Server (\u0026#39;,\u0026#39; servers+=Server)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;channels\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; channels+=Channel (\u0026#39;,\u0026#39; channels+=Channel)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;components\u0026#34;\u0026#39; \u0026#39;:\u0026#39; components=Components \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-sla\u0026#34;\u0026#39; \u0026#39;:\u0026#39; sla=Sla \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Info: {Info} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;version\u0026#34;\u0026#39; \u0026#39;:\u0026#39; version=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;termsOfService\u0026#34;\u0026#39; \u0026#39;:\u0026#39; termsOfService=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;contact\u0026#34;\u0026#39; \u0026#39;:\u0026#39; contact=Contact \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;license\u0026#34;\u0026#39; \u0026#39;:\u0026#39; license=License \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-basePackage\u0026#34;\u0026#39; \u0026#39;:\u0026#39; basePackage=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Contact: {Contact} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;email\u0026#34;\u0026#39; \u0026#39;:\u0026#39; email=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; License: {License} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Server: {Server} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;protocol\u0026#34;\u0026#39; \u0026#39;:\u0026#39; protocol=Protocol \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;variables\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; variables+=Variable (\u0026#39;,\u0026#39; variables+=Variable)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-isMonitored\u0026#34;\u0026#39; \u0026#39;:\u0026#39; isMonitored=Boolean \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Variable: {Variable} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;default\u0026#34;\u0026#39; \u0026#39;:\u0026#39; default=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; ^enum+=AnyString (\u0026#39;,\u0026#39; ^enum+=AnyString)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Channel: {Channel} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;publish\u0026#34;\u0026#39; \u0026#39;:\u0026#39; publish=Operation \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;subscribe\u0026#34;\u0026#39; \u0026#39;:\u0026#39; subscribe=Operation \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; parameters+=NamedParameter (\u0026#39;,\u0026#39; parameters+=NamedParameter)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Operation: {Operation} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operationId=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;message\u0026#34;\u0026#39; \u0026#39;:\u0026#39; message=AbstractMessage \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; traits+=AbstractOperationTrait ( \u0026#39;,\u0026#39; traits+=AbstractOperationTrait )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; AbstractMessage: Reference | Message; Message: {Message} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; \u0026#39;:\u0026#39; deprecated=Boolean \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; headers=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; tags+=Tag ( \u0026#39;,\u0026#39; tags+=Tag )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;payload\u0026#34;\u0026#39; \u0026#39;:\u0026#39; payload=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; traits+=AbstractMessageTrait ( \u0026#39;,\u0026#39; traits+=AbstractMessageTrait )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-identifier\u0026#34;\u0026#39; \u0026#39;:\u0026#39; identifier=MessageIdentifier )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedMessage: {NamedMessage} name=AnyString \u0026#39;:\u0026#39; message=AbstractMessage; Tag: {Tag} \u0026#39;{\u0026#39; ( (\u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;?)? \u0026amp; (\u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;?)? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; AbstractSchema: Reference | Schema; Schema: {Schema} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;type\u0026#34;\u0026#39; \u0026#39;:\u0026#39; type=JsonType \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;format\u0026#34;\u0026#39; \u0026#39;:\u0026#39; format=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;minimum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; minimum=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;maximum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; maximum=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;minItems\u0026#34;\u0026#39; \u0026#39;:\u0026#39; minItems=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;maxItems\u0026#34;\u0026#39; \u0026#39;:\u0026#39; maxItems=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;default\u0026#34;\u0026#39; \u0026#39;:\u0026#39; default=PrimitiveValue\u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;properties\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; properties+=NamedSchema (\u0026#39;,\u0026#39; properties+=NamedSchema)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; ^enum+=PrimitiveValue (\u0026#39;,\u0026#39; ^enum+=PrimitiveValue)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;items\u0026#34;\u0026#39; \u0026#39;:\u0026#39; items=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;required\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; required+=AnyString (\u0026#39;,\u0026#39; required+=AnyString)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedSchema: {NamedSchema} name=AnyString \u0026#39;:\u0026#39; schema=AbstractSchema; AbstractParameter: Reference | Parameter; Parameter: {Parameter} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;schema\u0026#34;\u0026#39; \u0026#39;:\u0026#39; schema=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;location\u0026#34;\u0026#39; \u0026#39;:\u0026#39; location=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedParameter: {NamedParameter} name=AnyString \u0026#39;:\u0026#39; parameter=AbstractParameter; AbstractOperationTrait: Reference | OperationTrait; OperationTrait: {OperationTrait} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operationId=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedOperationTrait: {NamedOperationTrait} name=AnyString \u0026#39;:\u0026#39; operationTrait=AbstractOperationTrait; AbstractMessageTrait: Reference | MessageTrait; MessageTrait: {MessageTrait} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; \u0026#39;:\u0026#39; deprecated=Boolean \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; headers=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; tags+=Tag ( \u0026#39;,\u0026#39; tags+=Tag )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedMessageTrait: {NamedMessageTrait} name=AnyString \u0026#39;:\u0026#39; messageTrait=AbstractMessageTrait; Components: {Components} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;schemas\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; schemas+=NamedSchema (\u0026#39;,\u0026#39; schemas+=NamedSchema)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; messages+=NamedMessage (\u0026#39;,\u0026#39; messages+=NamedMessage)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; parameters+=NamedParameter (\u0026#39;,\u0026#39; parameters+=NamedParameter)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;operationTraits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; operationTraits+=NamedOperationTrait (\u0026#39;,\u0026#39; operationTraits+=NamedOperationTrait)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;messageTraits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; messageTraits+=NamedMessageTrait (\u0026#39;,\u0026#39; messageTraits+=NamedMessageTrait)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-qosMetrics\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; qosMetrics+=QoSMetric (\u0026#39;,\u0026#39; qosMetrics+=QoSMetric)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Sla: {Sla} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;guaranteeTerm\u0026#34;\u0026#39; \u0026#39;:\u0026#39; guaranteeTerm+=GuaranteeTerm (\u0026#39;,\u0026#39; guaranteeTerm+=GuaranteeTerm)* ) ) \u0026#39;}\u0026#39;; GuaranteeTerm: {GuaranteeTerm} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;scopes\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; scopes+=Scope (\u0026#39;,\u0026#39; scopes+=Scope)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39; ) ( \u0026#39;\u0026#34;qualifyingConditions\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; qualifyingConditions+=QualifyingCondition (\u0026#39;,\u0026#39; qualifyingConditions+=QualifyingCondition)* \u0026#39;}\u0026#39;\u0026#39;,\u0026#39;)? ( \u0026#39;\u0026#34;slos\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; slos+=Slo (\u0026#39;,\u0026#39; slos+=Slo)* \u0026#39;}\u0026#39;)\t) \u0026#39;}\u0026#39;; Scope: {Scope}( name=AnyString \u0026#39;:\u0026#39; reference= [Channel|AnyString] ); QualifyingCondition: {QualifyingCondition} name=AnyString \u0026#39;:\u0026#39; condition=BooleanExpression ; Slo: {Slo} name=AnyString \u0026#39;:\u0026#39; condition=BooleanExpression ;\tAbstractQoSMetric: QoSMetricReference | QoSMetric; QoSMetricReference: metric= [QoSMetric|AnyString]\t; QoSMetric: (\u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )\t\u0026amp; ( \u0026#39;\u0026#34;metricType\u0026#34;\u0026#39; \u0026#39;:\u0026#39; metricType=QoSMetricType \u0026#39;,\u0026#39;? )\t\u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;unit\u0026#34;\u0026#39; \u0026#39;:\u0026#39; unit=QoSMetricUnit \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;groupedByEvent\u0026#34;\u0026#39; \u0026#39;:\u0026#39; groupedByEvent=Boolean \u0026#39;,\u0026#39;? )\t) (DerivedQoSMetric)?\t// Això està al final de tot, pq Xtext es queixa que no pot haver-hi una unasssigned rule dins d\u0026#39;una unordered list.\t\u0026#39;}\u0026#39;); DerivedQoSMetric: {DerivedQoSMetric}( \u0026#39;\u0026#34;derivedQoSMetricDefinition\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( (\u0026#39;\u0026#34;window\u0026#34;\u0026#39; \u0026#39;:\u0026#39; window = AnyString \u0026#39;,\u0026#39;? ) \u0026amp; (\u0026#39;\u0026#34;windowUnit\u0026#34;\u0026#39; \u0026#39;:\u0026#39; windowUnit = WindowUnit \u0026#39;,\u0026#39;? ) \u0026amp; (\u0026#39;\u0026#34;aggregationFunction\u0026#34;\u0026#39; \u0026#39;:\u0026#39; aggregationFunction = AggregationFunction \u0026#39;,\u0026#39;? ) ) \u0026#39;}\u0026#39; ) ; BooleanExpression: AndExpression | OrExpression | ComparisonExpression; AndExpression: {AndExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;AND\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; conditions+=BooleanExpression (\u0026#39;,\u0026#39; conditions+=BooleanExpression)* \u0026#39;]\u0026#39; \u0026#39;}\u0026#39; ; OrExpression: {OrExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;OR\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; conditions+=BooleanExpression (\u0026#39;,\u0026#39; conditions+=BooleanExpression)* \u0026#39;]\u0026#39; \u0026#39;}\u0026#39;; ComparisonExpression: {ComparisonExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;qosMetric\u0026#34;\u0026#39; \u0026#39;:\u0026#39; qosMetric = AbstractQoSMetric \u0026#39;,\u0026#39; \u0026#39;\u0026#34;operator\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operator = Operator \u0026#39;,\u0026#39; \u0026#39;\u0026#34;value\u0026#34;\u0026#39; \u0026#39;:\u0026#39; value = AnyString \u0026#39;}\u0026#39; ; Reference: {Reference} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;$ref\u0026#34;\u0026#39; \u0026#39;:\u0026#39; uri=AnyString \u0026#39;}\u0026#39;; //GenericJsonExpression: //\tPrimitiveValue //\t| GenericJsonObject //\t| GenericJsonArray; // //GenericJsonObject: //\t\u0026#39;{\u0026#39; \u0026#39;}\u0026#39; | \u0026#39;{\u0026#39; GenericJsonTuple (\u0026#39;,\u0026#39; GenericJsonTuple)* \u0026#39;}\u0026#39;; // //GenericJsonArray: //\t\u0026#39;[\u0026#39; \u0026#39;]\u0026#39; | \u0026#39;[\u0026#39; GenericJsonExpression (\u0026#39;,\u0026#39; GenericJsonExpression)* \u0026#39;]\u0026#39;; // //GenericJsonTuple: AnyString \u0026#39;:\u0026#39; GenericJsonExpression; // //GenericJsonTupleButRef: AnyStringButRef \u0026#39;:\u0026#39; GenericJsonExpression; enum WindowUnit: seconds = \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | minutes = \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | hours = \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | days = \u0026#39;\u0026#34;days\u0026#34;\u0026#39; | messages = \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; ; enum AggregationFunction: AVG = \u0026#39;\u0026#34;AVG\u0026#34;\u0026#39; | MEDIAN = \u0026#39;\u0026#34;MEDIAN\u0026#34;\u0026#39; | MAX = \u0026#39;\u0026#34;MAX\u0026#34;\u0026#39; | MIN = \u0026#39;\u0026#34;MIN\u0026#34;\u0026#39; ; enum QoSMetricType: availability = \u0026#39;\u0026#34;availability\u0026#34;\u0026#39; | bandwith = \u0026#39;\u0026#34;bandwith\u0026#34;\u0026#39; | cpu = \u0026#39;\u0026#34;cpu\u0026#34;\u0026#39; | capacity = \u0026#39;\u0026#34;capacity\u0026#34;\u0026#39; | disaster = \u0026#39;\u0026#34;disaster\u0026#34;\u0026#39; | resiliance = \u0026#39;\u0026#34;resiliance\u0026#34;\u0026#39; | discoverability = \u0026#39;\u0026#34;discoverability\u0026#34;\u0026#39; | documentation = \u0026#39;\u0026#34;documentation\u0026#34;\u0026#39; | exception_handling = \u0026#39;\u0026#34;exception_handling\u0026#34;\u0026#39; | expected_failures = \u0026#39;\u0026#34;expected_failures\u0026#34;\u0026#39; | failover = \u0026#39;\u0026#34;failover\u0026#34;\u0026#39; | jitter = \u0026#39;\u0026#34;jitter\u0026#34;\u0026#39; | latency = \u0026#39;\u0026#34;latency\u0026#34;\u0026#39; | load_balancing = \u0026#39;\u0026#34;load_balancing\u0026#34;\u0026#39; | maximum_throughput = \u0026#39;\u0026#34;maximum_throughput\u0026#34;\u0026#39; | memory_aapacity = \u0026#39;\u0026#34;memory_aapacity\u0026#34;\u0026#39; | packet_loss = \u0026#39;\u0026#34;packet_loss\u0026#34;\u0026#39; | precision = \u0026#39;\u0026#34;precision\u0026#34;\u0026#39; | probability_of_correctness = \u0026#39;\u0026#34;probability_of_correctness\u0026#34;\u0026#39; | round_trip_time = \u0026#39;\u0026#34;round_trip_time\u0026#34;\u0026#39; | throughput = \u0026#39;\u0026#34;throughput\u0026#34;\u0026#39; | time_to_tail = \u0026#39;\u0026#34;time_to_tail\u0026#34;\u0026#39; | time_to_tepair = \u0026#39;\u0026#34;time_to_tepair\u0026#34;\u0026#39; | type_consistency = \u0026#39;\u0026#34;type_consistency\u0026#34;\u0026#39; | uptime = \u0026#39;\u0026#34;uptime\u0026#34;\u0026#39; | up_to_dateness = \u0026#39;\u0026#34;up-to-dateness\u0026#34;\u0026#39; ; enum QoSMetricUnit: milliseconds = \u0026#39;\u0026#34;milliseconds\u0026#34;\u0026#39; | seconds = \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | minutes = \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | hours = \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | null = \u0026#39;\u0026#34;null\u0026#34;\u0026#39; ; enum Operator: greater = \u0026#39;\u0026#34;\u0026gt;\u0026#34;\u0026#39; | greater_equal = \u0026#39;\u0026#34;\u0026gt;=\u0026#34;\u0026#39; | equal = \u0026#39;\u0026#34;=\u0026#34;\u0026#39; | less_equal = \u0026#39;\u0026#34;\u0026lt;=\u0026#34;\u0026#39; | less = \u0026#39;\u0026#34;\u0026lt;\u0026#34;\u0026#39;\t; enum JsonType: string = \u0026#39;\u0026#34;string\u0026#34;\u0026#39; | number = \u0026#39;\u0026#34;number\u0026#34;\u0026#39; | integer = \u0026#39;\u0026#34;integer\u0026#34;\u0026#39; | boolean = \u0026#39;\u0026#34;boolean\u0026#34;\u0026#39; | object = \u0026#39;\u0026#34;object\u0026#34;\u0026#39; | array = \u0026#39;\u0026#34;array\u0026#34;\u0026#39; | any = \u0026#39;\u0026#34;any\u0026#34;\u0026#39; | null = \u0026#39;\u0026#34;null\u0026#34;\u0026#39;; enum Boolean: _false = \u0026#34;false\u0026#34; | _true = \u0026#34;true\u0026#34;; enum VersionNumber: _200 = \u0026#39;\u0026#34;2.0.0\u0026#34;\u0026#39;; enum MessageIdentifier: none =\u0026#39;\u0026#34;none\u0026#34;\u0026#39; | generated = \u0026#39;\u0026#34;generated\u0026#34;\u0026#39; | md5 = \u0026#39;\u0026#34;md5\u0026#34;\u0026#39; | sha256 = \u0026#39;\u0026#34;sha-256\u0026#34;\u0026#39;; enum Protocol: amqp = \u0026#39;\u0026#34;amqp\u0026#34;\u0026#39; | amqps = \u0026#39;\u0026#34;amqps\u0026#34;\u0026#39; | http = \u0026#39;\u0026#34;http\u0026#34;\u0026#39; | https = \u0026#39;\u0026#34;https\u0026#34;\u0026#39; | jms = \u0026#39;\u0026#34;jms\u0026#34;\u0026#39; | kafka = \u0026#39;\u0026#34;kafka\u0026#34;\u0026#39; | kafka_secure = \u0026#39;\u0026#34;kafka-secure\u0026#34;\u0026#39; | mqtt = \u0026#39;\u0026#34;mqtt\u0026#34;\u0026#39; | secure_mqtt = \u0026#39;\u0026#34;secure-mqtt\u0026#34;\u0026#39; | ws = \u0026#39;\u0026#34;ws\u0026#34;\u0026#39; | wss = \u0026#39;\u0026#34;wss\u0026#34;\u0026#39; | stomp = \u0026#39;\u0026#34;stomp\u0026#34;\u0026#39; | stomps = \u0026#39;\u0026#34;stomps\u0026#34;\u0026#39;; PrimitiveValue: AnyString | \u0026#34;true\u0026#34; | \u0026#34;false\u0026#34; | INT; AnyStringButRef: STRING | Keyword; AnyString: STRING | \u0026#39;\u0026#34;$ref\u0026#34;\u0026#39; | Keyword; terminal ID: \u0026#39;^\u0026#39;?(\u0026#39;a\u0026#39;..\u0026#39;z\u0026#39;|\u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;|\u0026#39;_\u0026#39;) (\u0026#39;a\u0026#39;..\u0026#39;z\u0026#39;|\u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;|\u0026#39;_\u0026#39;|\u0026#39;0\u0026#39;..\u0026#39;9\u0026#39;)*; terminal INT returns ecore::EInt: (\u0026#39;0\u0026#39;..\u0026#39;9\u0026#39;)+; terminal STRING: \u0026#39;\u0026#34;\u0026#39; ( \u0026#39;\\\\\u0026#39; . | !(\u0026#39;\\\\\u0026#39;|\u0026#39;\u0026#34;\u0026#39;) )* \u0026#39;\u0026#34;\u0026#39; | \u0026#34;\u0026#39;\u0026#34; ( \u0026#39;\\\\\u0026#39; . | !(\u0026#39;\\\\\u0026#39;|\u0026#34;\u0026#39;\u0026#34;) )* \u0026#34;\u0026#39;\u0026#34;; terminal WS: (\u0026#39; \u0026#39;|\u0026#39;\\t\u0026#39;|\u0026#39;\\r\u0026#39;|\u0026#39;\\n\u0026#39;)+; Keyword: \u0026#39;\u0026#34;2.0.0\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026lt;\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026lt;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026gt;\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026gt;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;AND\u0026#34;\u0026#39; | \u0026#39;\u0026#34;AVG\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MAX\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MEDIAN\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MIN\u0026#34;\u0026#39; | \u0026#39;\u0026#34;OR\u0026#34;\u0026#39; | \u0026#39;\u0026#34;aggregationFunction\u0026#34;\u0026#39; | \u0026#39;\u0026#34;amqp\u0026#34;\u0026#39; | \u0026#39;\u0026#34;amqps\u0026#34;\u0026#39; | \u0026#39;\u0026#34;any\u0026#34;\u0026#39; | \u0026#39;\u0026#34;array\u0026#34;\u0026#39; | \u0026#39;\u0026#34;asyncapi\u0026#34;\u0026#39; | \u0026#39;\u0026#34;availability\u0026#34;\u0026#39; | \u0026#39;\u0026#34;bandwith\u0026#34;\u0026#39; | \u0026#39;\u0026#34;boolean\u0026#34;\u0026#39; | \u0026#39;\u0026#34;capacity\u0026#34;\u0026#39; | \u0026#39;\u0026#34;channels\u0026#34;\u0026#39; | \u0026#39;\u0026#34;components\u0026#34;\u0026#39; | \u0026#39;\u0026#34;contact\u0026#34;\u0026#39; | \u0026#39;\u0026#34;cpu\u0026#34;\u0026#39; | \u0026#39;\u0026#34;dataType\u0026#34;\u0026#39; | \u0026#39;\u0026#34;days\u0026#34;\u0026#39; | \u0026#39;\u0026#34;default\u0026#34;\u0026#39; | \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; | \u0026#39;\u0026#34;derivedQoSMetricDefinition\u0026#34;\u0026#39; | \u0026#39;\u0026#34;description\u0026#34;\u0026#39; | \u0026#39;\u0026#34;disaster\u0026#34;\u0026#39; | \u0026#39;\u0026#34;discoverability\u0026#34;\u0026#39; | \u0026#39;\u0026#34;documentation\u0026#34;\u0026#39; | \u0026#39;\u0026#34;email\u0026#34;\u0026#39; | \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;exception_handling\u0026#34;\u0026#39; | \u0026#39;\u0026#34;expected_failures\u0026#34;\u0026#39; | \u0026#39;\u0026#34;failover\u0026#34;\u0026#39; | \u0026#39;\u0026#34;format\u0026#34;\u0026#39; | \u0026#39;\u0026#34;groupedByEvent\u0026#34;\u0026#39; | \u0026#39;\u0026#34;guaranteeTerm\u0026#34;\u0026#39; | \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; | \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | \u0026#39;\u0026#34;http\u0026#34;\u0026#39; | \u0026#39;\u0026#34;https\u0026#34;\u0026#39; | \u0026#39;\u0026#34;info\u0026#34;\u0026#39; | \u0026#39;\u0026#34;integer\u0026#34;\u0026#39; | \u0026#39;\u0026#34;items\u0026#34;\u0026#39; | \u0026#39;\u0026#34;jitter\u0026#34;\u0026#39; | \u0026#39;\u0026#34;jms\u0026#34;\u0026#39; | \u0026#39;\u0026#34;kafka\u0026#34;\u0026#39; | \u0026#39;\u0026#34;kafka-secure\u0026#34;\u0026#39; | \u0026#39;\u0026#34;latency\u0026#34;\u0026#39; | \u0026#39;\u0026#34;license\u0026#34;\u0026#39; | \u0026#39;\u0026#34;load_balancing\u0026#34;\u0026#39; | \u0026#39;\u0026#34;location\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maxItems\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maximum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maximum_throughput\u0026#34;\u0026#39; | \u0026#39;\u0026#34;memory_aapacity\u0026#34;\u0026#39; | \u0026#39;\u0026#34;message\u0026#34;\u0026#39; | \u0026#39;\u0026#34;messageTraits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; | \u0026#39;\u0026#34;metricType\u0026#34;\u0026#39; | \u0026#39;\u0026#34;milliseconds\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minItems\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minimum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | \u0026#39;\u0026#34;mqtt\u0026#34;\u0026#39; | \u0026#39;\u0026#34;mqtts\u0026#34;\u0026#39; | \u0026#39;\u0026#34;name\u0026#34;\u0026#39; | \u0026#39;\u0026#34;null\u0026#34;\u0026#39; | \u0026#39;\u0026#34;number\u0026#34;\u0026#39; | \u0026#39;\u0026#34;object\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operationTraits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operator\u0026#34;\u0026#39; | \u0026#39;\u0026#34;packet_loss\u0026#34;\u0026#39; | \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; | \u0026#39;\u0026#34;payload\u0026#34;\u0026#39; | \u0026#39;\u0026#34;precision\u0026#34;\u0026#39; | \u0026#39;\u0026#34;probability_of_correctness\u0026#34;\u0026#39; | \u0026#39;\u0026#34;properties\u0026#34;\u0026#39; | \u0026#39;\u0026#34;protocol\u0026#34;\u0026#39; | \u0026#39;\u0026#34;publish\u0026#34;\u0026#39; | \u0026#39;\u0026#34;qosMetric\u0026#34;\u0026#39; | \u0026#39;\u0026#34;qualifyingConditions\u0026#34;\u0026#39; | \u0026#39;\u0026#34;required\u0026#34;\u0026#39; | \u0026#39;\u0026#34;resiliance\u0026#34;\u0026#39; | \u0026#39;\u0026#34;round_trip_time\u0026#34;\u0026#39; | \u0026#39;\u0026#34;schema\u0026#34;\u0026#39; | \u0026#39;\u0026#34;schemas\u0026#34;\u0026#39; | \u0026#39;\u0026#34;scopes\u0026#34;\u0026#39; | \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | \u0026#39;\u0026#34;secure-mqtt\u0026#34;\u0026#39; | \u0026#39;\u0026#34;servers\u0026#34;\u0026#39; | \u0026#39;\u0026#34;slos\u0026#34;\u0026#39; | \u0026#39;\u0026#34;stomp\u0026#34;\u0026#39; | \u0026#39;\u0026#34;stomps\u0026#34;\u0026#39; | \u0026#39;\u0026#34;string\u0026#34;\u0026#39; | \u0026#39;\u0026#34;subscribe\u0026#34;\u0026#39; | \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; | \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; | \u0026#39;\u0026#34;termsOfService\u0026#34;\u0026#39; | \u0026#39;\u0026#34;throughput\u0026#34;\u0026#39; | \u0026#39;\u0026#34;time_to_tail\u0026#34;\u0026#39; | \u0026#39;\u0026#34;time_to_tepair\u0026#34;\u0026#39; | \u0026#39;\u0026#34;title\u0026#34;\u0026#39; | \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;type\u0026#34;\u0026#39; | \u0026#39;\u0026#34;type_consistency\u0026#34;\u0026#39; | \u0026#39;\u0026#34;unit\u0026#34;\u0026#39; | \u0026#39;\u0026#34;up-to-dateness\u0026#34;\u0026#39; | \u0026#39;\u0026#34;uptime\u0026#34;\u0026#39; | \u0026#39;\u0026#34;url\u0026#34;\u0026#39; | \u0026#39;\u0026#34;value\u0026#34;\u0026#39; | \u0026#39;\u0026#34;variables\u0026#34;\u0026#39; | \u0026#39;\u0026#34;version\u0026#34;\u0026#39; | \u0026#39;\u0026#34;window\u0026#34;\u0026#39; | \u0026#39;\u0026#34;windowUnit\u0026#34;\u0026#39; | \u0026#39;\u0026#34;ws\u0026#34;\u0026#39; | \u0026#39;\u0026#34;wss\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-basePackage\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-qosMetrics\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-sla\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-title\u0026#34;\u0026#39;; ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/asyncapi-code-generator/","summary":"Background IIoT（工业物联网）架构通常是分布式和异步的，通信由事件驱动，如消息的发布（和相应的订阅）。这些异步架构提高了可扩展性和对变化的耐受性，但也引发了互操作性问题，因为架构各元素之间对消息内部结构及其分类（主题）的明确知识被稀释了。\n事实上，这也是 REST 应用程序接口面临的一个问题，直到业界联合起来，提出了一种定义同步应用程序接口结构和模式的标准方法：OpenAPI（源自 Swagger）。\nIntroduction 对于异步架构，受 OpenAPI 的启发，AsyncAPI 的出现解决了这一问题：\nAsyncAPI 提供了一种规范，允许您以机器可读的格式定义消息驱动的 API。它与协议无关，因此可以用于通过 Kafka、MQTT、AMQP、WebSockets、STOMP 等工作的 API。该规范与 OpenAPI/Swagger 非常相似，所以如果你熟悉它，AsyncAPI 对你来说应该很容易。\n在 AsyncAPI 中，API 的规格可以用 YAML 或 JSON 定义，例如可以指定消息代理、感兴趣的主题或与每个主题相关的不同消息格式等。不过，AsyncAPI 还处于开发的早期阶段，AsyncAPI 工具市场还不发达，主要局限于生成供人类使用的文档。\nAsyncAPI 最初的贡献就是上图中展示的方法。\nAsyncAPI Toolkit 如上图所示，AsyncAPI 团队扩展了这一初始框架。基于 AsyncAPI 规范在 Xtext 中开发 AsyncAPI JSON 语法的，该语法可验证符合 AsyncAPI 规范的消息驱动 API 定义。同样，根据该语法，Xtext 会自动生成相应的 AsyncAPI 元模型和所有工具（带内容辅助功能的编辑器、解析器等），以便轻松创建 AsyncAPI JSON 定义并将其转换为符合 AsyncAPI 元模型的 AsyncAPI 模型。\n有了 AsyncAPI 元模型和作为符合模型的应用程序接口规范，就可以通过执行 M2T 转换（生成内部 DSL）来继续工作流程。目前，AsyncAPI Toolkit 支持 Java 语言，并生成一个库，通过提供流畅的 API 来协助开发人员创建、发布和接收格式良好的消息。\n值得注意的是，由于这些架构都是基于 message 的，因此数据建模起着至关重要的作用。因此，我们在上述工作流程中使用了另一种（图形化）具体语法，重点是对要交换的消息进行建模。这可用于引导 AsyncAPI JSON 定义，随后可对其进行手动完善。","title":"A Modeling Editor and Code Generator for message-driven architectures with AsyncAPI"},{"content":"OpenAPI Generator 可根据 OpenAPI yaml 规范生成代码，并支持多种语言。\n如何使用 OpenAPI 本节介绍如何创建一个基本的 OpenAPI yaml 规范，并用它为 Spring Boot 应用程序生成服务器端代码。\nCreate OpenAPI spec 首先要做的是为您的应用程序设计 OpenAPI 规范。您将设计一个客户 API。该 API 允许您创建一个客户，并根据其 ID 检索该客户。现实生活中的应用程序接口会更加复杂，但我们还是保持简单。\n使用 Swagger 编辑器 是设计 API 的简便方法。它会立即反馈您的规范是否有错误，并即时生成 Swagger 文档。\nOpenAPI 规范的 header 包含一些有关 API 的元数据，如标题、版本、API 运行的服务器等。标签可用于对资源进行分组，从而为您提供更多概览。\n1 2 3 4 5 6 7 8 9 openapi: \u0026#34;3.0.2\u0026#34; info: title: API Customer version: \u0026#34;1.0\u0026#34; servers: - url: https://localhost:8080 tags: - name: Customer description: Customer specific data. paths 部分包含资源规范。您定义的第一个资源是创建 Customer 的资源，将通过包含 JSON 主体的 POST 方式创建。生成器将使用 operationId 为该资源创建方法名称。为简单起见，只考虑成功响应。模式指的是 JSON 主体，将在本节后面介绍。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /customer: post: tags: - Customer summary: Create Customer operationId: createCustomer requestBody: content: application/json: schema: $ref: \u0026#39;#/components/schemas/Customer\u0026#39; responses: \u0026#39;200\u0026#39;: description: OK content: \u0026#39;application/json\u0026#39;: schema: $ref: \u0026#39;#/components/schemas/CustomerFullData\u0026#39; 第二个资源允许您检索客户。该资源也需要一个包含要检索的 customerId 的路径参数。如果 ID 不存在，将返回 NOT FOUND 的响应。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /customer/{customerId}: get: tags: - Customer summary: Retrieve Customer operationId: getCustomer parameters: - name: customerId in: path required: true schema: type: integer format: int64 responses: \u0026#39;200\u0026#39;: description: OK content: \u0026#39;application/json\u0026#39;: schema: $ref: \u0026#39;#/components/schemas/CustomerFullData\u0026#39; \u0026#39;404\u0026#39;: description: NOT FOUND 最后，在组件部分，定义了使用的模式。除了 ID 之外，Customer 模式和 CustomerFullData 模式共享所有属性。为了提高可维护性，可以使用 allOf 属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 components: schemas: Customer: type: object properties: firstName: type: string description: First name of the customer lastName: type: string description: Last name of the customer CustomerFullData: allOf: - $ref: \u0026#39;#/components/schemas/Customer\u0026#39; - type: object properties: customerId: type: integer description: The ID of the customer format: int64 description: Full data of the customer. 该应用程序的 OpenAPI 规范现已完成。\nCreate Spring Boot Application 要创建 Spring Boot 应用程序，请访问 start.spring.io，选择最新稳定的 Spring Boot 版本、Java 17 并添加 Spring Web 依赖关系。下载生成的项目并将其打开到您喜欢的集成开发环境中。在 src/main/resources 目录中添加 OpenAPI 规范，名称为 customer.yml。\n您将使用 Open API Generator Maven 插件，因此请将该插件添加到 pom 文件的构建部分。由于您使用的是 Spring Boot 应用程序，因此使用 spring 作为 generatorName，并使用 inputSpec 属性设置 customer.yml 文件的路径。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.openapitools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;openapi-generator-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;generate\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/customer.yml\u0026lt;/inputSpec\u0026gt; \u0026lt;generatorName\u0026gt;spring\u0026lt;/generatorName\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 执行以下命令生成代码：\n1 $ mvn clean compile 编译失败，出现以下错误：\n1 2 3 4 package io.swagger.annotations does not exist package io.swagger.annotations does not exist package org.openapitools.jackson.nullable does not exist cannot find symbol 为了解决这些问题，需要在 pom 文件中添加以下依赖项：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-annotations\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.validation\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;validation-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openapitools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind-nullable\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 再次运行编译会出现以下错误：\n1 2 3 4 5 6 7 8 9 package springfox.documentation.builders does not exist package springfox.documentation.builders does not exist package springfox.documentation.service does not exist package springfox.documentation.service does not exist package springfox.documentation.spi does not exist package springfox.documentation.spring.web.paths does not exist package springfox.documentation.spring.web.paths does not exist package springfox.documentation.spring.web.plugins does not exist package springfox.documentation.swagger2.annotations does not exist 在 pom 文件中添加以下依赖项可以解决这些错误：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-swagger-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-swagger2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 仔细看看生成了什么。导航至 target/generated-sources/open-api 目录，在该目录中可以找到生成的文件。以下目录包含生成的文件：\nsrc/main/org/openapitools/api : 是 Spring 控制器的一个接口，也是一个实现 src/main/org/openapitools/configuration : 是 Swagger 文档的控制器 src/main/org/openapitools/model : 基于 API 规范的 API 模型 src/main/org/openapitools : OpenAPI2SpringBoot 是一个 SpringBootApplication 当你想运行 Spring Boot 应用程序时，你会遇到一个错误，因为 Spring Boot 无法确定它需要运行哪个 SpringBootApplication :\n1 $ mvn spring-boot:run 由此产生的错误是 :\n1 Unable to find a single main class from the following candidates [org.openapitools.OpenAPI2SpringBoot, com.mydeveloperplanet.myopenapiplanet.MyOpenApiPlanetApplication 默认情况下会生成大量代码，也许比你需要的还要多。下一段将介绍如何调整配置。\nConfigure OpenAPI plugin 除了 OpenAPI 插件的 Maven 部分记录的所有选项外，还有许多额外的选项可在 OpenAPI 插件配置部分的 configOptions 部分进行配置。可通过在配置部分添加 configHelp 属性来显示可用选项。\n1 2 3 4 5 \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/customer.yml\u0026lt;/inputSpec\u0026gt; \u0026lt;generatorName\u0026gt;spring\u0026lt;/generatorName\u0026gt; \u0026lt;configHelp\u0026gt;true\u0026lt;/configHelp\u0026gt; \u0026lt;/configuration\u0026gt; 在此列表中，您将使用 interfaceOnly 属性，它只会为控制器和 API 模型生成接口。\n1 2 3 4 5 6 \u0026lt;configuration\u0026gt; ... \u0026lt;configOptions\u0026gt; \u0026lt;interfaceOnly\u0026gt;true\u0026lt;/interfaceOnly\u0026gt; \u0026lt;/configOptions\u0026gt; \u0026lt;/configuration\u0026gt; 此时，还可以删除之前添加的 Springfox 依赖项。这些都不再需要了。\n从生成的代码中还可以看到，代码是在 org.openapitools 包中生成的。你可能希望这是你自己的软件包名称，这可以通过一些基本属性来配置。通过 packageName 属性，您可以设置默认的软件包名称。不过，还必须设置 apiPackage 和 modelPackage 属性，否则这些属性仍将在 org.openapitools 包中生成。在配置部分添加以下内容。\n1 2 3 4 5 6 7 \u0026lt;configuration\u0026gt; .... \u0026lt;packageName\u0026gt;com.mydeveloperplanet.myopenapiplanet\u0026lt;/packageName\u0026gt; \u0026lt;apiPackage\u0026gt;com.mydeveloperplanet.myopenapiplanet.api\u0026lt;/apiPackage\u0026gt; \u0026lt;modelPackage\u0026gt;com.mydeveloperplanet.myopenapiplanet.model\u0026lt;/modelPackage\u0026gt; .... \u0026lt;/configuration\u0026gt; 生成的控制器界面如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @javax.annotation.Generated(value = \u0026#34;org.openapitools.codegen.languages.SpringCodegen\u0026#34;, date = \u0026#34;2022-01-15T12:51:43.809971036+01:00[Europe/Amsterdam]\u0026#34;) @Validated @Api(value = \u0026#34;customer\u0026#34;, description = \u0026#34;the customer API\u0026#34;) public interface CustomerApi { default Optional\u0026lt;NativeWebRequest\u0026gt; getRequest() { return Optional.empty(); } /** * POST /customer : Create Customer * * @param customer (optional) * @return OK (status code 200) */ @ApiOperation(value = \u0026#34;Create Customer\u0026#34;, nickname = \u0026#34;createCustomer\u0026#34;, notes = \u0026#34;\u0026#34;, response = CustomerFullData.class, tags={ \u0026#34;Customer\u0026#34;, }) @ApiResponses(value = { @ApiResponse(code = 200, message = \u0026#34;OK\u0026#34;, response = CustomerFullData.class) }) @RequestMapping( method = RequestMethod.POST, value = \u0026#34;/customer\u0026#34;, produces = { \u0026#34;application/json\u0026#34; }, consumes = { \u0026#34;application/json\u0026#34; } ) default ResponseEntity\u0026lt;CustomerFullData\u0026gt; createCustomer(@ApiParam(value = \u0026#34;\u0026#34;) @Valid @RequestBody(required = false) Customer customer) { getRequest().ifPresent(request -\u0026gt; { for (MediaType mediaType: MediaType.parseMediaTypes(request.getHeader(\u0026#34;Accept\u0026#34;))) { if (mediaType.isCompatibleWith(MediaType.valueOf(\u0026#34;application/json\u0026#34;))) { String exampleString = \u0026#34;null\u0026#34;; ApiUtil.setExampleResponse(request, \u0026#34;application/json\u0026#34;, exampleString); break; } } }); return new ResponseEntity\u0026lt;\u0026gt;(HttpStatus.NOT_IMPLEMENTED); } ... Use Generated Code 在应用程序中，首先要在包 domain 中创建一个 Customer 类。\n1 2 3 4 5 6 public class Customer { private Long customerId; private String firstName; private String lastName; // Getters and setters } 创建一个 CustomerController，实现生成的 CustomerApi 接口。\n创建 Customer 是一种基本的实现方式，您可以将 Customer 添加到 HashMap 中：计算索引是键，域客户对象是值。在实际应用中，您将把客户保存到数据库中。\n检索客户时，首先要检查所请求的 ID 是否存在于 HashMap 中。找到 ID 后，Customer 域对象将转换为 Customer API 模型对象并返回给请求者。如果未找到 ID，则会返回 NOT FOUND 响应。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @RestController public class CustomerController implements CustomerApi { private final HashMap\u0026lt;Long, com.mydeveloperplanet.myopenapiplanet.domain.Customer\u0026gt; customers = new HashMap\u0026lt;\u0026gt;(); private Long index = 0L; @Override public ResponseEntity\u0026lt;CustomerFullData\u0026gt; createCustomer(Customer apiCustomer) { com.mydeveloperplanet.myopenapiplanet.domain.Customer customer = new com.mydeveloperplanet.myopenapiplanet.domain.Customer(); customer.setCustomerId(index); customer.setFirstName(apiCustomer.getFirstName()); customer.setLastName(apiCustomer.getLastName()); customers.put(index, customer); index++; return ResponseEntity.ok(domainToApi(customer)); } @Override public ResponseEntity\u0026lt;CustomerFullData\u0026gt; getCustomer(Long customerId) { if (customers.containsKey(customerId)) { return ResponseEntity.ok(domainToApi(customers.get(customerId))); } else { return new ResponseEntity\u0026lt;\u0026gt;(HttpStatus.NOT_FOUND); } } private CustomerFullData domainToApi(com.mydeveloperplanet.myopenapiplanet.domain.Customer customer) { CustomerFullData cfd = new CustomerFullData(); cfd.setCustomerId(customer.getCustomerId()); cfd.setFirstName(customer.getFirstName()); cfd.setLastName(customer.getLastName()); return cfd; } } 运行 Spring Boot 应用程序：\n1 $ mvn spring-boot:run 添加 Consumer，并查找\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 $ curl -i -X \u0026#39;POST\u0026#39; \\ \u0026gt; \u0026#39;http://localhost:8080/customer\u0026#39; \\ \u0026gt; -H \u0026#39;accept: application/json\u0026#39; \\ \u0026gt; -H \u0026#39;Content-Type: application/json\u0026#39; \\ \u0026gt; -d \u0026#39;{ \u0026gt; \u0026#34;firstName\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026gt; \u0026#34;lastName\u0026#34;: \u0026#34;Bar\u0026#34; \u0026gt; }\u0026#39; HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:42:47 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;Foo\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Bar\u0026#34;,\u0026#34;customerId\u0026#34;:0} $ curl -i -X \u0026#39;POST\u0026#39; \\ \u0026gt; \u0026#39;http://localhost:8080/customer\u0026#39; \\ \u0026gt; -H \u0026#39;accept: application/json\u0026#39; \\ \u0026gt; -H \u0026#39;Content-Type: application/json\u0026#39; \\ \u0026gt; -d \u0026#39;{ \u0026gt; \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026gt; \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34; \u0026gt; }\u0026#39; HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:43:11 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34;,\u0026#34;customerId\u0026#34;:1} $ curl -i http://localhost:8080/customer/1 HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:45:21 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34;,\u0026#34;customerId\u0026#34;:1} $ curl -i http://localhost:8080/customer/2 HTTP/1.1 404 Content-Length: 0 Date: Sat, 15 Jan 2022 11:46:18 GMT Add OpenAPI Documentation https://springdoc.org/ 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springdoc-openapi-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.12\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在浏览器中导航至 http://localhost:8080/swagger-ui.html，即可显示 OpenAPI 文档，并可在此处下载 OpenAPI yaml 规范。\n当你仔细查看文档时，会发现它与 Swagger 编辑器中显示的文档有所不同。springdoc 依赖项默认会从源代码生成文档，并使用生成的文档。如何配置 springdoc 以使用 customer.yml 文件？\n首先，您需要将 customer.yml 文件移至 src/main/resources/static/customer.yml 目录。这也意味着你需要更改 pom 中的 Open API 生成器配置。\n1 2 3 4 \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/static/customer.yml\u0026lt;/inputSpec\u0026gt; ... \u0026lt;/configuration\u0026gt; 在 application.properties 文件中添加以下属性\n1 springdoc.swagger-ui.url=/customer.yml URL 现在显示的是您创建的 customer.yml 中定义的 API\nResources 官方 OpenAPI Specification v3.1.0 repo https://tools.openapis.org/categories/code-generators.html Blogs Open API Server Implementation Using OpenAPI Generator Generate Server Code Using OpenAPI Generator ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/openapi-code-generator/","summary":"OpenAPI Generator 可根据 OpenAPI yaml 规范生成代码，并支持多种语言。\n如何使用 OpenAPI 本节介绍如何创建一个基本的 OpenAPI yaml 规范，并用它为 Spring Boot 应用程序生成服务器端代码。\nCreate OpenAPI spec 首先要做的是为您的应用程序设计 OpenAPI 规范。您将设计一个客户 API。该 API 允许您创建一个客户，并根据其 ID 检索该客户。现实生活中的应用程序接口会更加复杂，但我们还是保持简单。\n使用 Swagger 编辑器 是设计 API 的简便方法。它会立即反馈您的规范是否有错误，并即时生成 Swagger 文档。\nOpenAPI 规范的 header 包含一些有关 API 的元数据，如标题、版本、API 运行的服务器等。标签可用于对资源进行分组，从而为您提供更多概览。\n1 2 3 4 5 6 7 8 9 openapi: \u0026#34;3.0.2\u0026#34; info: title: API Customer version: \u0026#34;1.0\u0026#34; servers: - url: https://localhost:8080 tags: - name: Customer description: Customer specific data. paths 部分包含资源规范。您定义的第一个资源是创建 Customer 的资源，将通过包含 JSON 主体的 POST 方式创建。生成器将使用 operationId 为该资源创建方法名称。为简单起见，只考虑成功响应。模式指的是 JSON 主体，将在本节后面介绍。","title":"Openapi Code Generator"},{"content":"REST 全称是 Representational State Transfer（表现层状态转化），更具体的全称是 Resource Representational State Transfer（资源表现层状态转化），具体可以见 Roy Thomas Fielding 的博士论文 https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm 这一章。\nREST 指的是一组架构约束条件和原则：\n为设计一个功能强、性能好、适宜通信的 web 应用 如果一个架构符合 REST 的约束条件和原则，我们就称它为 RESTful 结构 Resources restful petclinic tutorial docter paper bilibili-软件体系结构-2022.7-REST Create REST APIs with JAX-RS 核心概念 资源（Resources） 表现层（Representation） 状态转化（State Transfer） 资源 网络上的一个实体，或者说是网络上的一个具体信息，任何事物，只要有被引用到的必要，它就是一个资源。\n一段文本，一张图片，一首歌曲 数据库中的一行数据 一个手机号码，某用户的个人信息 一种服务 资源标识 要让一个资源可以被识别，需要有个唯一标识，在Web中这个唯一标识就是URI（Uniform Resource Identifier）。例如：\nhttps://www.ex.com/software/releases/latest.tar.gz https://www.ex.com/map/roads/USA/CA/17_mile_drive https://www.ex.com/search/cs578 URI 设计原则\n易读： https://www.oschina.net/news/38119/oschina-translate-reward-plan 表达资源的层级关系： https://github.com/git/git/commit/e3ae056f87e1d675913d08/orders/2012/10 表示资源的同级关系： /git/block-sha1/sha1.h/compare/e3af72cda056f87e;bd63e61bdf38eb264 表达资源的过滤： https://github.com/git/git/pulls?q=is%3Aclosed 统一资源接口\nRESTful 架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的 HTTP 方法如 GET，PUT 和 POST，并遵循这些方法的语义 如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性 GET和HEAD请求是安全的，无论请求多少次，都不改变服务器状态 GET、HEAD、PUT和DELETE请求是幂等的，无论对资源操作多少次，结果总是一样的，后面的请求并不会产生比第一次更多的影响 GET 获取表示，变更时获取表示（缓存）。安全且幂等。\n200: OK，表示已在响应中发出 204: 无内容，资源有空表示 301: Moved Permanently，资源的URI已被更新 303: See Other，其他（如，负载均衡） 304: not modified，资源未更改（缓存） 400: bad request，指代坏请求（如，参数错误） 404: not found，资源不存在 406: not acceptable，服务端不支持所需表示 500: internal server error，通用错误响应 503: Service Unavailable，服务端当前无法处理请求 POST 使用服务端管理的（自动产生）的实例号创建资源，或创建子资源，部分更新资源，如果没有被修改，则不过更新资源（乐观锁）。不安全且不幂等。\n406: not acceptable，服务端不支持所需表示 409: conflict，通用冲突 412: Precondition Failed，前置条件失败（如执行条件更新时的冲突） 415: unsupported media type，接受到的表示不受支持 500: internal server error，通用错误响应 503: Service Unavailable，服务当前无法处理请求 PUT 用客户端管理的实例号创建一个资源，通过替换的方式更新资源，如果未被修改，则更新资源（乐观锁）。不安全但幂等。\n200: OK，如果已存在资源被更改 201: created，如果新资源被创建 301: Moved Permanently，资源的URI已更改 303: See Other，其他（如，负载均衡） 400: bad request，指代坏请求 404: not found，资源不存在 DELETE 删除资源。不安全但幂等。\n200: OK，资源已被删除 301: Moved Permanently，资源的URI已更改 303: See Other，其他，如负载均衡 400: bad request，指代坏请求 404: not found，资源不存在 409: conflict，通用冲突 500: internal server error，通用错误响应 503: Service Unavailable，服务端当前无法处理请求 指导意义 统一资源接口要求使用标准的HTTP方法对资源进行操作，所以URI只应该来表示资源的名称，而不应该包括资源的操作。通俗来说，URI不应该使用动作来描述。例如：\nPOST /getUser?id=1 $\\rightarrow$ GET /Uset/1 GET /newUser $\\rightarrow$ POST /User GET /updateUser $\\rightarrow$ PUT /User/1 GET /deleteUser?id=2 $\\rightarrow$ DELETE /User/2 表现 (Representation) \u0026ldquo;资源\u0026quot;是一种信息实体，它可以有多种外在表现形式。我们把\u0026quot;资源\u0026quot;具体呈现出来的形式，叫做它的\u0026quot;表现层\u0026rdquo;（Representation）\n文本可以用txt格式表现，也可以用HTML格式、XMIL格式、JSON格式表现，甚至可以采用二进制格式 图片可以用JPG格式表现，也可以用PNG格式表示 资源表述 URI只代表资源的实体，不代表它的形式。严格地说，有些网址最后的 .html 后缀名是不必要的，因为这个后缀名表示格式，属于 \u0026ldquo;表现层\u0026rdquo; 范畴，而URI应该只代表 \u0026ldquo;资源\u0026rdquo; 的位置。\n资源的表述包括数据和描述数据的元数据，例如，HTTP头 \u0026ldquo;Content-Type\u0026rdquo; 就是这样一个元数据属性\n客户端可以通过 Accept 头请求一种特定格式的表述，服务端则通过 Content-Type 告诉客户端资源的表述形式\n支持的表达\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ~ » http get https://api.github.com/orgs/github \u0026#39;Accept: application/json\u0026#39; HTTP/1.1 200 OK Content-Type: application/json; charset=utf-8 { \u0026#34;archived_at\u0026#34;: null, \u0026#34;avatar_url\u0026#34;: \u0026#34;https://avatars.githubusercontent.com/u/9919?v=4\u0026#34;, \u0026#34;blog\u0026#34;: \u0026#34;https://github.com/about\u0026#34;, \u0026#34;company\u0026#34;: null, \u0026#34;created_at\u0026#34;: \u0026#34;2008-05-11T04:37:31Z\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;How people build software.\u0026#34;, \u0026#34;email\u0026#34;: null, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/events\u0026#34;, \u0026#34;followers\u0026#34;: 29993, \u0026#34;following\u0026#34;: 0, \u0026#34;has_organization_projects\u0026#34;: true, \u0026#34;has_repository_projects\u0026#34;: true, \u0026#34;hooks_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/hooks\u0026#34;, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github\u0026#34;, \u0026#34;id\u0026#34;: 9919, \u0026#34;is_verified\u0026#34;: true, \u0026#34;issues_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/issues\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;San Francisco, CA\u0026#34;, \u0026#34;login\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;members_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/members{/member}\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;GitHub\u0026#34;, \u0026#34;node_id\u0026#34;: \u0026#34;MDEyOk9yZ2FuaXphdGlvbjk5MTk=\u0026#34;, \u0026#34;public_gists\u0026#34;: 0, \u0026#34;public_members_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/public_members{/member}\u0026#34;, \u0026#34;public_repos\u0026#34;: 477, \u0026#34;repos_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/repos\u0026#34;, \u0026#34;twitter_username\u0026#34;: null, \u0026#34;type\u0026#34;: \u0026#34;Organization\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-11-29T19:44:55Z\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/orgs/github\u0026#34; } 不支持的表达\n1 2 3 4 5 6 7 8 ~ » http get https://api.github.com/orgs/github \u0026#39;Accept: text/xml\u0026#39; HTTP/1.1 415 Unsupported Media Type Content-Type: application/json; charset=utf-8 { \u0026#34;documentation_url\u0026#34;: \u0026#34;https://docs.github.com/v3/media\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Unsupported \u0026#39;Accept\u0026#39; header: \u0026#39;text/xml\u0026#39;. Must accept \u0026#39;application/json\u0026#39;.\u0026#34; } 资源链接 当你浏览Web网页时，从一个连接跳到一个页面，再从另一个连接跳到另外一冬页面，就是利用了超媒体的概念：把一个个把资源链接起来。\n同样，我们在表述格式里边加入链接来引导客户端：\n在Link头告诉客户端怎么访问下一页和最后一页的记录； 在响应体里用url来链接项目所有者和项目地址 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 ~ » http -h get https://api.github.com/orgs/github/repos HTTP/1.1 200 OK Content-Type: application/json; charset=utf-8 Link: \u0026lt;https://api.github.com/organizations/9919/repos?page=2\u0026gt;; rel=\u0026#34;next\u0026#34;, \u0026lt;https://api.github.com/organizations/9919/repos?page=16\u0026gt;; rel=\u0026#34;last\u0026#34; [ { \u0026#34;id\u0026#34;: 3222, \u0026#34;node_id\u0026#34;: \u0026#34;MDEwOlJlcG9zaXRvcnkzMjIy\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;media\u0026#34;, \u0026#34;full_name\u0026#34;: \u0026#34;github/media\u0026#34;, \u0026#34;private\u0026#34;: false, \u0026#34;owner\u0026#34;: { \u0026#34;login\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;id\u0026#34;: 9919, \u0026#34;node_id\u0026#34;: \u0026#34;MDEyOk9yZ2FuaXphdGlvbjk5MTk=\u0026#34;, \u0026#34;avatar_url\u0026#34;: \u0026#34;https://avatars.githubusercontent.com/u/9919?v=4\u0026#34;, \u0026#34;gravatar_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/users/github\u0026#34;, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github\u0026#34;, \u0026#34;followers_url\u0026#34;: \u0026#34;https://api.github.com/users/github/followers\u0026#34;, \u0026#34;following_url\u0026#34;: \u0026#34;https://api.github.com/users/github/following{/other_user}\u0026#34;, \u0026#34;gists_url\u0026#34;: \u0026#34;https://api.github.com/users/github/gists{/gist_id}\u0026#34;, \u0026#34;starred_url\u0026#34;: \u0026#34;https://api.github.com/users/github/starred{/owner}{/repo}\u0026#34;, \u0026#34;subscriptions_url\u0026#34;: \u0026#34;https://api.github.com/users/github/subscriptions\u0026#34;, \u0026#34;organizations_url\u0026#34;: \u0026#34;https://api.github.com/users/github/orgs\u0026#34;, \u0026#34;repos_url\u0026#34;: \u0026#34;https://api.github.com/users/github/repos\u0026#34;, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/users/github/events{/privacy}\u0026#34;, \u0026#34;received_events_url\u0026#34;: \u0026#34;https://api.github.com/users/github/received_events\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Organization\u0026#34;, \u0026#34;site_admin\u0026#34;: false }, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github/media\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Media files for use in your GitHub integration projects\u0026#34;, \u0026#34;fork\u0026#34;: false, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media\u0026#34;, \u0026#34;forks_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/forks\u0026#34;, \u0026#34;keys_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/keys{/key_id}\u0026#34;, \u0026#34;collaborators_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/collaborators{/collaborator}\u0026#34;, \u0026#34;teams_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/teams\u0026#34;, \u0026#34;hooks_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/hooks\u0026#34;, \u0026#34;issue_events_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues/events{/number}\u0026#34;, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/events\u0026#34;, \u0026#34;assignees_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/assignees{/user}\u0026#34;, \u0026#34;branches_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/branches{/branch}\u0026#34;, \u0026#34;tags_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/tags\u0026#34;, \u0026#34;blobs_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/blobs{/sha}\u0026#34;, \u0026#34;git_tags_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/tags{/sha}\u0026#34;, \u0026#34;git_refs_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/refs{/sha}\u0026#34;, \u0026#34;trees_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/trees{/sha}\u0026#34;, \u0026#34;statuses_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/statuses/{sha}\u0026#34;, \u0026#34;languages_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/languages\u0026#34;, \u0026#34;stargazers_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/stargazers\u0026#34;, \u0026#34;contributors_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/contributors\u0026#34;, \u0026#34;subscribers_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/subscribers\u0026#34;, \u0026#34;subscription_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/subscription\u0026#34;, \u0026#34;commits_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/commits{/sha}\u0026#34;, \u0026#34;git_commits_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/commits{/sha}\u0026#34;, \u0026#34;comments_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/comments{/number}\u0026#34;, \u0026#34;issue_comment_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues/comments{/number}\u0026#34;, \u0026#34;contents_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/contents/{+path}\u0026#34;, \u0026#34;compare_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/compare/{base}...{head}\u0026#34;, \u0026#34;merges_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/merges\u0026#34;, \u0026#34;archive_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/{archive_format}{/ref}\u0026#34;, \u0026#34;downloads_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/downloads\u0026#34;, \u0026#34;issues_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues{/number}\u0026#34;, \u0026#34;pulls_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/pulls{/number}\u0026#34;, \u0026#34;milestones_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/milestones{/number}\u0026#34;, \u0026#34;notifications_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/notifications{?since,all,participating}\u0026#34;, \u0026#34;labels_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/labels{/name}\u0026#34;, \u0026#34;releases_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/releases{/id}\u0026#34;, \u0026#34;deployments_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/deployments\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2008-03-09T22:43:49Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-09-23T01:50:37Z\u0026#34;, \u0026#34;pushed_at\u0026#34;: \u0026#34;2015-02-27T17:31:20Z\u0026#34;, \u0026#34;git_url\u0026#34;: \u0026#34;git://github.com/github/media.git\u0026#34;, \u0026#34;ssh_url\u0026#34;: \u0026#34;git@github.com:github/media.git\u0026#34;, \u0026#34;clone_url\u0026#34;: \u0026#34;https://github.com/github/media.git\u0026#34;, \u0026#34;svn_url\u0026#34;: \u0026#34;https://github.com/github/media\u0026#34;, \u0026#34;homepage\u0026#34;: \u0026#34;https://github.com/logos\u0026#34;, \u0026#34;size\u0026#34;: 4484, \u0026#34;stargazers_count\u0026#34;: 293, \u0026#34;watchers_count\u0026#34;: 293, \u0026#34;language\u0026#34;: null, \u0026#34;has_issues\u0026#34;: false, \u0026#34;has_projects\u0026#34;: true, \u0026#34;has_downloads\u0026#34;: true, \u0026#34;has_wiki\u0026#34;: false, \u0026#34;has_pages\u0026#34;: false, \u0026#34;has_discussions\u0026#34;: false, \u0026#34;forks_count\u0026#34;: 69, \u0026#34;mirror_url\u0026#34;: null, \u0026#34;archived\u0026#34;: true, \u0026#34;disabled\u0026#34;: false, \u0026#34;open_issues_count\u0026#34;: 0, \u0026#34;license\u0026#34;: null, \u0026#34;allow_forking\u0026#34;: true, \u0026#34;is_template\u0026#34;: false, \u0026#34;web_commit_signoff_required\u0026#34;: false, \u0026#34;topics\u0026#34;: [], \u0026#34;visibility\u0026#34;: \u0026#34;public\u0026#34;, \u0026#34;forks\u0026#34;: 69, \u0026#34;open_issues\u0026#34;: 0, \u0026#34;watchers\u0026#34;: 293, \u0026#34;default_branch\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;permissions\u0026#34;: { \u0026#34;admin\u0026#34;: false, \u0026#34;maintain\u0026#34;: false, \u0026#34;push\u0026#34;: false, \u0026#34;triage\u0026#34;: false, \u0026#34;pull\u0026#34;: true } }, ... ] 状态转移（State Transfer） 状态应该区分应用状态和资源状态，\n客户端负责维护应用状态， 而服务端维护资源状态。 客户端与服务端的交互必须是无状态的，并在每一次请求中包含处理该请求所需的一切信息。服务端不需要在请求间保留应用状态，只有在接受到实际请求的时候，服务端才会关注应用状态。这种无状态通信原则，使得服务端和中介能够理解独立的请求和响应。在多次请求中，同一客户端也不再需要依赖于同一服务器，方便实现高可扩展和高可用性的服务端。\n客户端应用状态在服务端提供的超媒体的指引下发生变迁。服务端通过超媒体告诉客户端当前状态有哪些后续状态可以进入。\n","permalink":"https://WFUing.github.io/posts/tech/network/restful/","summary":"REST 全称是 \u003cstrong\u003eRe\u003c/strong\u003epresentational \u003cstrong\u003eS\u003c/strong\u003etate \u003cstrong\u003eT\u003c/strong\u003eransfer（表现层状态转化），更具体的全称是 Resource Representational State Transfer（资源表现层状态转化），具体可以见 Roy Thomas Fielding 的博士论文","title":"Restful API Tutorial"},{"content":"Actor Model CPU 上有多个内核。如果我们想充分利用现有的这些硬件，就需要一种并发运行代码的方法。数十年来无法追踪的错误和开发人员的沮丧都表明，线程并不是解决问题的办法。不过不用担心，我们还有其他很好的选择，今天我要向你展示的就是其中之一：actor model。\nactor model actor model 是一种处理并发计算的概念模型。它为系统组件的行为和交互方式定义了一些通用规则。\nactors actor 是计算的原始单元。它接收 message，并根据 message进行某种计算。\n这种想法与面向对象语言（object-oriented languages）中的想法非常相似：对象接收 message（方法调用），并根据接收到的 message（我们调用的方法）进行操作。\n主要区别在于，actors 之间是完全隔离的，它们永远不会共享内存。值得注意的是，一个 actor 可以保持一个私有状态，其他 actor 永远无法直接改变该状态。\n一个 actor 不是 actor。它们是以系统的形式出现的。在 actor model 中，一切都是 actor，它们需要有地址，这样一个行为者才能向另一个 actor 发送 message。\nmailbox 虽然多个 actor 可以同时运行，但一个 actor 会按顺序处理给定的 message。这意味着，如果你向同一个 actor 发送 3 条 message，它只会一次执行一条。要同时执行这 3 条 message，你需要创建 3 个 actor，每个 actor 发送一条 message。\nmessage 是异步发送给角色的，角色在处理另一条消息时需要将消息存储在某个地方。mailbox 就是存储这些 message 的地方。\nactor 之间通过发送异步消息进行通信。这些 message 会保存在其他 actor 的 mailbox 中，直到它们被处理。\nWhat actors do 当 actor 收到 message 时，它可以做以下三件事中的一件：\nCreate more actors Send messages to other actors Designate what to do with the next message：指定义这个状态在收到下一条信息时的样子，行为体如何改变状态。假设我们有一个行为类似于计算器的行为体，它的初始状态是简单的数字 0。当这个行为体收到 add(1) 消息时，它不会改变自己的原始状态，而是指定在收到下一条消息时，状态将是 1。 Fault tolerance Erlang 引入了 \u0026ldquo;let it crash\u0026rdquo; 的理念。其理念是，你不需要进行防御性编程，试图预测所有可能发生的问题，并找到处理它们的方法，因为根本不可能考虑到每一个故障点。\nErlang 所做的就是简单地让它崩溃，但让这些关键代码由某个人监管，而这个人唯一的责任就是知道当崩溃发生时该做什么（比如将代码单元重置为稳定状态），而使这一切成为可能的就是 actor model。\n每段代码都运行在一个进程中（这也是 Erlang 对其角色的基本称呼）。这个进程是完全孤立的，这意味着它的状态不会影响任何其他进程。我们有一个 \u0026ldquo;监督者\u0026rdquo;，它基本上是另一个进程（所有东西都是行为体，还记得吗？），当被监督的进程崩溃时，它会收到通知，然后可以采取一些措施。\n这就使得创建 \u0026ldquo;self heal\u0026rdquo; 系统成为可能，也就是说，如果一个行为体由于某种原因进入了异常状态并崩溃，那么监管者就可以采取一些措施，尝试将其恢复到一致的状态（有多种策略可以做到这一点，最常见的就是以初始状态重新启动行为体）。\nActor Model For IoT 物联网（IoT）由许多节点组成，通常功能有限。通过互联网协议标准进行通信的小型软件组件通常在机器之间形成高度分布式的工作流程，人与机器之间的互动极少。一般的应用场景包括监控环境条件等数据的传感器。复杂的应用则使用传感器和执行器，例如：家庭自动化和健康数据跟踪。这些系统使机器能够将数据上传到互联网服务器。因此，它们可以随时随地跟踪数据。\n典型 IoT 系统的主要特点之一是涉及大量受管设备，每个设备的内部状态都在不断变化。在许多情况下，这些设备都是在一些简单的网络协议上运行的原始硬件。这种 \u0026ldquo;极简\u0026rdquo; 要求与 actor model 非常吻合，因为 actor model 的基本原则之一就是将业务逻辑分解成最小的任务，由各个 actor 来处理。\nactor 具有 delivery guarantees 和 isolation 特性，非常适合物联网世界，是模拟数百万个并发连接的传感器生成实时数据的绝佳工具。它们设计轻巧，因此可以在不消耗过多计算资源的情况下进行扩展。\n以下是行动者适合物联网的特征属性：\nScalability：物联网带来了许多挑战，如何处理所有同时连接的设备产生的大量数据，并对其进行检索、汇总、分析和推送，同时保持设备的响应速度。面临的挑战包括管理高峰期接收传感器数据的巨大突发流量、批处理和实时处理这些海量数据，以及进行模拟真实世界使用模式的大规模仿真。一些物联网部署还要求后端服务管理设备，而不仅仅是吸收设备发送的数据。管理这一切的后端系统需要能够按需扩展，并具有完全的弹性。这非常适合 reactive architectures ，尤其是 Akka。\nConcurrency：物联网应用网关是系统中将本地传感器和执行器连接到云的点（例如路边站、运输过程中的车载设备或家庭自动化网关）。即使一个应用程序在传感器、执行器和云服务之间 \u0026ldquo;只转发数据\u0026rdquo;，也会有并发事件。物联网应用网关需要处理在其环境中发生的事件流和到达其接口的数据流。环境以自己的速度产生数据并要求输出。Actor model 通过消息传递实现了对来自设备的消息的高性能并发处理，从而解决了上述问题。message-processing models的优势之一是，传统的并发问题（主要是共享状态的同步）不再是问题。行为体可以保留设备内部状态或活动会话等私有状态，并在没有锁的情况下自由更新。Actor model 可确保一次只处理一条消息。\nFault Tolerance：在构建可能被数百万联网设备使用的服务时，您需要一个应对信息流的模型。您需要对设备故障、信息丢失和服务失败时的情况进行抽象。今天，我们常常认为调用堆栈是理所当然的。但是，它们发明的年代，由于多 CPU 系统并不常见，并发编程并不那么重要。调用栈不能跨线程，因此不能模拟异步调用链。 上图显示了一个严重的问题。工作线程如何处理这种情况？它很可能无法解决问题，因为它通常不知道失败任务的目的。调用者 \u0026ldquo;线程需要得到通知，但没有调用栈可以释放异常。失败通知只能通过侧通道完成，例如，在 \u0026ldquo;调用者 \u0026ldquo;线程希望得到结果的地方放置一个错误代码。如果没有这种通知，\u0026ldquo;调用者 \u0026ldquo;就永远不会收到失败通知，任务也就丢失了！这与网络系统的工作原理惊人地相似，在网络系统中，信息/请求可能在没有任何通知的情况下丢失/失败。\n有了 actor，我们可以将 actor 组织成监管层次，因此，单个 actor 的错误不会导致整个系统瘫痪。\nLightWeight：基准测试表明，Akka 模型每千兆字节堆内存可处理 250 万个角色，单机每秒可处理 5000 万条消息。\nNetwork Protocol Decoupling：利用 actor model ，我们可以利用容错功能，将代表设备的角色与底层通信协议分离开来。这样，代表设备和设备状态的角色就可以从代表通信协议的 actor 中分离出来，从而使设备 actor 免受网络错误的影响，并提高各个 actor 的功能一致性。\nNon-blocking communications：物联网应用 \u0026ldquo;必须 \u0026ldquo;具有反应性和异步性。大多数物联网应用程序都应能够处理来自设备的许多连接以及从设备中获取的所有信息。异步消息传递广泛应用于机器对机器通信。异步通信具有灵活性：应用程序可以发送一条信息，然后继续处理其他事情。actor 是唯一可寻址的，拥有自己独立的邮箱或消息队列。它们通过消息传递支持非阻塞通信，因此适合构建非阻塞和分布式计算系统。\nCustomization：所有行为体都有一个定义明确的生命周期，并配有精致的钩子，如用于生命周期逻辑控制的 preStart()、postRestart() 和 postStop()。在模拟物联网设备时，可以轻松地将自定义初始化和终止例程锚定到相应的钩子上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 object Device { def props(deviceType: String, mqttPubSub: ActorRef) = //... } class Device(deviceType: String, mqttPubSub: ActorRef) extends Actor { import Device._ private var opState: OpState = InitialState(deviceType) override def preStart(): Unit = //Initialize device\u0026#39;s op-state... override def postStop(): Unit = //Reset/Shutdown device... def receive = { case ReportOpState =\u0026gt; //Assemble report data with OpState mqttPubSub ! new Publish(Mqtt.topicReport, reportData) case UpdateOpState(newState) =\u0026gt; //Update opState with newState mqttPubSub ! new Publish(Mqtt.topicUpdate, updateResult) case PowerOff =\u0026gt; //Shutdown device... } } view raw 上面的片段展示了如何在 Scala/Akka 中构建一个设备角色，使用行业标准 MQTT（消息队列遥测传输）发布-订阅消息协议向订阅者发布其运行状态信息。这里的目的并不是研究如何用 Scala 或 Akka 编程，而是提供一个简单的示例，说明 Akka 角色易于理解的逻辑流程。\nResources https://www.brianstorti.com/the-actor-model/ http://akshantalpm.github.io/Actor-Model-For-IoT/ https://www.infoworld.com/article/3209728/why-akka-and-the-actor-model-shine-for-iot-applications.html ","permalink":"https://WFUing.github.io/posts/tech/architecture/iot/actor/","summary":"Actor Model CPU 上有多个内核。如果我们想充分利用现有的这些硬件，就需要一种并发运行代码的方法。数十年来无法追踪的错误和开发人员的沮丧都表明，线程并不是解决问题的办法。不过不用担心，我们还有其他很好的选择，今天我要向你展示的就是其中之一：actor model。\nactor model actor model 是一种处理并发计算的概念模型。它为系统组件的行为和交互方式定义了一些通用规则。\nactors actor 是计算的原始单元。它接收 message，并根据 message进行某种计算。\n这种想法与面向对象语言（object-oriented languages）中的想法非常相似：对象接收 message（方法调用），并根据接收到的 message（我们调用的方法）进行操作。\n主要区别在于，actors 之间是完全隔离的，它们永远不会共享内存。值得注意的是，一个 actor 可以保持一个私有状态，其他 actor 永远无法直接改变该状态。\n一个 actor 不是 actor。它们是以系统的形式出现的。在 actor model 中，一切都是 actor，它们需要有地址，这样一个行为者才能向另一个 actor 发送 message。\nmailbox 虽然多个 actor 可以同时运行，但一个 actor 会按顺序处理给定的 message。这意味着，如果你向同一个 actor 发送 3 条 message，它只会一次执行一条。要同时执行这 3 条 message，你需要创建 3 个 actor，每个 actor 发送一条 message。\nmessage 是异步发送给角色的，角色在处理另一条消息时需要将消息存储在某个地方。mailbox 就是存储这些 message 的地方。\nactor 之间通过发送异步消息进行通信。这些 message 会保存在其他 actor 的 mailbox 中，直到它们被处理。","title":"Actor"},{"content":"Resources Demos https://github.com/gofireflyio/aiac https://github.com/JustAIGithub/AI-Code-Convert Blogs 25 Best AI Code Generators ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/ai-code-generators/","summary":"Resources Demos https://github.com/gofireflyio/aiac https://github.com/JustAIGithub/AI-Code-Convert Blogs 25 Best AI Code Generators ","title":"AI Code Generators"},{"content":"Resources git tutorial: https://wyag.thb.lt/ 动图展示10大Git命令: https://zhuanlan.zhihu.com/p/132573100 git intro: https://missing.csail.mit.edu/2020/version-control/ book: https://git-scm.com/book/en/v2 commit convention 规范: https://www.conventionalcommits.org/en/v1.0.0/#summary Write yourself a Git：https://wyag.thb.lt/ 如何编写Git Commit Message? 为了创建一个有用的 revision history ，团队应该首先就 commit message convention 达成一致，至少要定义以下三点：\nStyle：标记语法Markup syntax, 流式布局wrap margins, 语法grammar, 大小写capitalization, 标点符号punctuation。把这些东西写出来，去掉猜测，让一切尽可能简单。 Content：提交消息的正文应该包含什么样的信息？不应该包含什么？ Metadata：如何引用 issue tracking IDs、pull request numbers 等？ 幸运的是，Git提交信息的规范已经有了很好的约定。事实上，很多 Git 命令的功能中就包含了这些约定。您不需要重新发明什么。只要遵循下面的七条规则，您就能像专家一样 commit message 了。\nThe seven rules of a great Git commit message\nSeparate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs. how For example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Summarize changes in around 50 characters or less More detailed explanatory text, if necessary. Wrap it to about 72 characters or so. In some contexts, the first line is treated as the subject of the commit and the rest of the text as the body. The blank line separating the summary from the body is critical (unless you omit the body entirely); various tools like `log`, `shortlog` and `rebase` can get confused if you run the two together. Explain the problem that this commit is solving. Focus on why you are making this change as opposed to how (the code explains that). Are there side effects or other unintuitive consequences of this change? Here\u0026#39;s the place to explain them. Further paragraphs come after blank lines. - Bullet points are okay, too - Typically a hyphen or asterisk is used for the bullet, preceded by a single space, with blank lines in between, but conventions vary here If you use an issue tracker, put references to them at the bottom, like this: Resolves: #123 See also: #456, #789 1. Separate subject from body with a blank line From the git commit manpage:\n1 Though not required, it\u0026#39;s a good idea to begin the commit message with a single short (less than 50 character) line summarizing the change, followed by a blank line and then a more thorough description. The text up to the first blank line in a commit message is treated as the commit title, and that title is used throughout Git. For example, Git-format-patch(1) turns a commit into email, and it uses the title on the Subject line and the rest of the commit in the body. 首先，并非每次提交都需要主题和正文。有时一行就够了，特别是当修改非常简单，不需要更多上下文的时候。\n1 Fix typo in introduction to user guide 如果读者想知道错别字是什么，可以直接查 typo 本身，即使用 git show 或 git diff 或 git log -p。\n如果您在命令行提交类似的内容，使用 git commit 的 -m 选项也很方便\n1 $ git commit -m \u0026#34;Fix typo in introduction to user guide\u0026#34; 然而，当一个提交需要一些解释和上下文时，你需要写一个正文。例如：\n1 2 3 4 5 Derezz the master control program MCP turned out to be evil and had become intent on world domination. This commit throws Tron\u0026#39;s disc into MCP (causing its deresolution) and turns it back into a chess game. 使用 -m 选项编写带正文的提交信息并不容易。最好使用合适的文本编辑器来编写。\n在浏览日志时，主体与主体的分离是有好处的。以下是完整的日志记录：\n1 2 3 4 5 6 7 8 9 10 $ git log commit 42e769bdf4894310333942ffc5a15151222a87be Author: Kevin Flynn \u0026lt;kevin@flynnsarcade.com\u0026gt; Date: Fri Jan 01 00:00:00 1982 -0200 Derezz the master control program MCP turned out to be evil and had become intent on world domination. This commit throws Tron\u0026#39;s disc into MCP (causing its deresolution) and turns it back into a chess game. 现在只打印主题行 git log --oneline ：\n1 2 $ git log --oneline 42e769 Derezz the master control program 或者，按用户分组提交，同样只显示主题行，git shortlog：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ git shortlog Kevin Flynn (1): Derezz the master control program Alan Bradley (1): Introduce security program \u0026#34;Tron\u0026#34; Ed Dillinger (3): Rename chess program to \u0026#34;MCP\u0026#34; Modify chess program Upgrade chess program Walter Gibbs (1): Introduce protoype chess program 在Git中，主题行和正文之间的区别还有很多，但如果中间没有空行，它们都无法正常工作。\n2. Limit the subject line to 50 characters 50个字符不是硬性限制，只是一个经验法则。将主题行保持在这一长度可确保其可读性，并迫使作者思考如何以最简洁的方式说明内容。\n1 Tip: If you\u0026#39;re having a hard time summarizing, you might be committing too many changes at once. Strive for atomic commits (a topic for a separate post). GitHub\u0026rsquo;s UI is fully aware of these conventions. It will warn you if you go past the 50 character limit and will truncate any subject line longer than 72 characters with an ellipsis.\n3. Capitalize the subject line This is as simple as it sounds. Begin all subject lines with a capital letter.\nFor example:\nAccelerate to 88 miles per hour Instead of:\naccelerate to 88 miles per hour 4. Do not end the subject line with a period Trailing punctuation is unnecessary in subject lines. Besides, space is precious when you\u0026rsquo;re trying to keep them to 50 chars or less.\nExample:\nOpen the pod bay doors Instead of:\nOpen the pod bay doors. 5. Use the imperative mood in the subject line Imperative mood just means \u0026ldquo;spoken or written as if giving a command or instruction\u0026rdquo;. A few examples:\nClean your room Close the door Take out the trash Git itself uses the imperative whenever it creates a commit on your behalf.\n例如，使用 git merge 时创建的默认信息如下\n1 Merge branch \u0026#39;myfeature\u0026#39; 当使用 git revert 时，\n1 2 3 Revert \u0026#34;Add the thing with the stuff\u0026#34; This reverts commit cc87791524aedd593cff5a74532befe7ab69ce9d. 或 点击 GitHub 拉取请求上的 Merge 按钮时：\n1 Merge pull request #123 from someuser/somebranch 因此，当您在命令行中编写提交信息时，您遵循的是 Git 自带的约定。例如，\nRefactor subsystem X for readability Update getting started documentation Remove deprecated methods Release version 1.0.0 这样写一开始可能会有点尴尬。我们更习惯于用指示语气说话，而指示语气则是报告事实。这就是为什么提交的信息经常读起来像这样：\nFixed bug with Y Changing behavior of X 有时承诺信息会被写成内容描述：\nMore fixes for broken stuff Sweet new API methods 为了消除任何混淆，这里有一个简单的规则，以便每次都能正确操作。\n一个正确的Git提交主题行应该能够完成以下句子：\nIf applied, this commit will your subject line here For example:\nIf applied, this commit will refactor subsystem X for readability If applied, this commit will update getting started documentation If applied, this commit will remove deprecated methods If applied, this commit will release version 1.0.0 If applied, this commit will merge pull request #123 from user/branch Remember: Use of the imperative is important only in the subject line. You can relax this restriction when you\u0026rsquo;re writing the body.\n6. Wrap the body at 72 characters Git 不会自动换行。当您写提交信息的正文时，必须注意右边距，并手动换行。\n建议在72个字符时进行，这样Git就有足够的空间缩进文本，同时又能将所有内容保持在80个字符以内。\n7. Use the body to explain what and why vs. how Bitcoin Core 的这个 commit 是一个很好的例子，它解释了改变的内容和原因：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 commit eb0b56b19017ab5c16c745e6da39c53126924ed6 Author: Pieter Wuille \u0026lt;pieter.wuille@gmail.com\u0026gt; Date: Fri Aug 1 22:57:55 2014 +0200 Simplify serialize.h\u0026#39;s exception handling Remove the \u0026#39;state\u0026#39; and \u0026#39;exceptmask\u0026#39; from serialize.h\u0026#39;s stream implementations, as well as related methods. As exceptmask always included \u0026#39;failbit\u0026#39;, and setstate was always called with bits = failbit, all it did was immediately raise an exception. Get rid of those variables, and replace the setstate with direct exception throwing (which also removes some dead code). As a result, good() is never reached after a failure (there are only 2 calls, one of which is in tests), and can just be replaced by !eof(). fail(), clear(n) and exceptions() are just never called. Delete them. 看看完整的差异，想想作者花时间在此时此地提供这些上下文，为同事和未来的提交者节省了多少时间。如果他不这样做，这些内容可能会永远丢失。\n在大多数情况下，您可以省略关于如何修改的细节。在这方面，代码通常是不言自明的，如果代码非常复杂，需要用散文来解释，那就是源注释的作用。只需重点说明您首先进行修改的原因\u0026ndash;(修改前的工作方式以及有什么问题)、现在的工作方式，以及您为什么决定以这种方式解决问题。\n未来感谢您的维护者可能就是您自己！\n","permalink":"https://WFUing.github.io/posts/tech/architecture/git/how-to-write-a-git-commit-message/","summary":"Resources git tutorial: https://wyag.thb.lt/ 动图展示10大Git命令: https://zhuanlan.zhihu.com/p/132573100 git intro: https://missing.csail.mit.edu/2020/version-control/ book: https://git-scm.com/book/en/v2 commit convention 规范: https://www.conventionalcommits.org/en/v1.0.0/#summary Write yourself a Git：https://wyag.thb.lt/ 如何编写Git Commit Message? 为了创建一个有用的 revision history ，团队应该首先就 commit message convention 达成一致，至少要定义以下三点：\nStyle：标记语法Markup syntax, 流式布局wrap margins, 语法grammar, 大小写capitalization, 标点符号punctuation。把这些东西写出来，去掉猜测，让一切尽可能简单。 Content：提交消息的正文应该包含什么样的信息？不应该包含什么？ Metadata：如何引用 issue tracking IDs、pull request numbers 等？ 幸运的是，Git提交信息的规范已经有了很好的约定。事实上，很多 Git 命令的功能中就包含了这些约定。您不需要重新发明什么。只要遵循下面的七条规则，您就能像专家一样 commit message 了。\nThe seven rules of a great Git commit message\nSeparate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs.","title":"How to Write a Git Commit Message"},{"content":"Linux 的命令确实非常多，然而熟悉 Linux 的人从来不会因为 Linux 的命令太多而烦恼。因为我们仅仅只需要掌握常用命令，就完全可以驾驭 Linux。\n接下来，让我们一起来看看都有那些常用的 Linux 命令吧！\n一、文件目录操作 1.ls 命令 ls 命令不仅可以查看 linux 文件夹包含的文件而且可以查看文件权限（包括目录、文件夹、文件权限）查看目录信息等等。\n命令格式\n1 ls [选项][目录名] 常用参数\n-l ：列出长数据串，包含文件的属性与权限数据等 -a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用） -d ：仅列出目录本身，而不是列出目录的文件数据 -h ：将文件容量以较易读的方式（GB，kB等）列出来 -R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来 使用实例\n1.列出 home 目录下的所有文件和目录的详细资料。\n1 2 ls -a -l /home ls -al /home 2.列出当前目录下所有以\u0026quot;d\u0026quot;开头的文件目录详情内容。\n1 ls -l d* 2.cd命令 最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。用于切换当前目录至dirName。\n命令格式\n1 cd [目录名] 操作案例\n1.从当前目录进入系统根目录。\n1 cd / 2.跳转到 home/Code 目录。\n1 cd /home/Code 3.pwd 命令 查看\u0026quot;当前工作目录\u0026quot;的完整路径。\n命令格式\n1 pwd [选项] 常用参数\n-P :显示实际物理路径，而非使用连接（link）路径 -L :当目录为连接路径时，显示连接路径 操作案例\n1.显示当前所在路径。\n1 pwd 4.mkdir 命令 用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。\n命令格式\n1 mkdir [选项] 目录 常用参数\n-m, \u0026ndash;mode=模式，设定权限\u0026lt;模式\u0026gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p, \u0026ndash;parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v, \u0026ndash;verbose 每次创建新目录都显示信息 \u0026ndash;help 显示此帮助信息并退出 \u0026ndash;version 输出版本信息并退出 使用实例\n1.创建一个空目录。\n1 mkdir test 2.递归创建多个目录。\n1 mkdir test/test1 3.创建权限为777的目录。\n1 mkdir -m 777 test2 4.创建目录都显示信息。\n1 mkdir -v test4 5.rm 命令 删除一个目录中的一个或多个文件或目录，如果没有使用- r选项，则rm不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。\n命令格式\n1 rm [选项] 文件 常用参数\n-f, \u0026ndash;force 忽略不存在的文件，从不给出提示。 -i, \u0026ndash;interactive 进行交互式删除 -r, -R, \u0026ndash;recursive 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v, \u0026ndash;verbose 详细显示进行的步骤 \u0026ndash;help 显示此帮助信息并退出 \u0026ndash;version 输出版本信息并退出 使用实例\n1.删除文件 test.txt,系统会提示是否删除。\n1 rm test.txt 2.强制删除 test.txt，系统不再提示。\n1 rm -f test.txt 3.将 test 子目录及目录中所有档案删除。\n1 rm -r test 6.rmdir 命令 该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。\n命令格式\n1 rmdir [选项] 目录 常用参数\n-p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。 -v, \u0026ndash;verbose 显示指令执行过程 使用实例\n1.删除空目录 test1，非空目录无法删除。\n1 rmdir test1 2.当子目录被删除后使它也成为空目录的话，则顺便一并删除\n1 rmdir -p test2 # test 目录下仅有 test2 7. mv 命令 可以用来移动文件或者将文件改名（move (rename) files）。当第二个参数类型是文件时，mv命令完成文件重命名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。\n命令格式\n1 mv [选项] 源文件或目录 目标文件或目录 常用参数\n-b ：若需覆盖文件，则覆盖前先行备份 -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖 -u ：若目标文件已经存在，且 source 比较新，才会更新(update) -t ： \u0026ndash;target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后 使用实例\n1.将 test1.txt 重命名为 test2.txt。\n1 mv test1.txt test2.txt 2.移动文件 test1.txt 到目录 test2\n1 mv test1.txt test2 3.将文件 test1.txt、test2.txt、test3.txt 移动到目录 test3。\n1 mv test1.txt test2.txt test3.txt test3 8.cp 命令 将源文件复制至目标文件，或将多个源文件复制至目标目录。\n命令格式\n1 cp [选项] 源文件 目录 或 cp [选项] -t 目录 源文件 常用参数\n-t \u0026ndash;target-directory 指定目标目录 -i \u0026ndash;interactive 覆盖前询问（使前面的 -n 选项失效） -n \u0026ndash;no-clobber 不要覆盖已存在的文件（使前面的 -i 选项失效） -f \u0026ndash;force 强行复制文件或目录，不论目的文件或目录是否已经存在 -u \u0026ndash;update 使用这项参数之后，只会在源文件的修改时间较目的文件更新时，或是对应的目的文件并不存在，才复制文件 使用实例\n1.复制文件 test1.txt 到 test1 目录\n1 cp test1.txt test1 # 若文件存在，会提示是否覆盖。若不存在直接完成复制 复制 test1 整个目录到 test2\n1 cp -a test1 test2 9.touch 命令 touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。\n命令格式\n1 touch [选项] 文件 常用参数\n-a 或\u0026ndash;time=atime或\u0026ndash;time=access或\u0026ndash;time=use 只更改存取时间 -c 或\u0026ndash;no-create 不建立任何文档 -d 使用指定的日期时间，而非现在的时间 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题 -m 或\u0026ndash;time=mtime或\u0026ndash;time=modify 只更改变动时间 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同 -t 使用指定的日期时间，而非现在的时间 使用实例\n1.创建不存在的文件test.txt\n1 touch test.txt 2.更新 test.txt 的实践和 test1.txt 时间戳相同\n1 touch -r test.txt test1.txt 10.cat 命令 用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。\n命令格式\n1 cat [选项] [文件] 常用参数\n-A, \u0026ndash;show-all 等价于 -vET -b, \u0026ndash;number-nonblank 对非空输出行编号 -e 等价于 -vE -E, \u0026ndash;show-ends 在每行结束处显示 $ -n, \u0026ndash;number 对输出的所有行编号,由1开始对所有输出的行数编号 -s, \u0026ndash;squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价 -T, \u0026ndash;show-tabs 将跳格字符显示为 ^I -u (被忽略) -v, \u0026ndash;show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 使用实例\n1.把 test.log 的文件内容加上行号后输入 test1.log 这个文件里。\n1 cat -n test.log test1.log 将 test.log 的文件内容反向显示。\n1 tac test.log 11.nl 命令 输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。\n命令格式\n1 nl [选项] [文件] 常用参数\n-b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n) -b t ：如果有空行，空的那一行不要列出行号(默认值) -n ：列出行号表示的方法，主要有三种： -n ln ：行号在萤幕的最左方显示 -n rn ：行号在自己栏位的最右方显示，且不加 0 -n rz ：行号在自己栏位的最右方显示，且加 0 -w ：行号栏位的占用的位数 使用实例\n用 nl 列出 test.log 的内容。\n1 nl test.log 用 nl 列出 test.log 的内容，空本行也加上行号。\n1 nl -b a test.log 12.more 命令 more 命令和 cat 的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。\n命令格式\n1 more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 常用参数\n+n 从笫n行开始显示 -n 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示Press space to continue，'q' to quit（按空格键继续，按q键退出），禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 操作指令\nEnter：向下n行，需要定义。默认为1行 Ctrl+F：向下滚动一屏 空格键：向下滚动一屏 Ctrl+B：返回上一屏 = ：输出当前行的行号 ：f ：输出文件名和当前行的行号 V ：调用vi编辑器 !命令 ：调用Shell，并执行命令 q ：退出more 使用实例\n1.显示文件 test.log 第3行起内容。\n1 more +3 test.log 2.从文件 test.log 查找第一个出现\u0026quot;day3\u0026quot;字符串的行，并从该处前2行开始显示输出。\n1 more +/day3 test.log 设置每屏显示行数\n1 more -5 test.log 13.less 命令 less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。\n命令格式\n1 less [参数] 文件 常用参数\n-b \u0026lt;缓冲区大小\u0026gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o \u0026lt;文件名\u0026gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x \u0026lt;数字\u0026gt; 将\u0026quot;tab\u0026quot;键显示为规定的数字空格 操作命令\n/字符串：向下搜索\u0026quot;字符串\u0026quot;的功能 ?字符串：向上搜索\u0026quot;字符串\u0026quot;的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 使用实例\n1.查看文件 test.log。\n1 less test.log 14.head 命令 head 用来显示档案的开头至标准输出中，默认 head 命令打印其相应文件的开头 10 行。\n命令格式\n1 head [参数] [文件] 常用参数\n-q 隐藏文件名 -v 显示文件名 -c\u0026lt;字节\u0026gt; 显示字节数 -n\u0026lt;行数\u0026gt; 显示的行数 使用实例\n1.显示文件 test.log 的前 5 行\n1 head -n 5 test.log 2.显示文件 test.log 前 20 个字节\n1 head -c 20 test.log 15.tail 命令 显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。\n命令格式\n1 tail [必要参数] [选择参数] [文件] 常用参数\n-f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c\u0026lt;数目\u0026gt; 显示的字节数 -n\u0026lt;行数\u0026gt; 显示行数 \u0026ndash;pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q, \u0026ndash;quiet, \u0026ndash;silent 从不输出给出文件名的首部 -s, \u0026ndash;sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 使用实例\n1.显示文件 test.log 最后 5 行内容。\n1 tail -n 5 test.log 2.循环查看文件内容\n1 tail -f test.log 二、文件查找 16.which 命令 which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。\n命令格式\n1 which 可执行文件名称 常用参数\n-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名 -p 与-n参数相同，但此处的包括了文件的路径 -w 指定输出时栏位的宽度 -V 显示版本信息 使用实例\n1.查找文件、显示命令路径。\n1 which pwd 用 which 去找出 which\n1 which which 17.whereis 命令 whereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。\n命令格式\n1 whereis [-bmsu] [BMS 目录名 -f ] 文件名 常用参数\n-b 定位可执行文件 -m 定位帮助文件 -s 定位源代码文件 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 -B 指定搜索可执行文件的路径 -M 指定搜索帮助文件的路径 -S 指定搜索源代码文件的路径 使用实例\n1.将和 svn 文件相关的文件都查找出来。\n1 whereis svn 2.只将二进制文件查找出来。\n1 whereis -b svn 18.locate 命令 可以很快速的搜寻档案系统内是否有指定的档案。\n命令格式\n1 locate [选择参数] [样式] 常用参数\n-e 将排除在寻找的范围之外。 -1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。 -f 将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中。 -q 安静模式，不会显示任何错误讯息。 -n 至多显示 n个输出。 -r 使用正规运算式 做寻找的条件。 -o 指定资料库存的名称。 -d 指定资料库的路径 使用实例\n1.查找和 pwd 相关的所有文件。\n1 locate pwd 搜索etc 目录下，所有以 m 开头的文件。\n1 bash复制代码locate /etc/m 19.find 命令 主要作用是沿着文件层次结构向下遍历，匹配符合条件的文件，并执行相应的操作。\n命令格式\n1 find [选项] [搜索路径] [表达式] 常用参数\n-print find 命令将匹配的文件输出到标准输出 -exec find 命令对匹配的文件执行该参数所给出的 shell 命令\n-name 按照文件名查找文件 -type 查找某一类型的文件 使用实例\n1.打印当前目录文件目录列表。\n1 find . -print 2.打印当前目录下所有不以.txt 结尾的文件名。\n1 find . ! -name \u0026#34;*.txt\u0026#34; 3.打印当前目录下所有权限为 777 的 php 文件。\n1 find . -type f -name \u0026#34;*.php\u0026#34; -perm 777 4.找到当前目录下所有 php 文件，并显示其详细信息。\n1 find . -name \u0026#34;*.php\u0026#34; -exec ls -l {} \\; 5.查找当前目录下所有 c 代码文件，统计总行数。\n1 find . -type f -name \u0026#34;*.c\u0026#34; | xargs wc -l xargs 命令可以从标准输入接收输入，并把输入转换为一个特定的参数列表。\n命令格式\n1 command | xargs [选项] [command] xargs 命令应该紧跟在管道操作符之后，因为它以标准输入作为主要的源数据流。\n常用参数\n-n 指定每行最大的参数数量 -d 指定分隔符 三、文件打包上传和下载 20.tar 命令 用来压缩和解压文件。tar本身不具有压缩功能。他是调用压缩功能实现的。\n命令格式\n1 tar [必要参数] [选择参数] [文件] 常用参数\n必要参数\n-A 新增压缩文件到已存在的压缩 -B 设置区块大小 -c 建立新的压缩文件 -d 记录文件的差别 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -x 从压缩的文件中提取文件 -t 显示压缩文件的内容 -z 支持gzip解压文件 -j 支持bzip2解压文件 -Z 支持compress解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -W 确认压缩文件的正确性 可选参数\n-b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.将文件打全部打包成tar包。\n1 2 3 4 5 tar -cvf test.tar test.log # 仅打包，不压缩！ tar -zcvf test.tar.gz test.log # 打包后，以 gzip 压缩 tar -zcvf test.tar.bz2 test.log # 打包后，以 bzip2 压缩 2.将 tar 包解压缩\n1 tar -zxvf test.tar.gz 21.gzip 命令 使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出\u0026quot;.gz\u0026quot;的扩展名。\n命令格式\n1 gzip [参数] [文件或者目录] 常用参数\n-a或\u0026ndash;ascii 使用ASCII文字模式。 -c或\u0026ndash;stdout或\u0026ndash;to-stdout 把压缩后的文件输出到标准输出设备，不去更动原始文件。 -d或\u0026ndash;decompress或\u0026mdash;-uncompress 解开压缩文件。 -f或\u0026ndash;force 强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -h或\u0026ndash;help 在线帮助。 使用实例\n1.把 test1 目录下的每个文件压缩成.gz 文件。\n1 gzip * 四、文件权限设置 22.chmod 命令 用于改变linux系统文件或目录的访问权限。\n命令格式\n1 chmod [-cfvR] [--help] [--version] mode file 常用参数\n必要参数\n-c 当发生改变时，报告处理信息 -f 错误信息不输出 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细处理信息 选择参数\n\u0026ndash;reference=\u0026lt;目录或者文件\u0026gt; 设置成具有指定目录或者文件具有相同的权限 \u0026ndash;version 显示版本信息 \u0026lt;权限范围\u0026gt;+\u0026lt;权限设置\u0026gt; 使权限范围内的目录或者文件具有指定的权限 \u0026lt;权限范围\u0026gt;-\u0026lt;权限设置\u0026gt; 删除权限范围的目录或者文件的指定权限 \u0026lt;权限范围\u0026gt;=\u0026lt;权限设置\u0026gt; 设置权限范围内的目录或者文件的权限为指定的值 权限范围\nu ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 权限代号\nr：读权限，用数字4表示 w：写权限，用数字2表示 x：执行权限，用数字1表示 -：删除权限，用数字0表示 使用实例\n1.增加文件所有用户组可执行权限\n1 chmod a+x test.log 删除所有用户的可执行权限\n1 chmod a-x test.log 23.chgrp 命令 可采用群组名称或群组识别码的方式改变文件或目录的所属群组。\n命令格式\n1 chgrp [选项] [组] [文件] 常用参数\n必要参数\n-c 当发生改变时输出调试信息 -f 不显示错误信息 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 \u0026ndash;dereference 作用于符号链接的指向，而不是符号链接本身 \u0026ndash;no-dereference 作用于符号链接本身 选择参数\n\u0026ndash;reference=\u0026lt;文件或者目录\u0026gt; \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.改变文件的群组属性\n1 chgrp -v bin test.log 2.改变文件test1.log 的群组属性，使得文件test1.log的群组属性和参考文件test.log的群组属性相同\n1 chgrp --reference=test.log test1.log 24.chown 命令 通过chown改变文件的拥有者和群组。\n命令格式\n1 chown [选项] [所有者] [:[组]] 文件 常用参数\n必要参数\n-c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 显示详细的处理信息 -deference 作用于符号链接的指向，而不是链接文件本身 选择参数\n\u0026ndash;reference=\u0026lt;目录或文件\u0026gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 \u0026ndash;from=\u0026lt;当前用户：当前群组\u0026gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.改变拥有者和群组\n1 chown mail:mail test.log 五、磁盘存储 25.df 命令 显示指定磁盘文件的可用空间。\n命令格式 1 df [选项] [文件] 常用参数\n必要参数\n-a 全部文件系统列表 -h 方便阅读方式显示 -H 等于\u0026rsquo;-h\u0026rsquo;，但是计算式，1K=1000，而不是1K=1024 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地文件系统 -m 区块为1048576字节 \u0026ndash;no-sync 忽略 sync 命令 -P 输出格式为POSIX \u0026ndash;sync 在取得磁盘信息前，先执行sync命令 -T 文件系统类型 选择参数\n\u0026ndash;block-size=\u0026lt;区块大小\u0026gt; 指定区块大小 -t\u0026lt;文件系统类型\u0026gt; 只显示选定文件系统的磁盘信息 -x\u0026lt;文件系统类型\u0026gt; 不显示选定文件系统的磁盘信息 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.显示指定磁盘使用情况\n1 df -t ext3 du 命令 显示每个文件和目录的磁盘使用空间。\n命令格式\n1 du [选项] [文件] 常用参数\n-a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 \u0026ndash; -c或\u0026ndash;total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或\u0026ndash;kilobytes 以KB(1024bytes)为单位输出。 -m或\u0026ndash;megabytes 以MB为单位输出。 -s或\u0026ndash;summarize 仅显示总计，只列出最后加总的值。 -h或\u0026ndash;human-readable 以K，M，G为单位，提高信息的可读性。 -x或\u0026ndash;one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L\u0026lt;符号链接\u0026gt;或\u0026ndash;dereference\u0026lt;符号链接\u0026gt; 显示选项中所指定符号链接的源文件大小。 -S或\u0026ndash;separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X\u0026lt;文件\u0026gt;或\u0026ndash;exclude-from=\u0026lt;文件\u0026gt; 在\u0026lt;文件\u0026gt;指定目录或文件。 \u0026ndash;exclude=\u0026lt;目录或文件\u0026gt; 略过指定的目录或文件。 -D或\u0026ndash;dereference-args 显示指定符号链接的源文件大小。 -H或\u0026ndash;si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或\u0026ndash;count-links 重复计算硬件链接的文件。 使用实例\n1.显示指定目录或文件所占空间\n1 2 du test # 目录 du test.log # 文件 六、性能监控和优化命令 27.top 命令 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等。\n命令格式\n1 top [参数] 常见参数\n-b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i\u0026lt;时间\u0026gt; 设置间隔时间 -u\u0026lt;用户名\u0026gt; 指定用户名 -p\u0026lt;进程号\u0026gt; 指定进程 -n\u0026lt;次数\u0026gt; 循环显示的次数 使用实例\n显示进程信息\n1 top 28.free 命令 显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。\n命令格式\n1 free [参数] 常见参数\n-b 以Byte为单位显示内存使用情况 -k 以KB为单位显示内存使用情况 -m 以MB为单位显示内存使用情况 -g 以GB为单位显示内存使用情况 -o 不显示缓冲区调节列 -s \u0026lt;间隔秒数\u0026gt; 持续观察内存使用状况 -t 显示内存总和列。 -V 显示版本信息。 使用实例\n1.显示内存情况。\n1 2 3 free free -g #以GB为单位 free -m #以MB为单位 29.vmstat 用来显示虚拟内存的信息。\n命令格式\n1 2 3 4 5 6 7 vmstat [-a] [-n] [-S unit] [delay [ count]] vmstat [-s] [-n] [-S unit] vmstat [-m] [-n] [delay [ count]] vmstat [-d] [-n] [delay [ count]] vmstat [-p disk partition] [-n] [delay [ count]] vmstat [-f] vmstat [-V] 常见参数\n-a：显示活跃和非活跃内存 -f：显示从系统启动至今的fork数量 -m：显示slabinfo -n：只在开始时显示一次各字段名称 -s：显示内存相关统计信息及多种系统活动数量 delay：刷新时间间隔。如果不指定，只显示一条结果 count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷 -d：显示磁盘相关统计信息 -p：显示指定磁盘分区统计信息 -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） 使用实例\n1.显示活跃和非活跃内存。\n1 vmstat -a 5 5 # 5秒时间内进行5次采样 30.lostat 命令 通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况, 负载信息。\n命令格式\n1 iostat [参数] [时间] [次数] 常见参数\n-C 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 使用实例\n1.定时显示所有信息。\n1 iostat 2 3 #每隔 2秒刷新显示，且显示3次 31.lsof 命令 用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。\n命令格式\n1 lsof [参数] [文件] 常见参数\n-a 列出打开文件存在的进程 -c\u0026lt;进程名\u0026gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d\u0026lt;文件号\u0026gt; 列出占用该文件号的进程 +d\u0026lt;目录\u0026gt; 列出目录下被打开的文件 +D\u0026lt;目录\u0026gt; 递归列出目录下被打开的文件 -n\u0026lt;目录\u0026gt; 列出使用NFS的文件 -i\u0026lt;条件\u0026gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p\u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 使用实例\n1.查看谁正在使用bash文件，也就是说查找某个文件相关的进程。\n1 lsof /bin/bash 七、网络命令 32.ifconfig 命令 ifconfig 命令用来查看和配置网络设备。\n命令格式\n1 ifconfig [网络设备] [参数] 常见参数\nup 启动指定网络设备/网卡 down 关闭指定网络设备/网卡。 arp 设置指定网卡是否支持ARP协议 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 使用实例\n1.启动关闭指定网卡\n1 2 ifconfig eth0 up ifconfig eth0 down 2.用ifconfig修改MAC地址\n1 ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE 33.route 命令 Route命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。\n命令格式\n1 route [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]] 常见参数\n-c 显示更多信息 -n 不解析名字 -v 显示详细的处理信息 -F 显示发送信息 -C 显示路由缓存 -f 清除所有网关入口的路由表。 -p 与 add 命令一起使用时使路由具有永久性。 add:添加一条新路由。 del:删除一条路由。 -net:目标地址是一个网络。 -host:目标地址是一个主机。 netmask:当添加一个网络路由时，需要使用网络掩码。 gw:路由数据包通过网关。注意，你指定的网关必须能够达到。 metric：设置路由跳数。 Command 指定您想运行的命令 (Add/Change/Delete/Print)。 Destination 指定该路由的网络目标。 使用实例\n1.显示当前路由\n1 2 route route -n 2.添加网关/设置网关\n1 route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 ping 命令 确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。\n命令格式\n1 ping [参数] [主机名或IP地址] 常见参数\n-d 使用Socket的SO_DEBUG功能 -f 极限检测。大量且快速地送网络封包给一台机器，看它的回应 -n 只输出数值 -q 不显示任何传送封包的信息，只显示最后的结果 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题 -R 记录路由过程 -v 详细显示指令的执行过程 -c 数目：在发送指定数目的包后停止 -i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次 -I 网络界面：使用指定的网络界面送出数据包 -l 前置载入：设置在送出要求信息之前，先行发出的数据包 -p 范本样式：设置填满数据包的范本样式 -s 字节数：指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节 -t 存活数值：设置存活数值TTL的大小 使用实例\nping 网关\n1 ping -b 192.168.120.1 35.traceroute 命令\n让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。\n命令格式\n1 traceroute [参数] [主机] 常见参数\n-d 使用Socket层级的排错功能 -f 设置第一个检测数据包的存活数值TTL的大小 -F 设置勿离断位 -g 设置来源路由网关，最多可设置8个 -i 使用指定的网络界面送出数据包 -I 使用ICMP回应取代UDP资料信息 -m 设置检测数据包的最大存活数值TTL的大小 -n 直接使用IP地址而非主机名称 -p 设置UDP传输协议的通信端口 -r 忽略普通的Routing Table，直接将数据包送到远端主机上 -s 设置本地主机送出数据包的IP地址 -t 设置检测数据包的TOS数值 -v 详细显示指令的执行过程 -w 设置等待远端主机回报的时间 -x 开启或关闭数据包的正确性检验 使用实例\n1.traceroute 用法简单、最常用的用法\n1 traceroute www.baidu.com 跳数设置\n1 traceroute -m 10 www.baidu.com 36.netstat 命令 用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。\n命令格式\n1 netstat [-acCeFghilMnNoprstuvVwx] [-A\u0026lt;网络类型\u0026gt;] [--ip] 常见参数\n-a或-all 显示所有连线中的Socket -A\u0026lt;网络类型\u0026gt;或-\u0026lt;网络类型\u0026gt; 列出该网络类型连线中的相关地址 -c或-continuous 持续列出网络状态 -C或-cache 显示路由器配置的快取信息 -e或-extend 显示网络其他相关信息 -F或-fib 显示FIB -g或-groups 显示多重广播功能群组组员名单 -h或-help 在线帮助 -i或-interfaces 显示网络界面信息表单 -l或-listening 显示监控中的服务器的Socket -M或-masquerade 显示伪装的网络连线 -n或-numeric 直接使用IP地址，而不通过域名服务器 -N或-netlink或-symbolic 显示网络硬件外围设备的符号连接名称 -o或-timers 显示计时器 -p或-programs 显示正在使用Socket的程序识别码和程序名称 -r或-route 显示Routing Table -s或-statistice 显示网络工作信息统计表 -t或-tcp 显示TCP传输协议的连线状况 -u或-udp 显示UDP传输协议的连线状况 -v或-verbose 显示指令执行过程 -V或-version 显示版本信息 -w或-raw 显示RAW传输协议的连线状况 -x或-unix 此参数的效果和指定\u0026quot;-A unix\u0026quot;参数相同 -ip或-inet 此参数的效果和指定\u0026quot;-A inet\u0026quot;参数相同 使用实例\n列出所有端口\n1 netstat -a 37.telnet 命令 执行telnet指令开启终端机阶段作业，并登入远端主机。\n命令格式\n1 telnet [参数] [主机] 常见参数\n-8 允许使用8位字符资料，包括输入与输出 -a 尝试自动登入远端系统 -b\u0026lt;主机别名\u0026gt; 使用别名指定远端主机名称 -c 不读取用户专属目录里的.telnetrc文件 -d 启动排错模式 -e\u0026lt;脱离字符\u0026gt; 设置脱离字符 -E 滤除脱离字符 -f 此参数的效果和指定\u0026quot;-F\u0026quot;参数相同 使用实例\n1.远程服务器无法访问\n1 telnet 192.168.120.206 八、其他命令 38.ln 命令 为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。\n命令格式\n1 ln [参数] [源文件或目录] [目标文件或目录] 常用参数\n必要参数\n-b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 选择参数\n-S -S\u0026lt;字尾备份字符串\u0026gt; 或 --suffix=\u0026lt;字尾备份字符串\u0026gt; -V -V\u0026lt;备份方式\u0026gt; 或 --version-control=\u0026lt;备份方式\u0026gt;\n使用实例\n1.为 test.log文件创建软链接linktest\n1 ln -s test.log linktest 2.为 test.log创建硬链接lntest。\n1 ln test.log lntest 39.diff 命令 比较单个文件或者目录内容。\n命令格式\n1 diff [参数] [文件1或目录1] [文件2或目录2] 常用参数\n-c 上下文模式，显示全部内文，并标出不同之处 -u 统一模式，以合并的方式来显示文件内容的不同 -a 只会逐行比较文本文件 -N 在比较目录时，若文件 A 仅出现在某个目录中，预设会显示：Only in 目录。若使用 -N 参数，则 diff 会将文件 A 与一个空白的文件比较 -r 递归比较目录下的文件 使用实例\n1.显示 test1.txt 和 test2.txt 两个文件差异。\n1 diff test1.txt test2.txt 40.grep 命令 一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。\n命令格式\n1 grep [option] pattern file 常用参数\n-c 计算找到\u0026rsquo;搜寻字符串\u0026rsquo;（即 pattern）的次数 -i 忽略大小写的不同，所以大小写视为相同 -n 输出行号 -v 反向选择，打印不匹配的行 -r 递归搜索 \u0026ndash;color=auto 将找到的关键词部分加上颜色显示 使用实例\n1.将 /etc/passwd 文件中出现 root 的行取出来，关键词部分加上颜色显示。\n1 2 grep \u0026#34;root\u0026#34; /etc/passwd --color=auto cat /etc/passwd | grep \u0026#34;root\u0026#34; --color=auto 2.将 /etc/passwd 文件中没有出现 root 和 nologin 的行取出来。\n1 grep -v \u0026#34;root\u0026#34; /etc/passwd | grep -v \u0026#34;nologin\u0026#34; 41.wc 命令 用来显示文件所包含的行、字和字节数。\n命令格式\n1 wc [选项] [文件] 常用参数\n-c 统计字节数 -l 统计行数 -m 统计字符数，这个标志不能与 -c 标志一起使用 -w 统计字数，一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度 使用实例\n1.统计文件的字节数、行数和字符数。\n1 2 3 wc -c test.txt wc -l test.txt wc -m test.txt 2.统计文件的字节数、行数和字符数，只打印数字，不打印文件名。\n1 2 3 cat test.txt | wc -c cat test.txt | wc -l cat test.txt | wc -m 42.ps 命令 用来显示当前进程的状态。\n命令格式\n1 ps[参数] 常用参数\na 显示所有进程 -a 显示同一终端下的所有程序 -A 显示所有进程 c 显示进程的真实名称 -N 反向选择 -e 等于-A e 显示环境变量 f 显示程序间的关系 -H 显示树状结构 r 显示当前终端的进程 T 显示当前终端的所有程序 u 指定用户的所有进程 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -C\u0026lt;命令\u0026gt; 列出指定命令的状况 \u0026ndash;lines\u0026lt;行数\u0026gt; 每页显示的行数 \u0026ndash;width\u0026lt;字符数\u0026gt; 每页显示的字符数 使用实例\n1.显示所有进程信息。\n1 ps -A 显示指定用户信息。\n1 ps -u root 显示所有进程信息，连同命令行。\n1 ps -ef 43.watch 命令\n可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令。\n命令格式\n1 watch [参数] [命令] 常用参数\n-n或\u0026ndash;interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d或\u0026ndash;differences 用-d或\u0026ndash;differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 -h, \u0026ndash;help 查看帮助文档 使用实例\n1.每隔一秒高亮显示网络链接数的变化情况\n1 watch -n 1 -d netstat -ant 2.每隔一秒高亮显示http链接数的变化情况\n1 watch -n 1 -d \u0026#39;pstree|grep http\u0026#39; 44.at 命令 在一个指定的时间执行一个指定任务，只能执行一次。（需开启atd进程）\n命令格式\n1 at [参数] [时间] 常用参数\n-m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出 -I atq的别名 -d atrm的别名 -v 显示任务将被执行的时间 -c 打印任务的内容到标准输出 -V 显示版本信息 -q\u0026lt;列队\u0026gt; 使用指定的列队 -f\u0026lt;文件\u0026gt; 从指定文件读入任务而不是从标准输入读入 -t\u0026lt;时间参数\u0026gt; 以时间参数的形式提交要运行的任务 使用实例\n1.3天后的下午5点执行/bin/ls\n1 2 3 at 5pm+3 days at\u0026gt; /bin/ls at\u0026gt; \u0026lt;EOT\u0026gt; 45.crontab 命令 在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。(需开启crond服务)\n命令格式\n1 2 crontab [-u user] file 或 crontab [-u user] [ -e | -l | -r ] 常用参数\n-u user：用来设定某个用户的crontab服务，例如，-u ixdba表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。 file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i：在删除用户的crontab文件时给确认提示。 使用实例\n1.列出 crontab 文件。\n1 crontab -l 2.编辑crontab 文件。\n1 crontab -e Crontab 任务实例\n1.每1分钟执行一次command\n1 * * * * * command 2.每小时的第3和第15分钟执行\n1 3,15 * * * * command 3.在上午8点到11点的第3和第15分钟执行\n1 3,15 8-11 * * * command ","permalink":"https://WFUing.github.io/posts/tech/os/linux-instructions/","summary":"Linux 的命令确实非常多，然而熟悉 Linux 的人从来不会因为 Linux 的命令太多而烦恼。因为我们仅仅只需要掌握常用命令，就完全可以驾驭 Linux。\n接下来，让我们一起来看看都有那些常用的 Linux 命令吧！\n一、文件目录操作 1.ls 命令 ls 命令不仅可以查看 linux 文件夹包含的文件而且可以查看文件权限（包括目录、文件夹、文件权限）查看目录信息等等。\n命令格式\n1 ls [选项][目录名] 常用参数\n-l ：列出长数据串，包含文件的属性与权限数据等 -a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用） -d ：仅列出目录本身，而不是列出目录的文件数据 -h ：将文件容量以较易读的方式（GB，kB等）列出来 -R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来 使用实例\n1.列出 home 目录下的所有文件和目录的详细资料。\n1 2 ls -a -l /home ls -al /home 2.列出当前目录下所有以\u0026quot;d\u0026quot;开头的文件目录详情内容。\n1 ls -l d* 2.cd命令 最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。用于切换当前目录至dirName。\n命令格式\n1 cd [目录名] 操作案例\n1.从当前目录进入系统根目录。\n1 cd / 2.跳转到 home/Code 目录。\n1 cd /home/Code 3.pwd 命令 查看\u0026quot;当前工作目录\u0026quot;的完整路径。","title":"45 个常用Linux 命令，让你轻松玩转Linux！"},{"content":"Six strategies for getting better results Write clear instructions GPT 无法读懂你的心思。如果产出太长，请要求简短回复。如果结果太简单，要求专家级的写作。如果您不喜欢格式，请演示您希望看到的格式。GPT 越少需要猜测你想要什么，你就越有可能得到它。\n在您的询问中包含详细信息，以获得更多相关答案：为了得到高度相关的回复，请确保请求提供了任何重要的细节或上下文。否则，您就只能让模型来猜测您的意思了。 要求模特采用一个角色：系统信息可用于指定模型在回复中使用的角色。 使用分隔符清楚标明输入内容的不同部分：三引号、XML 标记、章节标题等分隔符可以帮助划分需要区别对待的文本部分。 指定完成任务所需的步骤：有些任务最好以一连串的步骤来指定。明确写出这些步骤可以让模型更容易地遵循它们。 举例说明：提供适用于所有示例的一般说明通常比通过示例演示任务的所有排列组合更有效，但在某些情况下，提供示例可能更容易。例如，如果您打算让模型复制一种难以明确描述的回应用户询问的特定风格，这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。 指定所需的输出长度：您可以要求模型生成具有给定目标长度的输出。可以用字数、句数、段落数、要点数等来指定目标输出长度。但请注意，指示模型生成特定字数的精确度并不高。模型可以更可靠地生成具有特定段落数或要点数的输出结果。 Provide reference text GPT 可以自信地编造虚假答案，尤其是在被问及深奥的话题或引用和 URL 时。就像一张笔记能帮助学生在考试中取得更好的成绩一样，为 GPT 提供参考文本也能帮助他们在作答时减少无中生有的情况。\n指导模型使用参考文本作答：如果我们能为模型提供与当前查询相关的可信信息，那么我们就可以指示模型使用所提供的信息来撰写答案。 指导范例引用参考文献回答问题：如果输入内容中已经补充了相关知识，那么就可以直接要求模型通过引用所提供文档中的段落来为其答案添加引文。请注意，输出中的引用可以通过所提供文档中的字符串匹配进行编程验证。 Split complex tasks into simpler subtasks 在软件工程中，将一个复杂的系统分解成一系列模块化组件是一种很好的做法，提交给 GPT 的任务也是如此。复杂任务的错误率往往高于简单任务。此外，复杂任务通常可以重新定义为较简单任务的工作流程，其中前期任务的输出被用于构建后期任务的输入。\n使用意图分类来确定与用户查询最相关的指令：对于需要大量独立指令集来处理不同情况的任务，首先对查询类型进行分类，并利用该分类来确定需要哪些指令，可能会有所帮助。这可以通过定义固定类别和硬编码与处理特定类别任务相关的指令来实现。这一过程也可以递归应用，将任务分解为一系列阶段。这种方法的优势在于，每次查询只包含执行任务下一阶段所需的指令，与使用单次查询执行整个任务相比，错误率更低。这还可以降低成本，因为运行较大的提示需要花费更多的成本。 对于需要冗长对话的对话应用程序，总结或过滤之前的对话：由于 GPT 的上下文长度是固定的，因此用户和助手之间的对话（整个对话都包含在上下文窗口中）不可能无限期地进行下去。解决这个问题有多种变通方法，其中之一就是总结对话中的前几轮对话。一旦输入的大小达到预定的阈值长度，就会触发一个对部分对话进行总结的查询，而之前对话的总结可以作为系统消息的一部分。或者，也可以在整个对话过程中在后台异步总结之前的对话。 对长文档进行分块摘要，并递归构建完整摘要：由于 GPT 有固定的上下文长度，因此在单次查询中，GPT 无法用于摘要长度超过上下文长度减去生成摘要长度的文本。 Give GPTs time to \u0026ldquo;think\u0026rdquo; 如果要求你用 17 乘以 28，你可能不会马上知道，但花点时间还是能算出来的。同样，GPT 学生在试图立即回答而不是花时间推理出答案时，会犯更多的推理错误。在回答问题之前，要求学生进行一连串的推理，可以帮助 GPT 学生更可靠地推理出正确答案。\n在匆忙得出结论之前，指示模型自己找出解决方案：如果我们明确指示模型在得出结论之前先从第一性原理进行推理，会得到更好的结果。例如，假设我们想要一个模型来评估学生对数学问题的解答。最明显的方法是简单地问模型学生的解法是否正确。 使用内心独白或一系列查询来隐藏模型的推理过程：前面的策略表明，在回答具体问题之前，模型有时必须对问题进行详细推理。对于某些应用，模型得出最终答案的推理过程不宜与用户共享。例如，在辅导应用中，我们可能希望鼓励学生自己找出答案，但模型对学生解决方案的推理过程可能会向学生透露答案。内心独白是一种可以用来缓解这种情况的策略。内心独白的原理是指示模型将输出结果中不对用户公开的部分转化为结构化格式，以便于解析。然后，在向用户展示输出结果之前，先对输出结果进行解析，只让部分输出结果可见。 Use external tools 向 GPT 提供其他工具的输出结果，弥补 GPT 的不足。例如，文本检索系统可以告诉 GPT 相关文档的信息。代码执行引擎可以帮助 GPT 进行数学运算和运行代码。如果某项任务可以通过工具而不是 GPT 更可靠或更高效地完成，那么就将其卸载，以获得两者的最佳效果。\n利用嵌入式搜索实现高效知识检索：如果将外部信息源作为输入的一部分，模型可以利用外部信息源。这可以帮助模型生成更多信息和最新回复。例如，如果用户询问有关特定电影的问题，那么在模型输入中添加有关电影的高质量信息（如演员、导演等\u0026hellip;\u0026hellip;）可能会很有用。嵌入可用于实现高效的知识检索，以便在运行时将相关信息动态添加到模型输入中。文本嵌入是一个可以衡量文本字符串之间相关性的向量。相似或相关的字符串会比不相关的字符串靠得更近。这一事实以及快速向量搜索算法的存在，意味着嵌入可以用来实现高效的知识检索。特别是，文本语料库可以分割成若干块，每个块都可以嵌入和存储。然后，可以嵌入给定的查询，并执行矢量搜索，从语料库中找到与查询最相关的嵌入文本块（即在嵌入空间中最接近的文本块）。 使用代码执行来执行更精确的计算或调用外部应用程序接口：不能依靠 GPT 自行准确执行算术运算或长时间计算。在需要的情况下，可以指示模型编写和运行代码，而不是自己进行计算。特别是，可以指示模型将需要运行的代码放入指定格式（如三重回溯）中。产生输出后，可提取并运行代码。最后，如有必要，可将代码执行引擎（即 Python 解释器）的输出作为下一次查询的模型输入。 让模型访问特定功能：聊天完成 API 允许在请求中传递函数描述列表。这样，模型就能根据提供的模式生成函数参数。生成的函数参数由 API 以 JSON 格式返回，可用于执行函数调用。然后，函数调用提供的输出可以在下一个请求中反馈到模型中，以结束循环。这是使用 GPT 模型调用外部函数的推荐方式。 Test changes systematically 如果能对性能进行测量，提高性能就会变得更容易。在某些情况下，对提示符的修改会在一些孤立的示例上取得更好的性能，但在更具代表性的示例集上却会导致整体性能下降。因此，为了确保修改对性能的净积极影响，可能有必要定义一个综合测试套件（也称为 \u0026ldquo;评估\u0026rdquo;）。\nResources https://platform.openai.com/docs/guides/gpt-best-practices https://github.com/mattnigh/ChatGPT3-Free-Prompt-List https://style.mla.org/citing-generative-ai/ ","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/chatgpt-guide/","summary":"Six strategies for getting better results Write clear instructions GPT 无法读懂你的心思。如果产出太长，请要求简短回复。如果结果太简单，要求专家级的写作。如果您不喜欢格式，请演示您希望看到的格式。GPT 越少需要猜测你想要什么，你就越有可能得到它。\n在您的询问中包含详细信息，以获得更多相关答案：为了得到高度相关的回复，请确保请求提供了任何重要的细节或上下文。否则，您就只能让模型来猜测您的意思了。 要求模特采用一个角色：系统信息可用于指定模型在回复中使用的角色。 使用分隔符清楚标明输入内容的不同部分：三引号、XML 标记、章节标题等分隔符可以帮助划分需要区别对待的文本部分。 指定完成任务所需的步骤：有些任务最好以一连串的步骤来指定。明确写出这些步骤可以让模型更容易地遵循它们。 举例说明：提供适用于所有示例的一般说明通常比通过示例演示任务的所有排列组合更有效，但在某些情况下，提供示例可能更容易。例如，如果您打算让模型复制一种难以明确描述的回应用户询问的特定风格，这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。 指定所需的输出长度：您可以要求模型生成具有给定目标长度的输出。可以用字数、句数、段落数、要点数等来指定目标输出长度。但请注意，指示模型生成特定字数的精确度并不高。模型可以更可靠地生成具有特定段落数或要点数的输出结果。 Provide reference text GPT 可以自信地编造虚假答案，尤其是在被问及深奥的话题或引用和 URL 时。就像一张笔记能帮助学生在考试中取得更好的成绩一样，为 GPT 提供参考文本也能帮助他们在作答时减少无中生有的情况。\n指导模型使用参考文本作答：如果我们能为模型提供与当前查询相关的可信信息，那么我们就可以指示模型使用所提供的信息来撰写答案。 指导范例引用参考文献回答问题：如果输入内容中已经补充了相关知识，那么就可以直接要求模型通过引用所提供文档中的段落来为其答案添加引文。请注意，输出中的引用可以通过所提供文档中的字符串匹配进行编程验证。 Split complex tasks into simpler subtasks 在软件工程中，将一个复杂的系统分解成一系列模块化组件是一种很好的做法，提交给 GPT 的任务也是如此。复杂任务的错误率往往高于简单任务。此外，复杂任务通常可以重新定义为较简单任务的工作流程，其中前期任务的输出被用于构建后期任务的输入。\n使用意图分类来确定与用户查询最相关的指令：对于需要大量独立指令集来处理不同情况的任务，首先对查询类型进行分类，并利用该分类来确定需要哪些指令，可能会有所帮助。这可以通过定义固定类别和硬编码与处理特定类别任务相关的指令来实现。这一过程也可以递归应用，将任务分解为一系列阶段。这种方法的优势在于，每次查询只包含执行任务下一阶段所需的指令，与使用单次查询执行整个任务相比，错误率更低。这还可以降低成本，因为运行较大的提示需要花费更多的成本。 对于需要冗长对话的对话应用程序，总结或过滤之前的对话：由于 GPT 的上下文长度是固定的，因此用户和助手之间的对话（整个对话都包含在上下文窗口中）不可能无限期地进行下去。解决这个问题有多种变通方法，其中之一就是总结对话中的前几轮对话。一旦输入的大小达到预定的阈值长度，就会触发一个对部分对话进行总结的查询，而之前对话的总结可以作为系统消息的一部分。或者，也可以在整个对话过程中在后台异步总结之前的对话。 对长文档进行分块摘要，并递归构建完整摘要：由于 GPT 有固定的上下文长度，因此在单次查询中，GPT 无法用于摘要长度超过上下文长度减去生成摘要长度的文本。 Give GPTs time to \u0026ldquo;think\u0026rdquo; 如果要求你用 17 乘以 28，你可能不会马上知道，但花点时间还是能算出来的。同样，GPT 学生在试图立即回答而不是花时间推理出答案时，会犯更多的推理错误。在回答问题之前，要求学生进行一连串的推理，可以帮助 GPT 学生更可靠地推理出正确答案。\n在匆忙得出结论之前，指示模型自己找出解决方案：如果我们明确指示模型在得出结论之前先从第一性原理进行推理，会得到更好的结果。例如，假设我们想要一个模型来评估学生对数学问题的解答。最明显的方法是简单地问模型学生的解法是否正确。 使用内心独白或一系列查询来隐藏模型的推理过程：前面的策略表明，在回答具体问题之前，模型有时必须对问题进行详细推理。对于某些应用，模型得出最终答案的推理过程不宜与用户共享。例如，在辅导应用中，我们可能希望鼓励学生自己找出答案，但模型对学生解决方案的推理过程可能会向学生透露答案。内心独白是一种可以用来缓解这种情况的策略。内心独白的原理是指示模型将输出结果中不对用户公开的部分转化为结构化格式，以便于解析。然后，在向用户展示输出结果之前，先对输出结果进行解析，只让部分输出结果可见。 Use external tools 向 GPT 提供其他工具的输出结果，弥补 GPT 的不足。例如，文本检索系统可以告诉 GPT 相关文档的信息。代码执行引擎可以帮助 GPT 进行数学运算和运行代码。如果某项任务可以通过工具而不是 GPT 更可靠或更高效地完成，那么就将其卸载，以获得两者的最佳效果。","title":"chatGPT 使用指南"},{"content":"Resources github：https://github.com/fatedier/frp document：https://gofrp.org/docs/ finalshell：https://sourceforge.net/projects/finalshell/ vscode remote ssh：https://code.visualstudio.com/docs/remote/ssh 下面给出一些blog，都详细写了如何使用frp搭建内网穿透，在本文中就不再赘述。\n使用frp进行内网穿透：https://sspai.com/post/52523 基于frp docker 进行内网穿透：https://izhaong.com/pages/b387de/ CentOS7下通过frp做内网穿透：https://blog.fengdis.com/2019/12/25/CentOS%E4%B8%8B%E9%80%9A%E8%BF%87frp%E5%81%9A%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/ 这一篇blog的05节写了遇到的常见问题，这也是本文关心的。\n常见问题：https://www.derrors.cn/index.php/it-tech/frp.html Questions 大部分都是网络端口上的问题，下面先给出一张frp的原理图。\nssh: connect to host xx.xx.xx.xx port xx: Operation timed out\n使用ssh连接时，连接超时 原因：服务器防火墙未开放frp配置中对应的remote_port端口； 解决：在服务器的防火墙中开放相应端口。 ssh: connect to host xx.xx.xx.xx port xx: Connection refused\n连接被拒绝 原因：服务器防火墙未开放frp配置中对应的server_port端口； 解决：在服务器的防火墙中开放相应端口。 当然云服务器端，也会有安全组或者防火墙，需要把相应的都开起来\n1 2 3 4 5 6 7 8 9 #开放端口 firewall-cmd --zone=public --add-port=7000/tcp --permanent firewall-cmd --zone=public --add-port=6000/tcp --permanent #查看开放端口列表 firewall-cmd --permanent --zone=public --list-ports #防火墙reload firewall-cmd --reload firewalld 拓展 这边很多的问题都跟防火墙有关系，这边给出 firewalld 的相关指令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 source: 根据源地址过滤（优先级最高） interface: 根据网卡过滤（优先级次高） service: 根据服务名过滤 port: 根据端口过滤 icmp-block: icmp 报文过滤，按照 icmp 类型配置 masquerade: ip 地址伪装 forward-port: 端口转发 rule: 自定义规则 # 查看是否开启 systemctl status firewalld.service # 打开防火墙 systemctl start firewalld.service # 停用防火墙 systemctl disable firewalld # 禁用防火墙 systemctl stop firewalld.service # 开机启动 systemctl enable firewalld # 取消开机启动 systemctl disable firewalld # 查看运行状态 firewall-cmd --state # 查看接口信息 firewall-cmd --list-all # 更新防火墙规则方法1:无需断开连接，动态更改规则 firewall-cmd --reload # 更新防火墙规则方法2:断开连接，以重启的方式更改规则 firewall-cmd --complete-reload # 查看帮助 firewall-cmd --help --zone=NAME # 指定 Zone --permanent # 为永久生效 --timeout=seconds # 持续一段时间，到期后自动移除，经常用于调试，且不能与 --permanent 同时使用 # 追加一个8181端口，永久有效 firewall-cmd --add-port=8181/tcp --permanent # 追加一段端口范围 firewall-cmd --add-port=6000-6600/tcp # 开放 ftp 服务 firewall-cmd --add-service=ftp # 添加eth0 接口至 public 信任等级，永久有效 firewall-cmd --zone=public --add-interface=eth0 --permanent # 关闭防火墙 sudo systemctl stop firewalld # 关闭端口 sudo firewall-cmd --remove-port=3000/tcp --permanent # 配置 public zone 的端口转发 firewall-cmd --zone=public --add-masquerade # 然后转发 tcp 22 端口至 9527 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=9527 # 转发 22 端口数据至另一个 ip 的相同端口上 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toaddr=192.168.1.123 # 转发 22 端口数据至另一 ip 的 9527 端口上 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=9527:toaddr=192.168.1.100 # IP 封禁 firewall-cmd --permanent --add-rich-rule=\u0026#34;rule family=\u0026#39;ipv4\u0026#39; source address=\u0026#39;192.168.1.123\u0026#39; reject\u0026#34; # 通过 ipset 来封禁 ip firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:ip firewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=192.168.1.123 # 封禁网段 firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:net firewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=192.168.1.0/24 # 倒入 ipset 规则 blacklist，然后封禁 blacklist firewall-cmd --permanent --zone=public --new-ipset-from-file=/path/blacklist.xml firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#39;rule source ipset=blacklist drop\u0026#39; ","permalink":"https://WFUing.github.io/posts/tech/network/frp-nat-traversal/","summary":"Resources github：https://github.com/fatedier/frp document：https://gofrp.org/docs/ finalshell：https://sourceforge.net/projects/finalshell/ vscode remote ssh：https://code.visualstudio.com/docs/remote/ssh 下面给出一些blog，都详细写了如何使用frp搭建内网穿透，在本文中就不再赘述。\n使用frp进行内网穿透：https://sspai.com/post/52523 基于frp docker 进行内网穿透：https://izhaong.com/pages/b387de/ CentOS7下通过frp做内网穿透：https://blog.fengdis.com/2019/12/25/CentOS%E4%B8%8B%E9%80%9A%E8%BF%87frp%E5%81%9A%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/ 这一篇blog的05节写了遇到的常见问题，这也是本文关心的。\n常见问题：https://www.derrors.cn/index.php/it-tech/frp.html Questions 大部分都是网络端口上的问题，下面先给出一张frp的原理图。\nssh: connect to host xx.xx.xx.xx port xx: Operation timed out\n使用ssh连接时，连接超时 原因：服务器防火墙未开放frp配置中对应的remote_port端口； 解决：在服务器的防火墙中开放相应端口。 ssh: connect to host xx.xx.xx.xx port xx: Connection refused\n连接被拒绝 原因：服务器防火墙未开放frp配置中对应的server_port端口； 解决：在服务器的防火墙中开放相应端口。 当然云服务器端，也会有安全组或者防火墙，需要把相应的都开起来\n1 2 3 4 5 6 7 8 9 #开放端口 firewall-cmd --zone=public --add-port=7000/tcp --permanent firewall-cmd --zone=public --add-port=6000/tcp --permanent #查看开放端口列表 firewall-cmd --permanent --zone=public --list-ports #防火墙reload firewall-cmd --reload firewalld 拓展 这边很多的问题都跟防火墙有关系，这边给出 firewalld 的相关指令。","title":"Frp Nat Traversal"},{"content":"Resources url: https://www.telosys.org/ tutorial: https://tomassetti.me/telosys-code-generation-tool/ ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/telosys-code-generation-tool/","summary":"Resources url: https://www.telosys.org/ tutorial: https://tomassetti.me/telosys-code-generation-tool/ ","title":"Telosys: a Code Generation Tool by Laurent Guerin"},{"content":"什么是 DevOps 什么是 DevOps？DevOps 集文化理念、实践和工具于一身，它强调团队授权、跨团队沟通和协作以及技术自动化，其最终目标是优化质量和交付。\nDevOps 理念，旨在打破开发工程师和运维工程师的壁垒，强调两个团队合而为一，在产品的整个生命周期（从开发、测试、部署再到运维、运营）内相互协作，工程师不再限于单一职能。\nDevOps 始于 2007 年左右，当时的开发和运维对传统的软件开发模式提出了担忧：在这种模式下，编写代码的开发人员与负责部署的运维人员分开工作。 DevOps 一词是开发（development）和运维（operations）这两个词的组合，反映了将二者合而为一的过程。\nDevOps 如何工作 DevOps 团队包括在整个产品生命周期中协同工作的开发人员和运维人员，以提高软件部署的速度和质量。这是一种新的工作方式，一种文化转变，对团队及其工作的组织具有重要意义。\n在 DevOps 模型下，开发和运维团队不再 \u0026ldquo;孤立\u0026rdquo;。有时，这两个团队甚至会合并为一个团队，工程师在整个应用程序生命周期中工作，需要具备从开发、测试到部署和运维的复合型能力。\nDevOps 团队使用工具来自动化和优化流程，这有助于提高可靠性。 DevOps 工具链可帮助团队处理重要的 DevOps 基础知识，包括持续集成、持续交付、自动化和协作。\nDevOps 价值观也适用于开发以外的团队。如果 QA、安全团队也和开发、运维团队紧密地结合在一起，贯穿产品的整个生命周期。此时，安全成为了所有 DevOps 团队成员的工作重点，此时可以称为为 \u0026ldquo;DevSecOps\u0026rdquo;。\nDevOps 的生命周期 由于 DevOps 的连续性，可以使用无限循环来展示 DevOps 生命周期的各个阶段是如何相互关联的。尽管看起来是按顺序流动的，但循环象征着在整个生命周期中始终保持持续迭代。\nDevOps 生命周期由六个阶段组成，分别代表开发和运维所需的流程、功能和工具。在每个阶段，团队协作和沟通以保持一致性、速度和质量。\nDevOps 的优势 速度：应用 DevOps 可以更频繁地发布可交付成果，并且质量和稳定性也更高。高效的迭代，可以根据客户和市场反馈进行快速响应，以适应市场变化，有效推动业务发展。 促进协作：DevOps 的基础是开发和运维之间的协作文化，两个团队紧密协作，共同承担诸多责任，并将各自的工作流程相互融合。这有助于减少效率低下的工作，同时节约大家的时间。 快速发布：提高发布的频率和速度，以便能够更快速地进行创新并完善产品。您发布新功能和修复错误的速度越快，就越能快速地响应客户需求并建立竞争优势。持续集成和持续交付是自动执行软件发布流程（从构建到部署）的两项实践经验。 可靠性：持续集成和持续部署等实践可检验程序变更后，功能是否正常，是否安全，从而提高软件产品的交付质量。监控和日志记录可以帮助团队实时了解服务当前的运行状态。 规模：大规模运行和管理您的基础设施及开发流程。自动化和一致性可在降低风险的同时，帮助您有效管理复杂或不断变化的系统。例如，基础设施即代码能够帮助您以一种可重复且更有效的方式来管理部署、测试和生产环境。 安全性：通过将自动实施的合规性策略、精细控制和配置管理技术集成到敏捷开发和 DevOps 工作流程中，使得产品内置了安全性。 DevOps 工具 DevOps 各生命周期阶段都有合适的工具可以作为解决方案。它们通过提高协作效率、减少上下文切换、引入自动化以及实现可监控来全方位增强 DevOps 实践。\nDevOps 工具链通常遵循两种模式：完整解决方案或开放式工具链。\n完整解决方案实现了端到端的交付，流程很完备，但是一般难以兼容、集成第三方工具。 开放式工具链允许使用不同的工具进行定制。 这两种方法各有利弊。\n这里列举一些常见的 DevOps 工具：\n项目管理：Jira 文档管理：Confluence 代码管理：Gitlab、Github CI/CD：Gitlab、Jenkins 容器 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 Kubernetes 是谷歌开源的容器集群管理系统 是用于自动部署，扩展和管理 Docker 应用程序的开源系统，简称 K8S。 日志 ELK 技术栈，通过数据采集工具 Logstack、Beats 套件、日志存储、解析服务 ElasticSearch、日志可视化工具 Kibnana，形成了一套完整的端到端日志解决方案，深受业界好评。 监控 ELK 的技术栈比较成熟，应用范围也比较广，除了可用作监控系统外，还可以用作日志查询和分析。 Prometheus 的独特之处在于它采用了拉数据的方式，对业务影响较小，同时也采用了时间序列数据库存储，而且支持独有的 PromQL 查询语言，功能强大而且简洁。 Grafana 是流行的监控数据分析和可视化套件。 Graphite 是基于时间序列数据库存储的监控系统，并且提供了功能强大的各种聚合函数比如 sum、average、top5 等可用于监控分析，而且对外提供了 API 也可以接入其他图形化监控系统如 Grafana。 链路追踪 Zipkin：Zipkin 是 Twitter 开源的调用链分析工具，目前基于 spring-cloud-sleuth 得到了广泛的使用，特点是轻量，使用、部署简单。 Pinpoint：是韩国人开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点是支持多种插件，UI 功能强大，接入端无代码侵入。 SkyWalking：是本土开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点是支持多种插件，UI 功能较强，接入端无代码侵入。目前已加入 Apache 孵化器。 CAT：CAT 是美团点评开源的基于编码和配置的调用链分析，应用监控分析，日志采集，监控报警等一系列的监控平台工具。 负载均衡 Nginx 可以作为四层或七层负载均衡器。 LVS 可以作为四层负载均衡器。其负载均衡的性能要优于 Nginx。 HAProxy 可以作为 HTTP 和 TCP 负载均衡器。 F5 作为硬件负载均衡 A10 作为硬件负载均衡 网关 Kong 是一个云原生、快速、可扩展和分布式的微服务抽象层（也称为 API 网关，API 中间件）。 Zuul 是 Netflix 开源的一个 API 网关，Zuul 在云平台上提供动态路由，监控，弹性，安全等边缘服务的框架。 告警：短信、邮件、企业聊天软件、OA 参考资料 【Youtube 视频】What is DevOps? - In Simple English 【Youtube 视频】DevOps In 5 Minutes DevOps: Breaking the development-operations barrier ","permalink":"https://WFUing.github.io/posts/tech/architecture/devoops/","summary":"DevOps 集文化理念、实践和工具于一身，它强调团队授权、跨团队沟通和协作以及技术自动化，其最终目标是优化质量和交付","title":"DevOps 简介"},{"content":"动态规划 【LeetCode 55】跳跃游戏 【LeetCode 72】编辑距离 【LeetCode 115】不同的子序列 【LeetCode 124】二叉树中的最大路径和 【LeetCode 174】地下城游戏 【LeetCode 188】买卖股票的最佳时机IV 【LeetCode 198】打家劫舍 【LeetCode 213】打家劫舍II 【LeetCode 233】数字1的个数 【LeetCode 300】最长递增子序列 【LeetCode 309】最佳买卖股票时机含冷冻期 【LeetCode 312】戳气球 【LeetCode 337】打家劫舍III 【LeetCode 354】俄罗斯套娃信封问题 【LeetCode 376】摆动序列 【LeetCode 390】消除游戏 【LeetCode 689】三个无重叠子数组的最大和 【LeetCode 714】买卖股票的最佳时机含手续费 【LeetCode 907】子数组的最小值之和 【LeetCode 943】最短超级串 【LeetCode 1031】两个非重叠子数组的最大和 【LeetCode 1039】多边形三角剖分的最低得分 【LeetCode 1186】删除一次得到子数组最大和 【LeetCode 系列】买卖股票的最佳时机 【LeetCode 面试题 08.11】硬币 贪心算法 【LeetCode 55】跳跃游戏 【LeetCode 121】买卖股票的最佳时机 【LeetCode 122】买卖股票的最佳时机II 【LeetCode 123】买卖股票的最佳时机III 【LeetCode 42】接雨水 【LeetCode 135】分发糖果 ","permalink":"https://WFUing.github.io/posts/tech/algorithm/leetcode/","summary":"动态规划 【LeetCode 55】跳跃游戏 【LeetCode 72】编辑距离 【LeetCode 115】不同的子序列 【LeetCode 124】二叉树中的最大路径和 【LeetCode 174】地下城游戏 【LeetCode 188】买卖股票的最佳时机IV 【LeetCode 198】打家劫舍 【LeetCode 213】打家劫舍II 【LeetCode 233】数字1的个数 【LeetCode 300】最长递增子序列 【LeetCode 309】最佳买卖股票时机含冷冻期 【LeetCode 312】戳气球 【LeetCode 337】打家劫舍III 【LeetCode 354】俄罗斯套娃信封问题 【LeetCode 376】摆动序列 【LeetCode 390】消除游戏 【LeetCode 689】三个无重叠子数组的最大和 【LeetCode 714】买卖股票的最佳时机含手续费 【LeetCode 907】子数组的最小值之和 【LeetCode 943】最短超级串 【LeetCode 1031】两个非重叠子数组的最大和 【LeetCode 1039】多边形三角剖分的最低得分 【LeetCode 1186】删除一次得到子数组最大和 【LeetCode 系列】买卖股票的最佳时机 【LeetCode 面试题 08.11】硬币 贪心算法 【LeetCode 55】跳跃游戏 【LeetCode 121】买卖股票的最佳时机 【LeetCode 122】买卖股票的最佳时机II 【LeetCode 123】买卖股票的最佳时机III 【LeetCode 42】接雨水 【LeetCode 135】分发糖果 ","title":"Leetcode"},{"content":"DSL 和 DSL 工具的一个重要方面是代码生成。DSL 本身在形式化、指定和交流内容方面具有优势，因为它们具有特定领域的性质。但是，如果能从指定的内容中推导出实现代码，就能大大提高工作效率。\nResources blogs https://www.typefox.io/blog/code-generation-for-langium-based-dsls/ https://www.typefox.io/blog/code-generation-for-langium-based-dsls-2 https://www.typefox.io/blog/code-generation-for-langium-based-dsls-3/ github repo: https://github.com/TypeFox/langium-in-browser-codegen-example/tree/main https://github.com/eclipse-langium/langium/blob/main/examples/arithmetics 运行示例 本帖中的运行示例使用 Langium 的 Arithmetics 示例实现。Arithmetics 的 grammar 见 arithmetics.langium\n代码生成器的输入示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 MODULE priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; DEF costPerUnit: materialPerUnit + laborPerUnit; DEF expectedNoOfSales: 200; DEF costOfGoodsSold: expectedNoOfSales * costPerUnit; DEF generalExpensesAndSales: 10000; DEF desiredProfitPerUnit: 50; DEF netPrice: (costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales + desiredProfitPerUnit; DEF vat: 0.15; DEF calcGrossListPrice(net, tax): net / (1 - tax); calcGrossListPrice(netPrice, vat); 本模块介绍一种非常简单的产品价格计算方法。它包括给变量分配常量值和计算值。最后，一个名为 calcGrossListPrice 的函数被调用，参数是之前定义的 netPrice 和 tax。下图展示了 Langium 在解析输入时创建的抽象语法树（AST）。\n现在，让我们将其转化为纯 JavaScript 代码。为了合成所需的代码段，生成器需要访问 AST 并检查相应的部分。让我们通过一个纯 JavaScript 模板来定义生成器的入口函数，如下所示，它会贡献一些静态框架代码：\n1 2 3 4 5 6 7 8 function generateModule(root: Module): string { return ` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 让我们也定义 generateModuleContent(Module) 并按如下方式实现它，由于需要循环，所以这次使用经典的字符串连接：\n1 2 3 4 5 6 7 8 9 function generateModuleContent(module: Module): string { let result = `let ${lastComputableExpressionValueVarName};\\n`; for (const s of module.statements) { result += generateStatement(s) + \u0026#39;\\n\u0026#39;; } result += `\\n` result += `return ${lastComputableExpressionValueVarName};`; return result; } 问题 1：对于多行模板文字，生成的代码将包含由 ········ 在 generateModule() 中指示的空白。我添加了空白，以使生成器符合我们的格式规则。\n缺点：会使生成结果变得混乱。\n问题 2：访问列表时，我们必须在每个语句的生成片段后插入换行符。此外，我们还必须注意 for 循环前后的换行符。最后，还有 \\n 与 \\r\\n 的问题。\n虽然这个问题在这里很简单，但如果出现有条件附加的代码段或者连续多个循环，就会变得相当困难。\n问题 3：generateModuleContent() 中的字符串连接没有注意 generateModule() 中调用该函数之前的缩进。\n生成的代码将如下所示，具体取决于 generateStatement() 的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; . . . return lastComputableExpressionValue; ········}) .... 这个示例很好地说明了生成代码中的缩进是如何出错的。周围的静态代码缩进了，但不应该缩进，而括弧中的语句没有缩进，但应该缩进。\nSolution A: Smart tagged templates Solution A：Langium 提供了一个名为 expandToString 的标签函数，可智能处理空白。\n在 generateModule(Module) 第 2 行的开头回车之前直接插入 expandToString 引用，可将后续模板转换为标记模板，请参见 generateModule2(Module)：\n1 2 3 4 5 6 7 8 9 10 import { expandToString } from \u0026#39;langium\u0026#39;; function generateModule2(root: Module): string { return expandToString` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 这样就得到了下面的生成结果：\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;use strict\u0026#34;; (() =\u0026gt; { let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; . . . return lastComputableExpressionValue; }) expandToString 实现以下这些功能：\n在模板的所有非空行中识别和修剪共同的前导空格 确定用 ${} 包装的表达式的偏移量 修剪 single leading and trailing line breaks 合并模板内的换行符 因此，\n功能 1 删除了生成模块 2(Module) 中由 ········ 表示的空白，这使得静态代码从偏移量 0 开始，即生成时没有任何缩进。 功能 2 将 ${generateModuleContent(root)} 行内的额外缩进 (␣␣) 应用到替换字符串中的每一行。在我们的示例中，这将产生正确缩进的语句实现片段，而缩进只需指定一次。 功能 3 丢弃了紧随开头回车符之后的初始换行符，以及包括结尾回车符缩进在内的尾部换行符。这与生成器入口函数（如 generateModule2(Module)）关系不大，但与从其他标记模板（如 generateModuleContent(Module)）中调用的生成器函数（如 generateModuleContent(Module)）非常相关，因为周围的换行符将由调用模板决定。最后但并非最不重要的一点是， 功能 4 使所有换行符都与系统换行符一致。这一点非常可取，因为生成的代码通常会被持久化到磁盘上，并希望与平台保持一致。 现在，让我们再来看看 generateModuleContent(Module) 模块：\n1 2 3 4 5 6 7 8 9 function generateModuleContent(module: Module): string { let result = `let ${lastComputableExpressionValueVarName};\\n`; for (const s of module.statements) { result += generateStatement(s) + \u0026#39;\\n\u0026#39;; } result += `\\n` result += `return ${lastComputableExpressionValueVarName};`; return result; } 将循环重写为 map;join 表达式后，我们就可以使用标记模板和 expandToString 来实现字符串连接，如下所示：\n1 2 3 4 5 6 7 8 function generateModuleContent2(module: Module): string { return expandToString` let ${lastComputableExpressionValueVarName}; ${ module.statements.map(generateStatement).join(\u0026#39;\\n\u0026#39;) } return ${lastComputableExpressionValueVarName}; `; } 连接操作中的分隔符会被功能 4 expandToString 处理，如果在 MS Windows 机器上执行，它会用 \\r\\n 替换单个 \\n。\n我们上面的价格计算示例的整个输出结果可能如下，我在这里跳过了缺失的生成器部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026#34;use strict\u0026#34;; (() =\u0026gt; { let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; const expectedNoOfSales = lastComputableExpressionValue = 200; const costPerUnit = lastComputableExpressionValue = materialPerUnit + laborPerUnit; const costOfGoodsSold = lastComputableExpressionValue = expectedNoOfSales * costPerUnit; const generalExpensesAndSales = lastComputableExpressionValue = 10000; const desiredProfitPerUnit = lastComputableExpressionValue = 50; const netPrice = lastComputableExpressionValue = ((costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales) + desiredProfitPerUnit; const vat = lastComputableExpressionValue = 0.15; const calcGrossListPrice = (net, tax) =\u0026gt; net / (1 - tax); lastComputableExpressionValue = calcGrossListPrice( netPrice, vat ); return lastComputableExpressionValue; }) 除了普通关键字、标识符和运算符的连接外，我的生成器还插入了典型的括号复合表达式，比如在计算 netPrice 的值时。此外，像 calcGrossListPrice 这样的函数调用会在多行中生成，从而使参数更易于阅读。\n结论：如果我们想使用 JavaScript 模板表达式而不是普通的字符串连接来实现代码生成器，如果我们想获得正确格式化的生成代码以及正确格式化的模板，那么 expandToString 将为我们提供极大的帮助。\n备注：重要的是要保持模板行缩进一致，特别是不要混合使用制表符和空格！VS 代码提供了一个显示空白字符的便捷选项，名为 Toggle Render Whitespace。\nSolution B: two stage code generation 试想一下，如果某些行后没有添加内容，您希望跳过这些行的换行符。试想一下，您需要对代码片段的缩进进行配置，或者需要对生成的代码进行后处理和调整，以满足特定条件。在生成 Java 或 JavaScript 等语言时，可以考虑添加导入子句，同时在代码中添加符号引用。生成丰富的表达式语法也可能需要比纯字符串更多的抽象。最后但并非最不重要的一点是，我们可能希望将生成的代码段与它们在文本中代表的源定义区域关联起来。这样的要求需要一种不同的方法。\n在本部分中，将重点介绍两阶段代码生成方法，并展示如何将其与 Solution A 中使用的 Tagged Templates 整合在一起。\nGeneration tree 要满足上述要求，一种可行的方法是将生成任务一分为二，并使用比字符串更具表现力的数据结构来捕获中间结果。任务 1 建立待生成代码的描述，任务 2 则渲染所需的输出结果。\n在我们的日常实践中，事实证明树状数据结构非常有用。我们定义了以下数据类型的联盟，并将其称为 Generated 类型：\n1 2 type Generated = string | GeneratorNode | undefined; type GeneratorNode = CompositeGeneratorNode | IndentNode | NewLineNode; 生成任务 1 的结果可能已经是字符串类型，例如，如果结果非常短。通常，它的类型是 GeneratorNode。此外，它还可能是 undefined 的。这在顶层没有太大意义，但在将模板的部分内容转移到子例程时却非常有用。未定义的可能结果允许这些函数向其调用者发出信号，表明该函数不会生成任何东西，这与空字符串等其他东西不同。\nCompositeGeneratorNode 实现了复合设计模式。该类型的实例是容器，可容纳一系列其他字符串和生成器节点。IndentNode 是 CompositeGeneratorNode 的特化，提供缩进信息。NewLineNode 的实例用于描述换行，它们的严格程度是可参数化的。\n在早期的 Langium 中，我们通过以编程方式合成生成器描述来构建代码生成器，例如 Langium CLI 中包含的描述。这样一来，代码生成器的实现就会被大量的 node.append(...) 或 node.children.push(...) 指令所支配，而所需生成的代码结构很快就会被混淆。\n通过 tagged templates 在 Langium v1.0 中，发布了另一个名为 expandToNode 的标签函数，也就是我们的解决方案 B。请回顾算术语言示例中的 generateModule2 示例：\n1 2 3 4 5 6 7 8 function generateModule2(root: Module): string { return expandToString` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 将标签函数替换为 expandToNode 并将返回类型更改为 Generated，就可以轻松将其转换为两阶段生成。\n1 2 3 4 5 6 7 8 function generateModule3(root: Module): Generated { return expandToNode` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent2(root)} ········}) `; } 与 expandToString 一样，模板中会自动删除 ········ 所指示的缩进。此外，还省略了开头 \\n 后的初始换行，以及结尾 \\n 前的换行和随后的空白。\n然后，必须将 generateModule3(Module) 的结果转换为字符串，这就是我上文提到的生成任务 2。为此，Langium 提供了名为 toString(unknown) 的函数。如果调用 toString 时使用了 GeneratorNode 类型的参数，它就会将该参数转换为字符串，否则就会委托 JavaScript 的默认字符串构造函数来处理。\n现在让我们看看 generateModuleContent2(Module) 的实现，这也是上次的内容：\n1 2 3 4 5 6 7 8 function generateModuleContent2(module: Module): string { return expandToString` let ${lastComputableExpressionValueVarName}; ${ module.statements.map(generateStatement).join(\u0026#39;\\n\u0026#39;) } return ${lastComputableExpressionValueVarName}; `; } 同样，我替换了上面的标记函数和返回类型。不过，我们并不想立即将语句元素的生成结果连接成一个字符串。相反，我们想为每个元素创建生成描述，并将其包含在该模板的结果中。为此，Langium 提供了 joinToNode() 函数。该函数的使用方法将在 generateModuleContent3(Module) 中进行说明：\n1 2 3 4 5 6 7 8 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; ${ joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } joinToNode 的第一个参数是一个要访问的元素集合、一个为每个元素创建生成描述的函数，以及一个可选的配置对象，用于确定分隔符或注册其他回调（如 element filter 和 prefix/suffix 提供程序）。如果输入集合为空，或者所有元素都没有生成，joinToNode 也不会返回任何结果，实际上用 undefined 来表示。\n为什么要区分 undefined ？ tl;dr：expandToNode 可以将换行符配置为可省略。如果某行的最后一个替换是未定义的或 GeneratorNode 类型的对象，它就会这样做。如果该行的剩余部分只包含空白字符，则整行将被省略，同时呈现所需的输出结果。\n1 2 3 let lastComputableExpressionValueVarName return lastComputableExpressionValueVarName; 调用 joinToNode(\u0026hellip;) 没有任何结果。不过，它的尾部换行符会被附加到生成的代码中，并产生第一个空行。然后，我们在模板中请求的空行也会被附加到生成的代码中，这样就连续生成了两行空行。不过，我个人（也许你也一样）更倾向于省略包含 joinToNode(\u0026hellip;) 调用的整行，即忽略替换后的换行。为了实现这一首选行为，expandToNode 会检查每一行是否有占位符/替换。如果包含替换，则按以下方式评估最后一个替换的值：\n如果替换值未定义或属于 GeneratorNode 类型，则配置该行的终端 NewLineNode，使其仅在前一行为非空时才显示为换行符。否则，配置 NewLineNode 为无条件换行。\n在我们的例子中，generateModuleContent3(Module) 的语句列表为空，这意味着我们将在第 1 行末尾得到一个换行符，因为该行至少包含静态字符串 let，即非空字符串。准确地说，无论其配置如何，添加到生成描述中的 NewLineNode 都会导致换行。第 2 行的占位符将解析为 undefined 的 \u0026ldquo;值\u0026rdquo;。因此，随后代表第 2 行末尾换行符的 NewLineNode 将被标记为 ifNotEmpty，如上所述。在稍后的字符串呈现过程中（任务 2），第 2 行将被评估为空，从而使结束符 NewLineNode 呈现为空。\n第 3 行仅包含一个换行符（不包含任何替换），并导致在生成描述中无条件添加一个 NewLineNode。第 4 行要求在生成说明中添加 return- 以及 lastComputableExpressionValueVarName 内容的字符串值。由于模板将在下一行关闭，因此结束符将被忽略。\n这种方法还允许对仅包含空白和可能导致 undefined 的替换的行强制执行无条件换行。只需将 ??'' 到（最后一个）替换内容中，或者在行尾再添加一个类似 ${''} 的替换。expandToNode 就会插入一个无条件的 NewLineNode。顺便说一下：后一个选项也适用于包含可能为空的 CompositeGeneratorNodes 的替换。\nBenefits 函数 expandToNode 返回 CompositeGeneratorNode 的一个实例，代表某段文本的生成描述。此类对象可任意组合，也可随意操作。元素可以添加、删除或改变顺序。此外，由于复合生成器节点（CompositeGeneratorNode）所描述的某些文本片段的具体缩进最终是在其跨容器（任务 2）的文本渲染时确定的，因此父节点和某些子节点的创建和组合可能完全独立于彼此。一个子节点甚至可能包含在同一生成描述中不同缩进级别的不同位置。此外，在要连接的字符串模板或表达式中，不再需要硬编码的换行符。\n此外，生成器实现可以在基于标记模板的实现风格和基于普通方法调用的风格之间来回切换，这取决于哪种风格最适合。由于 CompositeGeneratorNode 定义了更多的方便方法，因此这两者之间的界限并不明显。下面将提到其中一些方法，有关它们的精确定义，请参阅 Langium 代码库：\nappend(\u0026hellip;Generated[]) appendNewLine() appendNewLineIfNotEmpty() appendIf(boolean, \u0026hellip;Generated[]) appendTemplate\u0026lt;template content\u0026gt; appendTemplateIf(boolean)\u0026lt;template content\u0026gt; indent(Generated[]) … 在某些情况下，这种方式可能更好。\n1 2 3 4 5 6 7 8 9 10 11 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; `.appendNewLine() .appendIf(module.statements.length !== 0, joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) ).appendTemplate` return ${lastComputableExpressionValueVarName}; `; } The avigation between DSL source and generated code 在 Solution A 和 Solution B 中，已经使 TypeScript 和 JavaScript 中的代码生成变得简单且可扩展，现在是时候来讨论一些实际问题了，即如何处理生成的代码，而不是纯粹的字符串段连接。\n这包括在集成开发环境中导航生成的工件及其相应的源代码（例如，用于手动审查），以及在调试生成的代码时自动切换到基于 DSL 的源代码。为了在基于 DSL 的开发工具中启用这些功能，代码生成器需要收集数据，了解哪些源定义生成了哪些代码。\n用下面的截图来说明 DSL 源代码和生成代码之间的来回导航。DSL 工具的用户可能想了解代码生成器为某个专用语句生成了什么代码。DSL 开发工具可能会提供这样的审查工具，例如通过选择敏感的上下文菜单项，如第一张截图所示。当然，也可以进行其他集成：在生成的工件中，可能有多个地方会受到某个语句或定义的影响。\n另一方面，用户可能希望或需要调查为什么生成器会将某些语句放入生成的工件中，即源代码中的哪些定义。如第二张截图所示，如果有机会让开发工具说明生成代码中某些语句的原因或来源，可能会简化此类任务。\n除了这类静态代码分析外，还希望运行生成的代码，在某个入口点设置断点，并通过逐步浏览 DSL 编写的源代码来逐步实现，如下图所示。\n在这里，一个装有 Langium Arithmetics 示例语言的 Monaco editor 被添加到了一个普通网站上，并输入了在 Solution A 中介绍的正在运行的示例脚本。基于 Langium 的语言服务器已经处理了输入，确定没有验证错误，并调用了生成器。然后对获得的 JavaScript 代码和相应的源映射进行评估。源映射是根据 JavaScript 代码生成过程中捕获的跟踪数据创建的。\n获取追踪数据 为了实现上述功能，我们需要捕获跟踪数据，将源数据中的相关文本区域与 generated artifacts 中的相应文本区域关联起来。在此，我们假定源数据是以人类可读文本的形式（通常是根据某种 DSL）编制的，并保存在 disc 上的文件中（至少与某个 URI 相关联），而 generated artifacts 则假定由 a stream of characters 组成。\n回顾本系列的第二部分，我们将代码生成任务分为两项：\nthe composition of a generation description the rendering of the description into the desired text 引入了一种树形数据结构来捕获描述，它由几种不同的数据类型组成，这些数据类型都归属于联合类型 GeneratorNode。既然已经引入了这样一种专用数据结构，就可以根据自己的喜好为这些数据添加额外的信息。还记得上次的模板标签函数 expandToNode，它在任务（1）中为给定的 JavaScript 模板文字建立了 GeneratorNode 实例，以及生成器函数 generateModuleContent3(Module)：\n1 2 3 4 5 6 7 8 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; ${ joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } 无论所提供的模块中定义了哪些语句，所包含的模板都会生成静态代码，而生成的输出则代表模块所包含的语句。这些语句的生成由函数 generateStatement(Statement) 完成，该函数提供给第 4 行的 joinToNode(\u0026hellip;) 调用。因此，模板第 3 行、第 5 行和第 6 行的内容只能与 module 相关联，因为这是它们被添加到输出中的原因。与此相反，generateStatement(Statement) 产生的输出可以与 module 关联，因为这些语句包含在 module 中，但更具体地说，它们应该与 module.statements 中包含的相应 Statement 实例关联。为了实现这两个目的，Langium 提供了以下函数：\nexpandTracedToNode\u0026lt;T extends AstNode\u0026gt;(T, Properties\u0026lt;T\u0026gt;?, number?) joinTracedToNode\u0026lt;T extends AstNode\u0026gt;(T, Properties\u0026lt;T\u0026gt;?) 我们可以使用这些函数捕获所需的跟踪数据，并重写 generateModuleContent3 如下：\n1 2 3 4 5 6 7 8 function generateModuleContent4(module: Module): Generated { return expandTracedToNode(module)` let ${lastComputableExpressionValueVarName}; ${ joinTracedToNode(module, \u0026#39;statements\u0026#39;)(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } 请注意，这两个函数都会再次返回函数。返回函数的签名与 expandToNode 和 joinToNode 的签名完全一致。因此，expandTracedToNode(module) 的结果是一个将模板字面意义转换为标记模板的标记函数。它在内部委托给 expandToNode，并在组成的 GeneratorNode 中注释了模块是相应源对象的信息。\n同样的原理也适用于 joinTracedToNode(模块, \u0026lsquo;语句\u0026rsquo;)。它返回一个与 joinToNode(\u0026hellip;) 接口相同的函数。第 4 行中对 generateModuleContent4(Module) 的调用是指：对 module.statements 中的每个元素应用 generateStatement(Statement)，为生成的每个 GeneratorNode 注释跟踪信息，说明生成的部分代表父对象模块中名为 statements 的属性（集合）的第 i 个元素，将所有这些生成器节点添加到一个容器 GeneratorNode 中，并为该容器注释信息，说明生成的部分代表源对象模块中 statements 属性的全部内容。\n追踪数据剖析 Langium 会在生成任务（2）中对跟踪数据进行评估和计算。在这种情况下，函数 toStringAndTrace(GeneratorNode) 将取代 Langium 的 toString(unknown)。它返回一个形状为 { text: string, trace：traceRegion }，其中 text 是希望生成的文本，trace 是描述嵌套跟踪区域的复合结构，将生成文本中的区域与源文件中的区域关联起来。数据类型 TraceRegion 的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 interface TraceRegion { sourceRegion?: TextRegion; targetRegion: TextRegion; children?: TraceRegion[]; } interface TextRegion { fileURI?: string; offset: number; end: number; length?: number; range?: Range; } 假定源数据是 Langium 通过解析 DSL 语法表述的文本而创建的有效 AST 元素，AstNode 实例就会被注释为代表相应具体语法节点的对象。后者反过来又提供了其 DSL 文档中的起始和结束位置以及文档的文件 URI。通过这些信息，toStringAndTrace(GeneratorNode) 计算出生成器节点的源区域。在文本渲染过程中，通过记录生成器节点生成文本的开始和结束位置，计算出相应的目标区域。此时，目标 TextRegion 的 fileURI 属性永远不会被设置，因为此时还不知道生成的文本是否会被写入某个文件，如果是，文件的 URI 可能是什么。\n让我们来看看以下输入和相应输出的简化示例：\n1 2 3 4 Module priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; 1 2 3 4 5 let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; return lastComputableExpressionValue; 下面的截图中展示了所得到的轨迹区域：\n玫瑰色背景所限定的区域代表跟踪所描述的根跟踪区域，该区域来自 generateModuleContent4(module) 所返回的生成器节点。 淡黄色矩形表示的区域来自 generateModuleContent4(Module) 。第 4 行中调用 joinTracedToNode(\u0026hellip;)(\u0026hellip;) 生成器节点生成的区域。源区域等于对象模块属性 \u0026ldquo;语句 \u0026ldquo;中所有元素定义的 \u0026ldquo;边界框\u0026rdquo;，目标区域等于第 4 行中 joinTracedToNode(\u0026hellip;)(\u0026hellip;) 调用 generateStatement(Statement) 的结果所描述的所有文本片段的 \u0026ldquo;边界框\u0026rdquo;，加上 { appendNewLineIfNotEmpty: true } 所要求的插入分隔线。包含这些源文本区域和目标文本区域描述的 TraceRegion 实例可通过根跟踪对象的子属性（即 trace.children[0]）访问。 蓝色背景区域表示跟踪区域，包括对象模块属性 \u0026ldquo;statements \u0026ldquo;条目 0 定义所涉及的源文本区域，以及执行 generateStatement(module.statements[0])后返回的生成器节点所描述的目标区域。跟踪区域描述对象可通过 trace.children[0].children[0] 访问。同样的情况也适用于绿色背景区域，但它们表示 module.statements 的条目 1 的定义和生成文本。该跟踪区域描述可通过 trace.children[0].children[1] 访问。 实际上，这种深度的跟踪数据捕获并不是终点。如果我们继续将 expandTracedToNode(\u0026hellip;) 应用于在 generateStatement(Module) 中要区分的所有特殊情况，我们就会得到完全深度解析和细粒度的跟踪区域，直至每个标识符、运算符和数字字面。\n将跟踪数据转换为 JavaScript 源映射 如今的浏览器和 VS Code 都支持源映射的概念，以便于调试已编译、转译或最小化的代码。源映射可以作为单独文件附加到生产的 JavaScript 代码中，甚至可以内联到生产的代码中（这通常会大大增加要传输的代码）。因此，为了实现能够调试用算术 DSL 编写的脚本这一目标，我们不仅需要捕获跟踪信息，还需要使用它们来合成符合源映射格式的数据。好消息是我们不需要完全靠自己。https://npmjs.com 上发布的 source-map 软件包可以帮我们完成大部分工作。\n在 langium-in-browser-codegen-example GitHub 代码库中，我实现了源地图数据的组合，并将其内联到生成的 JavaScript 代码中。如果内联，源地图数据必须进行 base64 编码\u0026ndash;这意味着我们基本上没有机会审查我们实际生成的内容。不过，sokra 和其他一些好心人建立了一个工具 https://sokra.github.io/source-map-visualization/。它允许我们上传生成的代码，包括源地图数据（或将源地图数据作为单独文件上传）。下面，我添加了一张所提供的可视化截图。原始页面甚至允许通过将鼠标悬停在某个区域上，观察其对应区域的高亮度（如果有的话），以交互方式查看源区域和目标区域。\n","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/code-generation-for-langium-based-dsls/","summary":"DSL 和 DSL 工具的一个重要方面是代码生成。DSL 本身在形式化、指定和交流内容方面具有优势，因为它们具有特定领域的性质。但是，如果能从指定的内容中推导出实现代码，就能大大提高工作效率。\nResources blogs https://www.typefox.io/blog/code-generation-for-langium-based-dsls/ https://www.typefox.io/blog/code-generation-for-langium-based-dsls-2 https://www.typefox.io/blog/code-generation-for-langium-based-dsls-3/ github repo: https://github.com/TypeFox/langium-in-browser-codegen-example/tree/main https://github.com/eclipse-langium/langium/blob/main/examples/arithmetics 运行示例 本帖中的运行示例使用 Langium 的 Arithmetics 示例实现。Arithmetics 的 grammar 见 arithmetics.langium\n代码生成器的输入示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 MODULE priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; DEF costPerUnit: materialPerUnit + laborPerUnit; DEF expectedNoOfSales: 200; DEF costOfGoodsSold: expectedNoOfSales * costPerUnit; DEF generalExpensesAndSales: 10000; DEF desiredProfitPerUnit: 50; DEF netPrice: (costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales + desiredProfitPerUnit; DEF vat: 0.","title":"Code generation for Langium-based DSLs"},{"content":"模板引擎 模板引擎（也称为模板处理器或模板解析器）是设计用于将模板与数据模型结合起来以生成结果文档的软件，编写模板所用的语言称为模板语言或模板语言。模板引擎通常作为 Web 模板系统或应用程序框架的一部分，也可以用作预处理器或过滤器。流行的模板引擎包括 Ejs、Jade、Pug、Mustache、HandlebarsJS、Jinja2 和 Blade。\n模板引擎如何工作 上图说明了模板引擎的所有基本元素和处理流程。\n使用模板引擎构建服务器端应用程序时，模板引擎会将模板文件中的变量替换为实际值，并将此值显示给客户端。这样，我们就能更轻松地快速构建应用程序。\n使用 expressJS 和 ejs 模板引擎的示例 对于使用 NodeJS 运行时编写的服务器端应用程序，可以使用模板引擎。\n以下步骤演示了模板引擎如何使用 expressJs 和 ejs 模板引擎工作。下面的示例在网页上渲染用户数据。\n步骤 1：安装 express 和 ejs 模板引擎\n安装 ejs 模板引擎和 express 框架，\n1 npm install express ejs 步骤 2：设置视图引擎\n1 2 3 4 5 6 7 8 const express = require(\u0026#34;express\u0026#34;) const app = express(); // Set the View Engine or Template Engine app.set(\u0026#39;view engine\u0026#39;, \u0026#39;ejs\u0026#39;); app.listen(3000) 在上面的代码中，我们创建了 express 应用程序。该应用程序通过 3000 端口监听。\napp.set('view engine', 'ejs'); 告诉我们的 express 应用程序，我们要使用 EJS 作为模板引擎。\n步骤 3：设置视图文件夹\n创建一个名为 view 的文件夹。视图文件夹应包含我们的模板。其中一个模板是 index.ejs，它将生成我们的首页。第二个模板是 user.ejs，用于从服务器端传递用户数据，并立即在网页上呈现。\n1 2 3 4 index.js \u0026gt;view index.ejs user.ejs 步骤 4：设置 routes\n让我们为主页和用户页面创建routes。\n请注意下面的 res.render() 方法。这就是在 expressJS 中渲染模板的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 app.get(\u0026#39;/\u0026#39;, function (req, res) { res.render(\u0026#34;index\u0026#34;); }) app.get(\u0026#34;/user\u0026#34;, function(req,res){ const user = { name: \u0026#34;Theodore Kelechukwu O.\u0026#34;, stack: \u0026#34;MERN\u0026#34;, email: \u0026#34;theodoreonyejiaku@gmail.com\u0026#34;, hubby: [\u0026#34;singing\u0026#34;, \u0026#34;playing guitar\u0026#34;, \u0026#34;reading\u0026#34;, \u0026#34;philosoph\u0026#34;] } res.render(\u0026#34;user\u0026#34;, {user}); }) 正如我们所见，访问默认路由\u0026quot;\u0026quot;时，会显示或渲染 index.ejs 页面。同时，\u0026quot;\\user \u0026ldquo;会显示 user.ejs 页面。\n我们将用户对象传递给 render 对象，以便将用户属性传递给网页并进行渲染。\n步骤 5：模板化我们的视图文件\n现在，我们已经从服务器端传递了用户数据，我们需要立即在前端或网页上显示这些数据。\nindex.ejs\n1 2 3 4 5 6 7 8 9 10 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;This is the title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Welcome to Template Engines\u0026lt;/p\u0026gt; \u0026lt;a href=\u0026#34;/user\u0026#34;\u0026gt;View User\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; user.ejs\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;This is the title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to User Details\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Name:\u0026lt;/b\u0026gt; \u0026lt;%= user.name %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Email:\u0026lt;/b\u0026gt; \u0026lt;%= user.email %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Stack:\u0026lt;/b\u0026gt; \u0026lt;%= user.stack %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;u\u0026gt;\u0026lt;b\u0026gt;Hubbies\u0026lt;/b\u0026gt;\u0026lt;/u\u0026gt; \u0026lt;% user.hubby.forEach(hubby =\u0026gt;{ %\u0026gt; \u0026lt;li\u0026gt;\u0026lt;%= hubby %\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;% })%\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 注意显示值的 \u0026lt;%= variable %\u0026gt; 模式。这是在 ejs 中使用的方式。还要注意 user.forEach(); 这是为了显示模板引擎有多么强大。\nResources https://en.wikipedia.org/wiki/Template_processor https://www.educative.io/answers/what-are-template-engines ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/template-engine/","summary":"模板引擎 模板引擎（也称为模板处理器或模板解析器）是设计用于将模板与数据模型结合起来以生成结果文档的软件，编写模板所用的语言称为模板语言或模板语言。模板引擎通常作为 Web 模板系统或应用程序框架的一部分，也可以用作预处理器或过滤器。流行的模板引擎包括 Ejs、Jade、Pug、Mustache、HandlebarsJS、Jinja2 和 Blade。\n模板引擎如何工作 上图说明了模板引擎的所有基本元素和处理流程。\n使用模板引擎构建服务器端应用程序时，模板引擎会将模板文件中的变量替换为实际值，并将此值显示给客户端。这样，我们就能更轻松地快速构建应用程序。\n使用 expressJS 和 ejs 模板引擎的示例 对于使用 NodeJS 运行时编写的服务器端应用程序，可以使用模板引擎。\n以下步骤演示了模板引擎如何使用 expressJs 和 ejs 模板引擎工作。下面的示例在网页上渲染用户数据。\n步骤 1：安装 express 和 ejs 模板引擎\n安装 ejs 模板引擎和 express 框架，\n1 npm install express ejs 步骤 2：设置视图引擎\n1 2 3 4 5 6 7 8 const express = require(\u0026#34;express\u0026#34;) const app = express(); // Set the View Engine or Template Engine app.set(\u0026#39;view engine\u0026#39;, \u0026#39;ejs\u0026#39;); app.listen(3000) 在上面的代码中，我们创建了 express 应用程序。该应用程序通过 3000 端口监听。","title":"Template Engine"},{"content":"今天花了一点时间搭建了自己的GitHub的博客，当然咯，试验阶段总会发生很多乱七八糟的问题，记录下处理问题过程中几个比较 nice 的 blog\nResources 系列文章，用hugo的PaperMod Theme 建站: https://www.sulvblog.cn/posts/blog/ Hugo + GitHub Action，搭建你的博客自动发布系统: https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ PaperMod主题优化： https://kdjlyy.cn/posts/site/hugo-papermod-optimization https://dvel.me/posts/hugo-papermod-config/ ","permalink":"https://WFUing.github.io/posts/tech/architecture/git/how-to-build-github-blog-with-hugo/","summary":"今天花了一点时间搭建了自己的GitHub的博客，当然咯，试验阶段总会发生很多乱七八糟的问题，记录下处理问题过程中几个比较 nice 的 blog\nResources 系列文章，用hugo的PaperMod Theme 建站: https://www.sulvblog.cn/posts/blog/ Hugo + GitHub Action，搭建你的博客自动发布系统: https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ PaperMod主题优化： https://kdjlyy.cn/posts/site/hugo-papermod-optimization https://dvel.me/posts/hugo-papermod-config/ ","title":"How to Build Github Blog With Hugo"},{"content":"为什么要用代码生成 productivity：使用代码生成，只需编写一次 generator ，就可以根据需要多次重复使用。向 generator 提供特定输入并调用它比手动编写代码要快得多，因此代码生成可以节省时间。 Simplification：通过代码生成，你可以从一些抽象的描述中生成代码。需要维护的部分变成了 generator 的输入部分，该部分通常是代码的描述，而不是代码本身，与整个生成的代码相比，该描述通常更容易分析和检查。 Portability：一旦你有了为某种语言或框架生成代码的程序，你就可以简单地更改 generator ，并以不同的语言或框架为目标。您还可以同时针对多个平台。 例如，使用解析器生成器，您可以获得 C#、Java 和 C++ 的 parser。 另一个例子：您可能会编写一个 UML 图表，然后使用代码生成器用 C# 创建一个骨架类，并用 SQL 代码为 MySQL 创建一个数据库。因此，相同的抽象描述可用于生成不同类型的工件。 Consistency：有了代码生成，你总能得到你所期望的代码。生成的代码是根据相同的原则设计的，命名规则等也是一致的。当然，除了生成器中的 bug 之外，代码总是能按照你所期望的方式运行，代码质量始终如一。如果用手工编写代码，不同的开发人员可能会使用不同的风格，即使是最重复的代码也会偶尔出现错误。 为什么不要用代码生成 Maintenance：当您使用代码生成工具时，您的代码就会依赖于它。代码生成工具必须得到维护。如果你创建了它，你就必须不断更新它；如果你只是使用现有的工具，你就必须希望有人继续维护它，或者你必须自己接手。因此，代码生成的优势并不是免费的。如果你没有或找不到合适的能力来维护代码生成器，风险就会更大。 Complexity：自动生成的代码往往比手工编写的代码更复杂。有时，这与将不同部分连接在一起所需的胶水代码有关，或者与生成器支持的用例多于您所需的用例有关。在第二种情况下，生成的代码可以做比你想要的更多的事情，但这并不一定是一种优势。生成代码的优化程度肯定也不如手工编写的代码。有时这种差异很小，并不明显，但如果您的应用程序需要尽可能地提高性能，那么生成的代码对您来说可能并不是最佳选择。 如何使用代码生成? 根据具体情况，代码生成既可以提高工作效率，也可以成为开发过程中的重要组成部分。许多现代集成开发环境就是一个有用的例子：只需点击一个按钮，就能创建一个骨架类来实现接口或类似功能。你完全可以自己编写这样的代码，只不过会浪费一些时间来完成琐碎的任务。\n设计代码生成流水线的方法有很多种。基本上，我们需要定义两个要素：\nInput：用于生成代码的信息来自何处。 Output：如何获得生成的代码。 您也可以在输入和输出之间设置转换步骤。这些步骤可以简化输出层，并使输入和输出更加独立。\nPossible Inputs\nA DSL：例如，我们可以使用 ANTLR 来描述一种语言的语法。由此，我们可以生成一个解析器。 code in other formats：数据库模式。根据数据库模式，我们可以生成 DAO。 wizards：它们允许向用户询问信息。 reverse engineering：可通过处理复杂的代码工件获得信息。 data sources：比如一个DB，一个csv文件或者一个电子表格。 Possible Outputs\ntemplate engine：大多数网络程序员都知道模板引擎，它用于在 HTML UI 中填充数据。 code building APIs：例如，Javaparser 可用于以编程方式创建 Java 文件。 Some Pipelines\n现在让我们来检查一些 pipelines：\nparser generation：本网站的读者一定很熟悉 ANTLR 和其他此类从形式语法自动生成解析器的工具。在这种情况下，输入是一个 DSL，输出则是使用 template engine 生成的。 model driven design：集成开发环境或独立集成开发环境的插件，可以描述应用程序的模型，有时还提供图形界面，并据此生成整个应用程序或仅生成其骨架。 database-related code：这种用法可视为模型驱动设计和模板引擎的产物。通常，程序员会定义一个数据库模式，并据此生成整个 CRUD 应用程序或处理数据库的代码。也有一些工具可以执行相反的过程：根据现有数据库创建数据库模式或处理数据库的代码。 meta-programming languages：这些语言组包括可对程序代码进行近乎完全操作的语言，源代码只是另一种可操作的数据结构。 ad hoc applications：这一类包括所有内容：从为处理一件事情而设计的工具到企业环境中使用的临时系统，这些系统可以根据正式的自定义描述生成整个应用程序。这些应用程序通常是特定工作流程的一部分。例如，客户使用图形界面描述一个应用程序，一个临时系统会生成支持该应用程序的数据库模式，另一个系统会生成 CRUD 界面等。 IDE generated code：许多静态类型语言需要编写大量的模板代码，而集成开发环境通常可以生成其中的一部分：为要实现的方法提供存根的类、标准的等值、hashCode 和 toString 方法、所有现有属性的获取器和设置器。 代码生成工具 模板引擎 模板引擎组 (Template Engine) 可能是最著名和最常用的。模板引擎基本上就是一个能理解简单模板语言的迷你编译器。模板文件包含可由模板引擎解释的特殊符号。它能做的最简单的事情就是用运行时给出的适当数据替换这些特殊符号。大多数模板引擎还支持简单的流程控制命令（如 for 循环、if-else 语句），允许用户描述简单的结构。\n有很多例子，让我们来看两个代表大多数模板引擎行为方式的例子。\nJinja2 Jinja2 是一个广泛使用的 Python 模板引擎。它能做所有模板引擎都能做的事情：根据提供的数据创建独一无二的文档。 它支持模块化模板、控制流、变量等。不过，它也有强大的安全措施：HTML 转义系统和沙箱环境，可以控制对危险属性的访问。\n1 2 3 4 5 6 \u0026lt;title\u0026gt;{% block title %}{% endblock %}\u0026lt;/title\u0026gt; \u0026lt;ul\u0026gt; {% for user in users %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{ user.url }}\u0026#34;\u0026gt;{{ user.username }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; Jinja2 特别支持生成 HTML 页面，这也是最常用的功能。不过，它也可用于创建其他类型的文件。\nPug Pug 是一个深受 Haml 影响的高性能模板引擎，使用 JavaScript 实现，适用于 Node.js 和浏览器。在许多方面，Pug 与许多其他模板引擎一样：它支持模块化模板、控制流等。不同的是，Pug 看起来像 DSL，而且只适用于 HTML。因此，Pug 模板看起来非常简洁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 doctype html html(lang=\u0026#34;en\u0026#34;) head title= pageTitle script(type=\u0026#39;text/javascript\u0026#39;). if (foo) bar(1 + 5) body h1 Pug - node template engine #container.col if youAreUsingPug p You are amazing else p Get on it! p. Pug is a terse and simple templating language with a strong focus on performance and powerful features. 解析器生成器 解析器生成器 (Parser Generation) 是一种自动快速创建语言解析器的工具。它们非常成功且富有成效，因为人们已经对语言解析问题进行了广泛的研究。因此，有一些解决方案可以保证解析人们需要解析的大多数语言。\nANTLR ANTLR 可能是使用最多的解析器生成器。这意味着有很多示例。然而，庞大社区的真正附加价值在于大量可用的语法。\nANTLR 的输入是语法：对语言的正式描述。解析器的输出是一棵解析树：一种包含源代码的结构，其转换方式便于程序的其他部分使用。ANTLR 还提供了两种走解析树的方法：访问者和监听者。第一种适用于需要对解析树中的元素进行操作或交互的情况，而第二种则适用于只需要在规则匹配时做一些事情的情况。\n1 2 3 4 5 6 7 grammar simple; basic : NAME \u0026#39;:\u0026#39; NAME ; NAME : [a-zA-Z]* ; COMMENT : \u0026#39;/*\u0026#39; .*? \u0026#39;*/\u0026#39; -\u0026gt; skip ; 模型驱动设计 这些通常是集成开发环境的插件或独立的集成开发环境，可以通过图形界面描述应用程序的模型，并由此生成应用程序的骨架。之所以会出现这种情况，是因为模型驱动设计的基础是抽象模型，可以用 UML 图表或 DSL 来定义。一旦程序的主要特征可以根据模型进行描述，那么就有可能自动生成该程序的表示法。这种代码中的模型表示法会自动生成结构，但行为通常必须由开发人员自己直接实现。\nAcceleo Acceleo 3 是一款实现 OMG 模型到文本规范的代码生成器。它为开发人员提供了高质量代码生成集成开发环境所应具备的大部分功能：简单的语法、高效的代码生成、先进的工具以及与 JDT 不相上下的功能。Acceleo 可帮助开发人员处理代码生成器的生命周期。得益于基于原型的方法，您可以从现有原型的源代码中快速、轻松地创建第一个生成器，然后利用 Acceleo 工具的所有功能（如重构工具），您可以轻松地改进生成器，实现完整的代码生成器。\nAcceleo 的工作：实施模型驱动设计原则。但缺少的是对 Acceleo 工作体验的描述。Acceleo 基本上是一个 Eclipse 插件，它为您提供了一个工具，可以根据您指定的模板，从 EMF 模型开始创建 Java 代码。EMF 模型可以通过不同方式定义：UML 图表或自定义 DSL。\nUmple Umple 是一种建模工具和编程语言系列，可实现作者所说的面向模型的编程。它在面向对象编程语言（如 Java、C++、PHP 和 Ruby）中添加了关联、属性和状态机等抽象概念，这些抽象概念源自 UML。Umple 还可用于以文本方式创建 UML 类图和状态图。\nUmple 是一种将 UML 模式与传统编程语言结构化结合的工具。它的诞生是为了简化模型驱动开发的过程，而传统的模型驱动开发需要特定而复杂的工具。它本质上是一种编程语言，支持 UML（类和状态）图定义模型的功能。然后，Umple 代码会被其编译器转换为 Java 或 PHP 等传统语言。\nUmple 可以有多种用法：\n可用于以文本方式描述 UML 图表 可与传统语言结合使用，作为该目标语言的预处理器或扩展程序。Umple 编译器在目标语言中转换 Umple 代码，并保持现有目标语言不变。 由于其对 UML 状态机的大量支持，它可以作为状态机生成器使用。根据 Umple 对状态机的描述，可以生成许多目标语言的实现。 1 2 3 4 5 6 7 8 9 10 class Student {} class CourseSection {} class Registration { String grade; * -- 1 Student; * -- 1 CourseSection; } 下面的 Umple 代码描述的是一个状态机。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class GarageDoor { status { Open { buttonOrObstacle -\u0026gt; Closing; } Closing { buttonOrObstacle -\u0026gt; Opening; reachBottom -\u0026gt; Closed; } Closed { buttonOrObstacle -\u0026gt; Opening; } Opening { buttonOrObstacle -\u0026gt; HalfOpen; reachTop -\u0026gt; Open; } HalfOpen { buttonOrObstacle -\u0026gt; Opening; } } } Telosys Telosys 设计用于生成所有管道和重复代码。它不需要使用 UML，但允许用户从起始数据库或使用 DSL 生成模型。它是一个有趣且易于使用的解决方案，还以 Eclipse 插件的形式提供 IDE 支持。\nurl：https://tomassetti.me/telosys-code-generation-tool/ 数据库相关代码 这一切都围绕着一个数据库模式展开，而代码就是从这个模式中生成的，或者是从一个数据库中生成一个模式。之所以可以使用这些生成器，有两个原因：\n关系数据库支持与之交互的标准语言（SQL） 编程语言中存在与数据库交互的广泛模式和库 这两个原因保证了在编程语言和包含程序所需数据的数据库之间创建标准胶合代码成为可能。在实践中，数据库模式可以作为一个简单的模型，用来生成代码。\n许多框架或集成开发环境都包含从类生成数据库模式的基本工具，反之亦然，生成与数据库表交互的类。在本节中，我们将看到一个可以做更多事情的工具示例。\nCelerio Celerio 是面向数据应用程序的代码生成工具。\nCelerio 是一款 Java 工具，其中包括一个数据库提取器，用于从现有数据库中获取数据库模式。然后，它将生成的模式与配置文件结合起来，然后启动模板引擎，以创建整个应用程序。提取的数据库模式为 XML 格式。\nDomain Specific Language（DSL） DSL 是以正规化方式捕捉业务逻辑的好方法。之后，需要以某种方式执行这些逻辑。虽然有时会使用解释器和编译器来执行 DSL，但代码生成器却经常被使用。通过这种方式，DSL 可以被翻译成已经存在编译器的语言，如 Java 或 C#。\n现在，可以使用语言工作台来构建 DSL，语言工作台是专门为设计和实现 DSL 而设计的集成开发环境。语言工作台之所以有用，是因为它们还能以较低的成本为 DSL 定义编辑器和其他支持工具。这一点非常重要，因为非开发人员也可以使用 DSL，他们需要定制的编辑器来利用语言的功能，或者根本无法使用普通的文本编辑器。除其他功能外，语言工作台通常还集成了代码生成功能。让我们来看几个例子。\nJetBrains MPS\nJetBrains MPS 是基于项目编辑器的语言工作台。您可以用它创建一个或多个 DSL。它还可用于扩展现有语言。例如，mbeddr 就是基于 JetBrains MPS 的 C 语言扩展，用于改进嵌入式编程。\n所谓投影式编辑器，是指 MPS 会保留数据的基本结构，并以易于编辑的形式显示出来。这个概念可能有点难以理解。想想传统的编程：你写出源代码，然后编译器将源代码转换为逻辑表示，即解析树。编译器使用这种表示法来执行一些操作，如优化或将其转换为机器代码来执行。使用项目编辑器，您可以直接处理逻辑表示：解析树。不过，您只能按照编辑器（MPS）允许的方式对其进行修改。\n这样做的主要后果是，当使用 JetBrains MPS 创建 DSL 时，您需要整个集成开发环境及其所有功能和功能。您可以获得语法高亮、代码自动补全、项目管理等功能。\n不过，这种方法的优势在于，您可以创建一个使用任何形式的输入来修改代码的 DSL，因此您可以创建一个图形编辑器、一个表格输入，甚至是普通文本。这一优势使得创建非程序员也能使用的 DSL 特别有用。\nXtext Xtext 是一种语言工作台，构建于 Eclipse 和 Eclipse Modeling Framework 之上。它可用于设计文本 DSL 并为其获取编辑器。 从功能上讲，Xtext 是不同工具（如用于解析的 ANTLR、用于用户界面的 Eclipse 等）的组合，用于生成 DSL。\nJulia 让我们看看 Julia 中宏的示例，Julia 是一种受 Lisp 启发的语言，它的语法更易于理解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 julia\u0026gt; macro twostep(arg) println(\u0026#34;I execute at parse time. The argument is: \u0026#34;, arg) return :(println(\u0026#34;I execute at runtime. The argument is: \u0026#34;, $arg)) end @twostep (macro with 1 method) julia\u0026gt; ex = macroexpand( :(@twostep :(1, 2, 3)) ); julia\u0026gt; ex # the macro itself :((println)(\u0026#34;I execute at runtime. The argument is: \u0026#34;, $(Expr(:copyast, :($(QuoteNode(:((1, 2, 3))))))))) julia\u0026gt; eval(ex) # execution of the macro I execute at runtime. The argument is: (1, 2, 3) 可以看出，执行宏和执行宏返回的表达式是两码事。\n这个非常强大的功能可以用于代码生成：你不需要外部工具来创建模板代码，你可以从内部创建。在下面摘自 Julia 文档的示例中，你可以看到它是如何定义一系列新的三元运算符的。\n1 2 3 for op = (:+, :*, :\u0026amp;, :|, :$) eval(:(($op)(a,b,c) = ($op)(($op)(a,b),c))) end 代码利用已定义的二元运算符定义了这些新的三元运算符：\n在前两个元素之间进行基本的二进制运算 然后在第一个运算结果和第三个元素之间再次进行运算 请注意，Julia 的标准语法与传统语言类似：没有奇怪的括号，表达式正常等。然而，当您使用元编程功能时，您将使用类似 Lisp 的内部语法。\n这只是冰山一角，你可以查阅 Julia 手册，进一步了解元编程的强大功能。\nRacket 如果你想在元编程方面做得更多，可以使用 Racket，这是一种受 Lisp 和 Scheme（另一种受 Lisp 影响的语言）启发的语言。\nRacket 同时是一种语言和一个平台，它被设计成一种可以定义其他语言的语言。因此，它甚至可以使用比宏更强大的元编程功能。Racket 可以定义全新的语言，改变基本语言的语法。它之所以能做到这一点，基本上是因为它允许你改变解析本身。\nRacket 的传统语法类似 Lisp。\n1 2 3 (define (four p) (define two-p (hc-append p p)) (vc-append two-p two-p)) 你可以改变它，例如，你可以创建一种语言来定义文档：Scribble\n1 2 3 4 5 6 #lang scribble/base @title{On the Cookie-Eating Habits of Mice} If you give a mouse a cookie, he\u0026#39;s going to ask for a glass of milk. 该语言允许您创建 HTML、PDF 等文件。您可以在语言中定义结构，然后生成所需的任何输出。\n这是一个与元编程和 DSL 相匹配的全新层次：您可以使用类似 DSL 的易用界面轻松创建自定义生成器。当目标受众是其他开发人员时，可以采用这种方法。这是因为您虽然获得了一种功能强大的语言，但它仅仅是一种语言而已。如果使用语言工作台，您就可以拥有一整套强大的编辑工具，帮助普通用户使用语言。\nAd-Hoc Applications 这一类包括所有内容：从为处理一件事情而设计的工具到在企业环境中使用的临时系统，这些系统可以根据正式的自定义描述生成整个应用程序。这些应用程序通常是特定工作流程的一部分。例如，客户使用图形界面描述一个应用程序，一个临时系统会生成支持该应用程序的数据库模式，另一个系统会生成 CRUD 界面等。\n这不是一个正确定义的类别，而是一个总括类别，包括不属于特定组别的所有内容。这意味着这组程序没有标准结构。这也证明了代码生成的多功能性：如果你能创建一个问题模型或描述，那么你就能用代码生成来解决问题。当然，你还必须了解解决一般问题和创建代码生成工具是否有意义，还是直接解决问题更好。\n在本节中，我们将讨论两种工具：CMake 是一款开发工具，而 Yeoman 则是一款脚手架工具。前者主要是生成配置文件：为其他软件提供支持的软件。第二种工具简化了开发人员的工作，提供了一种创建即用项目的方法，可针对特定软件平台、库或需求进行优化。\nCMake CMake 是一个开源、跨平台的工具系列，用于构建、测试和打包软件。\nCMake 包括三个开发工具，用于帮助开发 C 和 C++。主要工具旨在为不同平台和工具链生成构建文件（即 makefile 和项目文件）。例如，它可以生成 Linux 的 makefile 和 Visual Studio 项目文件。\nCMake 不是编译器。用户以 CMake 格式定义项目结构，然后该工具会生成传统构建过程中使用的普通构建文件。\nCMake 文件看起来像一系列命令/宏，用于为编译器设置选项/标志、链接库、执行自定义命令等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 cmake_minimum_required(VERSION 2.8) project(\u0026#34;Antlr-cpp-tutorial\u0026#34;) [..] if (NOT WIN32) set(CMAKE_CXX_FLAGS \u0026#34;-Wdeprecated -Wno-attributes\u0026#34; ) endif() [..] if(APPLE) add_custom_command(TARGET antlr4-tutorial POST_BUILD COMMAND ${CMAKE_COMMAND} -E copy_if_different \u0026#34;${PROJECT_SOURCE_DIR}/libs/antlr4-runtime.dylib\u0026#34; $\u0026lt;TARGET_FILE_DIR:antlr4-tutorial\u0026gt;) endif() Yeoman Yeoman 是一个通用的脚手架系统，可以创建任何类型的应用程序。\n如今，要成为一名优秀的程序员，意味着不仅仅要知道如何编码。你需要了解你所使用的每种工具的最佳实践，并记住每次都要执行它们。编写代码本身就已经很困难了，如果还需要正确编写配置文件和使用正确的项目结构，那就更难了。这就是像 Yeoman 这样的工具的用武之地：它是一款脚手架工具，只需一条命令就能生成一个新项目，并立即实施所有最佳实践。\nYeoman 的核心是一个生成器生态系统，开发人员可以在此基础上构建自己的模板。该工具非常受欢迎，已有数千个模板可供使用。\nYeoman 是一款 JavaScript 应用程序，因此编写生成器只需编写 JavaScript 代码并使用提供的 API 即可。工作流程也非常简单：向用户询问项目信息（如名称），收集配置信息，然后生成项目。\n以下代码展示了生成器的部分示例，用于创建 Yeoman 模板。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 function makeGeneratorName(name) { name = _.kebabCase(name); name = name.indexOf(\u0026#39;generator-\u0026#39;) === 0 ? name : \u0026#39;generator-\u0026#39; + name; return name; } module.exports = class extends Generator { initializing() { this.props = {}; } prompting() { return askName( { name: \u0026#39;name\u0026#39;, message: \u0026#39;Your generator name\u0026#39;, default: makeGeneratorName(path.basename(process.cwd())), filter: makeGeneratorName, validate: str =\u0026gt; { return str.length \u0026gt; \u0026#39;generator-\u0026#39;.length; } }, this ).then(props =\u0026gt; { this.props.name = props.name; }); } [..] writing() { const pkg = this.fs.readJSON(this.destinationPath(\u0026#39;package.json\u0026#39;), {}); const generatorGeneratorPkg = require(\u0026#39;../package.json\u0026#39;); [..] this.fs.writeJSON(this.destinationPath(\u0026#39;package.json\u0026#39;), pkg); } conflicts() { this.fs.append(this.destinationPath(\u0026#39;.eslintignore\u0026#39;), \u0026#39;**/templatesn\u0026#39;); } install() { this.installDependencies({ bower: false }); } }; Resources https://tomassetti.me/code-generation/ ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/a-guide-to-code-generation/","summary":"为什么要用代码生成 productivity：使用代码生成，只需编写一次 generator ，就可以根据需要多次重复使用。向 generator 提供特定输入并调用它比手动编写代码要快得多，因此代码生成可以节省时间。 Simplification：通过代码生成，你可以从一些抽象的描述中生成代码。需要维护的部分变成了 generator 的输入部分，该部分通常是代码的描述，而不是代码本身，与整个生成的代码相比，该描述通常更容易分析和检查。 Portability：一旦你有了为某种语言或框架生成代码的程序，你就可以简单地更改 generator ，并以不同的语言或框架为目标。您还可以同时针对多个平台。 例如，使用解析器生成器，您可以获得 C#、Java 和 C++ 的 parser。 另一个例子：您可能会编写一个 UML 图表，然后使用代码生成器用 C# 创建一个骨架类，并用 SQL 代码为 MySQL 创建一个数据库。因此，相同的抽象描述可用于生成不同类型的工件。 Consistency：有了代码生成，你总能得到你所期望的代码。生成的代码是根据相同的原则设计的，命名规则等也是一致的。当然，除了生成器中的 bug 之外，代码总是能按照你所期望的方式运行，代码质量始终如一。如果用手工编写代码，不同的开发人员可能会使用不同的风格，即使是最重复的代码也会偶尔出现错误。 为什么不要用代码生成 Maintenance：当您使用代码生成工具时，您的代码就会依赖于它。代码生成工具必须得到维护。如果你创建了它，你就必须不断更新它；如果你只是使用现有的工具，你就必须希望有人继续维护它，或者你必须自己接手。因此，代码生成的优势并不是免费的。如果你没有或找不到合适的能力来维护代码生成器，风险就会更大。 Complexity：自动生成的代码往往比手工编写的代码更复杂。有时，这与将不同部分连接在一起所需的胶水代码有关，或者与生成器支持的用例多于您所需的用例有关。在第二种情况下，生成的代码可以做比你想要的更多的事情，但这并不一定是一种优势。生成代码的优化程度肯定也不如手工编写的代码。有时这种差异很小，并不明显，但如果您的应用程序需要尽可能地提高性能，那么生成的代码对您来说可能并不是最佳选择。 如何使用代码生成? 根据具体情况，代码生成既可以提高工作效率，也可以成为开发过程中的重要组成部分。许多现代集成开发环境就是一个有用的例子：只需点击一个按钮，就能创建一个骨架类来实现接口或类似功能。你完全可以自己编写这样的代码，只不过会浪费一些时间来完成琐碎的任务。\n设计代码生成流水线的方法有很多种。基本上，我们需要定义两个要素：\nInput：用于生成代码的信息来自何处。 Output：如何获得生成的代码。 您也可以在输入和输出之间设置转换步骤。这些步骤可以简化输出层，并使输入和输出更加独立。\nPossible Inputs\nA DSL：例如，我们可以使用 ANTLR 来描述一种语言的语法。由此，我们可以生成一个解析器。 code in other formats：数据库模式。根据数据库模式，我们可以生成 DAO。 wizards：它们允许向用户询问信息。 reverse engineering：可通过处理复杂的代码工件获得信息。 data sources：比如一个DB，一个csv文件或者一个电子表格。 Possible Outputs\ntemplate engine：大多数网络程序员都知道模板引擎，它用于在 HTML UI 中填充数据。 code building APIs：例如，Javaparser 可用于以编程方式创建 Java 文件。 Some Pipelines","title":"A Guide to Code Generation"},{"content":"案例驱动 通过几个简单的例子来解释和总结什么是交叉熵（Cross Entropy）以及机器学习分类问题中为什么使用交叉熵。\n第一个例子 假设随机从一个口袋里取硬币，口袋里有一个蓝色的，一个红色的，一个绿色的，一个橘色的。取出一个硬币之后，每次问一个问题，然后做出判断，目标是，问最少的问题，得到正确答案。其中一个最好的设计问题的策略如下：\n每一个硬币有 $\\frac{1}{4}$ 的概率被选中，$\\frac{1}{4}机率 * 2道题目 * 4颗球 = 2$，平均需要问两道题目才能找出不同颜色的球，也就是说期望值为 $2$，就是熵（entropy）。\n第二个例子 例子变了，变成了袋子中 $\\frac{1}{8}$ 的硬币是绿色的，$\\frac{1}{8}$ 的是橘色的，$\\frac{1}{4}$ 是红色的，$\\frac{1}{2}$ 是蓝色的，这时最优的问题的策略如下:\n$\\frac{1}{2}$ 的概率是蓝色，只需要 $1$ 个问题就可以知道是或者不是，$\\frac{1}{4}$ 的概率是红色，需要2个问题，按照这个逻辑，猜中硬币需要的问题的期望是\n$$ \\frac{1}{2}*1+\\frac{1}{4}*2+\\frac{1}{8}*3+\\frac{1}{8}*3=1.75 $$\n第三个例子 假设袋子中全部是蓝色的硬币，那么这时候需要 $0$ 个问题就可以猜到硬币，即 $\\log_{2}{1}=0$。 需要注意的是，只有当知道袋子中全部是蓝色的硬币的时候需要的问题是 $0$ 个。\n总结上面的例子，假设一种硬币出现的概率是 $p$，那么猜中该硬币的所需要的问题数是 $\\log_2{\\frac1{P_i}}$。例如 $p=\\frac{1}{4}，\\log_{2}{4}$ 。\n在这个问题中，问题个数的期望是\n$$ \\sum_i{p_i}*log_2{\\frac{1}{p_i}} $$\n这个式子就是熵的表达式 。简单来说，其意义就是在最优化策略下，猜到颜色所需要的问题的个数。熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。\n现在已经了解了熵是什么，那么，下面解释交叉熵（cross entropy） 的含义.对于第二个例子，如果仍然使用第一个例子中的策略，如下图:\n$\\frac{1}{8}$ 的概率，硬币是橘色，需要两个问题，$\\frac{1}{2}$ 的概率是蓝色，仍然需要两个问题，也就是说，认为小球的分布为 $(\\frac{1}{4},\\frac{1}{4},\\frac{1}{4},\\frac{1}{4})$ ，这个分布就是非真实分布。平均来说，需要的问题数是 $\\frac{1}{8}*2+\\frac{1}{8}*2+\\frac{1}{4}*2+\\frac{1}{2}*2=2$ 。\n因此，在例子二中使用例子一的策略是一个比较差的策略。其中 $2$ 是这个方案中的交叉熵，而最优方案的交叉熵是 $1.75$。\n给定一个策略，交叉熵就是在该策略下猜中颜色所需要的问题的期望值。更普遍的说，交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出成本的大小。交叉的字面意思在于：真实分布与非真实分布的交叉。给定一个方案，越优的策略，最终的交叉熵越低。具有最低的交叉熵的策略就是最优化策略，也就是上面定义的熵。因此，在机器学习中，我们需要最小化交叉熵。\n数学上来讲 其中，$p$ 是真正的概率，例如例子二中，橘色和绿色是 $\\frac{1}{8}$，红色是 $\\frac{1}{4}$，蓝色是 $\\frac{1}{2}$。$\\hat p$ 是错误地假设了的概率，例如，在例子二中我们错误地假设了所有的颜色的概率都是 $\\frac{1}{4}$。$p$ 和 $\\hat p$ 可能有点容易混淆。记住一点，$log$ 是用来计算在你的策略下猜中所需要的问题数，因此，$log$ 中需要的是你的预测概率 $\\hat p$ 。在决策树中，如果建立的树不是最优的，结果就是对于输出的概率分布的假设是错误地，导致的直接结果就是交叉熵很高。交叉熵不仅仅应用在决策树中，在其他的分类问题中也有应用。\n分类问题 在二分类问题中，标签 $y$ 是 $1$ 的似然是对于标签 $y$ 的预测 $\\hat y$ ，同样的，标签是 $0$ 的似然是 $1-\\hat y$ 。我们需要最大化似然函数，而且，由于二分类问题的特殊性，根据伯努力分布 (Bernoulli distribution)，可以把似然函数写成\n当 $y=1$ 的时候，第二项为 $1$，因此，优化的是 $\\hat y$ 当 $y=0$ 的时候，第一项为 $1$，优化的是 $1-\\hat y$ 。 对上面的似然函数取对数，结果是最大化似然函数，就是对上面表达式取负然后最小化。也是交叉熵的表达式。\n交叉熵有时候也被称为对数损失函数。注意与上边例子区别是多了个负号，上边例子是消除不确定性需要付出的成本；而现在这个加了负号的交叉熵，则是最终的目标函数。\n举例来说，假设我有 $3$ 枚硬币，正正反，记为 $(1,1,0)$ 。预测结果是 $(0.8,0.9,0.3)$，那么，交叉熵的均值是:\n$$ \\frac13(1×\\log_20.8+1×log_20.9+(1-0)×log_2(1-0.3)) $$\n假设有一个完美的算法，直接预测出了 $(1,1,0)$，那么交叉熵的结果就是 $0$。\n","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/cross-entropy/","summary":"案例驱动 通过几个简单的例子来解释和总结什么是交叉熵（Cross Entropy）以及机器学习分类问题中为什么使用交叉熵。\n第一个例子 假设随机从一个口袋里取硬币，口袋里有一个蓝色的，一个红色的，一个绿色的，一个橘色的。取出一个硬币之后，每次问一个问题，然后做出判断，目标是，问最少的问题，得到正确答案。其中一个最好的设计问题的策略如下：\n每一个硬币有 $\\frac{1}{4}$ 的概率被选中，$\\frac{1}{4}机率 * 2道题目 * 4颗球 = 2$，平均需要问两道题目才能找出不同颜色的球，也就是说期望值为 $2$，就是熵（entropy）。\n第二个例子 例子变了，变成了袋子中 $\\frac{1}{8}$ 的硬币是绿色的，$\\frac{1}{8}$ 的是橘色的，$\\frac{1}{4}$ 是红色的，$\\frac{1}{2}$ 是蓝色的，这时最优的问题的策略如下:\n$\\frac{1}{2}$ 的概率是蓝色，只需要 $1$ 个问题就可以知道是或者不是，$\\frac{1}{4}$ 的概率是红色，需要2个问题，按照这个逻辑，猜中硬币需要的问题的期望是\n$$ \\frac{1}{2}*1+\\frac{1}{4}*2+\\frac{1}{8}*3+\\frac{1}{8}*3=1.75 $$\n第三个例子 假设袋子中全部是蓝色的硬币，那么这时候需要 $0$ 个问题就可以猜到硬币，即 $\\log_{2}{1}=0$。 需要注意的是，只有当知道袋子中全部是蓝色的硬币的时候需要的问题是 $0$ 个。\n总结上面的例子，假设一种硬币出现的概率是 $p$，那么猜中该硬币的所需要的问题数是 $\\log_2{\\frac1{P_i}}$。例如 $p=\\frac{1}{4}，\\log_{2}{4}$ 。\n在这个问题中，问题个数的期望是\n$$ \\sum_i{p_i}*log_2{\\frac{1}{p_i}} $$\n这个式子就是熵的表达式 。简单来说，其意义就是在最优化策略下，猜到颜色所需要的问题的个数。熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。\n现在已经了解了熵是什么，那么，下面解释交叉熵（cross entropy） 的含义.对于第二个例子，如果仍然使用第一个例子中的策略，如下图:\n$\\frac{1}{8}$ 的概率，硬币是橘色，需要两个问题，$\\frac{1}{2}$ 的概率是蓝色，仍然需要两个问题，也就是说，认为小球的分布为 $(\\frac{1}{4},\\frac{1}{4},\\frac{1}{4},\\frac{1}{4})$ ，这个分布就是非真实分布。平均来说，需要的问题数是 $\\frac{1}{8}*2+\\frac{1}{8}*2+\\frac{1}{4}*2+\\frac{1}{2}*2=2$ 。\n因此，在例子二中使用例子一的策略是一个比较差的策略。其中 $2$ 是这个方案中的交叉熵，而最优方案的交叉熵是 $1.75$。\n给定一个策略，交叉熵就是在该策略下猜中颜色所需要的问题的期望值。更普遍的说，交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出成本的大小。交叉的字面意思在于：真实分布与非真实分布的交叉。给定一个方案，越优的策略，最终的交叉熵越低。具有最低的交叉熵的策略就是最优化策略，也就是上面定义的熵。因此，在机器学习中，我们需要最小化交叉熵。\n数学上来讲 其中，$p$ 是真正的概率，例如例子二中，橘色和绿色是 $\\frac{1}{8}$，红色是 $\\frac{1}{4}$，蓝色是 $\\frac{1}{2}$。$\\hat p$ 是错误地假设了的概率，例如，在例子二中我们错误地假设了所有的颜色的概率都是 $\\frac{1}{4}$。$p$ 和 $\\hat p$ 可能有点容易混淆。记住一点，$log$ 是用来计算在你的策略下猜中所需要的问题数，因此，$log$ 中需要的是你的预测概率 $\\hat p$ 。在决策树中，如果建立的树不是最优的，结果就是对于输出的概率分布的假设是错误地，导致的直接结果就是交叉熵很高。交叉熵不仅仅应用在决策树中，在其他的分类问题中也有应用。","title":"交叉熵"},{"content":" 英文名: WDS 职业: 程序员 运动: 跑步、乒乓球、爬山 ","permalink":"https://WFUing.github.io/about/","summary":" 英文名: WDS 职业: 程序员 运动: 跑步、乒乓球、爬山 ","title":"🙋🏻‍♂️"}]