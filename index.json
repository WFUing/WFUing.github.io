[{"content":"Git 简介 Git 是什么 Git 是一个开源的分布式版本控制系统。\nGit 和其它版本控制系统（包括 Subversion 和近似工具）的主要差别在于 Git 对待数据的方式。 从概念上来说，其它大部分系统以文件变更列表的方式存储信息，而 Git 是把数据看作是对小型文件系统的一系列快照。\n什么是版本控制 版本控制是一种记录一个或若干文件内容变化，以便将来查阅特定版本修订情况的系统。\n集中化的版本控制系统 介绍分布式版本控制系统前，有必要先了解一下传统的集中式版本控制系统。\n集中化的版本控制系统，诸如 CVS，Subversion 等，都有一个单一的集中管理的服务器，保存所有文件的修订版本，而协同工作的人们都通过客户端连到这台服务器，取出最新的文件或者提交更新。\n这么做最显而易见的缺点是中央服务器的单点故障。如果宕机一小时，那么在这一小时内，谁都无法提交更新，也就无法协同工作。要是中央服务器的磁盘发生故障，碰巧没做备份，或者备份不够及时，就会有丢失数据的风险。最坏的情况是彻底丢失整个项目的所有历史更改记录。\n分布式版本控制系统 分布式版本控制系统的客户端并不只提取最新版本的文件快照，而是把代码仓库完整地镜像下来。这么一来，任何一处协同工作用的服务器发生故障，事后都可以用任何一个镜像出来的本地仓库恢复。因为每一次的提取操作，实际上都是一次对代码仓库的完整备份。\n为什么使用 Git Git 是分布式的。这是 Git 和其它非分布式的版本控制系统（例如 svn，cvs 等），最核心的区别。分布式带来以下好处：\n工作时不需要联网 - 首先，分布式版本控制系统根本没有“中央服务器”，每个人的电脑上都是一个完整的版本库，这样，你工作的时候，就不需要联网了，因为版本库就在你自己的电脑上。既然每个人电脑上都有一个完整的版本库，那多个人如何协作呢？比方说你在自己电脑上改了文件 A，你的同事也在他的电脑上改了文件 A，这时，你们俩之间只需把各自的修改推送给对方，就可以互相看到对方的修改了。 更加安全 集中式版本控制系统，一旦中央服务器出了问题，所有人都无法工作。 分布式版本控制系统，每个人电脑中都有完整的版本库，所以某人的机器挂了，并不影响其它人。 Git 的工作原理 个人认为，对于 Git 这个版本工具，再不了解原理的情况下，直接去学习命令行，可能会一头雾水。所以，本文特意将原理放在命令使用章节之前讲解。\n版本库 当你一个项目到本地或创建一个 git 项目，项目目录下会有一个隐藏的 .git 子目录。这个目录是 git 用来跟踪管理版本库的，如果不熟悉其工作机制，千万不要手动修改。\nhooks 目录：包含客户端或服务端的钩子脚本（hook scripts） info 目录：包含一个全局性排除（global exclude）文件， 用以放置那些不希望被记录在 .gitignore 文件中的忽略模式（ignored patterns）。 objects 目录：存储所有数据内容。 refs 目录：存储指向数据（分支、远程仓库和标签等）的提交对象的指针 HEAD 文件：指向目前被检出的分支。 index 文件保存暂存区信息。 config 文件：包含项目特有的配置选项。 description 文件：description 文件仅供 GitWeb 程序使用，我们无需关心。 哈希值 Git 中所有数据在存储前都计算校验和，然后以校验和来引用。 这意味着不可能在 Git 不知情时更改任何文件内容或目录内容。 这个功能构筑在 Git 底层，是 Git 的关键组件。 若你在传送过程中丢失信息或损坏文件，Git 就能发现。\nGit 计算校验和的使用 SHA-1 哈希算法。 这是一个由 40 个十六进制字符（0-9 和 a-f）组成字符串，基于 Git 中文件的内容或目录结构计算出来。 SHA-1 哈希值看起来是这样：\n1 24b9da6552252987aa493b52f8696cd6d3b00373 Git 中使用这种哈希值的情况很多，你将经常看到这种哈希值。 实际上，Git 数据库中保存的信息都是以文件内容的哈希值来索引，而不是文件名。\n文件状态 在 GIt 中，你的文件可能会处于三种状态之一：\n已修改（modified） - 已修改表示修改了文件，但还没保存到数据库中。 已暂存（staged） - 已暂存表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。 已提交（committed） - 已提交表示数据已经安全的保存在本地数据库中。 工作区域 与文件状态对应的，不同状态的文件在 Git 中处于不同的工作区域。\n工作区（working） - 当你 git clone 一个项目到本地，相当于在本地克隆了项目的一个副本。工作区是对项目的某个版本独立提取出来的内容。 这些从 Git 仓库的压缩数据库中提取出来的文件，放在磁盘上供你使用或修改。 暂存区（staging） - 暂存区是一个文件，保存了下次将提交的文件列表信息，一般在 Git 仓库目录中。 有时候也被称作`‘索引’\u0026rsquo;，不过一般说法还是叫暂存区。 本地仓库（local） - 提交更新，找到暂存区域的文件，将快照永久性存储到 Git 本地仓库。 远程仓库（remote） - 以上几个工作区都是在本地。为了让别人可以看到你的修改，你需要将你的更新推送到远程仓库。同理，如果你想同步别人的修改，你需要从远程仓库拉取更新。 分支管理 Git Flow Git Flow 应该是目前流传最广的 Git 分支管理策略。Git Flow 围绕的核心点是版本发布（release），它适用于迭代版本较长的项目。\n详细内容，可以参考这篇文章：Git 在团队中的最佳实践\u0026ndash;如何正确使用 Git Flow\nGit Flow 常用分支：\nmaster - 主线分支 develop - 开发分支 feature - 特性分支 release - 发布分支 hotfix - 问题修复分支 Git Flow 工作流程\n2.1. 主干分支 主干分支有两个，它们是伴随着项目生命周期长期存在的分支。\nmaster - 这个分支对应发布到生产环境的代码。这个分支只允许从其他分支合入代码，不能在这个分支直接修改。所有在 master 分支上的 Commit 都应该打 Tag。 develop - 这个分支包含所有要发布到下一个 release 的代码，这个分支主要是从其他分支合入代码，比如 feature 分支。 2.2. feature 分支 这个分支主要是用来开发一个新的功能，一旦开发完成，我们合并回 develop 分支进入下一个 release。feature 分支开发结束后，必须合并回 develop 分支, 合并完分支后一般会删点这个 feature 分支，但是我们也可以保留。\n2.3. release 分支 release 分支基于 develop 分支创建，创建后，我们可以在这个 release 分支上进行测试，修复 Bug 等工作。同时，其它开发人员可以基于它开发新的 feature (记住：一旦创建了 release 分支之后不要从 develop 分支上合并新的改动到 release 分支)。\n发布 release 分支时，合并 release 到 master 和 develop， 同时在 master 分支上打个 Tag 记住 release 版本号，然后可以删除 release 分支了。\n2.4. hotfix 分支 当出现线上 bug 时，也意味着 master 存在 Bug。这时，我们需要基于 master 创建一个 hotfix 分支，在此分支上完成 bug 修复。修复后，我们应该将此分支合并回 master 和 develop 分支，同时在 master 上打一个 tag。所以，hotfix 的改动会进入下一个 release。\n2.5. 如何应用 Git Flow 在实际开发中，如何具体落地 Git Flow 流程呢？\ngit 提供了 git flow 命令来手动管理，但是比较麻烦，所以还是建议使用 Git Flow 的 GUI 工具。比如：SourceTree、VScode 的 GitFlow 插件、Intellij 的 GitFlow 插件等。\n想了解更详细的 Git Flow 介绍，可以参考：\nA Successful Git Branching Model\nGit 在团队中的最佳实践\u0026ndash;如何正确使用 Git Flow\nGithub Flow 对于简单且迭代频繁的项目来说，Git Flow 可能有些太复杂了。这时，可以考虑 Github Flow。\n在 Github Flow 策略中，所有分支都是基于 master 创建。在 Feature 或 Bugfix 分支中完成工作后，将其合入 master，然后继续迭代。\n想了解更详细的 Github Flow 介绍，可以参考：GitHub Flow\nGit Commit 规范 Git 每次提交代码，都要写 Commit message（提交说明），否则就不允许提交。\n好的 Commit message 可以让人一眼就明白提交者修改了什么内容，有什么影响；而不好的 Commit message 写了和没写一样，甚至还可能误导别人。\n先来看下图中不好的 Commit message 范例，从提交信息完全看不出来修改了什么。\n再来一张较好的 Commit message 范例，每次提交的是什么内容，做了什么一目了然。\nCommit message 的作用 从前面，我们不难看出，完善的 Commit message 非常有利于项目维护。即时是个人维护的项目，时间久了，可能也会忘记当初自己改了什么。\nCommit message 的作用还不仅仅是理解历史信息，它的主要作用如下：\n（1）提供易于理解的历史信息，方便检索\n（2）可以过滤某些 commit（比如文档改动），便于快速查找信息。\n（3）可以直接从 commit 生成 Change log。\nCommit message 的规范 开源社区有很多 Commit message 的规范，个人推荐使用 Angular Git Commit 规范，这是目前使用最广的写法，比较合理和系统化，并且有配套的工具。\n它主要有以下组成部分：\n标题行：必填, 描述主要修改类型和内容 主题内容：描述为什么修改, 做了什么样的修改, 以及开发的思路等等 页脚注释：放 Breaking Changes 或 Closed Issues 常用的修改项\ntype：commit 的类型 feat：新特性 fix：修改问题 refactor：代码重构 docs：文档修改 style：代码格式修改, 注意不是 css 修改 test：测试用例修改 chore：其他修改, 比如构建流程, 依赖管理. scope：commit 影响的范围, 比如：route, component, utils, build\u0026hellip; subject：commit 的概述 body：commit 具体修改内容, 可以分为多行 footer：一些备注, 通常是 BREAKING CHANGE 或修复的 bug 的链接 生成 Change log 如果你的所有 Commit 都符合 Angular Git Commit 规范，那么发布新版本时，就可以用脚本自动生成 Change log。\n生成的文档包括以下三个部分。\nNew features Bug fixes Breaking changes. 每个部分都会罗列相关的 commit ，并且有指向这些 commit 的链接。当然，生成的文档允许手动修改，所以发布前，你还可以添加其他内容。\nconventional-changelog 就是生成 Change log 的工具，运行下面的命令即可。\n1 2 3 $ npm install -g conventional-changelog $ cd my-project $ conventional-changelog -p angular -i CHANGELOG.md -w 上面命令不会覆盖以前的 Change log，只会在CHANGELOG.md的头部加上自从上次发布以来的变动。\n如果你想生成所有发布的 Change log，要改为运行下面的命令。\n1 $ conventional-changelog -p angular -i CHANGELOG.md -w -r 0 为了方便使用，可以将其写入package.json的scripts字段。\n1 2 3 4 5 { \u0026#34;scripts\u0026#34;: { \u0026#34;changelog\u0026#34;: \u0026#34;conventional-changelog -p angular -i CHANGELOG.md -w -r 0\u0026#34; } } 以后，直接运行下面的命令即可。\n1 $ npm run changelog Git 奇技淫巧 生成 SSH 公钥 许多 Git 服务器都使用 SSH 公钥进行认证。 为了向 Git 服务器提供 SSH 公钥，如果某系统用户尚未拥有密钥，必须事先为其生成一份。 这个过程在所有操作系统上都是相似的。 首先，你需要确认自己是否已经拥有密钥。 默认情况下，用户的 SSH 密钥存储在其 ~/.ssh 目录下。 进入该目录并列出其中内容，你便可以快速确认自己是否已拥有密钥：\n1 2 3 4 $ cd ~/.ssh $ ls authorized_keys2 id_dsa known_hosts config id_dsa.pub 我们需要寻找一对以 id_dsa 或 id_rsa 命名的文件，其中一个带有 .pub 扩展名。 .pub 文件是你的公钥，另一个则是私钥。 如果找不到这样的文件（或者根本没有 .ssh 目录），你可以通过运行 ssh-keygen 程序来创建它们。在 Linux/Mac 系统中，ssh-keygen 随 SSH 软件包提供；在 Windows 上，该程序包含于 MSysGit 软件包中。\n1 2 3 4 5 6 7 8 9 10 $ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/schacon/.ssh/id_rsa): Created directory \u0026#39;/home/schacon/.ssh\u0026#39;. Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/schacon/.ssh/id_rsa. Your public key has been saved in /home/schacon/.ssh/id_rsa.pub. The key fingerprint is: d0:82:24:8e:d7:f1:bb:9b:33:53:96:93:49:da:9b:e3 schacon@mylaptop.local 首先 ssh-keygen 会确认密钥的存储位置（默认是 .ssh/id_rsa），然后它会要求你输入两次密钥口令。如果你不想在使用密钥时输入口令，将其留空即可。\n现在，进行了上述操作的用户需要将各自的公钥发送给任意一个 Git 服务器管理员（假设服务器正在使用基于公钥的 SSH 验证设置）。 他们所要做的就是复制各自的 .pub 文件内容，并将其通过邮件发送。 公钥看起来是这样的：\n1 2 3 4 5 6 7 $ cat ~/.ssh/id_rsa.pub ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAklOUpkDHrfHY17SbrmTIpNLTGK9Tjom/BWDSU GPl+nafzlHDTYW7hdI4yZ5ew18JH4JW9jbhUFrviQzM7xlELEVf4h9lFX5QVkbPppSwg0cda3 Pbv7kOdJ/MTyBlWXFCR+HAo3FXRitBqxiX1nKhXpHAZsMciLq8V6RjsNAQwdsdMFvSlVK/7XA t3FaoJoAsncM1Q9x5+3V0Ww68/eIFmb1zuUFljQJKprrX88XypNDvjYNby6vw/Pb0rwert/En mZ+AW4OZPnTPI89ZPmVMLuayrD2cE86Z/il8b+gw3r3+1nKatmIkjn2so1d01QraTlMqVSsbx NrRFi9wrf+M7Q== schacon@mylaptop.local 在你的 Github 账户中，依次点击 Settings \u0026gt; SSH and GPG keys \u0026gt; New SSH key\n然后，将上面生成的公钥内容粘贴到 Key 编辑框并保存。至此大功告成。\n后面，你在克隆你的 Github 项目时使用 SSH 方式即可。\n如果觉得我的讲解还不够细致，可以参考：adding-a-new-ssh-key-to-your-github-account\n使用 .gitignore 忽略不必提交内容 .gitignore 文件可能从字面含义也不难猜出：这个文件里配置的文件或目录，会自动被 git 所忽略，不纳入版本控制。\n在日常开发中，我们的项目经常会产生一些临时文件，如编译 Java 产生的 *.class 文件，又或是 IDE 自动生成的隐藏目录（Intellij 的 .idea 目录、Eclipse 的 .settings 目录等）等等。这些文件或目录实在没必要纳入版本管理。在这种场景下，你就需要用到 .gitignore 配置来过滤这些文件或目录。\n.gitignore 配置的规则很简单，也没什么可说的，看几个例子，自然就明白了。\n【示例】一份 Java 的 .gitignore\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # Compiled class file *.class # Log file *.log # BlueJ files *.ctxt # Mobile Tools for Java (J2ME) .mtj.tmp/ # Package Files # *.jar *.war *.nar *.ear *.zip *.tar.gz *.rar # virtual machine crash logs, see http://www.java.com/en/download/help/error_hotspot.xml hs_err_pid* 【推荐】这里推荐一个 Github 的开源项目：gitignore，在这里，你可以找到很多常用的 .gitignore 模板，如：Java、Nodejs、C++ 的 .gitignore 模板等等。\n使用 .gitattributes 解决 LF 和 CRLF 问题 你有没有在和多人协同开发时遇到过以下烦恼？\n开发者们分别使用不同的操作系统进行开发，有的人用 Windows，有的人用 Linux/MacOS。众所周知，不同操作系统默认的文件结尾行是不同的：在 Windows 上默认的是回车换行（Carriage Return Line Feed, CRLF），然而，在 Linux/MacOS 上则是换行（Line Feed, LF）。这就可能导致这种情况：明明文件内容一模一样，但是版本比对时仍然存在版本差异。\n那么如何解决这个问题呢？Git 提供了 .gitattributes 配置文件，它允许使用者指定由 git 使用的文件和路径的属性。\n在 Git 库中，一个普通文本文件的行尾默认是 LF。对于工作目录，除了 text 属性之外，还可以设置 eol 属性或 core.eol 配置变量。\n.gitattributes 文件中，可以用 text 属性指定某类文件或目录下的文件，控制它的行结束标准化。当一个文本文件被标准化时，它的行尾将在存储库中转换为 LF。要控制工作目录中使用的行结束风格，请使用单个文件的eol属性和所有文本文件的 core.eol 配置变量。\n【示例】一份 .gitattributes 示例\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 * text=auto eol=lf *.txt text *.java text *.scala text *.groovy text *.gradle text *.properties text # unix style *.sh text eol=lf # win style *.bat text eol=crlf # binary *.jar binary *.war binary *.zip binary *.tar binary *.tar.gz binary *.gz binary *.apk binary *.bin binary *.exe binary 【推荐】这里推荐一个 Github 的开源项目：gitignore，在这里，你可以找到很多常用的 .gitignore 模板，如：Java、Nodejs、C++ 的 .gitignore 模板等等。\n同时提交代码到不同的远程仓库 如果，你在不同的 Git 远程仓库中维护同一个项目，你可能会有这样的需求：能不能一次提交，同时 push 到多个远程仓库中呢？\n这个可以有，解决方案如下：\n比如，我有一个 blog 项目，同时维护在 Github 和 Gitee 上。\n（1）首先，在 Github 和 Gitee 上配置本地的 ssh 公钥（如果是 Gitlab，也同样如此），这样中央仓库就能识别本地。\n生成 SSH 公钥的方法，请参考上文的 “生成 SSH 公钥” 章节。\n（2）进入 git 项目的隐藏目录 .git，打开 config 文件，参考下面配置进行编辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [core] repositoryformatversion = 0 filemode = false bare = false logallrefupdates = true symlinks = false ignorecase = true [remote \u0026#34;origin\u0026#34;] url = git@github.com:dunwu/blog.git url = git@gitee.com:turnon/blog.git fetch = +refs/heads/*:refs/remotes/origin/* [branch \u0026#34;master\u0026#34;] remote = origin merge = refs/heads/master [user] name = dunwu email = forbreak@163.com 重点在于 remote \u0026quot;origin\u0026quot;，同时配置了两个 url。配置后，一旦触发 push 远程仓库的动作，就会同时推送提交记录到配置的远程仓库。\nGithub Issue 和 Gitlab Issue 开发软件，Bug 再所难免，出现问题不可怕，可怕的是放任不管；所以，优秀的软件项目，都应该管理好问题追踪。软件的使用者，在使用中，可能会遇到形形色色的问题，难以解决，需要向维护者寻求帮助。\n问题追踪如此重要，所以各种代码托管平台都会提供 Issue 维护机制，如 Github Issue 和 Gitlab Issue。\n如果一个项目的开源社区很活跃，在没有任何约束的前提下，提问肯定是五花八门的，让维护者难以招架。\n其实，提问也是一门艺术，如果提问者的问题长篇大幅，言不达意，让别人难以理解，就很难得到有效帮助。关于如何高效的提问，推荐参考 提问的智慧 这篇文章，作者整理的非常好。\n作为开发者，你不能期望所有提问者都是训练有素的提问者。所以，使用规范化的 Issue 模板来引导提问者提问，可以大大减轻开发者的负担。\nGithub Issue 模板 如何在 Github Issue 平台上创建 Issue 模板呢？方法如下：\n（1）在仓库根目录创建新目录 .github\n（2）在 .github 目录中添加 ISSUE_TEMPLATE 目录，在其中添加的 md 文件都会被 Github 自动识，并将其作为 issue 的默认模板。\n示例，下面是携程 apollo 的一个 Issue 模板，要求提问者填充 bug 描述、复现步骤、期望、截图、日志等细节。\n更多模板：Github issue_templates 模板\nGitlab Issue 模板 如何在 Gitlab Issue 平台上创建 Issue 模板呢？方法如下：\n（1）在仓库根目录创建新目录 .gitlab\n（2）在 .gitlab 目录中添加 issue_templates 目录，在其中添加的 md 文件都会被 Gitlab 自动识，并将其作为 issue 的默认模板。\n更多模板：Gitlab 官方 issue_templates 模板\nGit Hook 在执行提交代码（git commit），推送代码（git push）等行为时，我们可能希望做一些代码检查性工作，例如：代码 lint 检查、代码格式化等。当检查发现代码存在问题时，就拒绝代码提交，从而保证项目质量。\nGit 提供了 Git Hook 机制，允许使用者在特定的重要动作发生时触发自定义脚本。有两类钩子：客户端钩子和服务器端钩子。客户端钩子由诸如提交和合并等操作所触发调用，而服务器端钩子作用于诸如接收被推送的提交这样的联网操作。钩子都被存储在 Git 项目目录下的 .git/hooks 子目录中。Git 在这个目录下放置了一些示例，这些示例的名字都是以 .sample 结尾，如果想启用它们，得先移除这个后缀。\n常用的客户端钩子：\npre-commit 钩子：在提交信息前运行。 它用于检查即将提交的快照，例如，检查是否有所遗漏，确保测试运行，以及核查代码。 如果该钩子以非零值退出，Git 将放弃此次提交，不过你可以用 git commit --no-verify 来绕过这个环节。 你可以利用该钩子，来检查代码风格是否一致（运行类似 lint 的程序）、尾随空白字符是否存在（自带的钩子就是这么做的），或新方法的文档是否适当。 prepare-commit-msg 钩子：在启动提交信息编辑器之前，默认信息被创建之后运行。 它允许你编辑提交者所看到的默认信息。 该钩子接收一些选项：存有当前提交信息的文件的路径、提交类型和修补提交的提交的 SHA-1 校验。 它对一般的提交来说并没有什么用；然而对那些会自动产生默认信息的提交，如提交信息模板、合并提交、压缩提交和修订提交等非常实用。 你可以结合提交模板来使用它，动态地插入信息。 commit-msg 钩子：接收一个参数，此参数即上文提到的，存有当前提交信息的临时文件的路径。 如果该钩子脚本以非零值退出，Git 将放弃提交，因此，可以用来在提交通过前验证项目状态或提交信息。 在本章的最后一节，我们将展示如何使用该钩子来核对提交信息是否遵循指定的模板。 post-commit 钩子：在整个提交过程完成后运行。它不接收任何参数，但你可以很容易地通过运行 git log -1 HEAD 来获得最后一次的提交信息。 该钩子一般用于通知之类的事情。 pre-push 钩子：会在 git push 运行期间， 更新了远程引用但尚未传送对象时被调用。 它接受远程分支的名字和位置作为参数，同时从标准输入中读取一系列待更新的引用。 你可以在推送开始之前，用它验证对引用的更新操作（一个非零的退出码将终止推送过程）。 Javascript 应用 Git Hook 想在 JavaScript 应用中使用 Git Hook，推荐使用 husky ，可以很方便的编写钩子处理命令。\n使用方法很简单，先安装 husky\n1 npm i -D husky 然后，在 package.json 中添加配置：\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;husky\u0026#34;: { \u0026#34;hooks\u0026#34;: { \u0026#34;pre-commit\u0026#34;: \u0026#34;lint-staged\u0026#34; } }, \u0026#34;lint-staged\u0026#34;: { \u0026#34;src/**/*.{js,vue}\u0026#34;: [ \u0026#34;eslint --fix\u0026#34;, \u0026#34;git add\u0026#34; ] }, 以上配置的作用是，当提交代码前（ pre-commit ），先执行 lint-staged；\nlint-staged 中执行的动作是，对 src 目录的所有 js、vue 文件进行 eslint 检查，并尝试修复。如果修复后没有问题，就 git add 添加修改后的文件；如果修复失败，则拒绝提交代码。\n参考资料 官方资源 Git 官网 Git Github Github 官方教程 模板 gitignore 模板 - .gitignore 文件模板 gitattributes 模板 - .gitattributes 文件模板 github-cheat-sheet - git 命令简略图表 Git 教程 Learn Git branching - 交互式教程 Git 官方推荐教程 - Scott Chacon 的 Git 书。 git-flight-rules git-tips Git 中文教程 廖雪峰的 Git 教程 有关 git 的学习资源 文章 Git Cookbook Git 奇技淫巧 Git 风格指南 Git 在团队中的最佳实践\u0026ndash;如何正确使用 Git Flow Commit message 和 Change log 编写指南 Git 工具 guis - Git 官网展示的客户端工具列表。 gogs - 极易搭建的自助 Git 服务。 gitflow - 应用 fit-flow 模型的工具。 firstaidgit.io 一个可搜索的最常被问到的 Git 的问题 git-extra-commands - 一堆有用的额外的 Git 脚本 git-extras - GIT 工具集 \u0026ndash; repo summary, repl, changelog population, author commit percentages and more git-fire - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。 git-tips - Git 小提示 git-town - 通用，高级 Git 工作流支持！ GUI 客户端 GitKraken - 豪华的 Git 客户端 Windows, Mac \u0026amp; Linux git-cola - 另外一个 Git 客户端 Windows \u0026amp; OS X GitUp - 一个新的 Git 客户端，在处理 Git 的复杂性上有自己的特点 gitx-dev - 图形化的 Git 客户端 OS X Source Tree - 免费的图形化 Git 客户端 Windows \u0026amp; OS X Tower - 图形化 Git 客户端 OS X(付费) git cheat sheet github-git-cheat-sheet ","permalink":"https://WFUing.github.io/posts/tech/architecture/git/git-principle/","summary":"Git 和其它版本控制系统（包括 Subversion 和近似工具）的主要差别在于 Git 对待数据的方式。 从概念上来说，其它大部分系统以文件变更列表的方式存储信息，而 Git 是把数据看作是对小型文件系统的一系列快照。","title":"Git Principle"},{"content":"Git 帮助手册 国外网友制作了一张 Git Cheat Sheet，总结很精炼，各位不妨收藏一下。\n本节选择性介绍 git 中比较常用的命令行场景。\n安装 （1）Debian/Ubuntu 环境安装\n如果你使用的系统是 Debian/Ubuntu ， 安装命令为：\n1 2 3 4 5 $ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ \u0026gt; libz-dev libssl-dev $ apt-get install git-core $ git --version git version 1.8.1.2 （2）Centos/RedHat 环境安装\n如果你使用的系统是 Centos/RedHat ，安装命令为：\n1 2 3 4 5 $ yum install curl-devel expat-devel gettext-devel \\ \u0026gt; openssl-devel zlib-devel $ yum -y install git-core $ git --version git version 1.7.1 （3）Windows 环境安装\n在Git 官方下载地址下载 exe 安装包。按照安装向导安装即可。\n建议安装 Git Bash 这个 git 的命令行工具。\n（4）Mac 环境安装\n在Git 官方下载地址下载 mac 安装包。按照安装向导安装即可。\n配置 Git 自带一个 git config 的工具来帮助设置控制 Git 外观和行为的配置变量。 这些变量存储在三个不同的位置：\n/etc/gitconfig 文件: 包含系统上每一个用户及他们仓库的通用配置。 如果使用带有 --system 选项的 git config 时，它会从此文件读写配置变量。 ~/.gitconfig 或 ~/.config/git/config 文件：只针对当前用户。 可以传递 --global 选项让 Git 读写此文件。 当前使用仓库的 Git 目录中的 config 文件（就是 .git/config）：针对该仓库。 每一个级别覆盖上一级别的配置，所以 .git/config 的配置变量会覆盖 /etc/gitconfig 中的配置变量。\n在 Windows 系统中，Git 会查找 $HOME 目录下（一般情况下是 C:\\Users\\$USER）的 .gitconfig 文件。 Git 同样也会寻找 /etc/gitconfig 文件，但只限于 MSys 的根目录下，即安装 Git 时所选的目标位置。\n配置用户信息 当安装完 Git 应该做的第一件事就是设置你的用户名称与邮件地址。 这样做很重要，因为每一个 Git 的提交都会使用这些信息，并且它会写入到你的每一次提交中，不可更改：\n1 2 git config --global user.name \u0026#34;John Doe\u0026#34; git config --global user.email johndoe@example.com 再次强调，如果使用了 --global 选项，那么该命令只需要运行一次，因为之后无论你在该系统上做任何事情， Git 都会使用那些信息。 当你想针对特定项目使用不同的用户名称与邮件地址时，可以在那个项目目录下运行没有 --global 选项的命令来配置。\n很多 GUI 工具都会在第一次运行时帮助你配置这些信息。\n给 Git 命令添加别名 在 OS X 和 Linux 下, 你的 Git 的配置文件储存在 ~/.gitconfig。我在[alias] 部分添加了一些快捷别名(和一些我容易拼写错误的)，如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 [alias] a = add amend = commit --amend c = commit ca = commit --amend ci = commit -a co = checkout d = diff dc = diff --changed ds = diff --staged f = fetch loll = log --graph --decorate --pretty=oneline --abbrev-commit m = merge one = log --pretty=oneline outstanding = rebase -i @{u} s = status unpushed = log @{u} wc = whatchanged wip = rebase -i @{u} zap = fetch -p 缓存一个仓库的用户名和密码 你可能有一个仓库需要授权，这时你可以缓存用户名和密码，而不用每次推/拉(push/pull)的时候都输入，Credential helper 能帮你。\n1 2 git config --global credential.helper cache ## Set git to use the credential memory cache 1 2 git config --global credential.helper \u0026#39;cache --timeout=3600\u0026#39; ## Set the cache to timeout after 1 hour (setting is in seconds) 仓库 初始化仓库 1 $ git init 克隆仓库 1 2 3 4 # 通过 SSH $ git clone ssh://user@domain.com/repo.git # 通过 HTTP $ git clone http://domain.com/user/repo.git 储藏 有时，我们需要在同一个项目的不同分支上工作。当需要切换分支时，偏偏本地的工作还没有完成，此时，提交修改显得不严谨，但是不提交代码又无法切换分支。这时，你可以使用 git stash 将本地的修改内容作为草稿储藏起来。\n官方称之为储藏，但我个人更喜欢称之为存草稿。\n1 2 3 4 5 6 7 8 9 10 11 12 # 1. 将修改作为当前分支的草稿保存 $ git stash # 2. 查看草稿列表 $ git stash list stash@{0}: WIP on master: 6fae349 📝 Writing docs. # 3.1 删除草稿 $ git stash drop stash@{0} # 3.2 读取草稿 $ git stash apply stash@{0} 暂存 git add 命令用于将修改添加到暂存区。\n暂存指定文件 1 git add xxx 暂存当前目录下所有修改 1 git add . 暂存所有修改 1 git add -A 暂存文件部分内容 暂存文件部分内容\n1 git add --patch filename.x -p 简写。这会打开交互模式， 你将能够用 s 选项来分隔提交(commit)；\n然而, 如果这个文件是新的, 会没有这个选择， 添加一个新文件时，这样做:\n1 git add -N filename.x 然后, 你需要用 e 选项来手动选择需要添加的行，执行 git diff --cached 将会显示哪些行暂存了哪些行只是保存在本地了。\n把暂存的内容变成未暂存，把未暂存的内容暂存起来 这个有点困难， 我能想到的最好的方法是先 stash 未暂存的内容， 然后重置(reset)，再 pop 第一步 stashed 的内容, 最后再 add 它们。\n1 2 3 4 git stash -k git reset --hard git stash pop git add -A 提交 git commit 命令用于将修改保存到到本地仓库。\n查看最近一次提交 1 git show 或者\n1 git log -n1 -p 提交本地的所有修改 1 git commit -a 提交暂存的修改 1 git commit 把暂存的内容添加到上一次的提交 1 git commit --amend 附加消息提交 1 git commit -m \u0026#39;commit message\u0026#39; 修改提交信息 如果你的提交信息写错了且这次提交（commit）还没有推送（push），可以使用以下命令修改：\n1 git commit --amend 或者\n1 git commit --amend -m \u0026#39;xxxxxxx\u0026#39; 修改提交信息中的用户名和邮箱 1 git commit --amend --author \u0026#34;New Authorname \u0026lt;authoremail@mydomain.com\u0026gt;\u0026#34; 从提交中移除一个文件 1 2 3 git checkout HEAD^ myfile git add -A git commit --amend 删除最后一次提交 如果你需要删除推了的提交(pushed commits)，你可以使用下面的方法。可是，这会不可逆的改变你的历史，也会搞乱那些已经从该仓库拉取(pulled)了的人的历史。简而言之，如果你不是很确定，千万不要这么做。\n1 2 git reset HEAD^ --hard git push -f [remote] [branch] 如果你还没有推到远程, 把 Git 重置(reset)到你最后一次提交前的状态就可以了(同时保存暂存的变化):\n1 (my-branch*)$ git reset --soft HEAD@{1} 这只能在没有推送之前有用. 如果你已经推了, 唯一安全能做的是 git revert SHAofBadCommit， 那会创建一个新的提交(commit)用于撤消前一个提交的所有变化(changes)； 或者, 如果你推的这个分支是 rebase-safe 的 (例如： 其它开发者不会从这个分支拉), 只需要使用 git push -f； 更多, 请参考 the above section。\n删除任意提交 同样的警告：不到万不得已的时候不要这么做.\n1 2 git rebase --onto SHA1_OF_BAD_COMMIT^ SHA1_OF_BAD_COMMIT git push -f [remote] [branch] 或者做一个 交互式 rebase 删除那些你想要删除的提交(commit)里所对应的行。\n我尝试推一个修正后的提交(amended commit)到远程，但是报错 1 2 3 4 5 6 7 To https://github.com/yourusername/repo.git ! [rejected] mybranch -\u0026gt; mybranch (non-fast-forward) error: failed to push some refs to \u0026#39;https://github.com/tanay1337/webmaker.org.git\u0026#39; hint: Updates were rejected because the tip of your current branch is behind hint: its remote counterpart. Integrate the remote changes (e.g. hint: \u0026#39;git pull ...\u0026#39;) before pushing again. hint: See the \u0026#39;Note about fast-forwards\u0026#39; in \u0026#39;git push --help\u0026#39; for details. 注意, rebasing(见下面)和修正(amending)会用一个新的提交(commit)代替旧的, 所以如果之前你已经往远程仓库上推过一次修正前的提交(commit)，那你现在就必须强推(force push) (-f)。 注意 – 总是 确保你指明一个分支!\n1 (my-branch)$ git push origin mybranch -f 一般来说, 要避免强推. 最好是创建和推(push)一个新的提交(commit)，而不是强推一个修正后的提交。后者会使那些与该分支或该分支的子分支工作的开发者，在源历史中产生冲突。\n不小心强制重置，想找回内容 如果你意外的做了 git reset --hard, 你通常能找回你的提交(commit), 因为 Git 对每件事都会有日志，且都会保存几天。\n1 (master)$ git reflog 你将会看到一个你过去提交(commit)的列表, 和一个重置的提交。 选择你想要回到的提交(commit)的 SHA，再重置一次:\n1 (master)$ git reset --hard SHA1234 这样就完成了。\n重置 撤销本地修改：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 移除缓存区的所有文件（i.e. 撤销上次git add） $ git reset HEAD # 将HEAD重置到上一次提交的版本，并将之后的修改标记为未添加到缓存区的修改 $ git reset \u0026lt;commit\u0026gt; # 将HEAD重置到上一次提交的版本，并保留未提交的本地修改 $ git reset --keep \u0026lt;commit\u0026gt; # 放弃工作目录下的所有修改 $ git reset --hard HEAD # 将HEAD重置到指定的版本，并抛弃该版本之后的所有修改 $ git reset --hard \u0026lt;commit-hash\u0026gt; # 用远端分支强制覆盖本地分支 $ git reset --hard \u0026lt;remote/branch\u0026gt; e.g., upstream/master, origin/my-feature # 放弃某个文件的所有本地修改 $ git checkout HEAD \u0026lt;file\u0026gt; 删除添加.gitignore文件前错误提交的文件：\n1 2 3 4 # 提交一条 git 记录，提交信息为 remove xyz file $ git rm -r --cached . $ git add . $ git commit -m \u0026#34;remove xyz file\u0026#34; 撤销远程修改（创建一个新的提交，并回滚到指定版本）：\n1 2 # revert 哈希号为 commit-hash 的记录 $ git revert \u0026lt;commit-hash\u0026gt; 彻底删除指定版本：\n1 2 3 # 执行下面命令后，commit-hash 提交后的记录都会被彻底删除，使用需谨慎 $ git reset --hard \u0026lt;commit-hash\u0026gt; $ git push -f 更新 1 2 3 4 5 6 7 8 # 下载远程端版本，但不合并到HEAD中 $ git fetch \u0026lt;remote\u0026gt; # 将远程端版本合并到本地版本中 $ git pull origin master # 以rebase方式将远端分支与本地合并 $ git pull --rebase \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; 推送 推送提交到远程仓库 1 git push remote \u0026lt;remote\u0026gt; \u0026lt;branch\u0026gt; 发布标签 1 git push --tags 未暂存 未暂存(Unstaged)的内容\n把未暂存的内容移动到一个新分支 git checkout -b my-branch 我想把未暂存的内容移动到另一个已存在的分支 1 2 3 git stash git checkout my-branch git stash pop 丢弃本地未提交的变化 如果你只是想重置源(origin)和你本地(local)之间的一些提交(commit)，你可以：\n1 2 3 4 5 6 7 8 ## one commit $ git reset --hard HEAD^ ## two commits $ git reset --hard HEAD^^ ## four commits $ git reset --hard HEAD~4 ## or $ git checkout -f 重置某个特殊的文件, 你可以用文件名做为参数:\n1 git reset filename 我想丢弃某些未暂存的内容 如果你想丢弃工作拷贝中的一部分内容，而不是全部。\n签出(checkout)不需要的内容，保留需要的。\n1 2 $ git checkout -p ## Answer y to all of the snippets you want to drop 另外一个方法是使用 stash， Stash 所有要保留下的内容, 重置工作拷贝, 重新应用保留的部分。\n1 2 3 4 $ git stash -p ## Select all of the snippets you want to save $ git reset --hard $ git stash pop 或者, stash 你不需要的部分, 然后 stash drop。\n1 2 3 $ git stash -p ## Select all of the snippets you don\u0026#39;t want to save $ git stash drop 分支 分支(Branches)\n列出所有的分支 1 git branch 列出所有的远端分支 1 git branch -r 基于当前分支创建新分支 1 git branch \u0026lt;new-branch\u0026gt; 基于远程分支创建新分支 1 git branch --track \u0026lt;new-branch\u0026gt; \u0026lt;remote-branch\u0026gt; 删除本地分支 1 git branch -d \u0026lt;branch\u0026gt; 强制删除本地分支 注意：强制删除本地分支，将会丢失未合并的修改\n1 git branch -D \u0026lt;branch\u0026gt; 删除远程分支 1 2 git push \u0026lt;remote\u0026gt; :\u0026lt;branch\u0026gt; (since Git v1.5.0) git push \u0026lt;remote\u0026gt; --delete \u0026lt;branch\u0026gt; (since Git v1.7.0) 切换分支 1 git checkout \u0026lt;branch\u0026gt; 创建并切换到新分支 1 git checkout -b \u0026lt;branch\u0026gt; 我从错误的分支拉取了内容，或把内容拉取到了错误的分支 这是另外一种使用 git reflog 情况，找到在这次错误拉(pull) 之前 HEAD 的指向。\n1 2 3 (master)$ git reflog ab7555f HEAD@{0}: pull origin wrong-branch: Fast-forward c5bc55a HEAD@{1}: checkout: checkout message goes here 重置分支到你所需的提交(desired commit):\n1 git reset --hard c5bc55a 完成。\n我想扔掉本地的提交(commit)，以便我的分支与远程的保持一致 先确认你没有推(push)你的内容到远程。\ngit status 会显示你领先(ahead)源(origin)多少个提交:\n1 2 3 4 5 (my-branch)$ git status ## On branch my-branch ## Your branch is ahead of \u0026#39;origin/my-branch\u0026#39; by 2 commits. ## (use \u0026#34;git push\u0026#34; to publish your local commits) # 一种方法是:\n1 (master)$ git reset --hard origin/my-branch 我需要提交到一个新分支，但错误的提交到了 master 在 master 下创建一个新分支，不切换到新分支,仍在 master 下:\n1 (master)$ git branch my-branch 把 master 分支重置到前一个提交:\n1 (master)$ git reset --hard HEAD^ HEAD^ 是 HEAD^1 的简写，你可以通过指定要设置的HEAD来进一步重置。\n或者, 如果你不想使用 HEAD^, 找到你想重置到的提交(commit)的 hash(git log 能够完成)， 然后重置到这个 hash。 使用git push 同步内容到远程。\n例如, master 分支想重置到的提交的 hash 为a13b85e:\n1 2 (master)$ git reset --hard a13b85e HEAD is now at a13b85e 签出(checkout)刚才新建的分支继续工作:\n1 (master)$ git checkout my-branch 我想保留来自另外一个 ref-ish 的整个文件 假设你正在做一个原型方案(原文为 working spike (see note)), 有成百的内容，每个都工作得很好。现在, 你提交到了一个分支，保存工作内容:\n1 (solution)$ git add -A \u0026amp;\u0026amp; git commit -m \u0026#34;Adding all changes from this spike into one big commit.\u0026#34; 当你想要把它放到一个分支里 (可能是feature, 或者 develop), 你关心是保持整个文件的完整，你想要一个大的提交分隔成比较小。\n假设你有:\n分支 solution, 拥有原型方案， 领先 develop 分支。 分支 develop, 在这里你应用原型方案的一些内容。 我去可以通过把内容拿到你的分支里，来解决这个问题:\n1 (develop)$ git checkout solution -- file1.txt 这会把这个文件内容从分支 solution 拿到分支 develop 里来:\n1 2 3 4 5 6 ## On branch develop ## Your branch is up-to-date with \u0026#39;origin/develop\u0026#39;. ## Changes to be committed: ## (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) # ## modified: file1.txt 然后, 正常提交。\nNote: Spike solutions are made to analyze or solve the problem. These solutions are used for estimation and discarded once everyone gets clear visualization of the problem. ~ Wikipedia.\n我把几个提交(commit)提交到了同一个分支，而这些提交应该分布在不同的分支里 假设你有一个master分支， 执行git log, 你看到你做过两次提交:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 (master)$ git log commit e3851e817c451cc36f2e6f3049db528415e3c114 Author: Alex Lee \u0026lt;alexlee@example.com\u0026gt; Date: Tue Jul 22 15:39:27 2014 -0400 Bug #21 - Added CSRF protection commit 5ea51731d150f7ddc4a365437931cd8be3bf3131 Author: Alex Lee \u0026lt;alexlee@example.com\u0026gt; Date: Tue Jul 22 15:39:12 2014 -0400 Bug #14 - Fixed spacing on title commit a13b85e984171c6e2a1729bb061994525f626d14 Author: Aki Rose \u0026lt;akirose@example.com\u0026gt; Date: Tue Jul 21 01:12:48 2014 -0400 First commit 让我们用提交 hash(commit hash)标记 bug (e3851e8 for #21, 5ea5173 for #14).\n首先, 我们把master分支重置到正确的提交(a13b85e):\n1 2 (master)$ git reset --hard a13b85e HEAD is now at a13b85e 现在, 我们对 bug #21 创建一个新的分支:\n1 2 (master)$ git checkout -b 21 (21)$ 接着, 我们用 cherry-pick 把对 bug #21 的提交放入当前分支。 这意味着我们将应用(apply)这个提交(commit)，仅仅这一个提交(commit)，直接在 HEAD 上面。\n1 (21)$ git cherry-pick e3851e8 这时候, 这里可能会产生冲突， 参见交互式 rebasing 章 冲突节 解决冲突.\n再者， 我们为 bug #14 创建一个新的分支, 也基于master分支\n1 2 3 (21)$ git checkout master (master)$ git checkout -b 14 (14)$ 最后, 为 bug #14 执行 cherry-pick:\n1 (14)$ git cherry-pick 5ea5173 我想删除上游(upstream)分支被删除了的本地分支 一旦你在 github 上面合并(merge)了一个 pull request, 你就可以删除你 fork 里被合并的分支。 如果你不准备继续在这个分支里工作, 删除这个分支的本地拷贝会更干净，使你不会陷入工作分支和一堆陈旧分支的混乱之中。\n1 git fetch -p 我不小心删除了我的分支 如果你定期推送到远程, 多数情况下应该是安全的，但有些时候还是可能删除了还没有推到远程的分支。 让我们先创建一个分支和一个新的文件:\n1 2 3 4 5 (master)$ git checkout -b my-branch (my-branch)$ git branch (my-branch)$ touch foo.txt (my-branch)$ ls README.md foo.txt 添加文件并做一次提交\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 (my-branch)$ git add . (my-branch)$ git commit -m \u0026#39;foo.txt added\u0026#39; (my-branch)$ foo.txt added 1 files changed, 1 insertions(+) create mode 100644 foo.txt (my-branch)$ git log commit 4e3cd85a670ced7cc17a2b5d8d3d809ac88d5012 Author: siemiatj \u0026lt;siemiatj@example.com\u0026gt; Date: Wed Jul 30 00:34:10 2014 +0200 foo.txt added commit 69204cdf0acbab201619d95ad8295928e7f411d5 Author: Kate Hudson \u0026lt;katehudson@example.com\u0026gt; Date: Tue Jul 29 13:14:46 2014 -0400 Fixes #6: Force pushing after amending commits 现在我们切回到主(master)分支，‘不小心的’删除my-branch分支\n1 2 3 4 5 6 7 (my-branch)$ git checkout master Switched to branch \u0026#39;master\u0026#39; Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. (master)$ git branch -D my-branch Deleted branch my-branch (was 4e3cd85). (master)$ echo oh noes, deleted my branch! oh noes, deleted my branch! 在这时候你应该想起了reflog, 一个升级版的日志，它存储了仓库(repo)里面所有动作的历史。\n1 2 3 4 (master)$ git reflog 69204cd HEAD@{0}: checkout: moving from my-branch to master 4e3cd85 HEAD@{1}: commit: foo.txt added 69204cd HEAD@{2}: checkout: moving from master to my-branch 正如你所见，我们有一个来自删除分支的提交 hash(commit hash)，接下来看看是否能恢复删除了的分支。\n1 2 3 4 5 6 (master)$ git checkout -b my-branch-help Switched to a new branch \u0026#39;my-branch-help\u0026#39; (my-branch-help)$ git reset --hard 4e3cd85 HEAD is now at 4e3cd85 foo.txt added (my-branch-help)$ ls README.md foo.txt 看! 我们把删除的文件找回来了。 Git 的 reflog 在 rebasing 出错的时候也是同样有用的。\n我想删除一个分支 删除一个远程分支:\n1 (master)$ git push origin --delete my-branch 你也可以:\n1 (master)$ git push origin :my-branch 删除一个本地分支:\n1 (master)$ git branch -D my-branch 我想从别人正在工作的远程分支签出(checkout)一个分支 首先, 从远程拉取(fetch) 所有分支:\n1 (master)$ git fetch --all 假设你想要从远程的daves分支签出到本地的daves\n1 2 3 (master)$ git checkout --track origin/daves Branch daves set up to track remote branch daves from origin. Switched to a new branch \u0026#39;daves\u0026#39; (--track 是 git checkout -b [branch] [remotename]/[branch] 的简写)\n这样就得到了一个daves分支的本地拷贝, 任何推过(pushed)的更新，远程都能看到.\n标签 添加标签 1 $ git tag \u0026lt;tag-name\u0026gt; 添加标签并附加消息 1 $ git tag -a \u0026lt;tag-name\u0026gt; 删除标签 1 2 git tag -d \u0026lt;tag_name\u0026gt; git push \u0026lt;remote\u0026gt; :refs/tags/\u0026lt;tag_name\u0026gt; 恢复已删除标签 如果你想恢复一个已删除标签(tag), 可以按照下面的步骤: 首先, 需要找到无法访问的标签(unreachable tag):\n1 git fsck --unreachable | grep tag 记下这个标签(tag)的 hash，然后用 Git 的 update-ref:\n1 git update-ref refs/tags/\u0026lt;tag_name\u0026gt; \u0026lt;hash\u0026gt; 这时你的标签(tag)应该已经恢复了。\nRebase 和 Merge merge 与 rebase 虽然是 git 常用功能，但是强烈建议不要使用 git 命令来完成这项工作。\n因为如果出现代码冲突，在没有代码比对工具的情况下，实在太艰难了。\n你可以考虑使用各种 Git GUI 工具。\n将分支合并到当前 HEAD 中 1 git merge \u0026lt;branch\u0026gt; 将当前 HEAD 版本重置到分支中 1 git rebase \u0026lt;branch\u0026gt; 撤销 rebase/merge 你可以合并(merge)或 rebase 了一个错误的分支, 或者完成不了一个进行中的 rebase/merge。 Git 在进行危险操作的时候会把原始的 HEAD 保存在一个叫 ORIG_HEAD 的变量里, 所以要把分支恢复到 rebase/merge 前的状态是很容易的。\n1 (my-branch)$ git reset --hard ORIG_HEAD 我已经 rebase 过, 但是我不想强推(force push) 不幸的是，如果你想把这些变化(changes)反应到远程分支上，你就必须得强推(force push)。 是因你快进(Fast forward)了提交，改变了 Git 历史, 远程分支不会接受变化(changes)，除非强推(force push)。这就是许多人使用 merge 工作流, 而不是 rebasing 工作流的主要原因之一， 开发者的强推(force push)会使大的团队陷入麻烦。使用时需要注意，一种安全使用 rebase 的方法是，不要把你的变化(changes)反映到远程分支上, 而是按下面的做:\n1 2 3 4 (master)$ git checkout my-branch (my-branch)$ git rebase -i master (my-branch)$ git checkout master (master)$ git merge --ff-only my-branch 更多, 参见 this SO thread.\n我需要组合(combine)几个提交(commit) 假设你的工作分支将会做对于 master 的 pull-request。 一般情况下你不关心提交(commit)的时间戳，只想组合 所有 提交(commit) 到一个单独的里面, 然后重置(reset)重提交(recommit)。 确保主(master)分支是最新的和你的变化都已经提交了, 然后:\n1 2 (my-branch)$ git reset --soft master (my-branch)$ git commit -am \u0026#34;New awesome feature\u0026#34; 如果你想要更多的控制, 想要保留时间戳, 你需要做交互式 rebase (interactive rebase):\n1 (my-branch)$ git rebase -i master 如果没有相对的其它分支， 你将不得不相对自己的HEAD 进行 rebase。 例如：你想组合最近的两次提交(commit), 你将相对于HEAD\\~2 进行 rebase， 组合最近 3 次提交(commit), 相对于HEAD\\~3, 等等。\n1 (master)$ git rebase -i HEAD~2 在你执行了交互式 rebase 的命令(interactive rebase command)后, 你将在你的编辑器里看到类似下面的内容:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature pick b729ad5 fixup pick e3851e8 another fix ## Rebase 8074d12..b729ad5 onto 8074d12 # ## Commands: ## p, pick = use commit ## r, reword = use commit, but edit the commit message ## e, edit = use commit, but stop for amending ## s, squash = use commit, but meld into previous commit ## f, fixup = like \u0026#34;squash\u0026#34;, but discard this commit\u0026#39;s log message ## x, exec = run command (the rest of the line) using shell # ## These lines can be re-ordered; they are executed from top to bottom. # ## If you remove a line here THAT COMMIT WILL BE LOST. # ## However, if you remove everything, the rebase will be aborted. # ## Note that empty commits are commented out 所有以 # 开头的行都是注释, 不会影响 rebase.\n然后，你可以用任何上面命令列表的命令替换 pick, 你也可以通过删除对应的行来删除一个提交(commit)。\n例如, 如果你想 单独保留最旧(first)的提交(commit),组合所有剩下的到第二个里面, 你就应该编辑第二个提交(commit)后面的每个提交(commit) 前的单词为 f:\n1 2 3 4 pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature f b729ad5 fixup f e3851e8 another fix 如果你想组合这些提交(commit) 并重命名这个提交(commit), 你应该在第二个提交(commit)旁边添加一个r，或者更简单的用s 替代 f:\n1 2 3 4 pick a9c8a1d Some refactoring pick 01b2fd8 New awesome feature s b729ad5 fixup s e3851e8 another fix 你可以在接下来弹出的文本提示框里重命名提交(commit)。\n1 2 3 4 5 6 7 8 9 10 Newer, awesomer features ## Please enter the commit message for your changes. Lines starting ## with \u0026#39;#\u0026#39; will be ignored, and an empty message aborts the commit. ## rebase in progress; onto 8074d12 ## You are currently editing a commit while rebasing branch \u0026#39;master\u0026#39; on \u0026#39;8074d12\u0026#39;. # ## Changes to be committed: # modified: README.md # 如果成功了, 你应该看到类似下面的内容:\n1 (master)$ Successfully rebased and updated refs/heads/master. 安全合并(merging)策略 --no-commit 执行合并(merge)但不自动提交, 给用户在做提交前检查和修改的机会。 no-ff 会为特性分支(feature branch)的存在过留下证据, 保持项目历史一致。\n1 (master)$ git merge --no-ff --no-commit my-branch 我需要将一个分支合并成一个提交(commit) 1 (master)$ git merge --squash my-branch 我只想组合(combine)未推的提交(unpushed commit) 有时候，在将数据推向上游之前，你有几个正在进行的工作提交(commit)。这时候不希望把已经推(push)过的组合进来，因为其他人可能已经有提交(commit)引用它们了。\n1 (master)$ git rebase -i @{u} 这会产生一次交互式的 rebase(interactive rebase), 只会列出没有推(push)的提交(commit)， 在这个列表时进行 reorder/fix/squash 都是安全的。\n检查是否分支上的所有提交(commit)都合并(merge)过了 检查一个分支上的所有提交(commit)是否都已经合并(merge)到了其它分支, 你应该在这些分支的 head(或任何 commits)之间做一次 diff:\n1 (master)$ git log --graph --left-right --cherry-pick --oneline HEAD...feature/120-on-scroll 这会告诉你在一个分支里有而另一个分支没有的所有提交(commit), 和分支之间不共享的提交(commit)的列表。 另一个做法可以是:\n1 (master)$ git log master ^feature/120-on-scroll --no-merges 交互式 rebase(interactive rebase)可能出现的问题 这个 rebase 编辑屏幕出现\u0026rsquo;noop' 如果你看到的是这样:\n1 noop 这意味着你 rebase 的分支和当前分支在同一个提交(commit)上, 或者 领先(ahead) 当前分支。 你可以尝试:\n检查确保主(master)分支没有问题 rebase HEAD\\~2 或者更早 有冲突的情况 如果你不能成功的完成 rebase, 你可能必须要解决冲突。\n首先执行 git status 找出哪些文件有冲突:\n1 2 3 4 5 6 7 (my-branch)$ git status On branch my-branch Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: README.md 在这个例子里面, README.md 有冲突。 打开这个文件找到类似下面的内容:\n1 2 3 4 5 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD some code ========= some code \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; new-commit 你需要解决新提交的代码(示例里, 从中间==线到new-commit的地方)与HEAD 之间不一样的地方.\n有时候这些合并非常复杂，你应该使用可视化的差异编辑器(visual diff editor):\n1 (master*)$ git mergetool -t opendiff 在你解决完所有冲突和测试过后, git add 变化了的(changed)文件, 然后用git rebase --continue 继续 rebase。\n1 2 (my-branch)$ git add README.md (my-branch)$ git rebase --continue 如果在解决完所有的冲突过后，得到了与提交前一样的结果, 可以执行git rebase --skip。\n任何时候你想结束整个 rebase 过程，回来 rebase 前的分支状态, 你可以做:\n1 (my-branch)$ git rebase --abort 查看信息 显示工作路径下已修改的文件：git status\n显示与上次提交版本文件的不同：git diff\n显示提交历史：\n1 2 3 4 5 6 7 8 # 从最新提交开始，显示所有的提交记录（显示hash， 作者信息，提交的标题和时间） $ git log # 显示某个用户的所有提交 $ git log --author=\u0026#34;username\u0026#34; # 显示某个文件的所有修改 $ git log -p \u0026lt;file\u0026gt; 显示搜索内容：\n1 2 3 4 5 # 从当前目录的所有文件中查找文本内容 $ git grep \u0026#34;Hello\u0026#34; # 在某一版本中搜索文本 $ git grep \u0026#34;Hello\u0026#34; v2.5 其他 克隆所有子模块 1 git clone --recursive git://github.com/foo/bar.git 如果已经克隆了:\n1 git submodule update --init --recursive 已删除补丁(patch) 如果某人在 GitHub 上给你发了一个 pull request, 但是然后他删除了他自己的原始 fork, 你将没法克隆他们的提交(commit)或使用 git am。在这种情况下, 最好手动的查看他们的提交(commit)，并把它们拷贝到一个本地新分支，然后做提交。\n做完提交后, 再修改作者，参见变更作者。 然后, 应用变化, 再发起一个新的 pull request。\n跟踪文件(Tracking Files) 我只想改变一个文件名字的大小写，而不修改内容 1 (master)$ git mv --force myfile MyFile 我想从 Git 删除一个文件，但保留该文件 1 (master)$ git rm --cached log.txt Fork 项目 GitHub 中 Fork 是 服务端的代码仓库克隆（即 新克隆出来的代码仓库在远程服务端），包含了原来的仓库（即 upstream repository，上游仓库）所有内容，如分支、Tag、提交。代码托管服务（如 Github、BitBucket）提供了方便的完成 Fork 操作的功能（在仓库页面点一下 Fork 按钮）。这样有了一个你自己的可以自由提交的远程仓库，然后可以通过的 Pull Request 把你的提交贡献回 原仓库。而对于原仓库 Owner 来说，鼓励别人 Fork 自己的仓库，通过 Pull Request 给自己的仓库做贡献，也能提高了自己仓库的知名度。\n参考：Fork a repo\n（1）执行 git remote -v，您将看到当前为 fork 配置的远程存储库。\n（2）添加上游项目的仓库地址\n1 git remote add upstream \u0026lt;github仓库地址\u0026gt; （3）确认是否添加成功，再次键入 git remote -v。\n（4）获取上游项目更新，可以执行 git fetch upstream\n（5）同步上游项目的代码到新仓库\n1 2 3 4 # merge git merge upstream/master # rebase git rebase upstream/master origin/master 我不知道我做错了些什么 你把事情搞砸了：你 重置(reset) 了一些东西, 或者你合并了错误的分支, 亦或你强推了后找不到你自己的提交(commit)了。有些时候, 你一直都做得很好, 但你想回到以前的某个状态。\n这就是 git reflog 的目的， reflog 记录对分支顶端(the tip of a branch)的任何改变, 即使那个顶端没有被任何分支或标签引用。基本上, 每次 HEAD 的改变, 一条新的记录就会增加到reflog。遗憾的是，这只对本地分支起作用，且它只跟踪动作 (例如，不会跟踪一个没有被记录的文件的任何改变)。\n1 2 3 4 (master)$ git reflog 0a2e358 HEAD@{0}: reset: moving to HEAD\\~2 0254ea7 HEAD@{1}: checkout: moving from 2.2 to master c10f740 HEAD@{2}: checkout: moving from master to 2.2 上面的 reflog 展示了从 master 分支签出(checkout)到 2.2 分支，然后再签回。 那里，还有一个硬重置(hard reset)到一个较旧的提交。最新的动作出现在最上面以 HEAD@{0}标识.\n如果事实证明你不小心回移(move back)了提交(commit), reflog 会包含你不小心回移前 master 上指向的提交(0254ea7)。\n1 git reset --hard 0254ea7 然后使用 git reset 就可以把 master 改回到之前的 commit，这提供了一个在历史被意外更改情况下的安全网。\n📚 资料 官方资源 Git 官网 Git Github Github 官方教程 模板 gitignore 模板 - .gitignore 文件模板 gitattributes 模板 - .gitattributes 文件模板 github-cheat-sheet - git 命令简略图表 Git 教程 Learn Git branching - 交互式教程 Git 官方推荐教程 - Scott Chacon 的 Git 书。 git-flight-rules git-tips Git 中文教程 廖雪峰的 Git 教程 有关 git 的学习资源 文章 Git Cookbook Git 奇技淫巧 Git 风格指南 Git 在团队中的最佳实践\u0026ndash;如何正确使用 Git Flow Commit message 和 Change log 编写指南 Git 工具 guis - Git 官网展示的客户端工具列表。 gogs - 极易搭建的自助 Git 服务。 gitflow - 应用 fit-flow 模型的工具。 firstaidgit.io 一个可搜索的最常被问到的 Git 的问题 git-extra-commands - 一堆有用的额外的 Git 脚本 git-extras - GIT 工具集 \u0026ndash; repo summary, repl, changelog population, author commit percentages and more git-fire - git-fire 是一个 Git 插件，用于帮助在紧急情况下添加所有当前文件, 做提交(committing), 和推(push)到一个新分支(阻止合并冲突)。 git-tips - Git 小提示 git-town - 通用，高级 Git 工作流支持！ GUI 客户端 GitKraken - 豪华的 Git 客户端 Windows, Mac \u0026amp; Linux git-cola - 另外一个 Git 客户端 Windows \u0026amp; OS X GitUp - 一个新的 Git 客户端，在处理 Git 的复杂性上有自己的特点 gitx-dev - 图形化的 Git 客户端 OS X Source Tree - 免费的图形化 Git 客户端 Windows \u0026amp; OS X Tower - 图形化 Git 客户端 OS X(付费) git cheat sheet github-git-cheat-sheet ","permalink":"https://WFUing.github.io/posts/tech/architecture/git/git-tutorial/","summary":"Git 帮助手册 国外网友制作了一张 Git Cheat Sheet，总结很精炼，各位不妨收藏一下。\n本节选择性介绍 git 中比较常用的命令行场景。\n安装 （1）Debian/Ubuntu 环境安装\n如果你使用的系统是 Debian/Ubuntu ， 安装命令为：\n1 2 3 4 5 $ apt-get install libcurl4-gnutls-dev libexpat1-dev gettext \\ \u0026gt; libz-dev libssl-dev $ apt-get install git-core $ git --version git version 1.8.1.2 （2）Centos/RedHat 环境安装\n如果你使用的系统是 Centos/RedHat ，安装命令为：\n1 2 3 4 5 $ yum install curl-devel expat-devel gettext-devel \\ \u0026gt; openssl-devel zlib-devel $ yum -y install git-core $ git --version git version 1.","title":"Git Tutorial"},{"content":" 由于 bash 是 Linux 标准默认的 shell 解释器，可以说 bash 是 shell 编程的基础。\n本文主要介绍 bash 的语法，对于 linux 指令不做任何介绍。\n1 2 3 4 5 ███████╗██╗ ██╗███████╗██╗ ██╗ ██╔════╝██║ ██║██╔════╝██║ ██║ ███████╗███████║█████╗ ██║ ██║ ╚════██║██╔══██║██╔══╝ ██║ ██║ ███████║██║ ██║███████╗███████╗███████╗ 简介 什么是 shell Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。 Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问 Linux 内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。\n什么是 shell 脚本 Shell 脚本（shell script），是一种为 shell 编写的脚本程序，一般文件后缀为 .sh。\n业界所说的 shell 通常都是指 shell 脚本，但 shell 和 shell script 是两个不同的概念。\nShell 环境 Shell 编程跟 java、php 编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。\nShell 的解释器种类众多，常见的有：\nsh - 即 Bourne Shell。sh 是 Unix 标准默认的 shell。 bash - 即 Bourne Again Shell。bash 是 Linux 标准默认的 shell。 fish - 智能和用户友好的命令行 shell。 xiki - 使 shell 控制台更友好，更强大。 zsh - 功能强大的 shell 与脚本语言。 指定脚本解释器 在 shell 脚本，#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 解释器。#! 被称作shebang（也称为 Hashbang ）。\n所以，你应该会在 shell 中，见到诸如以下的注释：\n指定 sh 解释器 1 #!/bin/sh 指定 bash 解释器 1 #!/bin/bash 注意\n上面的指定解释器的方式是比较常见的，但有时候，你可能也会看到下面的方式：\n1 #!/usr/bin/env bash 这样做的好处是，系统会自动在 PATH 环境变量中查找你指定的程序（本例中的bash）。相比第一种写法，你应该尽量用这种写法，因为程序的路径是不确定的。这样写还有一个好处，操作系统的PATH变量有可能被配置为指向程序的另一个版本。比如，安装完新版本的bash，我们可能将其路径添加到PATH中，来\u0026quot;隐藏\u0026quot;老版本。如果直接用#!/bin/bash，那么系统会选择老版本的bash来执行脚本，如果用#!/usr/bin/env bash，则会使用新版本。\n模式 shell 有交互和非交互两种模式。\n交互模式 简单来说，你可以将 shell 的交互模式理解为执行命令行。\n看到形如下面的东西，说明 shell 处于交互模式下：\n1 user@host:~$ 接着，便可以输入一系列 Linux 命令，比如 ls，grep，cd，mkdir，rm 等等。\n非交互模式 简单来说，你可以将 shell 的非交互模式理解为执行 shell 脚本。\n在非交互模式下，shell 从文件或者管道中读取命令并执行。\n当 shell 解释器执行完文件中的最后一个命令，shell 进程终止，并回到父进程。\n可以使用下面的命令让 shell 以非交互模式运行：\n1 2 3 4 sh /path/to/script.sh bash /path/to/script.sh source /path/to/script.sh ./path/to/script.sh 上面的例子中，script.sh是一个包含 shell 解释器可以识别并执行的命令的普通文本文件，sh和bash是 shell 解释器程序。你可以使用任何喜欢的编辑器创建script.sh（vim，nano，Sublime Text, Atom 等等）。\n其中，source /path/to/script.sh 和 ./path/to/script.sh 是等价的。\n除此之外，你还可以通过chmod命令给文件添加可执行的权限，来直接执行脚本文件：\n1 2 chmod +x /path/to/script.sh #使脚本具有执行权限 /path/to/test.sh 这种方式要求脚本文件的第一行必须指明运行该脚本的程序，比如：\n💻 『示例源码』\n1 2 #!/usr/bin/env bash echo \u0026#34;Hello, world!\u0026#34; 上面的例子中，我们使用了一个很有用的命令echo来输出字符串到屏幕上。\n基本语法 解释器 前面虽然两次提到了#! ，但是本着重要的事情说三遍的精神，这里再强调一遍：\n在 shell 脚本，#! 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 解释器。#! 被称作shebang（也称为 Hashbang ）。\n#! 决定了脚本可以像一个独立的可执行文件一样执行，而不用在终端之前输入sh, bash, python, php等。\n1 2 3 # 以下两种方式都可以指定 shell 解释器为 bash，第二种方式更好 #!/bin/bash #!/usr/bin/env bash 注释 注释可以说明你的代码是什么作用，以及为什么这样写。\nshell 语法中，注释是特殊的语句，会被 shell 解释器忽略。\n单行注释 - 以 # 开头，到行尾结束。 多行注释 - 以 :\u0026lt;\u0026lt;EOF 开头，到 EOF 结束。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #-------------------------------------------- # shell 注释示例 # author：zp #-------------------------------------------- # echo \u0026#39;这是单行注释\u0026#39; ########## 这是分割线 ########## :\u0026lt;\u0026lt;EOF echo \u0026#39;这是多行注释\u0026#39; echo \u0026#39;这是多行注释\u0026#39; echo \u0026#39;这是多行注释\u0026#39; EOF echo echo 用于字符串的输出。\n输出普通字符串：\n1 2 echo \u0026#34;hello, world\u0026#34; # Output: hello, world 输出含变量的字符串：\n1 2 echo \u0026#34;hello, \\\u0026#34;zp\\\u0026#34;\u0026#34; # Output: hello, \u0026#34;zp\u0026#34; 输出含变量的字符串：\n1 2 3 name=zp echo \u0026#34;hello, \\\u0026#34;${name}\\\u0026#34;\u0026#34; # Output: hello, \u0026#34;zp\u0026#34; 输出含换行符的字符串：\n1 2 3 4 5 6 7 8 # 输出含换行符的字符串 echo \u0026#34;YES\\nNO\u0026#34; # Output: YES\\nNO echo -e \u0026#34;YES\\nNO\u0026#34; # -e 开启转义 # Output: # YES # NO 输出含不换行符的字符串：\n1 2 3 4 5 6 7 8 9 10 echo \u0026#34;YES\u0026#34; echo \u0026#34;NO\u0026#34; # Output: # YES # NO echo -e \u0026#34;YES\\c\u0026#34; # -e 开启转义 \\c 不换行 echo \u0026#34;NO\u0026#34; # Output: # YESNO 输出重定向至文件\n1 echo \u0026#34;test\u0026#34; \u0026gt; test.txt 输出执行结果\n1 2 echo `pwd` # Output:(当前目录路径) 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #!/usr/bin/env bash # 输出普通字符串 echo \u0026#34;hello, world\u0026#34; # Output: hello, world # 输出含变量的字符串 echo \u0026#34;hello, \\\u0026#34;zp\\\u0026#34;\u0026#34; # Output: hello, \u0026#34;zp\u0026#34; # 输出含变量的字符串 name=zp echo \u0026#34;hello, \\\u0026#34;${name}\\\u0026#34;\u0026#34; # Output: hello, \u0026#34;zp\u0026#34; # 输出含换行符的字符串 echo \u0026#34;YES\\nNO\u0026#34; # Output: YES\\nNO echo -e \u0026#34;YES\\nNO\u0026#34; # -e 开启转义 # Output: # YES # NO # 输出含不换行符的字符串 echo \u0026#34;YES\u0026#34; echo \u0026#34;NO\u0026#34; # Output: # YES # NO echo -e \u0026#34;YES\\c\u0026#34; # -e 开启转义 \\c 不换行 echo \u0026#34;NO\u0026#34; # Output: # YESNO # 输出内容定向至文件 echo \u0026#34;test\u0026#34; \u0026gt; test.txt # 输出执行结果 echo `pwd` # Output:(当前目录路径) printf printf 用于格式化输出字符串。\n默认，printf 不会像 echo 一样自动添加换行符，如果需要换行可以手动添加 \\n。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # 单引号 printf \u0026#39;%d %s\\n\u0026#39; 1 \u0026#34;abc\u0026#34; # Output:1 abc # 双引号 printf \u0026#34;%d %s\\n\u0026#34; 1 \u0026#34;abc\u0026#34; # Output:1 abc # 无引号 printf %s abcdef # Output: abcdef(并不会换行) # 格式只指定了一个参数，但多出的参数仍然会按照该格式输出 printf \u0026#34;%s\\n\u0026#34; abc def # Output: # abc # def printf \u0026#34;%s %s %s\\n\u0026#34; a b c d e f g h i j # Output: # a b c # d e f # g h i # j # 如果没有参数，那么 %s 用 NULL 代替，%d 用 0 代替 printf \u0026#34;%s and %d \\n\u0026#34; # Output: # and 0 # 格式化输出 printf \u0026#34;%-10s %-8s %-4s\\n\u0026#34; 姓名 性别 体重kg printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 郭靖 男 66.1234 printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 杨过 男 48.6543 printf \u0026#34;%-10s %-8s %-4.2f\\n\u0026#34; 郭芙 女 47.9876 # Output: # 姓名 性别 体重kg # 郭靖 男 66.12 # 杨过 男 48.65 # 郭芙 女 47.99 printf 的转义符 序列 说明 \\a 警告字符，通常为 ASCII 的 BEL 字符 \\b 后退 \\c 抑制（不显示）输出结果中任何结尾的换行字符（只在%b 格式指示符控制下的参数字符串中有效），而且，任何留在参数里的字符、任何接下来的参数以及任何留在格式字符串中的字符，都被忽略 \\f 换页（formfeed） \\n 换行 \\r 回车（Carriage return） \\t 水平制表符 \\v 垂直制表符 \\\\ 一个字面上的反斜杠字符 \\ddd 表示 1 到 3 位数八进制值的字符。仅在格式字符串中有效 \\0ddd 表示 1 到 3 位的八进制值字符 变量 跟许多程序设计语言一样，你可以在 bash 中创建变量。\nBash 中没有数据类型，bash 中的变量可以保存一个数字、一个字符、一个字符串等等。同时无需提前声明变量，给变量赋值会直接创建变量。\n变量命名原则 命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。 中间不能有空格，可以使用下划线（_）。 不能使用标点符号。 不能使用 bash 里的关键字（可用 help 命令查看保留关键字）。 声明变量 访问变量的语法形式为：${var} 和 $var 。\n变量名外面的花括号是可选的，加不加都行，加花括号是为了帮助解释器识别变量的边界，所以推荐加花括号。\n1 2 3 word=\u0026#34;hello\u0026#34; echo ${word} # Output: hello 只读变量 使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。\n1 2 3 4 rword=\u0026#34;hello\u0026#34; echo ${rword} readonly rword # rword=\u0026#34;bye\u0026#34; # 如果放开注释，执行时会报错 删除变量 使用 unset 命令可以删除变量。变量被删除后不能再次使用。unset 命令不能删除只读变量。\n1 2 3 4 5 6 7 dword=\u0026#34;hello\u0026#34; # 声明变量 echo ${dword} # 输出变量值 # Output: hello unset dword # 删除变量 echo ${dword} # Output: （空） 变量类型 局部变量 - 局部变量是仅在某个脚本内部有效的变量。它们不能被其他的程序和脚本访问。 环境变量 - 环境变量是对当前 shell 会话内所有的程序或脚本都可见的变量。创建它们跟创建局部变量类似，但使用的是 export 关键字，shell 脚本也可以定义环境变量。 常见的环境变量：\n变量 描述 $HOME 当前用户的用户目录 $PATH 用分号分隔的目录列表，shell 会到这些目录中查找命令 $PWD 当前工作目录 $RANDOM 0 到 32767 之间的整数 $UID 数值类型，当前用户的用户 ID $PS1 主要系统输入提示符 $PS2 次要系统输入提示符 这里 有一张更全面的 Bash 环境变量列表。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #!/usr/bin/env bash ################### 声明变量 ################### name=\u0026#34;world\u0026#34; echo \u0026#34;hello ${name}\u0026#34; # Output: hello world ################### 输出变量 ################### folder=$(pwd) echo \u0026#34;current path: ${folder}\u0026#34; ################### 只读变量 ################### rword=\u0026#34;hello\u0026#34; echo ${rword} # Output: hello readonly rword # rword=\u0026#34;bye\u0026#34; # 如果放开注释，执行时会报错 ################### 删除变量 ################### dword=\u0026#34;hello\u0026#34; # 声明变量 echo ${dword} # 输出变量值 # Output: hello unset dword # 删除变量 echo ${dword} # Output: （空） ################### 系统变量 ################### echo \u0026#34;UID:$UID\u0026#34; echo LOGNAME:$LOGNAME echo User:$USER echo HOME:$HOME echo PATH:$PATH echo HOSTNAME:$HOSTNAME echo SHELL:$SHELL echo LANG:$LANG ################### 自定义变量 ################### days=10 user=\u0026#34;admin\u0026#34; echo \u0026#34;$user logged in $days days age\u0026#34; days=5 user=\u0026#34;root\u0026#34; echo \u0026#34;$user logged in $days days age\u0026#34; # Output: # admin logged in 10 days age # root logged in 5 days age ################### 从变量读取列表 ################### colors=\u0026#34;Red Yellow Blue\u0026#34; colors=$colors\u0026#34; White Black\u0026#34; for color in $colors do echo \u0026#34; $color\u0026#34; done 字符串 单引号和双引号 shell 字符串可以用单引号 ''，也可以用双引号 “”，也可以不用引号。\n单引号的特点 单引号里不识别变量 单引号里不能出现单独的单引号（使用转义符也不行），但可成对出现，作为字符串拼接使用。 双引号的特点 双引号里识别变量 双引号里可以出现转义字符 综上，推荐使用双引号。\n拼接字符串 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 使用单引号拼接 name1=\u0026#39;white\u0026#39; str1=\u0026#39;hello, \u0026#39;${name1}\u0026#39;\u0026#39; str2=\u0026#39;hello, ${name1}\u0026#39; echo ${str1}_${str2} # Output: # hello, white_hello, ${name1} # 使用双引号拼接 name2=\u0026#34;black\u0026#34; str3=\u0026#34;hello, \u0026#34;${name2}\u0026#34;\u0026#34; str4=\u0026#34;hello, ${name2}\u0026#34; echo ${str3}_${str4} # Output: # hello, black_hello, black 获取字符串长度 1 2 3 4 text=\u0026#34;12345\u0026#34; echo ${#text} # Output: # 5 截取子字符串 1 2 3 4 text=\u0026#34;12345\u0026#34; echo ${text:2:2} # Output: # 34 从第 3 个字符开始，截取 2 个字符\n查找子字符串 1 2 3 4 5 6 7 8 #!/usr/bin/env bash text=\u0026#34;hello\u0026#34; echo `expr index \u0026#34;${text}\u0026#34; ll` # Execute: ./str-demo5.sh # Output: # 3 查找 ll 子字符在 hello 字符串中的起始位置。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 #!/usr/bin/env bash ################### 使用单引号拼接字符串 ################### name1=\u0026#39;white\u0026#39; str1=\u0026#39;hello, \u0026#39;${name1}\u0026#39;\u0026#39; str2=\u0026#39;hello, ${name1}\u0026#39; echo ${str1}_${str2} # Output: # hello, white_hello, ${name1} ################### 使用双引号拼接字符串 ################### name2=\u0026#34;black\u0026#34; str3=\u0026#34;hello, \u0026#34;${name2}\u0026#34;\u0026#34; str4=\u0026#34;hello, ${name2}\u0026#34; echo ${str3}_${str4} # Output: # hello, black_hello, black ################### 获取字符串长度 ################### text=\u0026#34;12345\u0026#34; echo \u0026#34;${text} length is: ${#text}\u0026#34; # Output: # 12345 length is: 5 # 获取子字符串 text=\u0026#34;12345\u0026#34; echo ${text:2:2} # Output: # 34 ################### 查找子字符串 ################### text=\u0026#34;hello\u0026#34; echo `expr index \u0026#34;${text}\u0026#34; ll` # Output: # 3 ################### 判断字符串中是否包含子字符串 ################### result=$(echo \u0026#34;${str}\u0026#34; | grep \u0026#34;feature/\u0026#34;) if [[ \u0026#34;$result\u0026#34; != \u0026#34;\u0026#34; ]]; then echo \u0026#34;feature/ 是 ${str} 的子字符串\u0026#34; else echo \u0026#34;feature/ 不是 ${str} 的子字符串\u0026#34; fi ################### 截取关键字左边内容 ################### full_branch=\u0026#34;feature/1.0.0\u0026#34; branch=`echo ${full_branch#feature/}` echo \u0026#34;branch is ${branch}\u0026#34; ################### 截取关键字右边内容 ################### full_version=\u0026#34;0.0.1-SNAPSHOT\u0026#34; version=`echo ${full_version%-SNAPSHOT}` echo \u0026#34;version is ${version}\u0026#34; ################### 字符串分割成数组 ################### str=\u0026#34;0.0.0.1\u0026#34; OLD_IFS=\u0026#34;$IFS\u0026#34; IFS=\u0026#34;.\u0026#34; array=( ${str} ) IFS=\u0026#34;$OLD_IFS\u0026#34; size=${#array[*]} lastIndex=`expr ${size} - 1` echo \u0026#34;数组长度：${size}\u0026#34; echo \u0026#34;最后一个数组元素：${array[${lastIndex}]}\u0026#34; for item in ${array[@]} do echo \u0026#34;$item\u0026#34; done ################### 判断字符串是否为空 ################### #-n 判断长度是否非零 #-z 判断长度是否为零 str=testing str2=\u0026#39;\u0026#39; if [[ -n \u0026#34;$str\u0026#34; ]] then echo \u0026#34;The string $str is not empty\u0026#34; else echo \u0026#34;The string $str is empty\u0026#34; fi if [[ -n \u0026#34;$str2\u0026#34; ]] then echo \u0026#34;The string $str2 is not empty\u0026#34; else echo \u0026#34;The string $str2 is empty\u0026#34; fi #\tOutput: #\tThe string testing is not empty #\tThe string is empty ################### 字符串比较 ################### str=hello str2=world if [[ $str = \u0026#34;hello\u0026#34; ]]; then echo \u0026#34;str equals hello\u0026#34; else echo \u0026#34;str not equals hello\u0026#34; fi if [[ $str2 = \u0026#34;hello\u0026#34; ]]; then echo \u0026#34;str2 equals hello\u0026#34; else echo \u0026#34;str2 not equals hello\u0026#34; fi 数组 bash 只支持一维数组。\n数组下标从 0 开始，下标可以是整数或算术表达式，其值应大于或等于 0。\n创建数组 1 2 3 # 创建数组的不同方式 nums=([2]=2 [0]=0 [1]=1) colors=(red yellow \u0026#34;dark blue\u0026#34;) 访问数组元素 访问数组的单个元素： 1 2 echo ${nums[1]} # Output: 1 访问数组的所有元素： 1 2 3 4 5 echo ${colors[*]} # Output: red yellow dark blue echo ${colors[@]} # Output: red yellow dark blue 上面两行有很重要（也很微妙）的区别：\n为了将数组中每个元素单独一行输出，我们用 printf 命令：\n1 2 3 4 5 6 printf \u0026#34;+ %s\\n\u0026#34; ${colors[*]} # Output: # + red # + yellow # + dark # + blue 为什么dark和blue各占了一行？尝试用引号包起来：\n1 2 3 printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;${colors[*]}\u0026#34; # Output: # + red yellow dark blue 现在所有的元素都在一行输出 —— 这不是我们想要的！让我们试试${colors[@]}\n1 2 3 4 5 printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;${colors[@]}\u0026#34; # Output: # + red # + yellow # + dark blue 在引号内，${colors[@]}将数组中的每个元素扩展为一个单独的参数；数组元素中的空格得以保留。\n访问数组的部分元素： 1 2 3 echo ${nums[@]:0:2} # Output: # 0 1 在上面的例子中，${array[@]} 扩展为整个数组，:0:2取出了数组中从 0 开始，长度为 2 的元素。\n访问数组长度 1 2 3 echo ${#nums[*]} # Output: # 3 向数组中添加元素 向数组中添加元素也非常简单：\n1 2 3 4 colors=(white \u0026#34;${colors[@]}\u0026#34; green black) echo ${colors[@]} # Output: # white red yellow dark blue green black 上面的例子中，${colors[@]} 扩展为整个数组，并被置换到复合赋值语句中，接着，对数组colors的赋值覆盖了它原来的值。\n从数组中删除元素 用unset命令来从数组中删除一个元素：\n1 2 3 4 unset nums[0] echo ${nums[@]} # Output: # 1 2 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 #!/usr/bin/env bash ################### 创建数组 ################### nums=( [ 2 ] = 2 [ 0 ] = 0 [ 1 ] = 1 ) colors=( red yellow \u0026#34;dark blue\u0026#34; ) ################### 访问数组的单个元素 ################### echo ${nums[1]} # Output: 1 ################### 访问数组的所有元素 ################### echo ${colors[*]} # Output: red yellow dark blue echo ${colors[@]} # Output: red yellow dark blue printf \u0026#34;+ %s\\n\u0026#34; ${colors[*]} # Output: # + red # + yellow # + dark # + blue printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;${colors[*]}\u0026#34; # Output: # + red yellow dark blue printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;${colors[@]}\u0026#34; # Output: # + red # + yellow # + dark blue ################### 访问数组的部分元素 ################### echo ${nums[@]:0:2} # Output: # 0 1 ################### 获取数组长度 ################### echo ${#nums[*]} # Output: # 3 ################### 向数组中添加元素 ################### colors=( white \u0026#34;${colors[@]}\u0026#34; green black ) echo ${colors[@]} # Output: # white red yellow dark blue green black ################### 从数组中删除元素 ################### unset nums[ 0 ] echo ${nums[@]} # Output: # 1 2 运算符 算术运算符 下表列出了常用的算术运算符，假定变量 x 为 10，变量 y 为 20：\n运算符 说明 举例 + 加法 expr $x + $y 结果为 30。 - 减法 expr $x - $y 结果为 -10。 * 乘法 expr $x * $y 结果为 200。 / 除法 expr $y / $x 结果为 2。 % 取余 expr $y % $x 结果为 0。 = 赋值 x=$y 将把变量 y 的值赋给 x。 == 相等。用于比较两个数字，相同则返回 true。 [ $x == $y ] 返回 false。 != 不相等。用于比较两个数字，不相同则返回 true。 [ $x != $y ] 返回 true。 **注意：**条件表达式要放在方括号之间，并且要有空格，例如: [$x==$y] 是错误的，必须写成 [ $x == $y ]。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 x=10 y=20 echo \u0026#34;x=${x}, y=${y}\u0026#34; val=`expr ${x} + ${y}` echo \u0026#34;${x} + ${y} = $val\u0026#34; val=`expr ${x} - ${y}` echo \u0026#34;${x} - ${y} = $val\u0026#34; val=`expr ${x} \\* ${y}` echo \u0026#34;${x} * ${y} = $val\u0026#34; val=`expr ${y} / ${x}` echo \u0026#34;${y} / ${x} = $val\u0026#34; val=`expr ${y} % ${x}` echo \u0026#34;${y} % ${x} = $val\u0026#34; if [[ ${x} == ${y} ]] then echo \u0026#34;${x} = ${y}\u0026#34; fi if [[ ${x} != ${y} ]] then echo \u0026#34;${x} != ${y}\u0026#34; fi # Output: # x=10, y=20 # 10 + 20 = 30 # 10 - 20 = -10 # 10 * 20 = 200 # 20 / 10 = 2 # 20 % 10 = 0 # 10 != 20 关系运算符 关系运算符只支持数字，不支持字符串，除非字符串的值是数字。\n下表列出了常用的关系运算符，假定变量 x 为 10，变量 y 为 20：\n运算符 说明 举例 -eq 检测两个数是否相等，相等返回 true。 [ $a -eq $b ]返回 false。 -ne 检测两个数是否相等，不相等返回 true。 [ $a -ne $b ] 返回 true。 -gt 检测左边的数是否大于右边的，如果是，则返回 true。 [ $a -gt $b ] 返回 false。 -lt 检测左边的数是否小于右边的，如果是，则返回 true。 [ $a -lt $b ] 返回 true。 -ge 检测左边的数是否大于等于右边的，如果是，则返回 true。 [ $a -ge $b ] 返回 false。 -le 检测左边的数是否小于等于右边的，如果是，则返回 true。 [ $a -le $b ]返回 true。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 x=10 y=20 echo \u0026#34;x=${x}, y=${y}\u0026#34; if [[ ${x} -eq ${y} ]]; then echo \u0026#34;${x} -eq ${y} : x 等于 y\u0026#34; else echo \u0026#34;${x} -eq ${y}: x 不等于 y\u0026#34; fi if [[ ${x} -ne ${y} ]]; then echo \u0026#34;${x} -ne ${y}: x 不等于 y\u0026#34; else echo \u0026#34;${x} -ne ${y}: x 等于 y\u0026#34; fi if [[ ${x} -gt ${y} ]]; then echo \u0026#34;${x} -gt ${y}: x 大于 y\u0026#34; else echo \u0026#34;${x} -gt ${y}: x 不大于 y\u0026#34; fi if [[ ${x} -lt ${y} ]]; then echo \u0026#34;${x} -lt ${y}: x 小于 y\u0026#34; else echo \u0026#34;${x} -lt ${y}: x 不小于 y\u0026#34; fi if [[ ${x} -ge ${y} ]]; then echo \u0026#34;${x} -ge ${y}: x 大于或等于 y\u0026#34; else echo \u0026#34;${x} -ge ${y}: x 小于 y\u0026#34; fi if [[ ${x} -le ${y} ]]; then echo \u0026#34;${x} -le ${y}: x 小于或等于 y\u0026#34; else echo \u0026#34;${x} -le ${y}: x 大于 y\u0026#34; fi # Output: # x=10, y=20 # 10 -eq 20: x 不等于 y # 10 -ne 20: x 不等于 y # 10 -gt 20: x 不大于 y # 10 -lt 20: x 小于 y # 10 -ge 20: x 小于 y # 10 -le 20: x 小于或等于 y 布尔运算符 下表列出了常用的布尔运算符，假定变量 x 为 10，变量 y 为 20：\n运算符 说明 举例 ! 非运算，表达式为 true 则返回 false，否则返回 true。 [ ! false ] 返回 true。 -o 或运算，有一个表达式为 true 则返回 true。 [ $a -lt 20 -o $b -gt 100 ] 返回 true。 -a 与运算，两个表达式都为 true 才返回 true。 [ $a -lt 20 -a $b -gt 100 ] 返回 false。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 x=10 y=20 echo \u0026#34;x=${x}, y=${y}\u0026#34; if [[ ${x} != ${y} ]]; then echo \u0026#34;${x} != ${y} : x 不等于 y\u0026#34; else echo \u0026#34;${x} != ${y}: x 等于 y\u0026#34; fi if [[ ${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 15 ]]; then echo \u0026#34;${x} 小于 100 且 ${y} 大于 15 : 返回 true\u0026#34; else echo \u0026#34;${x} 小于 100 且 ${y} 大于 15 : 返回 false\u0026#34; fi if [[ ${x} -lt 100 || ${y} -gt 100 ]]; then echo \u0026#34;${x} 小于 100 或 ${y} 大于 100 : 返回 true\u0026#34; else echo \u0026#34;${x} 小于 100 或 ${y} 大于 100 : 返回 false\u0026#34; fi if [[ ${x} -lt 5 || ${y} -gt 100 ]]; then echo \u0026#34;${x} 小于 5 或 ${y} 大于 100 : 返回 true\u0026#34; else echo \u0026#34;${x} 小于 5 或 ${y} 大于 100 : 返回 false\u0026#34; fi # Output: # x=10, y=20 # 10 != 20 : x 不等于 y # 10 小于 100 且 20 大于 15 : 返回 true # 10 小于 100 或 20 大于 100 : 返回 true # 10 小于 5 或 20 大于 100 : 返回 false 逻辑运算符 以下介绍 Shell 的逻辑运算符，假定变量 x 为 10，变量 y 为 20:\n运算符 说明 举例 \u0026amp;\u0026amp; 逻辑的 AND [[ ${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 100 ]] 返回 false ` ` 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 x=10 y=20 echo \u0026#34;x=${x}, y=${y}\u0026#34; if [[ ${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 100 ]] then echo \u0026#34;${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 100 返回 true\u0026#34; else echo \u0026#34;${x} -lt 100 \u0026amp;\u0026amp; ${y} -gt 100 返回 false\u0026#34; fi if [[ ${x} -lt 100 || ${y} -gt 100 ]] then echo \u0026#34;${x} -lt 100 || ${y} -gt 100 返回 true\u0026#34; else echo \u0026#34;${x} -lt 100 || ${y} -gt 100 返回 false\u0026#34; fi # Output: # x=10, y=20 # 10 -lt 100 \u0026amp;\u0026amp; 20 -gt 100 返回 false # 10 -lt 100 || 20 -gt 100 返回 true 字符串运算符 下表列出了常用的字符串运算符，假定变量 a 为 \u0026ldquo;abc\u0026rdquo;，变量 b 为 \u0026ldquo;efg\u0026rdquo;：\n运算符 说明 举例 = 检测两个字符串是否相等，相等返回 true。 [ $a = $b ] 返回 false。 != 检测两个字符串是否相等，不相等返回 true。 [ $a != $b ] 返回 true。 -z 检测字符串长度是否为 0，为 0 返回 true。 [ -z $a ] 返回 false。 -n 检测字符串长度是否为 0，不为 0 返回 true。 [ -n $a ] 返回 true。 str 检测字符串是否为空，不为空返回 true。 [ $a ] 返回 true。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 x=\u0026#34;abc\u0026#34; y=\u0026#34;xyz\u0026#34; echo \u0026#34;x=${x}, y=${y}\u0026#34; if [[ ${x} = ${y} ]]; then echo \u0026#34;${x} = ${y} : x 等于 y\u0026#34; else echo \u0026#34;${x} = ${y}: x 不等于 y\u0026#34; fi if [[ ${x} != ${y} ]]; then echo \u0026#34;${x} != ${y} : x 不等于 y\u0026#34; else echo \u0026#34;${x} != ${y}: x 等于 y\u0026#34; fi if [[ -z ${x} ]]; then echo \u0026#34;-z ${x} : 字符串长度为 0\u0026#34; else echo \u0026#34;-z ${x} : 字符串长度不为 0\u0026#34; fi if [[ -n \u0026#34;${x}\u0026#34; ]]; then echo \u0026#34;-n ${x} : 字符串长度不为 0\u0026#34; else echo \u0026#34;-n ${x} : 字符串长度为 0\u0026#34; fi if [[ ${x} ]]; then echo \u0026#34;${x} : 字符串不为空\u0026#34; else echo \u0026#34;${x} : 字符串为空\u0026#34; fi # Output: # x=abc, y=xyz # abc = xyz: x 不等于 y # abc != xyz : x 不等于 y # -z abc : 字符串长度不为 0 # -n abc : 字符串长度不为 0 # abc : 字符串不为空 文件测试运算符 文件测试运算符用于检测 Unix 文件的各种属性。\n属性检测描述如下：\n操作符 说明 举例 -b file 检测文件是否是块设备文件，如果是，则返回 true。 [ -b $file ] 返回 false。 -c file 检测文件是否是字符设备文件，如果是，则返回 true。 [ -c $file ] 返回 false。 -d file 检测文件是否是目录，如果是，则返回 true。 [ -d $file ] 返回 false。 -f file 检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。 [ -f $file ] 返回 true。 -g file 检测文件是否设置了 SGID 位，如果是，则返回 true。 [ -g $file ] 返回 false。 -k file 检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。 [ -k $file ]返回 false。 -p file 检测文件是否是有名管道，如果是，则返回 true。 [ -p $file ] 返回 false。 -u file 检测文件是否设置了 SUID 位，如果是，则返回 true。 [ -u $file ] 返回 false。 -r file 检测文件是否可读，如果是，则返回 true。 [ -r $file ] 返回 true。 -w file 检测文件是否可写，如果是，则返回 true。 [ -w $file ] 返回 true。 -x file 检测文件是否可执行，如果是，则返回 true。 [ -x $file ] 返回 true。 -s file 检测文件是否为空（文件大小是否大于 0），不为空返回 true。 [ -s $file ] 返回 true。 -e file 检测文件（包括目录）是否存在，如果是，则返回 true。 [ -e $file ] 返回 true。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 file=\u0026#34;/etc/hosts\u0026#34; if [[ -r ${file} ]]; then echo \u0026#34;${file} 文件可读\u0026#34; else echo \u0026#34;${file} 文件不可读\u0026#34; fi if [[ -w ${file} ]]; then echo \u0026#34;${file} 文件可写\u0026#34; else echo \u0026#34;${file} 文件不可写\u0026#34; fi if [[ -x ${file} ]]; then echo \u0026#34;${file} 文件可执行\u0026#34; else echo \u0026#34;${file} 文件不可执行\u0026#34; fi if [[ -f ${file} ]]; then echo \u0026#34;${file} 文件为普通文件\u0026#34; else echo \u0026#34;${file} 文件为特殊文件\u0026#34; fi if [[ -d ${file} ]]; then echo \u0026#34;${file} 文件是个目录\u0026#34; else echo \u0026#34;${file} 文件不是个目录\u0026#34; fi if [[ -s ${file} ]]; then echo \u0026#34;${file} 文件不为空\u0026#34; else echo \u0026#34;${file} 文件为空\u0026#34; fi if [[ -e ${file} ]]; then echo \u0026#34;${file} 文件存在\u0026#34; else echo \u0026#34;${file} 文件不存在\u0026#34; fi # Output:(根据文件的实际情况，输出结果可能不同) # /etc/hosts 文件可读 # /etc/hosts 文件可写 # /etc/hosts 文件不可执行 # /etc/hosts 文件为普通文件 # /etc/hosts 文件不是个目录 # /etc/hosts 文件不为空 # /etc/hosts 文件存在 控制语句 条件语句 跟其它程序设计语言一样，Bash 中的条件语句让我们可以决定一个操作是否被执行。结果取决于一个包在[[ ]]里的表达式。\n由[[ ]]（sh中是[ ]）包起来的表达式被称作 检测命令 或 基元。这些表达式帮助我们检测一个条件的结果。这里可以找到有关bash 中单双中括号区别的答案。\n共有两个不同的条件表达式：if和case。\nif （1）if 语句\nif在使用上跟其它语言相同。如果中括号里的表达式为真，那么then和fi之间的代码会被执行。fi标志着条件代码块的结束。\n1 2 3 4 5 6 7 8 9 10 # 写成一行 if [[ 1 -eq 1 ]]; then echo \u0026#34;1 -eq 1 result is: true\u0026#34;; fi # Output: 1 -eq 1 result is: true # 写成多行 if [[ \u0026#34;abc\u0026#34; -eq \u0026#34;abc\u0026#34; ]] then echo \u0026#34;\u0026#34;abc\u0026#34; -eq \u0026#34;abc\u0026#34; result is: true\u0026#34; fi # Output: abc -eq abc result is: true （2）if else 语句\n同样，我们可以使用if..else语句，例如：\n1 2 3 4 5 6 if [[ 2 -ne 1 ]]; then echo \u0026#34;true\u0026#34; else echo \u0026#34;false\u0026#34; fi # Output: true （3）if elif else 语句\n有些时候，if..else不能满足我们的要求。别忘了if..elif..else，使用起来也很方便。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 x=10 y=20 if [[ ${x} \u0026gt; ${y} ]]; then echo \u0026#34;${x} \u0026gt; ${y}\u0026#34; elif [[ ${x} \u0026lt; ${y} ]]; then echo \u0026#34;${x} \u0026lt; ${y}\u0026#34; else echo \u0026#34;${x} = ${y}\u0026#34; fi # Output: 10 \u0026lt; 20 case 如果你需要面对很多情况，分别要采取不同的措施，那么使用case会比嵌套的if更有用。使用case来解决复杂的条件判断，看起来像下面这样：\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 exec case ${oper} in \u0026#34;+\u0026#34;) val=`expr ${x} + ${y}` echo \u0026#34;${x} + ${y} = ${val}\u0026#34; ;; \u0026#34;-\u0026#34;) val=`expr ${x} - ${y}` echo \u0026#34;${x} - ${y} = ${val}\u0026#34; ;; \u0026#34;*\u0026#34;) val=`expr ${x} \\* ${y}` echo \u0026#34;${x} * ${y} = ${val}\u0026#34; ;; \u0026#34;/\u0026#34;) val=`expr ${x} / ${y}` echo \u0026#34;${x} / ${y} = ${val}\u0026#34; ;; *) echo \u0026#34;Unknown oper!\u0026#34; ;; esac 每种情况都是匹配了某个模式的表达式。|用来分割多个模式，)用来结束一个模式序列。第一个匹配上的模式对应的命令将会被执行。*代表任何不匹配以上给定模式的模式。命令块儿之间要用;;分隔。\n循环语句 循环其实不足为奇。跟其它程序设计语言一样，bash 中的循环也是只要控制条件为真就一直迭代执行的代码块。\nBash 中有四种循环：for，while，until和select。\nfor循环 for与它在 C 语言中的姊妹非常像。看起来是这样：\n1 2 3 4 for arg in elem1 elem2 ... elemN do ### 语句 done 在每次循环的过程中，arg依次被赋值为从elem1到elemN。这些值还可以是通配符或者大括号扩展。\n当然，我们还可以把for循环写在一行，但这要求do之前要有一个分号，就像下面这样：\n1 for i in {1..5}; do echo $i; done 还有，如果你觉得for..in..do对你来说有点奇怪，那么你也可以像 C 语言那样使用for，比如：\n1 2 3 for (( i = 0; i \u0026lt; 10; i++ )); do echo $i done 当我们想对一个目录下的所有文件做同样的操作时，for就很方便了。举个例子，如果我们想把所有的.bash文件移动到script文件夹中，并给它们可执行权限，我们的脚本可以这样写：\n💻 『示例源码』\n1 2 3 4 5 DIR=/home/zp for FILE in ${DIR}/*.sh; do mv \u0026#34;$FILE\u0026#34; \u0026#34;${DIR}/scripts\u0026#34; done # 将 /home/zp 目录下所有 sh 文件拷贝到 /home/zp/scripts while循环 while循环检测一个条件，只要这个条件为 真，就执行一段命令。被检测的条件跟if..then中使用的基元并无二异。因此一个while循环看起来会是这样：\n1 2 3 4 while [[ condition ]] do ### 语句 done 跟for循环一样，如果我们把do和被检测的条件写到一行，那么必须要在do之前加一个分号。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ### 0到9之间每个数的平方 x=0 while [[ ${x} -lt 10 ]]; do echo $((x * x)) x=$((x + 1)) done # Output: # 0 # 1 # 4 # 9 # 16 # 25 # 36 # 49 # 64 # 81 until循环 until循环跟while循环正好相反。它跟while一样也需要检测一个测试条件，但不同的是，只要该条件为 假 就一直执行循环：\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 x=0 until [[ ${x} -ge 5 ]]; do echo ${x} x=`expr ${x} + 1` done # Output: # 0 # 1 # 2 # 3 # 4 select循环 select循环帮助我们组织一个用户菜单。它的语法几乎跟for循环一致：\n1 2 3 4 select answer in elem1 elem2 ... elemN do ### 语句 done select会打印elem1..elemN以及它们的序列号到屏幕上，之后会提示用户输入。通常看到的是$?（PS3变量）。用户的选择结果会被保存到answer中。如果answer是一个在1..N之间的数字，那么语句会被执行，紧接着会进行下一次迭代 —— 如果不想这样的话我们可以使用break语句。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 #!/usr/bin/env bash PS3=\u0026#34;Choose the package manager: \u0026#34; select ITEM in bower npm gem pip do echo -n \u0026#34;Enter the package name: \u0026#34; \u0026amp;\u0026amp; read PACKAGE case ${ITEM} in bower) bower install ${PACKAGE} ;; npm) npm install ${PACKAGE} ;; gem) gem install ${PACKAGE} ;; pip) pip install ${PACKAGE} ;; esac break # 避免无限循环 done 这个例子，先询问用户他想使用什么包管理器。接着，又询问了想安装什么包，最后执行安装操作。\n运行这个脚本，会得到如下输出：\n1 2 3 4 5 6 7 $ ./my_script 1) bower 2) npm 3) gem 4) pip Choose the package manager: 2 Enter the package name: gitbook-cli break 和 continue 如果想提前结束一个循环或跳过某次循环执行，可以使用 shell 的break和continue语句来实现。它们可以在任何循环中使用。\nbreak语句用来提前结束当前循环。\ncontinue语句用来跳过某次迭代。\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 # 查找 10 以内第一个能整除 2 和 3 的正整数 i=1 while [[ ${i} -lt 10 ]]; do if [[ $((i % 3)) -eq 0 ]] \u0026amp;\u0026amp; [[ $((i % 2)) -eq 0 ]]; then echo ${i} break; fi i=`expr ${i} + 1` done # Output: 6 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 # 打印10以内的奇数 for (( i = 0; i \u0026lt; 10; i ++ )); do if [[ $((i % 2)) -eq 0 ]]; then continue; fi echo ${i} done # Output: # 1 # 3 # 5 # 7 # 9 函数 bash 函数定义语法如下：\n1 2 3 4 [ function ] funname [()] { action; [return int;] } 💡 说明：\n函数定义时，function 关键字可有可无。 函数返回值 - return 返回函数返回值，返回值类型只能为整数（0-255）。如果不加 return 语句，shell 默认将以最后一条命令的运行结果，作为函数返回值。 函数返回值在调用该函数后通过 $? 来获得。 所有函数在使用前必须定义。这意味着必须将函数放在脚本开始部分，直至 shell 解释器首次发现它时，才可以使用。调用函数仅使用其函数名即可。 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 #!/usr/bin/env bash calc(){ PS3=\u0026#34;choose the oper: \u0026#34; select oper in + - \\* / # 生成操作符选择菜单 do echo -n \u0026#34;enter first num: \u0026#34; \u0026amp;\u0026amp; read x # 读取输入参数 echo -n \u0026#34;enter second num: \u0026#34; \u0026amp;\u0026amp; read y # 读取输入参数 exec case ${oper} in \u0026#34;+\u0026#34;) return $((${x} + ${y})) ;; \u0026#34;-\u0026#34;) return $((${x} - ${y})) ;; \u0026#34;*\u0026#34;) return $((${x} * ${y})) ;; \u0026#34;/\u0026#34;) return $((${x} / ${y})) ;; *) echo \u0026#34;${oper} is not support!\u0026#34; return 0 ;; esac break done } calc echo \u0026#34;the result is: $?\u0026#34; # $? 获取 calc 函数返回值 执行结果：\n1 2 3 4 5 6 7 8 9 $ ./function-demo.sh 1) + 2) - 3) * 4) / choose the oper: 3 enter first num: 10 enter second num: 10 the result is: 100 位置参数 位置参数是在调用一个函数并传给它参数时创建的变量。\n位置参数变量表：\n变量 描述 $0 脚本名称 $1 … $9 第 1 个到第 9 个参数列表 ${10} … ${N} 第 10 个到 N 个参数列表 $* or $@ 除了$0外的所有位置参数 $# 不包括$0在内的位置参数的个数 $FUNCNAME 函数名称（仅在函数内部有值） 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 #!/usr/bin/env bash x=0 if [[ -n $1 ]]; then echo \u0026#34;第一个参数为：$1\u0026#34; x=$1 else echo \u0026#34;第一个参数为空\u0026#34; fi y=0 if [[ -n $2 ]]; then echo \u0026#34;第二个参数为：$2\u0026#34; y=$2 else echo \u0026#34;第二个参数为空\u0026#34; fi paramsFunction(){ echo \u0026#34;函数第一个入参：$1\u0026#34; echo \u0026#34;函数第二个入参：$2\u0026#34; } paramsFunction ${x} ${y} 执行结果：\n1 2 3 4 5 6 7 8 9 10 11 $ ./function-demo2.sh 第一个参数为空 第二个参数为空 函数第一个入参：0 函数第二个入参：0 $ ./function-demo2.sh 10 20 第一个参数为：10 第二个参数为：20 函数第一个入参：10 函数第二个入参：20 执行 ./variable-demo4.sh hello world ，然后在脚本中通过 $1、$2 \u0026hellip; 读取第 1 个参数、第 2 个参数。。。\n函数处理参数 另外，还有几个特殊字符用来处理参数：\n参数处理 说明 $# 返回参数个数 $* 返回所有参数 $$ 脚本运行的当前进程 ID 号 $! 后台运行的最后一个进程的 ID 号 $@ 返回所有参数 $- 返回 Shell 使用的当前选项，与 set 命令功能相同。 $? 函数返回值 💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 runner() { return 0 } name=zp paramsFunction(){ echo \u0026#34;函数第一个入参：$1\u0026#34; echo \u0026#34;函数第二个入参：$2\u0026#34; echo \u0026#34;传递到脚本的参数个数：$#\u0026#34; echo \u0026#34;所有参数：\u0026#34; printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;$*\u0026#34; echo \u0026#34;脚本运行的当前进程 ID 号：$$\u0026#34; echo \u0026#34;后台运行的最后一个进程的 ID 号：$!\u0026#34; echo \u0026#34;所有参数：\u0026#34; printf \u0026#34;+ %s\\n\u0026#34; \u0026#34;$@\u0026#34; echo \u0026#34;Shell 使用的当前选项：$-\u0026#34; runner echo \u0026#34;runner 函数的返回值：$?\u0026#34; } paramsFunction 1 \u0026#34;abc\u0026#34; \u0026#34;hello, \\\u0026#34;zp\\\u0026#34;\u0026#34; # Output: # 函数第一个入参：1 # 函数第二个入参：abc # 传递到脚本的参数个数：3 # 所有参数： # + 1 abc hello, \u0026#34;zp\u0026#34; # 脚本运行的当前进程 ID 号：26400 # 后台运行的最后一个进程的 ID 号： # 所有参数： # + 1 # + abc # + hello, \u0026#34;zp\u0026#34; # Shell 使用的当前选项：hB # runner 函数的返回值：0 Shell 扩展 扩展 发生在一行命令被分成一个个的 记号（tokens） 之后。换言之，扩展是一种执行数学运算的机制，还可以用来保存命令的执行结果，等等。\n感兴趣的话可以阅读关于 shell 扩展的更多细节。\n大括号扩展 大括号扩展让生成任意的字符串成为可能。它跟 文件名扩展 很类似，举个例子：\n1 echo beg{i,a,u}n ### begin began begun 大括号扩展还可以用来创建一个可被循环迭代的区间。\n1 2 echo {0..5} ### 0 1 2 3 4 5 echo {00..8..2} ### 00 02 04 06 08 命令置换 命令置换允许我们对一个命令求值，并将其值置换到另一个命令或者变量赋值表达式中。当一个命令被``或$()包围时，命令置换将会执行。举个例子：\n1 2 3 4 5 now=`date +%T` ### or now=$(date +%T) echo $now ### 19:08:26 算数扩展 在 bash 中，执行算数运算是非常方便的。算数表达式必须包在$(( ))中。算数扩展的格式为：\n1 2 result=$(( ((10 + 5*3) - 7) / 2 )) echo $result ### 9 在算数表达式中，使用变量无需带上$前缀：\n1 2 3 4 5 x=4 y=7 echo $(( x + y )) ### 11 echo $(( ++x + y++ )) ### 12 echo $(( x + y )) ### 13 单引号和双引号 单引号和双引号之间有很重要的区别。在双引号中，变量引用或者命令置换是会被展开的。在单引号中是不会的。举个例子：\n1 2 echo \u0026#34;Your home: $HOME\u0026#34; ### Your home: /Users/\u0026lt;username\u0026gt; echo \u0026#39;Your home: $HOME\u0026#39; ### Your home: $HOME 当局部变量和环境变量包含空格时，它们在引号中的扩展要格外注意。随便举个例子，假如我们用echo来输出用户的输入：\n1 2 3 INPUT=\u0026#34;A string with strange whitespace.\u0026#34; echo $INPUT ### A string with strange whitespace. echo \u0026#34;$INPUT\u0026#34; ### A string with strange whitespace. 调用第一个echo时给了它 5 个单独的参数 —— $INPUT 被分成了单独的词，echo在每个词之间打印了一个空格。第二种情况，调用echo时只给了它一个参数（整个$INPUT 的值，包括其中的空格）。\n来看一个更严肃的例子：\n1 2 3 FILE=\u0026#34;Favorite Things.txt\u0026#34; cat $FILE ### 尝试输出两个文件: `Favorite` 和 `Things.txt` cat \u0026#34;$FILE\u0026#34; ### 输出一个文件: `Favorite Things.txt` 尽管这个问题可以通过把 FILE 重命名成Favorite-Things.txt来解决，但是，假如这个值来自某个环境变量，来自一个位置参数，或者来自其它命令（find, cat, 等等）呢。因此，如果输入 可能 包含空格，务必要用引号把表达式包起来。\n流和重定向 Bash 有很强大的工具来处理程序之间的协同工作。使用流，我们能将一个程序的输出发送到另一个程序或文件，因此，我们能方便地记录日志或做一些其它我们想做的事。\n管道给了我们创建传送带的机会，控制程序的执行成为可能。\n学习如何使用这些强大的、高级的工具是非常非常重要的。\n输入、输出流 Bash 接收输入，并以字符序列或 字符流 的形式产生输出。这些流能被重定向到文件或另一个流中。\n有三个文件描述符：\n代码 描述符 描述 0 stdin 标准输入 1 stdout 标准输出 2 stderr 标准错误输出 重定向 重定向让我们可以控制一个命令的输入来自哪里，输出结果到什么地方。这些运算符在控制流的重定向时会被用到：\nOperator Description \u0026gt; 重定向输出 \u0026amp;\u0026gt; 重定向输出和错误输出 \u0026amp;\u0026gt;\u0026gt; 以附加的形式重定向输出和错误输出 \u0026lt; 重定向输入 \u0026lt;\u0026lt; Here 文档 语法 \u0026lt;\u0026lt;\u0026lt; Here 字符串 以下是一些使用重定向的例子：\n1 2 3 4 5 6 7 8 9 10 11 ### ls的结果将会被写到list.txt中 ls -l \u0026gt; list.txt ### 将输出附加到list.txt中 ls -a \u0026gt;\u0026gt; list.txt ### 所有的错误信息会被写到errors.txt中 grep da * 2\u0026gt; errors.txt ### 从errors.txt中读取输入 less \u0026lt; errors.txt /dev/null 文件 如果希望执行某个命令，但又不希望在屏幕上显示输出结果，那么可以将输出重定向到 /dev/null：\n1 $ command \u0026gt; /dev/null /dev/null 是一个特殊的文件，写入到它的内容都会被丢弃；如果尝试从该文件读取内容，那么什么也读不到。但是 /dev/null 文件非常有用，将命令的输出重定向到它，会起到\u0026quot;禁止输出\u0026quot;的效果。\n如果希望屏蔽 stdout 和 stderr，可以这样写：\n1 $ command \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 Debug shell 提供了用于 debug 脚本的工具。\n如果想采用 debug 模式运行某脚本，可以在其 shebang 中使用一个特殊的选项：\n1 #!/bin/bash options options 是一些可以改变 shell 行为的选项。下表是一些可能对你有用的选项：\nShort Name Description -f noglob 禁止文件名展开（globbing） -i interactive 让脚本以 交互 模式运行 -n noexec 读取命令，但不执行（语法检查） -t — 执行完第一条命令后退出 -v verbose 在执行每条命令前，向stderr输出该命令 -x xtrace 在执行每条命令前，向stderr输出该命令以及该命令的扩展参数 举个例子，如果我们在脚本中指定了-x例如：\n1 2 3 4 5 #!/bin/bash -x for (( i = 0; i \u0026lt; 3; i++ )); do echo $i done 这会向stdout打印出变量的值和一些其它有用的信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 $ ./my_script + (( i = 0 )) + (( i \u0026lt; 3 )) + echo 0 0 + (( i++ )) + (( i \u0026lt; 3 )) + echo 1 1 + (( i++ )) + (( i \u0026lt; 3 )) + echo 2 2 + (( i++ )) + (( i \u0026lt; 3 )) 有时我们值需要 debug 脚本的一部分。这种情况下，使用set命令会很方便。这个命令可以启用或禁用选项。使用-启用选项，+禁用选项：\n💻 『示例源码』\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 开启 debug set -x for (( i = 0; i \u0026lt; 3; i++ )); do printf ${i} done # 关闭 debug set +x # Output: # + (( i = 0 )) # + (( i \u0026lt; 3 )) # + printf 0 # 0+ (( i++ )) # + (( i \u0026lt; 3 )) # + printf 1 # 1+ (( i++ )) # + (( i \u0026lt; 3 )) # + printf 2 # 2+ (( i++ )) # + (( i \u0026lt; 3 )) # + set +x for i in {1..5}; do printf ${i}; done printf \u0026#34;\\n\u0026#34; # Output: 12345 参考资料 awesome-shell - shell 资源列表 awesome-bash - bash 资源列表 bash-handbook bash-guide - bash 基本用法指南 bash-it - 为你日常使用、开发以及维护 shell 脚本和自定义命令提供了一个可靠的框架 dotfiles.github.io - 上面有 bash 和其它 shell 的各种 dotfiles 集合以及 shell 框架的链接 Runoob Shell 教程 shellcheck - 一个静态 shell 脚本分析工具，本质上是 bash／sh／zsh 的 lint。 最后，Stack Overflow 上 bash 标签下有很多你可以学习的问题，当你遇到问题时，也是一个提问的好地方。\n","permalink":"https://WFUing.github.io/posts/tech/architecture/shell/","summary":"由于 bash 是 Linux 标准默认的 shell 解释器，可以说 bash 是 shell 编程的基础。\n本文主要介绍 bash 的语法，对于 linux 指令不做任何介绍。\n1 2 3 4 5 ███████╗██╗ ██╗███████╗██╗ ██╗ ██╔════╝██║ ██║██╔════╝██║ ██║ ███████╗███████║█████╗ ██║ ██║ ╚════██║██╔══██║██╔══╝ ██║ ██║ ███████║██║ ██║███████╗███████╗███████╗ 简介 什么是 shell Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。 Shell 既是一种命令语言，又是一种程序设计语言。 Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问 Linux 内核的服务。 Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。\n什么是 shell 脚本 Shell 脚本（shell script），是一种为 shell 编写的脚本程序，一般文件后缀为 .sh。","title":"Shell"},{"content":"我们将注意力转向过程抽象，这是一种将复杂程序分解成 functions (也称为 procedures 或 subroutines 。这些术语在不同语境中的用法有细微差别，但就我们的目的而言，我们将把它们视为同义词) 形式的较小代码片段的策略。函数将某些计算封装在一个接口之后，与任何抽象概念一样，函数的用户只需知道函数做了什么，而不需要知道函数是如何完成计算的。函数还通过接收影响其计算的参数来概括计算。计算的结果就是函数的返回值。\n在本单元中，我们首先介绍 Lisp 家族中的函数式语言 Scheme。然后，我们将讨论与所有 procedural languages 相关的函数方面的问题，然后再仔细研究 functional programming，这是一种以数学函数为计算模型的编程范式。\nIntroduction to Scheme R5RS Scheme 语言采用了与 Python 非常相似的计算模型，但只使用 expressions (不使用statements)，擅长 symbolic computation。\nScheme 是 Lisp 的一种方言，Lisp 是当今仍在广泛使用的第二古老的编程语言（仅次于 Fortran）。几十年来，Lisp 程序员社区一直在蓬勃发展，而新的 Lisp 方言（如 Clojure）也是所有现代编程语言中开发者社区发展最快的。要跟上本文的示例，可以下载 Scheme 解释器或使用在线解释器。\nExpressions Scheme 程序由 expressions 组成，expressions 可以是简单表达式，也可以是列表形式的组合。简单表达式由一个文字或符号组成。组合表达式是一种 compound expression，由一个运算符表达式和零个或多个操作数子表达式组成。运算符和操作数都包含在括号中：\n1 2 \u0026gt; (quotient 10 2) 5 Scheme 只使用前缀符号。操作符通常是符号，如 + 和 *。复合表达式可以嵌套，也可以跨一行以上：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; (+ (* 3 5) (- 10 6)) 19 \u0026gt; (+ (* 3 (+ (* 2 4) (+ 3 5) ) ) (+ (- 10 7) 6 ) ) 57 对组合进行求值时，首先需要检查运算符是否代表 special form，因为 special form 有自己的求值程序。如果运算符不是 special form，那么运算符和操作数表达式将按照任意顺序进行求值。然后，作为运算符值的函数将应用于作为操作数值的参数。\n在 Scheme 中，if 表达式是特殊形式的一个例子。虽然它在语法上看起来与调用表达式相似，但它的评估过程却与调用表达式不同。if 表达式的一般形式是\n1 (if \u0026lt;predicate\u0026gt; \u0026lt;consequent\u0026gt; \u0026lt;alternative\u0026gt;) 要对 if 表达式进行求值，解释器首先会对表达式的 \u0026lt;predicate\u0026gt; 部分进行求值。如果 \u0026lt;predicate\u0026gt; 求值为 true，解释器将求值 \u0026lt;consequent\u0026gt; 并返回其值。否则，解释器将求值 \u0026lt;alternative\u0026gt;，并返回其值，\u0026lt;alternative\u0026gt;可省略。\nNumerical values 可以使用熟悉的比较运算符进行比较，但在这种情况下也使用 prefix notation：\n1 2 \u0026gt; (\u0026gt;= 2 1) #t 在 Scheme 中，真值 (包括布尔值 #t 表示真， #f 表示假) 可以与布尔特殊形式相结合，它们的求值过程如下：\n(and \u0026lt;e1\u0026gt; ... \u0026lt;en\u0026gt;) 解释器按从左到右的顺序逐次求值表达式 \u0026lt;e\u0026gt;。如果任何 \u0026lt;e\u0026gt; 的值为 false，则 and 表达式的值就是该 false，其余 \u0026lt;e\u0026gt; 的值不予求值。如果所有 \u0026lt;e\u0026gt; 的值都为 true，那么 and 表达式的值就是最后一个 \u0026lt;e\u0026gt; 的值。 (or \u0026lt;e1\u0026gt; ... \u0026lt;en\u0026gt;) 解释器按从左到右的顺序，一次评估一个 \u0026lt;e\u0026gt; 表达式。如果任何 \u0026lt;e\u0026gt; 的值为 true，该值将作为 or 表达式的值返回，其余的 \u0026lt;e\u0026gt; 将不被求值。如果所有 \u0026lt;e\u0026gt; 的值都为 false，则 or 表达式的值就是最后一个 \u0026lt;e\u0026gt; 的值。 true 也可以用 not 程序来处理：\n(not \u0026lt;e\u0026gt;) 当表达式 \u0026lt;e\u0026gt; 的值为假值时，not 表达式的值为 #t，否则为 #f。 Definitions 可以使用 define 特殊形式对值进行命名：\n1 2 3 \u0026gt; (define pi 3.14) \u0026gt; (* pi 2) 6.28 新函数（在 Scheme 中通常称为 procedures）可以使用 define 特殊形式的第二个版本来定义。例如，要定义平方，我们可以写下\n1 (define (square x) (* x x)) 程序定义的一般形式是\n1 (define (\u0026lt;name\u0026gt; \u0026lt;formal parameters\u0026gt;) \u0026lt;body\u0026gt;) \u0026lt;name\u0026gt; 是与环境中存储过程定义相关联的符号。 \u0026lt;formal parameters\u0026gt; 是存储过程正文中使用的名称，用于指代存储过程的相应参数。 \u0026lt;body\u0026gt; 是一个表达式，当形式参数被存储过程的实际参数替换时，它将产生存储过程应用的值。 \u0026lt;name\u0026gt; 和 \u0026lt;formal parameters\u0026gt; 放在括号中，就像在实际调用存储过程时一样。 定义了 square 之后，我们就可以在调用表达式中使用它了:\n1 2 3 4 5 6 7 8 \u0026gt; (square 21) 441 \u0026gt; (square (+ 2 5)) 49 \u0026gt; (square (square 3)) 81 用户自定义函数可以接受多个参数，并在函数体中包含特殊形式：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; (define (average x y) (/ (+ x y) 2)) \u0026gt; (average 1 3) 2 \u0026gt; (define (abs x) (if (\u0026lt; x 0) (- x) x ) ) \u0026gt; (abs -3) 3 Scheme 支持具有 static scope 的局部函数定义。我们将推迟到讨论高阶函数时再讨论这个问题。\n匿名函数也称为 lambda 函数，是使用 lambda 特殊形式创建的。使用 lambda 创建存储过程的方法与定义相同，只是不指定存储过程的名称：\n1 (lambda (\u0026lt;formal-parameters\u0026gt;) \u0026lt;body\u0026gt;) 由此产生的存储过程与使用 define 创建的存储过程一样。唯一不同的是，它没有与环境中的任何名称相关联。事实上，下面的表达式是等价的：\n1 2 \u0026gt; (define (plus4 x) (+ x 4)) \u0026gt; (define plus4 (lambda (x) (+ x 4))) 与任何以 procedure 为值的表达式一样，lambda 表达式也可以用作 call expression 中的操作符：\n1 2 \u0026gt; ((lambda (x y z) (+ x y (square z))) 1 2 3) 12 Compound Values Pairs 是内置于 Scheme 语言中的。由于历史原因，Pairs 使用 cons 内置函数创建，因此，Pairs 也被称为 cons 单元，Pairs 中的元素使用 car 和 cdr 访问：\n1 2 3 4 5 6 7 \u0026gt; (define x (cons 1 2)) \u0026gt; x (1 . 2) \u0026gt; (car x) 1 \u0026gt; (cdr x) 2 A pair consisting of the elements 1 and 2 该语言还使用成对的方式建立 Recursive lists 。用 '() 表示的特殊值代表 empty list。递归列表值的呈现方式是将其元素放在括号内，中间用空格隔开：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 \u0026gt; (cons 1 (cons 2 (cons 3 (cons 4 \u0026#39;()) ) ) ) (1 2 3 4) \u0026gt; (list 1 2 3 4) (1 2 3 4) \u0026gt; (define one-through-four (list 1 2 3 4)) \u0026gt; (car one-through-four) 1 \u0026gt; (cdr one-through-four) (2 3 4) \u0026gt; (car (cdr one-through-four)) 2 \u0026gt; (cons 10 one-through-four) (10 1 2 3 4) \u0026gt; (cons 5 one-through-four) (5 1 2 3 4) 下图为文本表示为 (1 2 3 4) 的列表对应的结构由一连串的对组成，以空列表在图中表示为包含符号 $\\emptyset$：\nA list containing the elements 1, 2, 3, and 4 以空列表以外的其他元素结束的数对序列称为 improper list。如上面的 (cons 1 2) 的结果就是一个例子，它只包含序列中的 pair。下面演示的是一个更复杂的序列：\n1 2 3 4 5 6 \u0026gt; (cons 1 (cons 2 (cons 3 4) ) ) (1 2 3 . 4) An improper list containing the elements 1, 2, and 3, and terminated by 4 rather than the empty list 证明了 pairs 和其他 compound objects 具有引用语义 \u0026ndash; 配对的 cdr 部分存储了对序列中下一对配对的引用。下面的代码通过变量进一步演示了这些引用语义：\n1 2 3 4 5 6 7 \u0026gt; (define x (cons 1 2)) \u0026gt; (define y x) \u0026gt; (eqv? x y) #t \u0026gt; (set-car! y 7) \u0026gt; x (7 . 2) 在这里，定义 (define y x) 的结果是 x 和 y 指向同一个数据 pair object。只有当两个参数指向同一个对象对时，存储过程 eqv? 才会返回 true（而 equal? 则从结构上对对象对进行比较）。此外，当我们使用 set-car! 变量修改 y 所引用的配对的第一个项目时，我们可以看到 x 引用了同一个配对，因为它也显示了修改。\n一个对象是否为空列表，可以使用原始的 null? 。利用它，我们可以定义用于计算适当列表长度和选择元素的标准序列操作：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 \u0026gt; (define (list-length items) (if (null? items) 0 (+ 1 (list-length (cdr items))) ) ) \u0026gt; (define (getitem items n) (if (= n 0) (car items) (getitem (cdr items) (- n 1)) ) ) \u0026gt; (define squares (list 1 4 9 16 25)) \u0026gt; (length squares) 5 \u0026gt; (getitem squares 3) 16 内置的 length 和 list-ref 程序提供了与这里的 list-length 和 getitem 相同的功能。\nSymbolic Data 我们迄今为止使用过的所有复合数据对象最终都是由数字构建的。使用任意符号作为数据是 Scheme 的优势之一。\n为了操作符号，我们需要在语言中加入一个新元素：引用数据对象的能力。假设我们要构造列表 (a b)。我们不能用 (list a b) 来实现这个目的，因为这个表达式构造的是一个包含 a 和 b 值的列表，而不是符号本身。在 Scheme 中，我们会在符号 a 和 b 之前加上单引号，来指代它们，而不是它们的值：\n1 2 3 4 5 6 7 8 \u0026gt; (define a 1) \u0026gt; (define b 2) \u0026gt; (list a b) (1 2) \u0026gt; (list \u0026#39;a \u0026#39;b) (a b) \u0026gt; (list \u0026#39;a b) (a 2) 在 Scheme 中，任何未被求值的表达式都被称为 quoted。引号的概念源于一个经典的哲学，即一个事物，如到处乱跑并吠叫的狗与 \u0026ldquo;狗\u0026rdquo; 这个词之间的区别，\u0026ldquo;狗\u0026rdquo; 这个词是用于指定此类事物的语言结构。当我们使用带引号的 \u0026ldquo;狗\u0026rdquo; 时，我们指的并不是某只狗，而是一个词。在语言中，引号允许我们谈论语言本身，在 Scheme 中也是如此：\n1 2 \u0026gt; (list \u0026#39;define \u0026#39;list) (define list) 引号还允许我们使用传统的列表打印表示法键入复合对象。我们已经看到，'() 表示空列表。下面是其他例子：\n1 2 3 4 5 \u0026gt; (car \u0026#39;(a b c)) a \u0026gt; (cdr \u0026#39;(a b c)) (b c) Scheme 中的引号与字符串不同，后者表示字符格式的原始、非结构化数据，而前者表示结构化数据。\n1 2 3 4 5 6 7 8 9 10 \u0026gt; \u0026#34;(- 3)\u0026#34; ; a string containing the characters #\\( #\\- #\\space #\\3 #\\) \u0026#34;(- 3)\u0026#34; \u0026gt; \u0026#39;(- 3) ; produces a list containing the symbol - and number 3 (- 3) \u0026gt; (car \u0026#39;(- 3)) - \u0026gt; (cdr \u0026#39;(- 3)) (3) \u0026gt; (- 3) ; calls the - procedure on the number 3 -3 在上面的示例中，字符串字面形式 \u0026quot;(- 3)\u0026quot; 的值为其本身，带引号的表达式 '(- 3) 求值为一个列表，列表的第一个元素是符号 -，第二个元素是数字 3。最后一个示例对符号 - 进行求值以获得相应的存储过程，将数字 3 求值为自身，然后在数字 3 上调用存储过程 -，得到 -3。换句话说，字符串字面量中的数据仍然是字符数据，既不会被求值，也不会被解析。带引号表达式会被解析，但不会被求值，而是产生数据的结构化表示。未加引号的表达式会被解释器解析和求值。\n完整的 Scheme 语言还包含其他功能，如 mutation operations、vectors 和 maps。不过，我们迄今为止介绍的子集提供了一种丰富的函数式编程语言，能够实现我们迄今为止讨论过的许多想法。\nFunctions 我们首先要考虑的是以参数形式向函数传递数据的各种方案。我们将出现在函数定义中的参数，也称为 formal parameters，与调用函数时传递给函数的实际值区分开来，后者通常被称为 actual parameter。\n本文将使用 argument 一词来指代 actual parameter， 用 parameter 一词指代 formal parameters。 Keyword Arguments 有些语言允许甚至要求在调用函数时提供参数名，这种策略称为 named parameters 或 keyword arguments。\n关键字参数通常允许以不同于函数参数列表的顺序提供参数。例如，在 Python 中，keyword argument 可以用于任何参数。请看下面的代码：\n1 2 def foo(x, y): print(x, y) 调用不带关键字参数的 foo() 时，第一个参数会作为第一个参数传递，第二个参数会作为第二个参数传递：\n1 2 \u0026gt;\u0026gt;\u0026gt; foo(1, 2) 1 2 不过，参数可以使用参数名重新排序：\n1 2 \u0026gt;\u0026gt;\u0026gt; foo(y = 1, x = 2) 2 1 Python 还提供了将参数定义为 positional-only 或 keyword-only 的机制，但我们不会在这里讨论这些机制。\n有少数语言要求默认为所有或大部分参数提供名称，并要求以与参数相同的顺序提供参数。下面是 Swift 3 中的一个示例：\n1 2 3 4 5 func greet(name: String, withGreeting: String) { print(withGreeting + \u0026#34; \u0026#34; + name) } greet(name: \u0026#34;world\u0026#34;, withGreeting: \u0026#34;hello\u0026#34;) 以相反的参数顺序调用 greet() 是错误的。\nSwift 允许为一个参数指定不同的参数名和参数名，这一点也很罕见。这意味着调用函数时为参数提供的名称可能与函数主体中使用的参数内部名称不同。\nDefault Arguments 在某些语言中，函数声明或定义可能会提供一个 default argument，允许在没有该参数的情况下调用函数。这可以替代重载，即编写单独的函数定义来处理存在或缺少参数的情况。\n下面是一个 Python 示例：\n1 2 def power(base, exponent=2): return base ** exponent power() 函数可以调用一个参数，在这种情况下，默认参数 2 用于计算数字的平方。也可以使用两个参数来计算任意幂：\n1 2 3 4 \u0026gt;\u0026gt;\u0026gt; power(3) 9 \u0026gt;\u0026gt;\u0026gt; power(3, 4) 81 有 default arguments 一般必须出现在参数列表的末尾。对于何时以及在哪种环境下评估默认参数，不同语言的做法各不相同。最常见的策略是每次调用函数时都评估缺省参数，但在定义 environment (static scope) 中进行。Python 的罕见之处在于，它只在函数定义语句执行时评估一次缺省参数。这意味着，如果在函数中修改了参数值，那么对同一函数的后续调用可能会对同一参数使用不同的缺省值。例如\n1 2 3 4 5 6 7 8 9 10 def test(x=[]): x.append(1) print(x) test() test() // output [1] [1, 1] C 和 C++ 有许多关于缺省参数的规则，这是因为一个实体可以声明多次。默认参数既可以在独立声明中提供，也可以在定义中提供。但是，同一实体的多个可见声明为同一参数提供默认参数是非法的，即使提供的值是相同的。缺省参数集是同一作用域内所有可见声明的集合，只有在前面和当前声明已为所有后续参数提供缺省参数的情况下，声明才能为参数引入缺省参数。缺省参数中使用的名称在声明时进行解析，但参数表达式在调用函数时进行求值。\n下面是 C++ 中多重声明的一个合法示例：\n1 2 3 4 int foo(int x, int y = 4); int foo(int x = 3, int y) { return x + y; } 除函数参数外，C++ 还允许模板参数使用默认参数，其有效性规则与此类似。\nVariadic Functions 一种语言可能会提供一种机制，让函数在调用时可以使用数量可变的参数。这种特性通常被称为 varargs，使用这种特性的函数被称为变量函数 (variadic)。这种机制可能提供类型安全，也可能允许不安全的使用，从而导致错误或未定义的行为。可变参数一般必须出现在参数列表的末尾，它匹配的是非可变参数匹配后剩余的参数。通常只允许使用一个变量参数。\n在提供安全变量函数的语言中，一种常见的机制是自动将变量参数打包到一个 container 中，例如 array 或 tuple。例如，下面的 Python 函数计算其参数的乘积：\n1 2 3 4 5 def product(*args): result = 1 for i in args: result *= i return result 参数名前面的 * 表示变量参数，变量参数以绑定到参数名的元组形式传递。上述函数遍历元组中的元素，更新总乘积。要调用 product()，必须提供 0 个或更多参数：\n1 2 3 4 \u0026gt;\u0026gt;\u0026gt; product() 1 \u0026gt;\u0026gt;\u0026gt; product(1, 2, 3) 6 Python 还提供了可变关键字参数，这些参数被打包成一个字典。在参数前面加上 ** 表示它是一个可变关键字参数，并且这样的参数必须是最后一个。例如，下面的函数同时包含一个非关键字可变参数和一个可变关键字参数，打印出前者对应的元组和后者对应的字典：\n1 2 3 def print_args(*args, **kwargs): print(args) print(kwargs) 1 2 3 \u0026gt;\u0026gt;\u0026gt; print_args(3, 4, x = 5, y = 6) (3, 4) {\u0026#39;x\u0026#39;: 5, \u0026#39;y\u0026#39;: 6} 最后，Python 允许使用 * 或 ** 操作符对序列或字典进行 \u0026ldquo;解包\u0026rdquo;，从而将解包后的值用于需要值列表的地方。例如，下面的代码将一个列表解包，以调用 product()：\n1 2 product(*[1, 2, 3]) 6 此外，Scheme 还支持可变参数。一个存储过程可以使用一个不恰当的列表作为参数列表，并以一个符号而不是空列表结束，这样就可以定义一个存储过程来接受可变参数。可变参数与任意数量的参数绑定，并打包成一个列表：\n1 2 3 4 5 6 7 \u0026gt; (define (func . args) args ) \u0026gt; (func) () \u0026gt; (func 1 2 3) (1 2 3) 存储过程 func 可以接收任意数量的参数，并返回包含这些参数的 list。因此，它的行为与内置的 list 存储过程相同。我们还可以定义一个存储过程，同时接收必参数和可变参数，例如下面的 average 定义：\n1 2 3 4 5 6 7 8 9 10 11 \u0026gt; (define (average x . nums) (/ (apply + x nums) (+ 1 (length nums)) ) ) \u0026gt; (average 1) 1 \u0026gt; (average 1 3) 2 \u0026gt; (average 1 3 5 7) 4 procedure 接收一个或多个参数，其中第一个参数与参数 x 绑定，其余参数封装在一个与变量 nums 参数绑定的列表中。我们可以使用 apply 来转发变量参数，它接收一个存储过程、任意数量的常规参数，最后是一个包含其余参数的列表。例如，(apply + 1 2 '(3 4)) 相当于调用 (+ 1 2 3 4)。在上面第一个使用 average 的示例中，nums 在调用 (average 1) 时绑定为一个空列表，而 (apply + x nums) 相当于 (apply + 1 '()) ，后者本身相当于 (+ 1)。在第三个例子中，nums 绑定到一个列表 (3 5 7)，因此 (apply + x nums) 等价于 (apply + 1 '(3 5 7))，而 (apply + 1 '(3 5 7)) 又等价于 (+ 1 3 5 7)。\n在 Python 和 Scheme 中，可变参数可以匹配任何类型的参数，因为这两种语言都是动态类型的。然而，在静态类型语言中，可变参数通常被限制为单一类型，尽管该类型可能是多态的。例如，下面是 Java 中的一个变量方法：\n1 2 3 4 5 public static void print_all(String... args) { for (String s : args) { System.out.println(s); } } print_all() 的参数必须是字符串，并将它们打包成一个字符串数组。Java 也允许将单个字符串数组作为参数传递：\n1 2 print_all(\u0026#34;hello\u0026#34;, \u0026#34;world\u0026#34;); print_all(new String[] { \u0026#34;good\u0026#34;, \u0026#34;bye\u0026#34; }); C 和 C++ 也有一种可变参数机制，但它存在严重的安全问题。尤其是，它无法向被调用的函数提供关于参数个数及其类型的信息。下面是一个返回参数之和的函数示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 #include \u0026lt;stdarg.h\u0026gt; int sum(int count, ...) { va_list args; int total = 0; int i; va_start(args, count); for (i = 0; i \u0026lt; count; i++) { total += va_arg(args, int); } va_end(args); return total; } 在该函数中，第一个参数被假定为其余参数的个数，而后一个参数被假定为 int 类型。如果违反其中任何一个条件，都会产生未定义的行为。另一种策略是使用格式字符串来确定参数的数量和类型，如 printf() 和类似函数中使用的方法。可变参数缺乏安全性，会导致格式字符串攻击等漏洞。\nC++11 提供了类型安全的 variadic templates。\nParameter Passing 语言的另一个不同之处在于函数与其调用者之间传递参数的 semantics 和 mechanism。函数参数可以是单向的，仅用于向函数传递输入或仅用于从函数向调用者传递输出，也可以是双向的。这些情况被称为 input、output 和 input/output 参数。一种语言不必支持所有三种参数类别。\n各种语言使用不同的参数传递技术或调用模式。这些技术会影响参数和参数的语义以及支持的参数类别。以下是不同语言使用的具体调用模式：\nCall by value，参数代表函数调用框架中的一个新变量。参数值被复制到与新变量相关的存储空间中。按值调用参数只为函数提供输入，如下面的 C++ 示例：\n1 2 3 4 5 6 7 8 9 10 void foo(int x) { x++; cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; endl; } int main() { int y = 3; foo(y); // prints 4 cout \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; // prints 3 } 即使 foo() 修改了输入值，修改后的值也不会传回 caller。\nCall by reference，参数必须传递一个 l-value，因为参数 aliases 了传递进来的对象。对参数的任何修改都会反映在参数对象中。因此，引用调用参数同时提供输入和输出。在 C++ 中，引用参数提供了引用调用，并且可以通过声明 const 将其限制为仅提供输入。下面的 C++ 示例使用引用调用交换了两个对象的值：\n1 2 3 4 5 6 7 8 9 10 11 void swap(int \u0026amp;x, int \u0026amp;y) { int tmp = x; x = y; y = tmp; } int main() { int x = 3, y = 4; swap(x, y); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; // prints 4 3 } 引用调用有时用来指使用指针间接传递对象。下面的 C/C++ 函数使用指针交换对象值：\n1 2 3 4 5 6 7 8 9 10 11 void swap(int *x, int *y) { int tmp = *x; *x = *y; *y = tmp; } int main() { int x = 3, y = 4; swap(\u0026amp;x, \u0026amp;y); printf(\u0026#34;%d %d\\n\u0026#34;, x, y); // prints 4 3 } 但从技术上讲，参数和参量是独立的指针对象，通过值传递。尽管如此，这种效果模拟了引用调用，使输入和输出都能通过一个参数来实现。\nCall by result，在这种模式下，参数代表一个新变量，调用者不对其进行初始化。相反，调用者会为参数指定一个 l-value，当函数调用结束时，参数的最终值会被复制到 l-value 中。因此，按结果调用只提供输出参数。下面是一个使用类似 C 的语法、按结果调用的示例：\n1 2 3 4 5 6 7 8 void foo(result int x) { x = 3; x++; // x is now 4 } int y = 5; foo(y); // y is now 4 print(y); // prints 4 Call by value-result，这是 Call by value 和 Call by result 的组合。参数值被复制到与参数相对应的新变量中，然后从函数返回时，参数值又被复制到调用者提供的 l-value 值中。这与引用调用的不同之处在于，在进入和退出函数时都会进行复制。可以通过将相同的 l-value 传递给多个参数来说明这一点，例如在下面的示例中使用了类似于 C 语言的语法，即按 Call by value-result：\n1 2 3 4 5 6 7 8 int foo(value-result int x, value-result int y) { x++; return x - y; } int z = 3; print(foo(z, z)); // prints 1 print(z); // prints 3 or 4, depending on the semantics 在这段代码中，x 和 y 是新变量，它们被初始化为 z 的值，即 3。x 的增量不会影响 y，因为它们是独立的变量，所以调用 foo() 返回 1。因此，1 会被打印出来。z 的最终值取决于从 x 还是从 y 复制的语言语义。如果使用引用调用，那么 x 和 y 将 alias 为同一个对象，调用 foo() 将返回 0。\nCall by name，在这种模式下，可以提供一个完整的表达式作为参数，但在调用函数时不会对其进行求值。相反，在函数中出现参数名的地方，参数名会被表达式替换，而表达式会在主体中遇到时进行求值。这是一种 lazy evaluation，即在需要时才计算值。下面是一个使用 C-like syntax、按名称调用的示例：\n1 2 3 4 5 6 7 8 9 void foo(name int a, name int b) { print(b); // becomes print(++y) print(b); // becomes print(++y) } int x = -1, y = 3; foo(++x, ++y); // prints 4, then 4 or 5 depending on the exact // language semantics; y is now 4 or 5 print(x); // prints -1 -- x is unchanged 在本例中，参数表达式 ++x 从未被求值，因为相应的逐名调用参数 a 从未被使用。另一方面，表达式 ++y 被计算，因为相应的参数 b 确实被使用了。根据语言语义的不同，表达式可能只被求值一次，其值被缓存以备后续使用，也可能在每次使用参数时都被求值。\n按名称调用会产生一个微妙的问题。请看下面这段代码，它使用了 C-like syntax 和按名称调用：\n1 2 3 4 5 6 7 void bar(name int x) { int y = 3; print(x + y); } int y = 1; bar(y + 1); 如果我们用参数表达式替换 bar() 中出现的参数 x，就会得到 y + 1 + y 作为 print() 的参数。如果在 bar() 的环境中求值，结果将是 7。这是不可取的，因为这意味着局部声明 y 的实现细节改变了函数的行为。\n相反，参数表达式应在调用者的环境中进行评估。这就要求在函数调用时同时传递参数及其环境。使用名称调用的语言通常使用编译器生成的局部函数，称为 thunk ，来封装参数表达式及其环境。然后将 thunk 传递给被调用的函数，当遇到参数时，就会调用 thunk。\n在某些语言中，与 call-by-name parameter 相对应的表达式仅在首次引用该参数时进行评估，并缓存评估结果。缓存的结果将用于随后每次出现的参数。\ncall by value 是大多数现代语言使用的调用模式，包括 C、C++（用于非引用参数）、Java、Scheme 和 Python。程序员经常误以为后三种语言使用 call by reference，但实际上，它们将 call by value 与 call by reference 语义结合在一起。这种组合有时被称为 object reference 。下面的示例说明 Python 使用的是 call by value：\n1 2 3 4 def swap(x, y): tmp = x x = y y = tmp 1 2 3 4 \u0026gt;\u0026gt;\u0026gt; x, y = 1, 2 \u0026gt;\u0026gt;\u0026gt; swap(x, y) \u0026gt;\u0026gt;\u0026gt; x, y (1, 2) 错误的 swap() 函数只是改变了局部变量的值，从而改变了它们所引用的对象，而没有影响作为参数的变量。这表明全局 x 和 y 的存储空间与参数的存储空间是不同的，因此 Python 没有使用引用调用。事实上，Python 甚至不能像 C 和 C++ 指针那样模拟引用调用。\nl-value and r-value l-value 和 r-value 是 C++ 表达式的基础。简单地说，l-value 是对象引用，r-value 是值。l-value 和 r-value 之间的区别在表达式的编写和理解中起着重要作用。\nl-value 是产生对象引用的表达式，例如变量名、数组下标引用、取消引用指针或返回引用的函数调用。l-value 总是有一个定义的存储区域，因此可以获取其地址。 r-value 是指不是 l-value 的表达式。r-value 的例子包括字面量、大多数运算符的结果以及返回非引用的函数调用。r-value 不一定与任何存储空间相关联。 严格来说，函数是一个 l-value，但它的唯一用途是用于调用函数或确定函数的地址。大多数情况下，l-value 指的是对象 l-value。\nEvaluation of Function Calls 下面我们总结一下函数调用的实现过程：\n第一步是确定嵌套函数调用的非本地环境。在使用嵌套函数和静态作用域的语言中，当执行嵌套函数定义本身时，非本地环境的引用会存储在关联的函数对象中。在具有深绑定的动态作用域下，非本地环境是在函数名称被引用时确定的。最后，在浅绑定的动态作用域中，非本地环境是函数被调用时处于活动状态的环境。\n下一步是使用新创建的函数调用激活记录将参数传递给函数。参数在现有环境中进行评估，并按如下方式传递给被调用者：\nCall by value and call by value-result : 对参数进行评估以获得其 r-value。r-value 将被复制到新激活记录中相应参数的存储空间。 Call by reference : 参数的 l-value。相应的参数会绑定到与 l-value 相关的对象上。 Call by result : 参数进行评估，以获得其 l-value 。在新的激活记录中，存储空间会被分配，但不会被初始化。 Call by name : 参数表达式会被打包到一个包含当前环境的 thunk 中。参数绑定到 thunk 的引用上。 一旦参数被传递，调用者的执行就会暂停，而被调用者的主体将在一个由新创建的激活记录和被调用者的非本地环境组成的环境中执行。对于 call by name，根据语言的语义，call by name 参数的出现会在参数第一次被指名或每次被指名时调用相应的 thunk。\n当被调用的函数返回时，其返回值（如果有的话）会被放置在指定的存储位置，通常是在调用者的激活记录中。对于 call-by-result 或 call-by-value-result 参数，参数的当前 r-value 会被复制到与相应函数调用参数的 l-value 相关联的对象中。然后，被调用者的激活记录将被销毁，调用者将在函数调用后恢复执行。函数调用本身的评估结果就是函数的返回值。\nRecursion Recursion 是一种利用函数和函数应用进行重复的机制。它涉及函数直接或间接地调用自身，通常使用在某种意义上比前一个参数 \u0026ldquo;小 \u0026ldquo;的参数。递归计算在达到基数时终止，基数是指无需进行任何递归调用即可直接计算出结果的输入。\n一种语言要想达到图灵完备性，只需提供 recursion 和 conditionals 即可。\nActivation Records 在机器上，递归之所以起作用，是因为函数的每次调用都有自己的激活记录，将局部变量映射为值。请看下面的阶乘递归定义：\n1 2 3 4 def factorial(n): if n == 0: return 1 return n * factorial(n - 1) 调用 factorial(4) 会导致五次调用 factorial()，参数从 4 到 0，每次都有自己的激活记录和参数 n 的绑定：\n1 2 3 4 5 factorial(4): n --\u0026gt; 4 factorial(3): n --\u0026gt; 3 factorial(2): n --\u0026gt; 2 factorial(1): n --\u0026gt; 1 factorial(0): n --\u0026gt; 0 Activation records used to compute factorial(4) 在执行 factorial() 主体时查找 n，每次调用都会获得自己的 n 值，而不会受到其他激活记录的影响。\n要使函数调用生效，激活记录需要的不仅仅是参数和局部变量的存储空间。临时值也需要存储在某个地方，由于每个调用都需要自己的临时值存储空间，因此这些临时值通常也要放在激活记录中。调用还需要知道在哪里存储其返回值，通常是在调用者框架中的临时存储区。最后，函数需要知道如何将执行返回给调用者。具体细节不在本文讨论范围之内，但这些信息包括调用者函数调用后的指令地址和调用者激活记录的地址。\n临时对象集可以通过静态方式保守地确定，因此激活记录的大小以及对象在其中的位置都可以在编译时确定。对于上面的 factor()，需要临时存储 n - 1 以及递归调用 factorial() 的结果。递归调用会使用后者在调用程序中的位置来存储其返回值。根据不同的实现，调用 factorial(0) 的激活记录中可能仍然有这些临时对象的空间，即使它们不会被使用。\nTail Recursion 递归计算对函数的每次调用都使用单独的激活记录。存储这些记录所需的空间与激活函数调用的次数成正比。在上面的 factorial(n) 中，当计算达到 factorial(0) 时，所有 n + 1 次调用都同时激活，需要的空间为 O(n)。与之相比，下面的迭代实现使用的空间是恒定的：\n1 2 3 4 5 6 def factorial_iter(n): result = 1 while n \u0026gt; 0: result *= n n -= 1 return result 然而，递归版本的 factorial() 所需的空间并不是使用递归的内在原因，而是函数编写方式的结果。事实上，由于在递归调用之后还需要完成调用的工作，因此在递归调用期间必须保留其激活记录，这就导致了线性空间需求。\n考虑另一种阶乘递推计算方法：\n1 2 3 4 def factorial_tail(n, partial_result = 1): if n == 0: return partial_result return factorial_tail(n - 1, n * partial_result) 请注意，在完成递归调用后，factorial_tail() 函数不做任何工作。这意味着在进行递归调用时，它不再需要存储参数、局部变量或临时对象。此外，由于 factorial(n, k) 直接返回递归调用 factorial(n - 1, n * k) 的结果，因此后者可以将其返回值存储在 factorial(n, k) 的调用者中用于存放 factorial(n, k) 返回值的位置，并直接将执行返回给该调用者。因此，优化后的实现可以为 factorial_tail(n - 1, n * k) 重用 factorial_tail(n, k) 的激活记录空间，因为前者不再需要激活记录。\n这个过程可以推广到任何函数调用，而不仅仅是递归调用。如果函数的调用者直接返回调用值，而不执行任何额外的计算，那么该函数调用就是尾调用。如果一个函数的所有递归调用都是尾调用，那么这个函数就是尾递归函数。因此，factorial_tail() 是尾部递归函数。\n尾递归计算只使用固定数量的激活记录，因此其空间使用量与等效的迭代计算相当。事实上，许多函数式语言并不提供迭代的构造，因为它们可以等效地使用尾递归来表达。这些语言通常要求实现执行尾调用优化，尽可能重复使用激活记录的空间。\n由于尾调用要求在返回后不执行任何计算，因此在语法上看似尾调用的调用可能不是尾调用，因为隐式计算可能发生在函数的末尾。这方面的一个具体例子是基于作用域的资源管理，如下例所示：\n1 2 3 4 5 6 int sum(vector\u0026lt;int\u0026gt; values, int index, int partial_result = 0) { if (values.size() == index) { return 0; } return sum(values, index + 1, partial_result + values[index]) } 虽然这段代码在递归调用后似乎没有进行计算，但本地 vector\u0026lt;int\u0026gt; 对象有一个析构函数，必须在递归调用完成后运行。因此，对 sum() 的递归调用不是尾部调用，该计算也不是尾部递归计算。\n另一种阻碍尾调用优化的情况是，在使用静态作用域并支持高阶函数全部功能的语言中，函数内部包含一个函数定义。嵌套函数需要访问其定义环境，因此如果嵌套函数可以在其外层函数调用完成后或在尾调用中使用，则必须保留该环境。\nHigher-Order Functions first-class entity 是一种支持对语言中的其他 entities 进行操作的 entity，包括作为参数传递、从函数返回和动态创建。\n在 functions 是 first-class entity 的语言中，可以编写 higher-order functions，将另一个 function 作为参数传递或返回一个 function。 其他语言也可能支持 higher-order functions，但是在这些语言中 function 不是可以在运行时动态创建的 entity 。 Function Objects 在某些语言中，可以定义本身不是函数但提供与函数相同接口的对象。这些对象被称为函数对象或函数器。一般来说，语言通过允许重载函数调用操作符来编写函数器。请看下面的 C++ 示例：\n1 2 3 4 5 6 7 8 9 10 11 class Counter { public: Counter : count(0) {} int operator()() { return count++; } private: int count; }; Counter 类实现了一个函数，可以返回它被调用的次数。可以同时存在多个 Counter 对象，每个对象都有自己的计数：\n1 2 3 4 5 6 7 Counter counter1, counter2; cout \u0026lt;\u0026lt; counter1() \u0026lt;\u0026lt; endl; // prints 0 cout \u0026lt;\u0026lt; counter1() \u0026lt;\u0026lt; endl; // prints 1 cout \u0026lt;\u0026lt; counter1() \u0026lt;\u0026lt; endl; // prints 2 cout \u0026lt;\u0026lt; counter2() \u0026lt;\u0026lt; endl; // prints 0 cout \u0026lt;\u0026lt; counter2() \u0026lt;\u0026lt; endl; // prints 1 cout \u0026lt;\u0026lt; counter1() \u0026lt;\u0026lt; endl; // prints 3 函数允许 function-like object 存在多个实例，每个实例都有自己的状态，并在函数的生命周期内持续存在。这与 function 截然不同，function 中的自动对象不会在单次调用后持续存在，而静态对象则会在整个程序执行过程中持续存在。\nPython 还允许通过定义特殊的 __call__ 方法来编写函数：\n1 2 3 4 5 6 7 class Counter: def __init__(self): self.count = 0 def __call__(self): self.count += 1 return self.count - 1 一般来说，在重载函数调用操作符时，可以指定额外的参数，以模拟可以接收这些参数的函数。\n有些语言不允许重载函数调用操作符本身，但规定了允许定义和使用类函数对象的约定。例如，下面是 Counter 在 Java 中使用 Supplier\u0026lt;T\u0026gt; 接口的实现，该接口指定了一个产生 T 的零参数方法：\n1 2 3 4 5 6 7 class Counter implements Supplier\u0026lt;Integer\u0026gt; { public Integer get() { return count++; } private int count = 0; } 然后通过明确调用 get() 方法来调用这个类函数对象：\n1 2 3 4 5 6 7 8 Supplier\u0026lt;Integer\u0026gt; counter1 = new Counter(); Supplier\u0026lt;Integer\u0026gt; counter2 = new Counter(); System.out.println(counter1.get()); // prints 0 System.out.println(counter1.get()); // prints 1 System.out.println(counter1.get()); // prints 2 System.out.println(counter2.get()); // prints 0 System.out.println(counter2.get()); // prints 1 System.out.println(counter1.get()); // prints 3 再比如，Java 中的 Predicate 接口是通过 functor-like objects 实现的，这些对象接收一个参数并返回一个布尔值：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 interface Predicate\u0026lt;T\u0026gt; { boolean test(T t); ... } class GreaterThan implements Predicate\u0026lt;Integer\u0026gt; { public GreaterThan(int threshold) { this.threshold = threshold; } public boolean test(Integer i) { return i \u0026gt; threshold; } private int threshold; } 使用这些 functor-like objects 的代码会调用 test() 方法，而不是直接调用对象：\n1 2 3 GreaterThan gt3 = new GreaterThan(3); System.out.println(gt3.test(2)); // prints out false System.out.println(gt3.test(20)); // prints out true java.util.function 函数库包中为常见模式提供了单独的接口。\nFunctions as Parameters higher-order function 可以将另一个函数作为参数。我们首先研究那些只有 top-level functions 并允许将函数指针或引用作为参数传递的语言。然后，我们将研究将函数作为参数传递会如何影响函数代码的执行环境。\nFunction Pointers 在某些语言中，函数可以作为参数或返回值传递，但不能在另一个函数的上下文中创建。在这些语言中，所有函数都是在顶层定义的，只有指向函数的指针或引用才能作为值使用。下面是 C 语言中的一个例子，C 语言提供了函数指针：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 void apply(int *array, size_t size, int (*func)(int)) { for (; size \u0026gt; 0; --size, ++array) { *array = func(*array); } } int add_one(int x) { return x + 1; } int main() { int A[5] = { 1, 2, 3, 4, 5 }; apply(A, 5, add_one); printf(\u0026#34;%d, %d, %d, %d, %d\\n\u0026#34;, A[0], A[1], A[2], A[3], A[4]); return 0; } apply() 函数接收数组、数组大小和一个指向接收 int 并返回 int 的 function pointer。它将函数应用于数组中的每个元素，并用结果替换原值。add_one() 函数作为参数传递给 apply()，C 语言会自动将函数转换为函数指针，其结果是 A 中的每个元素都被递增。\nBinding Policy 在上面的代码中，有三个环境与 add_one() 函数相关联：定义环境、在 main() 中引用环境和在 apply() 中调用环境。根据语言的语义，这三个环境中的任何一个都可能是 add_one() 主体执行环境的组成部分。\n在静态作用域中，函数中的代码可以访问其定义环境中的名称，而在动态作用域中，它可以访问其使用环境中的名称。考虑到动态作用域，函数的非本地环境是函数被引用的环境还是函数被调用的环境？下面是一个与这种区别有关的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 int foo(int (*bar)()) { int x = 3; return bar(); } int baz() { return x; } int main() { int x = 4; print(foo(baz)); } 在动态作用域中，函数可以访问其使用环境。然而，在上面的示例中，根据 baz() 的使用环境是函数被引用的地方还是被调用的地方，结果是不同的。\n函数被引用的地方的情况下，baz() 的非本地环境是 main() 的环境，baz() 主体中的 x 将引用 main() 中定义的 x。这就是所谓的深度绑定。 函数被调用的地方的情况下，baz() 的非本地环境是 foo() 的环境，baz() 中的 x 将引用 foo() 中定义的 x。这就是所谓的浅绑定。这两种方法都是有效的，语言的绑定策略决定了使用哪种方法。 使用静态作用域时，绑定策略也会对递归函数内部本地定义的函数产生影响。然而，在使用静态作用域的语言中，深度绑定被普遍使用，因此函数定义时所建立的环境就是函数所能访问的环境。\nNested Functions 函数式编程的一个主要特点是可以在另一个函数中定义一个函数，从而动态创建一个函数。在具有静态作用域的语言中，这种嵌套函数可以访问其定义环境，函数与其定义环境的组合称为 closure。嵌套函数中使用但在外层环境中定义的变量被称为 closure 所捕获。如果嵌套函数从外层函数中返回或泄漏，外层函数的环境通常必须在函数返回后继续存在，因为嵌套函数可能会访问其中的绑定。\n举例来说，请看下面这个返回嵌套函数的 Python higher-order function：\n1 2 3 4 5 def make_greater_than(threshold): def greater_than(x): return x \u0026gt; threshold return greater_than make_greater_than() 函数接收一个阈值，并构造一个嵌套函数来判断其输入是否大于阈值。threshold 变量位于 make_greater_than() 的激活记录中，但被 greater_than() 捕获。由于后者会返回阈值，因此激活记录必须持续存在，这样 greater_than() 的调用才能访问 threshold 的绑定。\n请注意，每次调用 make_greater_than()，都会创建一个不同的 greater_than() 实例，并拥有自己的外层环境。因此，不同的 make_greater_than() 调用会产生不同的函数：\n1 2 3 4 5 6 7 8 9 10 \u0026gt;\u0026gt;\u0026gt; gt3 = make_greater_than(3) \u0026gt;\u0026gt;\u0026gt; gt30 = make_greater_than(30) \u0026gt;\u0026gt;\u0026gt; gt3(2) False \u0026gt;\u0026gt;\u0026gt; gt3(20) True \u0026gt;\u0026gt;\u0026gt; gt30(20) False \u0026gt;\u0026gt;\u0026gt; gt30(200) True Environment for multiple instances of a nested function 调用的父框架是 threshold 绑定为 3 的框架，因此 x \u0026gt; threshold 的值为 false。\n非纯函数式语言可能允许修改捕获的变量。例如，下面使用嵌套函数定义了一个银行账户的数据抽象：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 def make_account(balance): def deposit(amount): nonlocal balance balance += amount return balance def withdraw(amount): nonlocal balance if 0 \u0026lt;= amount \u0026lt;= balance: balance -= amount return amount else: return 0 return deposit, withdraw Python 需要 nonlocal ，因为它默认赋值给本地变量。然后，我们可以如下使用创建的函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026gt;\u0026gt;\u0026gt; deposit, withdraw = make_account(100) \u0026gt;\u0026gt;\u0026gt; withdraw(10) 10 \u0026gt;\u0026gt;\u0026gt; deposit(0) 90 \u0026gt;\u0026gt;\u0026gt; withdraw(20) 20 \u0026gt;\u0026gt;\u0026gt; deposit(0) 70 \u0026gt;\u0026gt;\u0026gt; deposit(10) 80 \u0026gt;\u0026gt;\u0026gt; withdraw(100) 0 \u0026gt;\u0026gt;\u0026gt; deposit(0) 80 Decorators Python 中的一种常见模式是通过应用高阶函数来转换函数或类。这样的高阶函数被称为 decorator，Python 有专门的语法来装饰函数：\n1 2 3 @\u0026lt;decorator\u0026gt; def \u0026lt;name\u0026gt;(\u0026lt;parameters\u0026gt;): \u0026lt;body\u0026gt; 这在很大程度上相当于\n1 2 3 4 def \u0026lt;name\u0026gt;(\u0026lt;parameters\u0026gt;): \u0026lt;body\u0026gt; \u0026lt;name\u0026gt; = \u0026lt;decorator\u0026gt;(\u0026lt;name\u0026gt;) 被装饰函数的定义被正常执行，然后在函数上调用装饰器。调用的结果与函数名称绑定。\n举个例子，假设我们想通过打印函数名称及其参数来跟踪函数被调用的时间。我们可以定义一个高阶函数，接收一个函数并返回一个新的嵌套函数，该函数首先打印出原始函数的名称及其参数，然后调用该函数：\n1 2 3 4 5 6 7 def trace(fn): def tracer(*args): args_string = \u0026#39;, \u0026#39;.join(repr(arg) for arg in args) print(f\u0026#39;{fn.__name__}({args_string})\u0026#39;) return fn(*args) return tracer 在这里，我们使用变量参数为原始函数传递任意数量的参数。为了简单起见，我们忽略了关键字参数。然后，我们可以使用装饰器语法将其应用到函数中：\n1 2 3 @trace def factorial(n): return 1 if n == 0 else n * factorial(n - 1) 现在，只要调用 factorial()，我们就能得到参数的打印输出：\n1 2 3 4 5 6 7 8 \u0026gt;\u0026gt;\u0026gt; factorial(5) factorial(5) factorial(4) factorial(3) factorial(2) factorial(1) factorial(0) 120 请注意，递归调用也会调用转换后的函数。这是因为在 factorial() 的外层环境中，factorial 这个名称现在与嵌套的跟踪函数绑定在一起，因此查找这个名称时，会调用跟踪函数，而不是原来的函数。这样做的一个副作用是产生了相互递归，即一组函数通过彼此间接地进行递归调用。\nMutual recursion resulting from decorating a recursive function Lambda Functions 嵌套函数定义允许在运行时构造函数，从而满足了函数成为 first-class entity 的要求之一。不过，到目前为止，我们只看到了嵌套函数定义的命名，即在定义环境中引入了绑定。这与其他一流实体，如数据值，形成了鲜明对比，后者可以在不绑定名称的情况下创建。就像构造不带名称的值很有用一样，比如将其作为参数传递或返回时，构造不带名称的函数也很有用。这些函数被称为匿名函数或 lambda 函数。\nlambda 函数在函数式语言中无处不在，但许多常用的命令式语言也提供某种形式的 lambda 函数。不同语言的语法和功能各不相同，我们将研究几个具有代表性的示例。\nScheme 在以函数式为主的 Lisp 系列语言中，lambda 是一种常见的构造，Scheme 也不例外。lambda 特殊形式构造了一个匿名函数：\n1 (lambda (\u0026lt;parameters\u0026gt;) \u0026lt;body\u0026gt;) 使用 define 形式的函数定义可视为变量定义和 lambda 的简写：\n1 2 3 (define (\u0026lt;name\u0026gt; \u0026lt;parameters\u0026gt;) \u0026lt;body\u0026gt;) --\u0026gt; (define \u0026lt;name\u0026gt; (lambda (\u0026lt;parameters\u0026gt;) \u0026lt;body\u0026gt;)) 例如，下面的函数创建并返回一个匿名函数，该函数将给定的数字添加到参数中：\n1 2 3 4 5 (define (make-adder n) (lambda (x) (+ x n) ) ) 这比只使用 define 的等价定义更简单、更恰当：\n1 2 3 4 5 6 (define (make-adder n) (define (adder x) (+ x n) ) adder ) 然后，我们就可以在各个参数上调用 make-adder 的结果：\n1 2 3 4 5 6 7 \u0026gt; (define add3 (make-adder 3)) \u0026gt; (add3 4) 7 \u0026gt; (add3 5) 8 \u0026gt; ((make-adder 4) 5) 9 Scheme 中的嵌套函数使用静态作用域，因此匿名函数可以访问其定义环境中的变量 n。然后，它将自己的参数 x 与 n 相加，返回总和。\nScheme 并非纯函数式，它允许变量和复合数据的变异。嵌套函数，无论是否匿名，都可以修改其非本地环境中的变量。下面的函数创建了一个计数器函数，返回它被调用的次数：\n1 2 3 4 5 6 7 8 (define (make-counter) (let ((count 0)) (lambda () (set! count (+ count 1)) (- count 1) ) ) ) set! 将变量变为给定值。这样，我们就可以使用 make-counter 函数了：\n1 2 3 4 5 6 7 \u0026gt; (define counter (make-counter)) \u0026gt; (counter) 0 \u0026gt; (counter) 1 \u0026gt; (counter) 2 Resources https://eecs390.github.io/notes/functional.html ","permalink":"https://WFUing.github.io/posts/tech/language/functional-programming/","summary":"我们将注意力转向过程抽象，这是一种将复杂程序分解成 functions (也称为 procedures 或 subroutines 。这些术语在不同语境中的用法有细微差别，但就我们的目的而言，我们将把它们视为同义词) 形式的较小代码片段的策略。函数将某些计算封装在一个接口之后，与任何抽象概念一样，函数的用户只需知道函数做了什么，而不需要知道函数是如何完成计算的。函数还通过接收影响其计算的参数来概括计算。计算的结果就是函数的返回值。\n在本单元中，我们首先介绍 Lisp 家族中的函数式语言 Scheme。然后，我们将讨论与所有 procedural languages 相关的函数方面的问题，然后再仔细研究 functional programming，这是一种以数学函数为计算模型的编程范式。\nIntroduction to Scheme R5RS Scheme 语言采用了与 Python 非常相似的计算模型，但只使用 expressions (不使用statements)，擅长 symbolic computation。\nScheme 是 Lisp 的一种方言，Lisp 是当今仍在广泛使用的第二古老的编程语言（仅次于 Fortran）。几十年来，Lisp 程序员社区一直在蓬勃发展，而新的 Lisp 方言（如 Clojure）也是所有现代编程语言中开发者社区发展最快的。要跟上本文的示例，可以下载 Scheme 解释器或使用在线解释器。\nExpressions Scheme 程序由 expressions 组成，expressions 可以是简单表达式，也可以是列表形式的组合。简单表达式由一个文字或符号组成。组合表达式是一种 compound expression，由一个运算符表达式和零个或多个操作数子表达式组成。运算符和操作数都包含在括号中：\n1 2 \u0026gt; (quotient 10 2) 5 Scheme 只使用前缀符号。操作符通常是符号，如 + 和 *。复合表达式可以嵌套，也可以跨一行以上：\n1 2 3 4 5 6 7 8 9 10 11 12 \u0026gt; (+ (* 3 5) (- 10 6)) 19 \u0026gt; (+ (* 3 (+ (* 2 4) (+ 3 5) ) ) (+ (- 10 7) 6 ) ) 57 对组合进行求值时，首先需要检查运算符是否代表 special form，因为 special form 有自己的求值程序。如果运算符不是 special form，那么运算符和操作数表达式将按照任意顺序进行求值。然后，作为运算符值的函数将应用于作为操作数值的参数。","title":"Functional Programming"},{"content":"Serverless Devs 是一个开源开放的 Serverless 开发者平台，致力于为开发者提供强大的工具链体系。通过该平台，开发者不仅可以一键体验多云 Serverless 产品，极速部署 Serverless 项目，还可以在 Serverless 应用全生命周期进行项目的管理，并且非常简单快速的将 Serverless Devs 与其他工具/平台进行结合，进一步提升研发、运维效能。\n平台/产品支持 目前 Serverless Devs 项目已经支持的 FaaS 平台/产品：\nHosted 阿里云函数计算（FC）: 项目仓库 AWS Lambda: 项目仓库 百度智能云函数计算（CFC）: 项目仓库 华为云函数工作流（FG）: 项目仓库 腾讯云云函数（SCF）: 项目仓库 Installable OpenFunction（ofn）: 项目仓库 Laf: 开发中\u0026hellip; 项目期望 Serverless Devs 希望可以为 Serverless 开发者们提供一款可以无厂商锁定的，可以在 Serverless 应用全生命周期发挥作用的 Serverless 开发者工具； Serverless Registry 希望可以为 Serverless 生态提供一套完整的包管理规范，与 Python 中的 pypi， Nodejs 中的 npm 等类似，将以此来开放和分享 Serverless Package，建设 Serverless 生态； Serverless Developer Meetup 希望可以打造最符合 Serverless 开发者的社区活动，通过这个活动，希望更多人可以一起交流、学习 Serverless 相关的产品； 快速上手 本快速上手案例以 阿里云函数计算 为例的快速上手 Serverless Devs\n工具安装 第一步：安装 Node.js(\u0026gt;=12.0.0) 与 NPM 包管理工具； 第二步：安装 Serverless Devs 开发者工具； 1 $ npm install @serverless-devs/s -g 第三步：可以通过s -v判断工具是否安装成功，如果安装成功可以看到相对应的版本信息，例如： 1 @serverless-devs/s: 2.1.2, core: 0.1.41, s-home: /Users/xxx/.s, darwin-x64, node-v17.7.1 密钥配置 以阿里云密钥配置为例：\n获取密钥页面：https://usercenter.console.aliyun.com/#/manage/ak 打开 获取密钥页面 获取密钥信息 ：\n执行s config add，并选择Alibaba Cloud (alibaba)：\n1 2 3 4 $ s config add ? Please select a provider: Alibaba Cloud (alibaba) 🧭 Refer to the document for alibaba key: http://config.devsapp.net/account/alibaba ? AccessKeyID: 此时，可以按照引导，进行密钥的配置：\n1 2 3 4 5 6 7 8 9 10 11 12 ? Please select a template: Alibaba Cloud (alibaba) 🧭 Refer to the document for alibaba key: http://config.devsapp.net/account/alibaba ? AccessKeyID 此处填写AccessKeyID ? AccessKeySecret 此处填写AccessKeySecret ? Please create alias for key pair. If not, please enter to skip alibaba-access Alias: alibaba-access AccountID: 自动获取AccountID AccessKeyID: 此处填写AccessKeyID AccessKeySecret: 此处填写AccessKeySecret ✔ Configuration successful 为了验证密钥是否正确配置，可以通过s config get -a alibaba-access进行指定密钥的查看：\n1 2 3 4 5 $ s config get -a alibaba-access alibaba-access: AccountID: 此处填*******tID AccessKeyID: 此处填*********yID AccessKeySecret: 此处填*************ret 上手体验 Serverless：Hello World 执行s命令：\n1 2 $ s ? No Serverless-Devs project is currently detected. Do you want to create a new project? (Y/n) 填写y，并按回车，可以进入到创建引导部分：\n1 2 3 4 5 6 7 8 9 🚀 More applications: https://registry.serverless-devs.com ? Hello Serverless for Cloud Vendors (Use arrow keys or type to search) ❯ Alibaba Cloud Serverless AWS Cloud Serverless Baidu Cloud Serverless Huawei Cloud Serverless Tencent Cloud Serverless Dev Template for Serverless Devs 此时只需要选择对应的选项，按照引导进行操作，即可。例如选择Alibaba Cloud Serverless，就可以看到阿里云Serverless产品下的应用模板分类:\n1 2 3 4 5 6 ? Hello, serverlesser. Which template do you like? (Use arrow keys or type to search) ❯ Quick start [Deploy a Hello World function to FaaS] Container example [Deploy function to FaaS with custom-container] Web Framework [Deploy a web framework to FaaS] Static website [Deploy a static website] Best practice [Experience serverless project] 此时可以继续选择某分类下的具体应用进行初始化，例如选择Quick start之后，可以看到该分类下的具体模板应用：\n1 2 3 4 5 6 7 8 9 ? Which template do you like? (Use arrow keys or type to search) ❯ [HTTP] Node.js 14 - 快速部署一个 nodejs14 http函数 [HTTP] Python3 - 快速部署一个 python3 http函数 [HTTP] Java8 - 快速部署一个 java8 http函数 [HTTP] PHP7 - 快速部署一个 php http函数 [HTTP] C++ (custom)- 快速部署一个 C++ http函数 [Event] Node.js 14 - 快速部署一个 nodejs14 event函数 [Event] Python3 - 快速部署一个 python3 event函数 ... ... 选择[HTTP] Node.js 14即可完成创建，在引导的过程中，可能会出现填写项目名称以及选择密钥的过程：\n项目名称可以是：start-fc-http-nodejs14 地域可以是：cn-hangzhou 服务名可以是： hello-world-service 函数名可以是： start-fc-http-nodejs14 密钥可以选择我们上文中创建过的：alibaba-access 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 🚀 More applications: https://registry.serverless-devs.com ? Hello Serverless for Cloud Vendors Alibaba Cloud Serverless ? Hello, serverlesser. Which template do you like? Quick start [Deploy a Hello World function to FaaS] ? Which template do you like? [HTTP] Node.js 14 😋 Create application command: [s init devsapp/start-fc-http-nodejs14] ? Please input your project name (init dir) start-fc-http-nodejs14 ✔ file decompression completed Serverless Devs Application Case Cloud services required： - FC : https://fc.console.aliyun.com/ Tips： - FC Component: https://www.serverless-devs.com/fc/readme 创建应用所在的地区 ? 地域 cn-hangzhou 服务名称，只能包含字母、数字、下划线和中划线。不能以数字、中划线开头。长度在 1-128 之间 ? 服务名 hello-world-service 函数名称，只能包含字母、数字、下划线和中划线。不能以数字、中划线开头。长度在 1-64 之间 ? 函数名 start-fc-http-nodejs14 ? please select credential alias alibaba-access * Before using, please check whether the actions command in Yaml file is available * Carefully reading the notes in s.yaml is helpful for the use of the tool * If need help in the use process, please apply to join the Dingtalk Group: 33947367 🏄‍ Thanks for using Serverless-Devs 👉 You could [cd /Users/nanxuanli/work/demo/devs/start-fc-http-nodejs14] and enjoy your serverless journey! 🧭️ If you need help for this example, you can use [s -h] after you enter folder. 💞 Document ❤ Star: https://github.com/Serverless-Devs/Serverless-Devs 🚀 More applications: https://registry.serverless-devs.com ? Do you want to deploy the project immediately? (Y/n) 可以看到，系统在最后有一个提醒，是否要部署该项目，此时可以输入y，直接进行项目的部署，稍等片刻，可以看到部署结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 helloworld: region: cn-hangzhou service: name: hello-world-service function: name: start-fc-http-nodejs14 runtime: nodejs14 handler: index.handler memorySize: 128 timeout: 60 url: system_url: https://start-fp-nodejs-hello-w-service-uxcvfbhdii.cn-hangzhou.fcapp.run custom_domain: - domain: http://start-fc-http-nodejs14.hello-world-service.1816647648916833.cn-hangzhou.fc.devsapp.net triggers: - type: http name: httpTrigger 此时可以打开domain返回给我们的域名，进行测试。\n人工智能：目标检测 初始化一个已有的人工智能目标检测项目：s init devsapp/image-prediction-app，初始化过程中可能会出现填写项目名称以及选择密钥的过程：\n项目名称可以是：image-prediction-app 密钥可以选择我们上文中创建过的：alibaba-access 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 $ s init devsapp/image-prediction-app 🚀 Serverless Awesome: https://github.com/Serverless-Devs/package-awesome ? Please input your project name (init dir) image-prediction-app ✔ file decompression completed ? please select credential alias alibaba-access ___ __ __ _______ _______ _______ | | | |_| || _ || || | | | | || |_| || ___|| ___| | | | || || | __ | |___ | | | || || || || ___| | | | ||_|| || _ || |_| || |___ |___| |_| |_||__| |__||_______||_______| Welcome to the image-prediction-app application This application requires to open these services: FC : https://fc.console.aliyun.com/ This application can help you quickly deploy the image-prediction-app project. The application uses FC component：https://github.com/devsapp/fc The application homepage: https://github.com/devsapp/image-prediction-app 🏄‍ Thanks for using Serverless-Devs 👉 You could [cd /Users/jiangyu/start-application/image-prediction-app] and enjoy your serverless journey! 🧭️ If you need help for this example, you can use [s -h] after you enter folder. 💞 Document ❤ Star：https://github.com/Serverless-Devs/Serverless-Devs 进入项目目录：cd image-prediction-app\n通过deploy命令进行项目的部署：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 Tips for next step ====================== * Display information of the deployed resource: s info * Display metrics: s metrics * Display logs: s logs * Invoke remote function: s invoke * Remove Service: s remove service * Remove Function: s remove function * Remove Trigger: s remove trigger * Remove CustomDomain: s remove domain imageAi: region: cn-hangzhou url: custom_domain: - domain: http://server.ai-cv-image-prediction.1583208943291465.cn-hangzhou.fc.devsapp.net 此时可以打开系统分配的测试域名，并上传一张图片进行测试： 传统框架：基于Django的博客项目 初始化一个已有的基于Django的博客项目：s init django-blog，初始化过程中可能会出现填写项目名称以及选择密钥的过程：\n项目名称可以是：django-blog 密钥可以选择我们上文中创建过的：alibaba-access 例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 $ s init django-blog 🚀 Serverless Awesome: https://github.com/Serverless-Devs/package-awesome ? Please input your project name (init dir) django-blog ✔ file decompression completed ? please select credential alias alibaba-access ______ ___ _______ __ _ _______ _______ _______ ___ _______ _______ | | | || _ || | | || || || _ || | | || | | _ | | || |_| || |_| || ___|| _ || |_| || | | _ || ___| | | | | | || || || | __ | | | || || | | | | || | __ | |_| | ___| || || _ || || || |_| || _ | | |___ | |_| || || | | || || _ || | | || |_| || || |_| || || || |_| | |______| |_______||__| |__||_| |__||_______||_______||_______||_______||_______||_______| Welcome to the django-blog application This application requires to open these services: FC : https://fc.console.aliyun.com/ This application can help you quickly deploy the django-blog project. The application uses Django component：https://github.com/devsapp/django The application homepage: https://github.com/devsapp/django-blog * Python 3.7 is recommended; * If the version is greater than Python 3.7: * Operation error: ImportError: cannot import name \u0026#39;metadata\u0026#39; from \u0026#39;importlib\u0026#39;, you can refer to: https://stackoverflow.com/questions/59216175/importerror-cannot-import-name-metadata-from-importlib * Default information: * Admin：/admin * Default Admin Username: blog * Default Admin Password: myblog12345! 🏄‍ Thanks for using Serverless-Devs 👉 You could [cd /Users/jiangyu/django-blog] and enjoy your serverless journey! 🧭️ If you need help for this example, you can use [s -h] after you enter folder. 💞 Document ❤ Star：https://github.com/Serverless-Devs/Serverless-Devs 进入项目目录：cd django-blog\n通过deploy命令进行项目的部署：\n1 2 3 4 5 6 7 8 9 10 Tips for next step ====================== * Invoke remote function: s invoke ✔ Try container acceleration djangoBlog: region: cn-shenzhen serviceName: serverless-devs-django functionName: django customDomains: - http://django.serverless-devs-django.1583208943291465.cn-shenzhen.fc.devsapp.net 此时可以打开系统分配的测试域名，并上传一张图片进行测试： Resources Github: https://github.com/Serverless-Devs/Serverless-Devs ","permalink":"https://WFUing.github.io/posts/tech/architecture/serverless/serverless-dev/","summary":"Serverless Devs 是一个开源开放的 Serverless 开发者平台，致力于为开发者提供强大的工具链体系。通过该平台，开发者不仅可以一键体验多云 Serverless 产品，极速部署 Serverless 项目，还可以在 Serverless 应用全生命周期进行项目的管理，并且非常简单快速的将 Serverless Devs 与其他工具/平台进行结合，进一步提升研发、运维效能。\n平台/产品支持 目前 Serverless Devs 项目已经支持的 FaaS 平台/产品：\nHosted 阿里云函数计算（FC）: 项目仓库 AWS Lambda: 项目仓库 百度智能云函数计算（CFC）: 项目仓库 华为云函数工作流（FG）: 项目仓库 腾讯云云函数（SCF）: 项目仓库 Installable OpenFunction（ofn）: 项目仓库 Laf: 开发中\u0026hellip; 项目期望 Serverless Devs 希望可以为 Serverless 开发者们提供一款可以无厂商锁定的，可以在 Serverless 应用全生命周期发挥作用的 Serverless 开发者工具； Serverless Registry 希望可以为 Serverless 生态提供一套完整的包管理规范，与 Python 中的 pypi， Nodejs 中的 npm 等类似，将以此来开放和分享 Serverless Package，建设 Serverless 生态； Serverless Developer Meetup 希望可以打造最符合 Serverless 开发者的社区活动，通过这个活动，希望更多人可以一起交流、学习 Serverless 相关的产品； 快速上手 本快速上手案例以 阿里云函数计算 为例的快速上手 Serverless Devs","title":"Serverless Dev"},{"content":"Serverless 是一种计算模型，它使得开发者能够在无需管理服务器和基础架构的情况下运行代码（或称函数）。使用无服务器计算，开发者可以将代码上传到云平台，平台会在需要时根据流量自动进行资源分配和处理。\nServerless 的特点\n按需分配 无服务器计算基于事件驱动和按需调用，只在需要时才会进行计算资源的分配和管理 弹性伸缩 无服务器计算平台会自动根据负载量的变化进行资源的动态分配和优化，无需手动干预 简化开发与部署 开发者专注于编写核心业务逻辑代码，简化应用开发以及部署流程 Concept Models Serverless 核心资源 Service\n阿里云提供服务这一抽象 服务是函数计算资源管理的单位，同一服务下的所有函数共享一些设置，如服务授权和日志配置 一个应用可拆分为多个服务，一个服务可由多个函数组成 Function\n云函数，云函数由代码和运行环境描述组成 云函数可能依赖于其他云函数，或者外部服务，如对象存储，API 网关，消息队列 Trigger\n触发器，用于在满足某些条件时，触发 Function 的执行 基于事件驱动 常见的触发器类型 定时触发器 Cron Trigger API 网关触发器 HTTP Trigger 消息队列触发器 MQ Trigger External Service\n云函数在运行过程中，可能调用外部的服务完成任务，如调用 Redis 或 RDBMS 存储状态 Function 表示 Serverless 函数\nFunction 基本信息\n包括函数的代码 URI，运行时，处理函数名称等\nFunction 资源需求\n指定函数运行时所需的计算资源，如内存，CPU 等\nFunction 触发器\n1 2 3 4 5 6 7 8 9 export interface Function { runtime: string; codeDir: string; // source code directory to bundle resource: { memory: string; cpu: string; }; triggers: {}[]; } Trigger 函数触发器，基于事件驱动机制触发函数执行\n1 2 3 4 5 export interface Trigger { name: string; type: string; props: unknown; } Application Application 表示当前部署的 Serverless 应用\n一个 Application 可能包含多个 Function\nApplication 需要指定默认的部署参数，比如使用的 Provider\n1 2 3 4 5 6 7 export interface Application { provider: { name: string; props: {}; }; functions: Function[]; } 执行器会解析入口模块的 Application，并执行实际的部署\nFunction 部署过程涉及到的阶段 函数部署会涉及以下阶段\n状态查询：向集群查询部署状态，判断是否已有部署 构建：打包用户代码和依赖，执行构建，生成 Artifact 上传：将构建好的 Artifact 上传到指定的存储服务 执行部署：调用 Provider 提供的 API，创建函数资源 对于基于 Kubernetes 的 Serverless 平台，如 OpenFaas，OpenWhisk 和 Knative。函数的运行基本单位为 POD，产物为 Docker 镜像。\n对于腾讯云，阿里云等公有云厂商，产物为构建好的二进制文件，打包为 zip，并需要上传至 OSS\n","permalink":"https://WFUing.github.io/posts/tech/architecture/serverless/serverless-concept-models/","summary":"Serverless 是一种计算模型，它使得开发者能够在无需管理服务器和基础架构的情况下运行代码（或称函数）。使用无服务器计算，开发者可以将代码上传到云平台，平台会在需要时根据流量自动进行资源分配和处理。\nServerless 的特点\n按需分配 无服务器计算基于事件驱动和按需调用，只在需要时才会进行计算资源的分配和管理 弹性伸缩 无服务器计算平台会自动根据负载量的变化进行资源的动态分配和优化，无需手动干预 简化开发与部署 开发者专注于编写核心业务逻辑代码，简化应用开发以及部署流程 Concept Models Serverless 核心资源 Service\n阿里云提供服务这一抽象 服务是函数计算资源管理的单位，同一服务下的所有函数共享一些设置，如服务授权和日志配置 一个应用可拆分为多个服务，一个服务可由多个函数组成 Function\n云函数，云函数由代码和运行环境描述组成 云函数可能依赖于其他云函数，或者外部服务，如对象存储，API 网关，消息队列 Trigger\n触发器，用于在满足某些条件时，触发 Function 的执行 基于事件驱动 常见的触发器类型 定时触发器 Cron Trigger API 网关触发器 HTTP Trigger 消息队列触发器 MQ Trigger External Service\n云函数在运行过程中，可能调用外部的服务完成任务，如调用 Redis 或 RDBMS 存储状态 Function 表示 Serverless 函数\nFunction 基本信息\n包括函数的代码 URI，运行时，处理函数名称等\nFunction 资源需求\n指定函数运行时所需的计算资源，如内存，CPU 等\nFunction 触发器\n1 2 3 4 5 6 7 8 9 export interface Function { runtime: string; codeDir: string; // source code directory to bundle resource: { memory: string; cpu: string; }; triggers: {}[]; } Trigger 函数触发器，基于事件驱动机制触发函数执行","title":"Serverless Concept Models"},{"content":"元编程是编写可在其他程序上运行的计算机程序的技术。诸如编译器和程序分析器之类的系统可以被视为元程序，因为它们将其他程序作为输入。我们将在这里讨论的元编程形式特别关注生成要作为程序一部分包含的代码。从某种意义上说，它们可以被认为是初级编译器。\nMacros and Code Generation macro 是将输入序列转换为某种替换输出序列的规则。这个翻译过程称为 macro expansion，一些语言提供宏作为其规范的一部分。宏设施可以被实现为 preprocessing step，其中宏扩展发生在 lexical and syntactic analysis 之前，或者它可以被合并为 syntax analysis 或 a later translation step。\n使用最广泛的 macro systems 之一是 C 预处理器（CPP），它作为处理程序的第一步被包含在 C 和 C++ 中。预处理器指令以散列符号开头，包括 #include、#define、#if 等。例如，下面定义了一个类似函数的 macro 来交换两个项目：\n1 #define SWAP(a, b) { auto tmp = b; b = a; a = tmp; } 然后，我们可以如下使用宏：\n1 2 3 4 5 6 7 8 9 int main() { int x = 3; int y = 4; SWAP(x, y); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; } // output 4 3 通过向 g++ 传递 -E 标志，可以获得宏扩展的结果：\n1 $ g++ -E \u0026lt;source\u0026gt; 不过，如果使用 #includes 指令，结果可能会非常混乱，因为该指令会从给定文件中调入代码。\nCPP macros perform text 替换，因此上述代码等同于：\n1 2 3 4 5 6 int main() { int x = 3; int y = 4; { auto tmp = y; y = x; x = tmp; }; cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; } 使用 SWAP 宏后的分号仍然保留，表示空语句。不过，在需要使用单一语句的情况下，例如一个没有被 block 括住的条件分支，这就会造成问题：\n1 2 3 4 if (x \u0026lt; y) SWAP(x, y); else cout \u0026lt;\u0026lt; \u0026#34;no swap\u0026#34; \u0026lt;\u0026lt; endl; 避免这一问题的常用方法是将 macro 的扩展代码放在 do/while 中：\n1 2 3 4 5 #define SWAP(a, b) do { \\ auto tmp = b; \\ b = a; \\ a = tmp; \\ } while (false) 在这里，我们在一行的末尾添加了一个 \\，表示下一行应被视为上一行的继续。do/while 循环在语法上以分号结束，因此 SWAP(x, y); 中的分号在语法上是 do/while 循环的一部分。因此，扩展代码的语法是正确的：\n1 2 3 4 if (x \u0026lt; y) do { auto tmp = b; b = a; a = tmp; } while (false); else cout \u0026lt;\u0026lt; \u0026#34;no swap\u0026#34; \u0026lt;\u0026lt; endl; 虽然 textual replacement 很有用，但它也有缺点，因为虽然宏在语法上类似函数，但它们的行为却不像函数。具体来说，它们不把参数作为自己的实体，也不引入独立的作用域。请看下面的例子：\n1 2 3 4 5 6 7 8 9 10 int main() { int x = 3; int y = 4; int z = 5; SWAP(x \u0026lt; y ? x : y, z); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; endl; } // output 3 4 3 使用 g++ -E，我们可以看到预处理后的代码。只看 main() 的输出，我们会发现\n1 2 3 4 5 6 7 8 9 10 11 int main() { int x = 3; int y = 4; int z = 5; do { auto tmp = z; z = x \u0026lt; y ? x : y; x \u0026lt; y ? x : y = tmp; } while (false); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; endl; } 在这里，我们手动添加了换行符和空格，以使输出更易读；而预处理器本身会将宏输出放在一行中。罪魁祸首是最后生成的语句：\n1 x \u0026lt; y ? x : y = tmp; 在 C++ 中，条件运算符 ? : 和赋值运算符 = 具有相同的优先级，并且从右向左关联，因此这等同于\n1 x \u0026lt; y ? x : (y = tmp); 由于 x \u0026lt; y，这里没有赋值。因此，x 的值保持不变。\n我们可以在每次使用 macro argument 时加上括号来解决这个问题：\n1 2 3 4 5 #define SWAP(a, b) do { \\ auto tmp = (b); \\ (b) = (a); \\ (a) = tmp; \\ } while (false) Ranking the Operator Precedence in C\u0026#43;\u0026#43; 现在会产生预期的结果，因为括号明确地将这些操作联系起来：\n1 2 3 4 5 6 7 8 9 10 11 int main() { int x = 3; int y = 4; int z = 5; do { auto tmp = (z); (z) = (x \u0026lt; y ? x : y); (x \u0026lt; y ? x : y) = tmp; } while (false); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; z \u0026lt;\u0026lt; endl; } 然而，第二个问题并不那么容易解决。考虑一下当我们将 SWAP 宏应用于名为 tmp 的变量时会发生什么：\n1 2 3 4 5 6 7 8 9 int main() { int x = 3; int tmp = 4; SWAP(tmp, x); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; tmp \u0026lt;\u0026lt; endl; } // output 3 4 没有发生交换！再次使用 g++ -E 检查输出，我们可以看到（模数间隔）\n1 2 3 4 5 6 7 8 9 10 int main() { int x = 3; int tmp = 4; do { auto tmp = (x); (x) = (tmp); (tmp) = tmp; } while (false); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; tmp \u0026lt;\u0026lt; endl; } 由于 SWAP 使用的临时变量与参数同名，因此临时变量会捕获生成代码中出现的参数。这是因为宏只是执行文本替换，并不能确保名称被解析到适当的作用域。因此，宏实际上并不使用按名称调用，而按名称调用可确保参数中的名称解析到适当的作用域。对文本替换的依赖使 CPP 成为一个不卫生的宏系统。其他系统（如 Scheme 的系统）是卫生的，它们为宏引入的名称创建了单独的作用域，并确保参数不会被捕获。\nScheme Macros 作为 R5RS Scheme 规范的一部分，宏系统是卫生的。宏由 define-syntax、let-syntax 或 letrec-syntax 中的一种形式引入，并将给定的名称与宏绑定。例如，下面是 let 作为宏的定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 (define-syntax let (syntax-rules () ((let ((name val) ...) body1 body2 ... ) ((lambda (name ...) body1 body2 ... ) val ... ) ) ) ) syntax-rules 指定了宏转换的规则。第一个参数是规则模式与输入之间必须匹配的字面形式列表。例如，cond 形式中的 else 标识符。但在这种情况下，没有字面意义。syntax-rules 的其余参数指定了转换。转换的第一项是输入模式，第二项是输出模式。...的作用类似于克莱因星，将前一项与输入中出现的零次或多次相匹配。输入模式中出现但不在字面量列表中的名称，除了作为宏名称的第一项，都是与输入元素相匹配的卫生变量。这些变量可以在输出模式中引用，以指定如何构造输出。\n在全局环境中评估上述表达式时，会将 let 名称与一个转换为 lambda 的宏绑定。\n宏主体引入的标识符保证避免与其他标识符冲突，解释器通常会重命名标识符以避免冲突。下面是 swap 宏的定义：\n1 2 3 4 5 6 7 8 9 10 (define-syntax swap (syntax-rules () ((swap a b) (let ((tmp b)) (set! b a) (set! a tmp) ) ) ) ) 这就将 swap 的使用转化为一个表达式，通过临时变量 tmp 交换两个参数。因此\n1 2 3 4 5 6 7 \u0026gt; (define x 3) \u0026gt; (define y 4) \u0026gt; (swap x y) \u0026gt; x 4 \u0026gt; y 3 不过，与 CPP 宏不同的是，swap 宏引入的 tmp 与其他任何 tmp 都是不同的：\n1 2 3 4 5 6 \u0026gt; (define tmp 5) \u0026gt; (swap x tmp) \u0026gt; x 5 \u0026gt; tmp 4 因为宏在 Scheme 中是卫生的，所以我们会得到预期的行为。\n为了支持宏，Scheme 解释器的评估过程会像往常一样评估列表中的第一个项目。如果评估结果是一个宏，那么解释器将对列表的其余部分执行宏扩展，而不会首先评估参数。扩展引入的任何名称都与其他名称置于不同的作用域。扩展后，解释器会对扩展结果重复求值过程，因此，如果最终结果是一个 let 表达式 (如上文 swap 中的表达式)，就会对该表达式进行求值。\n一个宏定义可以指定多个模式规则。再加上扩展的结果会被求值，这使得宏定义可以递归，如下面的 let* 定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 (define-syntax let* (syntax-rules () ((let* () body1 body2 ... ) (let () body1 body2 ... ) ) ((let* ((name1 val1) (name2 val2) ...) body1 body2 ... ) (let ((name1 val1)) (let* ((name2 val2) ...) body1 body2 ... ) ) ) ) ) 当 let* 没有绑定时，有一种基本模式，在这种情况下，它直接转化为一个 let。当至少有一个绑定时，也有一个递归模式，在这种情况下，let* 会转化为一个嵌套在 let 中的更简单的 let*。宏定义中的省略号 (...) 类似于正则表达式中的 Kleene 星号 (*)，表示前一项可以匹配零次或多次。因此，具有单一绑定的 let* 与上述第二条模式规则相匹配，其中 (name2 val2) 匹配次数为零。\nCPP Macros 我们再来看看 CPP 宏。尽管宏不卫生，但在涉及元编程的任务中却非常有用。\nCPP 允许我们使用 #define 来定义两种类型的 macro，即 object-like macro 和 function-like macro。object-like macro 是一种简单的文本替换，用一个文本序列替换另一个文本序列。在历史上，定义常量是一种常用的方法：\n1 2 3 4 5 6 #define PI 3.1415926535 int main() { cout \u0026lt;\u0026lt; \u0026#34;pi = \u0026#34; \u0026lt;\u0026lt; PI \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;tau = \u0026#34; \u0026lt;\u0026lt; PI * 2 \u0026lt;\u0026lt; endl; } 在 C++ 中，更好的做法是使用 const 或 constexpr 定义常量。\nfunction-like macro 接受参数 (如上文的 SWAP)，并能将参数文本替换到替换文本中的特定位置。\n使用 function-like macro 的一个更复杂的例子是对遵循相同模式的多段代码进行抽象定义。请看表示复数的类型定义：\n1 2 3 4 5 6 7 8 struct Complex { double real; double imag; }; ostream \u0026amp;operator\u0026lt;\u0026lt;(ostream \u0026amp;os, Complex c) { return os \u0026lt;\u0026lt; \u0026#34;(\u0026#34; \u0026lt;\u0026lt; c.real \u0026lt;\u0026lt; \u0026#34;+\u0026#34; \u0026lt;\u0026lt; c.imag \u0026lt;\u0026lt; \u0026#34;i)\u0026#34;; } 假设除了上述重载的流插入操作符之外，我们还希望支持算术运算 +、- 和 *。这些运算的基本形式相同：\n1 2 3 Complex operator \u0026lt;op\u0026gt;(Complex a, Complex b) { return Complex{ \u0026lt;expression for real\u0026gt;, \u0026lt;expression for imag\u0026gt; }; } 在这里，我们使用了 uniform initialization syntax 来初始化一个含有其成员值的 Complex。然后，我们可以编写一个 function-like macro 来抽象这个结构：\n1 2 3 4 #define COMPLEX_OP(op, real_part, imag_part) \\ Complex operator op(Complex a, Complex b) { \\ return Complex{ real_part, imag_part }; \\ } 该 macro 的参数包括运算符、计算实部的表达式和计算虚部的表达式。我们可以使用下面的宏来定义运算：\n1 2 3 4 COMPLEX_OP(+, a.real+b.real, a.imag+b.imag); COMPLEX_OP(-, a.real-b.real, a.imag-b.imag); COMPLEX_OP(*, a.real*b.real - a.imag*b.imag, a.imag*b.real + a.real*b.imag); 与我们最初的 SWAP 实现一样，尾部的分号是多余的，但却提高了可读性以及与语法高亮程序的交互性。使用 g++ -E 在预处理器中运行代码，我们可以得到（修改间距）：\n1 2 3 4 5 6 7 8 9 10 Complex operator +(Complex a, Complex b) { return Complex{ a.real+b.real, a.imag+b.imag }; }; Complex operator -(Complex a, Complex b) { return Complex{ a.real-b.real, a.imag-b.imag }; }; Complex operator *(Complex a, Complex b) { return Complex{ a.real*b.real - a.imag*b.imag, a.imag*b.real + a.real*b.imag }; }; 接下来，我们可以定义 Complex 和 double 之间的运算。我们再次发现，这种操作具有特定的模式：\n1 2 3 Complex operator \u0026lt;op\u0026gt;(\u0026lt;type1\u0026gt; a, \u0026lt;type2\u0026gt; b) { return \u0026lt;expr1\u0026gt; \u0026lt;op\u0026gt; \u0026lt;expr2\u0026gt;; } 这里，\u0026lt;exprN\u0026gt; 是转换为 Complex 表示的相应参数。我们可以使用宏对其进行抽象：\n1 2 3 4 #define REAL_OP(op, typeA, typeB, argA, argB) \\ Complex operator op(typeA a, typeB b) { \\ return argA op argB; \\ } 我们还可以定义一个宏，将 double 转换为 Complex：\n1 2 #define CONVERT(a) \\ (Complex{ a, 0 }) 这样，我们就可以对操作进行如下定义：\n1 2 3 4 5 6 REAL_OP(+, Complex, double, a, CONVERT(b)); REAL_OP(+, double, Complex, CONVERT(a), b); REAL_OP(-, Complex, double, a, CONVERT(b)); REAL_OP(-, double, Complex, CONVERT(a), b); REAL_OP(*, Complex, double, a, CONVERT(b)); REAL_OP(*, double, Complex, CONVERT(a), b); 通过预处理器运行，我们可以得到\n1 2 3 4 5 6 Complex operator +(Complex a, double b) { return a + (Complex{ b, 0 }); }; Complex operator +(double a, Complex b) { return (Complex{ a, 0 }) + b; }; Complex operator -(Complex a, double b) { return a - (Complex{ b, 0 }); }; Complex operator -(double a, Complex b) { return (Complex{ a, 0 }) - b; }; Complex operator *(Complex a, double b) { return a * (Complex{ b, 0 }); }; Complex operator *(double a, Complex b) { return (Complex{ a, 0 }) * b; }; 现在我们可以如下使用复数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 int main() { Complex c1{ 3, 4 }; Complex c2{ -1, 2 }; double d = 0.5; cout \u0026lt;\u0026lt; c1 + c2 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 - c2 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 * c2 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 + d \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 - d \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; c1 * d \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; d + c1 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; d - c1 \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; d * c1 \u0026lt;\u0026lt; endl; } 1 2 3 4 5 6 7 8 9 (2+6i) (4+2i) (-11+2i) (3.5+4i) (2.5+4i) (1.5+2i) (3.5+4i) (-2.5+-4i) (1.5+2i) Stringification and Concatenation 在使用宏时，将宏参数转换为字符串或将其与其他标记连接起来可能很有用。例如，假设我们要编写一个交互式应用程序，读取用户的输入并执行相应的操作。对于复数，目标函数可能如下：\n1 2 3 4 5 6 7 8 Complex Complex_conjugate(Complex c) { return Complex{ c.real, -c.imag }; } string Complex_polar(Complex c) { return \u0026#34;(\u0026#34; + to_string(sqrt(pow(c.real, 2) + pow(c.imag, 2))) + \u0026#34;,\u0026#34; + to_string(atan(c.imag / c.real)) + \u0026#34;)\u0026#34;; } 应用程序会将用户输入与代表操作的字符串进行比较，调用相应的函数，并打印出结果。这就是常见的模式：\n1 2 if (\u0026lt;input\u0026gt; == \u0026#34;\u0026lt;action\u0026gt;\u0026#34;) cout \u0026lt;\u0026lt; Complex_\u0026lt;action\u0026gt;(\u0026lt;value\u0026gt;) \u0026lt;\u0026lt; endl; 在这里，我们既需要动作的字符串表示法，也需要将 Complex_ 标记与动作标记本身连接起来的能力。我们可以为这种模式定义如下宏：\n1 2 3 #define ACTION(str, name, arg) \\ if (str == #name) \\ cout \u0026lt;\u0026lt; Complex_ ## name(arg) \u0026lt;\u0026lt; endl 标记前的 ## 是字符串化运算符，将标记转换为字符串。Complex_ 和 name 之间的 ## 是标记粘贴操作符，用于连接两边的标记。\n这样，我们就可以编写如下应用代码：\n1 2 3 4 5 6 Complex c1 { 3, 4 }; string s; while (cin \u0026gt;\u0026gt; s) { ACTION(s, conjugate, c1); ACTION(s, polar, c1); } 通过预处理器运行这个程序，我们就能得到想要的结果：\n1 2 3 4 5 6 Complex c1 { 3, 4 }; string s; while (cin \u0026gt;\u0026gt; s) { if (s == \u0026#34;conjugate\u0026#34;) cout \u0026lt;\u0026lt; Complex_conjugate(c1) \u0026lt;\u0026lt; endl; if (s == \u0026#34;polar\u0026#34;) cout \u0026lt;\u0026lt; Complex_polar(c1) \u0026lt;\u0026lt; endl; } The Macro Namespace 使用 CPP 宏的一个缺陷是，它们不包含在任何特定的命名空间中。事实上，只要定义了宏，它就能替换任何符合条件的标识符，无论该标识符位于何处。因此，定义一个宏就相当于让一个特定的标识符充当保留关键字，程序员无法使用。这也是为什么常量通常最好定义为变量，限定为 const 或 constexpr，而不是类似对象的宏的原因之一。\n为避免污染全局命名空间，使用了几种约定。\n第一种是在所有宏的前缀加上定义宏的库所特有的字符，以避免与其他库发生冲突。例如，我们的复数宏可以用 COMPLEX_ 作为前缀，以避免与其他宏或标识符冲突。 第二种策略是在不再需要宏时，使用 #undef 预处理器指令取消对宏的定义。例如，在库代码的末尾，我们可能有如下代码： 1 2 3 4 #undef COMPLEX_OP #undef REAL_OP #undef CONVERT #undef ACTION 这样，标识符就可以在以后的代码中用于其他目的。\nCode Generation 虽然 macros 允许我们使用一种语言提供的宏设施生成代码，但在某些情况下，这种设施无法使用或不足以满足我们的目的。在这种情况下，在外部程序中用同一种语言或另一种语言编写代码生成器可能会比较方便。这种技术也称为 automatic programming。\n例如，R5RS Scheme 规范要求实现提供 car 和 cdr 的组合，最深可达四层。例如，(caar x) 应等同于 (car (car x))，(caddar x) 应等同于 (car (cdr (cdr (car x))))。除了 car 和 cdr 本身外，还需要提供 28 种组合，手工编写既繁琐又容易出错。相反，我们可以定义下面的 Python 脚本来生成一个 Scheme 库文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 import itertools def cadrify(seq): if len(seq): return \u0026#39;(c{0}r {1})\u0026#39;.format(seq[0], cadrify(seq[1:])) return \u0026#39;x\u0026#39; def defun(seq): return \u0026#39;(define (c{0}r x) {1})\u0026#39;.format(\u0026#39;\u0026#39;.join(seq), cadrify(seq)) for i in range(2, 5): for seq in itertools.product((\u0026#39;a\u0026#39;, \u0026#39;d\u0026#39;), repeat=i): print(defun(seq)) cadrify() 函数是一个递归函数，它接收一个序列，如 ('a','d','a')，并使用第一个项目和序列其余部分的递归结果构造一个调用。在本例中，后者是 (cdr (car x))，因此结果是 (car (cdr (car x)))。基本情况是序列为空，只产生 x。\ndefun() 函数接收一个序列，并用它为相应的组合构建定义。它调用 cadrify() 构建正文。对于序列 ('a','d','a')，结果是\n1 (define (cadar x) (car (cdr (car x)))) 最后，循环结束时会产生每个长度的 a 和 d 的所有组合。它使用函数库中的 itertools.product() 函数来获得一个序列，该序列是元组 ('a','d') 的第 i 次幂。对于每个组合，它都会调用 defun() 生成该组合的函数。\n1 2 3 4 5 6 7 8 9 (define (caar x) (car (car x))) (define (cadr x) (car (cdr x))) (define (cdar x) (cdr (car x))) (define (cddr x) (cdr (cdr x))) (define (caaar x) (car (car (car x)))) (define (caadr x) (car (car (cdr x)))) ... (define (cdddar x) (cdr (cdr (cdr (car x))))) (define (cddddr x) (cdr (cdr (cdr (cdr x))))) 我们可以将生成的代码放入标准库中，由 Scheme 解释器加载。\nTemplate Metaprogramming Template metaprogramming 是一种在编译时使用模板生成源代码的技术，然后将源代码与程序的其他代码一起编译。它通常是指利用语言的模板实例化规则进行编译时执行的一种形式。Template metaprogramming 在 C++ 中最为常见，但也有少数其他语言可以使用。\nC++ 中模板元编程的关键是 template specialization，它允许编写专门的定义来实例化带有特定参数的模板。例如，考虑一个包含静态值域的类模板，如果模板参数为 int，该值域为 true，否则为 false。我们可以如下编写通用模板：\n1 2 3 4 template \u0026lt;class T\u0026gt; struct is_int { static const bool value = false; }; 现在我们可以定义当参数为 int 时该模板的特殊化：\n1 2 3 4 template \u0026lt;\u0026gt; struct is_int\u0026lt;int\u0026gt; { static const bool value = true; }; 特化中的模板参数列表包含非特化参数。在上面的例子中，没有任何参数，所以是空的。然后，在模板名称之后，我们提供了实例化的全部参数集，在本例中只有 int。然后，我们提供实例化的其余定义。\n现在，当我们使用模板时，如果模板参数与特化兼容，编译器就会使用特化，否则就会使用通用模板：\n1 2 3 4 5 cout \u0026lt;\u0026lt; is_int\u0026lt;double\u0026gt;::value \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; is_int\u0026lt;int\u0026gt;::value \u0026lt;\u0026lt; endl; // output 0 1 模板特化使我们能够编写以模板参数为条件的代码。与递归实例化相结合，这使得模板实例化具有图灵完备性。模板不对可变变量进行编码，因此模板元编程实际上是函数式编程的一种形式。\nPairs RESOURCES https://eecs390.github.io/notes/metaprogramming.html http://philo.top/2021/03/14/metaprogramming/ ","permalink":"https://WFUing.github.io/posts/tech/language/metaprogramming/","summary":"元编程是编写可在其他程序上运行的计算机程序的技术。诸如编译器和程序分析器之类的系统可以被视为元程序，因为它们将其他程序作为输入。我们将在这里讨论的元编程形式特别关注生成要作为程序一部分包含的代码。从某种意义上说，它们可以被认为是初级编译器。\nMacros and Code Generation macro 是将输入序列转换为某种替换输出序列的规则。这个翻译过程称为 macro expansion，一些语言提供宏作为其规范的一部分。宏设施可以被实现为 preprocessing step，其中宏扩展发生在 lexical and syntactic analysis 之前，或者它可以被合并为 syntax analysis 或 a later translation step。\n使用最广泛的 macro systems 之一是 C 预处理器（CPP），它作为处理程序的第一步被包含在 C 和 C++ 中。预处理器指令以散列符号开头，包括 #include、#define、#if 等。例如，下面定义了一个类似函数的 macro 来交换两个项目：\n1 #define SWAP(a, b) { auto tmp = b; b = a; a = tmp; } 然后，我们可以如下使用宏：\n1 2 3 4 5 6 7 8 9 int main() { int x = 3; int y = 4; SWAP(x, y); cout \u0026lt;\u0026lt; x \u0026lt;\u0026lt; \u0026#34; \u0026#34; \u0026lt;\u0026lt; y \u0026lt;\u0026lt; endl; } // output 4 3 通过向 g++ 传递 -E 标志，可以获得宏扩展的结果：","title":"meta-programming"},{"content":"Introduction 有限状态机 (finite-state machine, FSM) 是一种抽象机器，在任何给定时间内都可以处于有限个状态中的一个状态。FSM 可以根据某些外部输入从一种状态转换到另一种状态，从一种状态转换到另一种状态称为转换。FSM 是由其状态列表、初始状态和每个转换的条件定义的。\n状态是对等待执行转换的系统状态的描述。\nExample 下面是一个简单状态机的直观描述。 这是一个简单的开关模型。\nA simple on/off switch with two states 它由 \u0026ldquo;开 \u0026ldquo;和 \u0026ldquo;关 \u0026ldquo;两种状态组成。因此，这台机器在任何时刻都可以处于这两种状态中的一种。换句话说，状态之间的转换是瞬时的。flick 事件会导致机器在不同状态间转换。 当机器进入 on 状态时，会产生一个副作用。一盏灯被打开。 当机器退出 on 状态时，会产生另一个副作用。一盏灯被关闭。 这个简单的状态机就相当于一个布尔变量，来控制某件事情的 on 与 off。 What is state anyway? 程序状态是程序中所有变量及其在任意时间点上的值的集合 Wikipedia 。\n一个程序或软件组件有五个独立变量，每个变量都可能为真或假，那么理论上它可以处于 $2^5=32$ 种状态中的任何一种。然而，程序经常会出现 invalid 状态，而在传统软件中，变量都会经过仔细检查和处理，以避免出现这些 invalid 状态。\nRelationship with statecharts 理解状态机几乎等同于理解 statecharts。 在许多方面，statecharts是状态机的 \u0026ldquo;大哥\u0026rdquo;，旨在克服状态机的一些局限性。statecharts 本质上是一种状态机，它允许任何状态以分层的方式包含更多的状态机。这是为了克服状态机固有的一些局限性。\nAbstract machine vs run-time 抽象机器本身（如状态机的绘制或代码）与特定抽象机器更具体的运行时执行之间必须作出重要区分。这种区别类似于类（抽象定义）和对象（具体实例化）之间的区别。同样，对于单个抽象机器来说，可能有许多执行，就像任何特定类往往有许多实例一样。\n术语 \u0026ldquo;statechart\u0026rdquo;、\u0026ldquo;state machine \u0026ldquo;和 \u0026ldquo;FSM \u0026ldquo;通常既指抽象形式，也指运行时形式，尽管运行时形式有时带有限定词 \u0026ldquo;run\u0026rdquo; 或 \u0026ldquo;execution\u0026rdquo;，如 \u0026ldquo;state machine execution\u0026rdquo; 或 \u0026ldquo;statetchart run\u0026rdquo;。\nabstract state machine 是一种软件组件，它定义了一组有限的状态：\n有一种状态被定义为 initial state。当机器开始执行时，它会自动进入这种状态。 每个状态都可以定义机器进入或退出该状态时发生的操作。操作通常会产生 side effects。 每个状态都能定义触发转换的 transition。 transition 定义了机器如何对事件做出反应，即退出一种状态并进入另一种状态。 transition 可以定义过渡发生时的 actions。动作通常会产生 side effects。 在运行状态机时，会执行这个抽象状态机。首先，状态机进入initial state。 然后，一旦有事件发生，就会立即传递给状态机。 当事件发生时\n将根据当前状态的转换对事件进行检查 如果某个转场与事件相匹配，该转场就会发生 由于 transition 发生，状态 exited 或 entered，并执行相关操作 机器立即进入新状态，准备处理下一个事件。 Resources Wikipedia defines a finite-state machine statecharts ","permalink":"https://WFUing.github.io/posts/tech/architecture/distributed/iot/state-machine/","summary":"有限状态机 (finite-state machine, FSM) 是一种抽象机器，在任何给定时间内都可以处于有限个状态中的一个状态。FSM 可以根据某些外部输入从一种状态转换到另一种状态，从一种状态转换到另一种状态称为转换。","title":"State Machine"},{"content":"简介 ANTLR 是 ANother Tool for Language Recognition 的缩写，是一个功能强大的解析器生成器框架，用于从语法文件中构建语言识别器、编译器和翻译器，语法文件中包含从源语言到目标语言的每个语句所要执行的操作。\n使用编译器设计的概念来定义每种现代编程语言的写作风格。这是一套典型的步骤，首先是 Lexical, Syntactical 和 Semantic Analysis，确定语言的基本编写方式，以便识别。接下来是一系列非常有趣的步骤：中间代码生成、优化和目标代码生成。\n目前的版本为 4.7，它提供了一种方便的、对开发人员友好的方式来定义自己的规则集（又称语法），它由一系列标记和操作组成，这些标记和操作定义了语句在源语言中的书写方式，从而可以正确识别和解析语句。更有趣的是，它还能让用户对代码进行操作，并将其生成目标代码，所有这一切都可以用您选择的语言来实现。\n那么，谁在使用 ANTLR 呢？\n编程语言：Boo、Groovy、Mantra、Nemerle、XRuby 等。 其他工具、框架：Apache Spark、Hibernate、Intellij IDEA、Jazillian、JBoss Rules、Keynote(Apple)、WebLogic（Oracle）等。 The Basics 1 2 def sum(a, b): return a + b 考虑到上面 Python 的例子，这些编译器设计步骤从识别 Python 中编写的每条语句（源代码）的基本单元开始，并将其分解为 a stream of tokens，每个标记都被识别或映射为特定类型，也就是 Lexical Analysis。\nLexical Analysis of the python function yielding a stream of tokens 然后，根据这些标记出现的顺序来确定书面语句的上下文，并通过语义分析构建一棵树（或 Abstract Syntax Tree）来检查其正确性，同时提供使用现有树遍历方法之一进行遍历的能力。\nSyntax tree after Semantic analysis TLDR 概念 Lexer : converts a stream of characters to a stream of tokens. Parser : processes of tokens, possibly creating AST. Abstract Syntax Tree(AST): an intermediate tree representation of the parsed input that is simpler to process than the stream of tokens. Tree Parser: It processes an AST. String Template: a library that supports using templates with placeholders for outputting text (something very specific to ANTLR). ANTLR 是一种 LL parser（Left-to-right, Leftmost derivation），是一种自顶向下的剖析器，适用于无上下文语言的子集。它从左到右解析输入，对句子进行 Leftmost derivation。它简化了许多步骤，使创建语言识别器和解析器变得更容易、更方便。\nSyntax tree after Semantic analysis Example1 下面是我为解析 python 函数而编写的解析器的一个快速示例。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 grammar PythonParserExample; tokens { INDENT, DEDENT, LINE_BREAK } statement : (single_input)? EOF ; single_input : LINE_BREAK | simple_stmt | complex_stmt (LINE_BREAK)? EOF ; complex_stmt: funcdef; simple_stmt : small_stmt (SEMI_COLON small_stmt)* SEMI_COLON? (LINE_BREAK)? EOF ; stmt : simple_stmt | complex_stmt ; funcdef : ASYNC? DEF name OPEN_PAREN typedargslist? CLOSE_PAREN (ARROW name)? COLON \u0026#39;\\n\u0026#39;? funcbody ; typedargslist : (def_parameters COMMA)? (args (COMMA def_parameters)? ) COMMA? | def_parameters COMMA? ; funcbody : simple_stmt | LINE_BREAK INDENT stmt+ DEDENT ; args : STAR name ; def_parameters : def_parameter (COMMA def_parameter)* ; small_stmt : RETURN expression #return_stmt ; def_parameter : name | STAR ; expression: name op=OPERATOR name ; name: NAME; DEF : D E F; SEMI_COLON : \u0026#39;;\u0026#39;; STAR : \u0026#39;*\u0026#39;; OPERATOR : STAR|\u0026#39;+\u0026#39;|\u0026#39;/\u0026#39;|\u0026#39;**\u0026#39;|\u0026#39;-\u0026#39;; RETURN : R E T U R N; ASYNC : A S Y N C; COMMA : \u0026#39;,\u0026#39;; OPEN_PAREN : \u0026#39;(\u0026#39;; CLOSE_PAREN : \u0026#39;)\u0026#39;; ARROW : \u0026#39;-\u0026gt;\u0026#39;; COLON : \u0026#39;:\u0026#39;; NAME : ID_START ID_CONTINUE*; WS : [ \\t]+ {HandleSpaces();} -\u0026gt; channel(HIDDEN); 它的一个主要优点是，用户可以使用相同的 syntax 进行 lexing 和 parsing。然而，在语法层面上，这里的区别在于命名约定:\n以大写字母开头的规则是 lexer rules 其他的都是 parse rules ANTLR plugin (on Intellij IDEA) output for the above python function parsing 一旦定义完毕，complete ANLTR jar 文件就会提供一个选项，将其生成一组文件，并使用您喜欢的编程语言代码，也就是一个 parser。\n1 java -Xmx500M -cp \u0026lt;path to ANTLR complete JAR\u0026gt; org.antlr.v4.Tool -Dlanguage=\u0026lt;target_language\u0026gt; PythonParserExample.g4 由于我使用 Python3 作为生成解析器的目标，ANTLR 的配置会生成 3 个 python 文件，这些文件可以作为代码翻译过程的一部分，用于将一种语言的源代码转换为另一种语言。\nANTLR plugin (on Intellij IDEA) output for the above python function parsing Setting up an ANTLR Project ANTLR plugin for VSCode 这里使用的设置将是在 VSCode 上创建的 Java-Maven 项目。\nANTLR plugin for VSCode 提供了各种选项（甚至比 Intellij 还多）来调试语法文件，并创建了美观的 parse trees，以便轻松调试用户输入语句的特定配置。\nANTLR plugin (on Intellij IDEA) output for the above python function parsing 要生成这些可视化效果，需要使用 vscode 的 ANTLR 启动配置在调试模式下运行语法文件，并为语法指定输入文件。下面是 VS Code 上 ANTLR 的 launch.json 配置文件：\n1 2 3 4 5 6 7 8 9 10 { \u0026#34;name\u0026#34;: \u0026#34;Debug ANTLR4 grammar\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;antlr-debug\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;input\u0026#34;: \u0026#34;input.txt\u0026#34;, \u0026#34;grammar\u0026#34;: \u0026#34;BooleanExprParser.g4\u0026#34;, \u0026#34;startRule\u0026#34;: \u0026#34;parse\u0026#34;, \u0026#34;printParseTree\u0026#34;: true, \u0026#34;visualParseTree\u0026#34;: true } Grammar 让我们先为解析器创建一个基本语法或 BooleanExpr.g4 文件。\n1 2 3 4 grammar BooleanExpr; @header { package antlrsource; } 请注意 parser file 是如何以 grammar BooleanExpr; 开始的。这可以通过将 Lexer tokens (大写字母表示) 和 parser tokens (所有其他标记) 保存在两个不同的文件中来分解：\n1 2 3 4 lexer grammar BooleanExprLexer; @header { package antlrsource; } 1 2 3 4 parser grammar BooleanExprParser; @header { package antlrsource; } 一个用于 parser，另一个用于 lexer，这样更便于维护。接下来，我们先定义一个头文件和软件包名称，放在生成的解析器类的开头。这将允许我们指定一个包，以便在 Java 代码中导入。\n从 Lexer 开始，我们将 IDENTIFIER 定义为 lexer rule，并提供与之匹配的描述：\n1 2 3 IDENTIFIER : [a-zA-Z_] [a-zA-Z_0-9]* ; Lexer rules 总是以大写字母开头。这些规则是 parser 的基本构件，重点是构建 parser rules 的基础。对正则表达式稍有接触的人来说，这应该有点熟悉。\n这里，A-Z 表示 A 和 Z 之间的字母，而 a-z 表示 a 和 z 之间的字母。同样，0-9 表示数字 0 和 9 之间的数字。由于规则可能包含也可能不包含这些字母的多次出现，因此可以用 (*/+) 运算符作为后缀，表示这些字母出现的频率。这里，* 表示可能完全不出现（0 次或更多次）。这意味着，我们的 IDENTIFIER 规则将匹配大写字母、小写字母（总是以大写/小写字母开头）和整数字符的任意组合，但不匹配空字符。\n一般来说，所有空白都会被词法识别器标记化。因此，您必须在解析器规则中定义空格以及所有可能使用空格的地方。不过，由于我们的源布尔表达式在某些地方不需要对空格敏感，因此我们可以编写一条词法规则来处理这个问题。\n1 WS: [ \\r\\t\\u000C\\n]+ -\u0026gt; skip; 请注意留白标记的定义是如何编写的，以识别一个或多个空格、制表符和换行符，并让 ANTLR 跳过它们。箭头（-\u0026gt;）运算符定义了遇到标记时要执行的操作（本例中为跳过操作）。接下来是为布尔表达式定义标记，其中包括多个运算符和操作数。这包括以下标记：\n1 2 3 4 5 6 7 8 9 10 11 12 13 AND: A N D; OR: O R; NOT: N O T; TRUE: \u0026#39;True\u0026#39;; FALSE: \u0026#39;False\u0026#39;; GT: G T {setText(\u0026#34; \u0026gt; \u0026#34;);}; GE: G E {setText(\u0026#34; \u0026gt;= \u0026#34;);}; LT: L T {setText(\u0026#34; \u0026lt; \u0026#34;);}; LE: L E {setText(\u0026#34; \u0026lt;= \u0026#34;);}; EQ: E Q {setText(\u0026#34; == \u0026#34;);}; LPARENTHESIS: \u0026#39;(\u0026#39;; RPARENTHESIS: \u0026#39;)\u0026#39;; DECIMAL_NUMBER: \u0026#39;-\u0026#39;? [0-9]+ ( \u0026#39;.\u0026#39; [0-9]+)?; Embedding Actions 规则 GT、GE、LT、LE 和 EQ 包含代码块，允许它们在遇到各自的标记时执行某些动作。这样就可以在语法文件中定义某些动作，但需要注意的是，只能定义简单的小动作，而不能定义复杂的代码块。\n如果我们不希望产生构建解析树的开销，我们可以在解析过程中即时计算值或打印内容。另一方面，这意味着要在表达式语法中嵌入任意代码，这就比较困难；我们必须了解这些操作对解析器的影响，以及这些操作的位置。 The Definitive ANTLR 4 Reference\n请注意，每条规则都由用空格隔开的字母组成。这些被称为 fragments。它们的主要目的是减少每个标记的杂乱定义，这基本上需要处理对大小写敏感的用例。这样，用户就不必为识别同一个 token 而写下所有可能的文本组合。其定义如下\n1 2 3 4 fragment A : [aA]; // match either an \u0026#39;a\u0026#39; or \u0026#39;A\u0026#39; fragment B : [bB]; ... fragment Z : [zZ]; 虽然大多数字母数字令牌都可以通过使用片段来创建，但其他令牌则可以通过自定义正则表达式定义或使用引号括起来的纯字符串（如 LPARENTHESIS 和 DECIMAL_NUMBER）来创建。\n而 parser rules（所有其他规则）则以小写字母开头。这些规则的主要目的是在 DSL 中定义布尔表达式的上下文，并帮助从生成的词法标记中构建解析树或抽象语法树。\nBasic Building Blocks 让我们开始定义规则。首先，我们定义根节点（或通常所说的解析节点），它本身只能指向一条规则（此处为 basicBooleanExpression）。首先是一个返回语句，其中包含它应该返回的变量（可选，但在我们的例子中是必需的）及其返回类型。\n这条规则指向另一条名为 basicBooleanExpression 的规则，该规则后跟有 EOF（或文件结束）字符。不包含该字符实质上意味着您正试图解析整个输入内容，而只解析部分输入内容是可以接受的，这将避免任何语法错误。\n1 2 3 4 parse returns[String str] @init {$str=\u0026#34;\u0026#34;;}: basicBooleanExpression {$str=$basicBooleanExpression.str;} EOF; 使用 EOF character 的原因是，如果在解析 basicbooleanExpression 规则时出现语法错误，那么解析规则将尝试恢复语法错误并报告收集到的语法错误，然后继续解析，因为 EOF 是完成规则所必需的，而且解析器尚未到达 EOF。\n由于我们已经定义了语法并将其分成了两个独立的文件，因此我们可以选择在解析器文件中将词法作为定义规则的词汇:\n1 2 3 options { tokenVocab = BooleanExprLexer; } 回到我们的解析器，\n第一条规则或 basicBooleanExpresion 规则定义了三个选项，在我们的 python 目标代码评估中应始终返回一个布尔值。第一种是后两种规则的组合，即两个布尔表达式与一个逻辑和/或运算符的组合； 第二种是另一种三元表达式，即使用比较器（如、小于或 LT）比较两个基本表达式彼此返回的某个值； 最后，第三种是单元表达式（只有一个布尔值，如 True 或 False）。 这些规则由运算符 | 分隔。这意味着，basicBooleanExpression 在识别输入字符串时，可以根据从左到右的文本识别，递归地引用其子规则中的任一规则。\n1 2 3 4 5 basicBooleanExpression returns[String str]: left = basicBooleanExpression op = logicalOperator right = basicBooleanExpression {$str=$left.str +\u0026#34; \u0026#34;+$op.text+\u0026#34; \u0026#34;+$right.str;} # logicalExpression | left = expression op = comparator right = expression {$str=\u0026#34;(\u0026#34;+$left.text +\u0026#34; \u0026#34;+$op.text+\u0026#34; \u0026#34;+$right.text+\u0026#34;)\u0026#34;;} # comparisonExpression | bool {$str=$bool.str;} # booleanExpression; basicBooleanExpression 中的每条规则都分配给一个变量名，如 left、right（表达式中的左右操作数）和 op（操作数的缩写），或者是一条单标记规则。$str 变量用于分配当前表达式解析的结果，并使用规则开头的 [String str] 返回值返回。\n# 用于标记每条规则，使其在目标语言解析器（在我们的例子中是 Java 解析器类）中有专门的监听器方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 lexer grammar BooleanExprLexer; @header { package antlrsource; } AND: A N D; OR: O R; NOT: N O T; TRUE: \u0026#39;True\u0026#39;; FALSE: \u0026#39;False\u0026#39;; GT: G T {setText(\u0026#34; \u0026gt; \u0026#34;);}; GE: G E {setText(\u0026#34; \u0026gt;= \u0026#34;);}; LT: L T {setText(\u0026#34; \u0026lt; \u0026#34;);}; LE: L E {setText(\u0026#34; \u0026lt;= \u0026#34;);}; EQ: E Q {setText(\u0026#34; == \u0026#34;);}; LPARENTHESIS: \u0026#39;(\u0026#39;; RPARENTHESIS: \u0026#39;)\u0026#39;; DECIMAL_NUMBER: \u0026#39;-\u0026#39;? [0-9]+ ( \u0026#39;.\u0026#39; [0-9]+)?; IDENTIFIER: [a-zA-Z_] [a-zA-Z_0-9]*; WS: [ \\r\\t\\u000C\\n]+ -\u0026gt; skip; fragment A : [aA]; // match either an \u0026#39;a\u0026#39; or \u0026#39;A\u0026#39; fragment B : [bB]; fragment C : [cC]; fragment D : [dD]; fragment E : [eE]; fragment F : [fF]; fragment G : [gG]; fragment H : [hH]; fragment I : [iI]; fragment J : [jJ]; fragment K : [kK]; fragment L : [lL]; fragment M : [mM]; fragment N : [nN]; fragment O : [oO]; fragment P : [pP]; fragment Q : [qQ]; fragment R : [rR]; fragment S : [sS]; fragment T : [tT]; fragment U : [uU]; fragment V : [vV]; fragment W : [wW]; fragment X : [xX]; fragment Y : [yY]; fragment Z : [zZ]; BooleanExprLexer.g4\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 parser grammar BooleanExprParser; @header { package antlrsource; } options { tokenVocab = BooleanExprLexer; } parse returns[String str] @init {$str=\u0026#34;\u0026#34;;}: basicBooleanExpression {$str=$basicBooleanExpression.str;} EOF; basicBooleanExpression returns[String str]: left = basicBooleanExpression op = logicalOperator right = basicBooleanExpression\t{$str=$left.str +\u0026#34; \u0026#34;+$op.text+\u0026#34; \u0026#34;+$right.str;} # logicalExpression | left = expression op = comparator right = expression {$str=\u0026#34;(\u0026#34;+$left.text +\u0026#34; \u0026#34;+$op.text+\u0026#34; \u0026#34;+$right.text+\u0026#34;)\u0026#34;;}\t# comparisonExpression | bool\t{$str=$bool.str;}\t# booleanExpression; expression returns[String str]: LPARENTHESIS expression RPARENTHESIS\t# parenthesisExpression | NOT expression\t# notExpression | bool\t# unaryboolExpression | IDENTIFIER\t# identifierExpression | DECIMAL_NUMBER\t# decimalExpression ; comparator returns[String str]: GT | GE | LT | LE | EQ; logicalOperator returns[String str]: AND | OR; bool returns[String str]: TRUE | FALSE; BooleanExprParser.g4\n1 2 a gt b and c gt d a eq b input demo\nMaven Configuration 现在，让我们继续生成解析器文件。这次，我将使用 maven 配置和 VS Code 的 ANTLR 插件来生成这些文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.antlr\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;antlr4-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.8-1\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;antlr\u0026lt;/id\u0026gt; \u0026lt;phase\u0026gt;package\u0026lt;/phase\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;libDirectory\u0026gt;${basedir}/src/main/antlr\u0026lt;/libDirectory\u0026gt; \u0026lt;sourceDirectory\u0026gt;${basedir}/src/main/antlr\u0026lt;/sourceDirectory\u0026gt;\u0026lt;outputDirectory\u0026gt;${basedir}/src/main/java/antlrsource\u0026lt;/outputDirectory\u0026gt; \u0026lt;visitor\u0026gt;false\u0026lt;/visitor\u0026gt; \u0026lt;listener\u0026gt;true\u0026lt;/listener\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;antlr4\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 每个标签都定义了 ANTLR 在生成解析器类时应使用的目录或需要或不需要生成的文件。例如，监听器和访问者标签的定义都是为了根据它们的布尔值生成相应的 java classes/interfaces。\nThe set of target language parser files Traversal Patterns 让我们深入了解 Listener vs Visitor traversal patterns ，并探索 BooleanExprParserBaseListener class 的功能。\nANTLR4 提供了两种遍历语法树的方法：\nListener(default)：listener pattern 是一种事件驱动方法，用于遍历每个解析器规则类型的语法树。为每个解析器规则提供一个包含进入和退出事件方法的接口。 Visitor：这使得用户也可以控制解析树的遍历。解析树中的节点（解析器规则）将使用提供的访问方法明确遍历或访问。 根据使用环境的不同，Listener 和 Visitor 模式各有利弊。\n相同点\n两种实现方式的规则语法规则完全相同。 两种实现方式的解析器输出也完全相同。 不同点\n由于 Listener pattern 依赖于用户来定义其遍历序列，因此它使用调用堆栈来管理这些遍历，这意味着大量输入可能会导致溢出，而在已分配堆上使用堆栈的监听器则不会出现这种问题。 Listener pattern 和 Visitor pattern 的最大区别在于，监听器方法是由 ANTLR 提供的行走器对象独立调用的，而访问者方法必须通过显式访问调用来行走其子节点。如果忘记在节点的子节点上调用访问者方法，就意味着这些子树不会被访问。\n跳回到我们生成的 Listener\nListener Implementation Listener Interface 接口类的实现只针对某些语言，一般来说，implementing class/module 是在目标语言中定义的。请注意，interface 和 implementation 中都定义了根（或解析）节点监听器方法。所有方法都有相应的上下文对象，该对象由生成的解析器类提供。这样就可以在遍历解析树时对该规则的上下文进行操作。\n让我们创建与解析器的第一次 interaction ，并生成一个简单表达式的输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // Creates a lexer for the input string to generate the tokens BooleanExprLexer lexer = new BooleanExprLexer(CharStreams.fromString(\u0026#34;a eq b\u0026#34;)); // Stores the tokens generated by the lexer for the input string CommonTokenStream tokens = new CommonTokenStream(lexer); /** Creates a parser for generation of an Abstract Syntax tree from the stream of tokens to identify context */ BooleanExprParser parser = new BooleanExprParser(tokens); /** Creates a parse tree for generating the output string and manipulation of the parser and lexer tokens in the parse tree. The tree is create considering the parse rule in the grammar as the root node. This tree will be used later for listener. */ ParseTree tree = parser.parse(); /** Convert the root node\u0026#39;s output to it\u0026#39;s rule context and use its attribute for printing the parser\u0026#39;s output string. */ ParseContext context = (ParseContext) tree; System.out.println(context.str); 由于我们已经在语法文件中添加了将基本运算符转换为 python 对应运算符的操作，因此解析器的输出表达式已经是解析形式。例如，一个简单的比较表达式，如 a eq b，将转换为 python 表达式 a == b 。\n现在，我们已经转换了表达式，可以使用监听器文件中的某些更改将其转换为函数，并使用 template 将该表达式替换为 placeholder function text，用于多个类似表达式：\n1 2 def \u0026lt;function_name\u0026gt;(\u0026lt;list_of_parameters\u0026gt;): return a == b parsed expression 可以很容易地替换成上面的表达式。不用担心替换部分，我们稍后会讲到。现在，为了从每个表达式中提取参数列表，我们将添加一个列表，以便在每次触发标识符类型（解析器规则）的输入事件监听器方法时捕获每个标识符名称。\n让我们定义一个字符串列表作为实例变量，在无参数构造函数中对其进行初始化，定义其 getter 方法，并添加一个方法来清除该列表，以便每次表达式解析和替换完成后都能清除该列表。\n1 2 3 4 5 6 public class BooleanExprParserBaseListener implements BooleanExprParserListener { private List\u0026lt;String\u0026gt; identifiersList; public BooleanExprParserBaseListener(){ identifiersList= new ArrayList\u0026lt;\u0026gt;(); } ... 让我们把上下文 getText 方法中的标识符名称添加到我们为 identifierExpression 每次触发输入事件时创建的列表中：\n1 2 3 4 5 6 7 8 9 public void clearIdentifiers() { identifiersList.clear(); } public List\u0026lt;String\u0026gt; getIdentifiersList() { return identifiersList; } @Override public void enterIdentifierExpression(BooleanExprParser.IdentifierExpressionContext ctx) { identifiersList.add(ctx.getText()); } 最后，我们需要在树上遍历，以触发这些事件，从而收集表达式的所有参数。ANTLR 为此提供了 ParseTreeWalker 类。顾名思义，该类允许在走过解析树时同时使用监听器和访问者实现类。让我们使用监听器来遍历上面定义的解析树：\n1 2 3 4 5 BooleanExprParserBaseListener booleanExprBaseListener = new BooleanExprParserBaseListener(); ParseTreeWalker walker = new ParseTreeWalker(); walker.walk(booleanExprBaseListener, tree); List\u0026lt;String\u0026gt; identifiers = booleanExprBaseListener.getIdentifiersList(); booleanExprBaseListener.clearIdentifiers(); 请注意，这里的 walk 方法使用 listener 来监听在解析树上行走时触发的事件。接下来，我们使用 getter 方法获取解析表达式时获取的所有标识符名称列表。\nGenerate Code A gist of what the process looks like so far 将使用上一部分 generated expression 或 the output of intermediate code generation，并将其替换为模板组文件(templating engine 使用的东西)，这样我们就可以将渲染的函数串写入 python 文件。\ntemplating engine 将以我们的目标语言（即 Python）生成实际可用的代码，从而实现代码生成的目标。\n提到 templating engine ，你首先想到的就是 web frameworks。几乎所有的现代 web frameworks 都有一个共同的目标，那就是使用模板引擎生成动态的、业务就绪的网页。每个模板引擎的最终目标都是将获取的输出结果替换为模板文件，以便即时显示给最终用户。\ntemplating engines compared side-by-side\nStringTemplate 我将使用一个名为 StringTemplate 的类似模板引擎。它被广泛用于网页模板化，但也支持用于创建目标语言代码文件的基本模板操作。\n\u0026lt;attribute\u0026gt; 如果存在，则求值为属性的字符串值，否则为空字符串。 例如，在使用 Java 中的 StringTemplate 对象时，\u0026lt;expression\u0026gt; 将以 key expression 表示。因此，如果用户在 expression 键上输入任何值，它就会在模板中被称为 expression 属性。 对于模板内的自定义或用户定义对象，请使用 \u0026lt;attribute.property\u0026gt; ，将属性作为属性查找，然后使用 getProperty() 或 isProperty() 或 hasProperty() 等访问器方法。 \u0026lt;attribute:t1(argument-list)：... :tN(argument-list)\u0026gt; 迭代同一个模板替换的对象列表。从左到右依次应用多个模板。在多值属性上应用模板的结果是另一个多值属性。整个表达式的求值结果是所有模板元素的连接结果 \u0026lt;! comment !\u0026gt; StringTemplate 会忽略已定义的注释。 模板定义看起来就像带有未键入参数的函数定义： templateName(arg1, arg2, ..., argN) ::= \u0026quot;single-line template\u0026quot; templateName(arg1, arg2, ..., argN) ::= \u0026lt;\u0026lt;multi-line template\u0026gt;\u0026gt; templateName(arg1, arg2, ..., argN) ::= \u0026lt;%multi-line template that ignores indentation and newlines%\u0026gt; 下面我们来看看 Python StringTemplateExample.stg 文件的示例：\n1 2 3 4 5 6 7 \u0026lt;! StringTemplateExample.stg !\u0026gt; templateExample(functions) ::= \u0026lt;\u0026lt; \u0026lt;functions :{function | def \u0026lt;function.function_name\u0026gt;(\u0026lt;function.params_list\u0026gt;) return \u0026lt;function.expression\u0026gt; }\u0026gt; \u0026gt;\u0026gt; 请注意，为了保持缩进和两行间隙，我使用了上面基础示例中的第二种模板类型，因为这需要遵循 Python PEP8 的规则，即在 Python 方法之间有两行间隙。下面我们来看看该模板在 Java 中的用法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 List\u0026lt;String\u0026gt; lines = reader.lines().collect(Collectors.toList()); String functionName = \u0026#34;generated_function_%1$s\u0026#34;; List\u0026lt;Map\u0026gt; functions = new ArrayList\u0026lt;\u0026gt;(); Map \u0026lt;String,String\u0026gt; function; for (int i = 0; i \u0026lt; lines.size(); i++) { BooleanExprLexer lexer = new BooleanExprLexer(CharStreams.fromString(lines.get(i))); CommonTokenStream tokens = new CommonTokenStream(lexer); BooleanExprParser parser = new BooleanExprParser(tokens); ParseTree tree = parser.parse(); ParseContext context = (ParseContext) tree; System.out.println(context.str); BooleanExprParserBaseListener booleanExprBaseListener = new BooleanExprParserBaseListener(); ParseTreeWalker walker = new ParseTreeWalker(); walker.walk(booleanExprBaseListener, tree); List\u0026lt;String\u0026gt; identifiers = booleanExprBaseListener.getIdentifiersList(); function = new HashMap\u0026lt;\u0026gt;(); function.put(\u0026#34;function_name\u0026#34;, String.format(functionName, i)); function.put(\u0026#34;expression\u0026#34;, context.str); function.put(\u0026#34;params_list\u0026#34;, identifiers.stream().collect(Collectors.joining(\u0026#34;, \u0026#34;))); functions.add(function); booleanExprBaseListener.clearIdentifiers(); } stringTemplateExample.add(\u0026#34;functions\u0026#34;, functions); System.out.println(stringTemplateExample.render()); INPUT\n1 2 a gt b and c gt d a eq b Output\n1 2 3 4 5 def generated_function_0(a, b, c, d) return (a \u0026gt; b) and (c \u0026gt; d) def generated_function_1(a, b) return (a == b) Resources repo : https://github.com/WFUing/BooleanParser https://medium.com/analytics-vidhya/antlr-and-code-generation-a71ead442005 https://medium.com/analytics-vidhya/python-from-expressions-the-antlr-series-part-1-3d7696c3a01c https://medium.com/analytics-vidhya/python-from-expressions-the-antlr-series-part-2-5436ef00bcf https://medium.com/analytics-vidhya/python-from-expressions-the-antlr-series-part-3-7ac541a1d08c ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/antlr-code-generation/","summary":"ANTLR 是 \u003cstrong\u003eAN\u003c/strong\u003eother \u003cstrong\u003eT\u003c/strong\u003eool for \u003cstrong\u003eL\u003c/strong\u003eanguage \u003cstrong\u003eR\u003c/strong\u003eecognition 的缩写，是一个功能强大的解析器生成器框架，用于从语法文件中构建语言识别器、编译器和翻译器，语法文件中包含从源语言到目标语言的每个语句所要执行的操作。","title":"Antlr Code Generation"},{"content":"下面列出了所有类型的编程语言的完整分类列表。编程语言没有严格的分类方案。因此，我们可以将一种语言视为不止一种编程语言的示例。\n让我们一一理解这些编程语言。由于列表很大，因此不可能详细讨论所有这些内容。在这里，我正在用所有这些各种编程语言的示例编写简短的介绍。\n编程语言流行度排名 编译语言 编译语言是一种编程语言，其中我们使用编译器来编译和执行代码。编译器通常是从我们的书面源代码生成机器级代码的翻译器。\nC\nC ++\nC＃\nALGOL\nCobol\nFortran\nJava\nVisual Basic\nSmalltalk\n解释语言 解释语言是一种编程语言，在其中，无需将程序编译为机器语言的指令，我们就可以直接自由地执行指令。解释器逐行执行程序。语言解释为编译后的实现（如平台独立性，动态范围，动态类型等）提供了更多的灵活性。\nPython\nRuby\nPerl\nPascal\nLisp\nBASIC\nAPL\n脚本语言 脚本语言是控制应用程序的编程语言。可以在任何其他应用程序上独立执行的脚本。它们被广泛应用于它们所控制的应用中，并被用于自动化领域。\nPHP\nVBScript\nWindows PowerShell\nF-Script\nBeanShell\nAutoIt\nR\nGame Maker Language\n标记语言 标记语言是一种人工语言，用于对文档进行注释，以便在语法上与文本（可定义文本显示方式的文本）区分开。\nHTML\nXML\nXHTML\nSGML\nCurl\n程序语言 程序（命令式）编程意味着指定程序达到预期状态应采取的步骤。过程不过是一组可以通过过程调用引用的指令。这有助于代码的重用。这种类型的编程使程序结构化并易于跟踪程序流。\nHyperTalk\nGo\nPL/C\nPL/I\nMATLAB\nCurl\nMathematica\nMATLAB\n函数式语言 函数式编程语言将每次计算都定义为数学评估。他们专注于函数的应用。一些函数式编程语言是纯函数式语言，但是许多所谓的函数式语言是不纯净的，包含命令式功能，它们不是纯函数式语言。\nPure Functional\nAgda\nSAC\nSASL\nCuneiform\nCurry\nFuthark\nHaskell\n不纯功能语言 APL\nC++ (since C++11)\nC#\nVB.NET\nCeylon\nKotlin\nLisp\nClojure\nJScript\nPHP\nPython\n基于逻辑的编程语言 逻辑编程是一种编程范例，主要基于形式逻辑。基于逻辑的编程是一组逻辑形式的语句，这些语句表达有关问题域的事实和规则。\nProlog\nROOP\nALF\nAlma-0\nCurry\nFril\nJanus\n面向对象的语言 面向对象的编程（OOP）是基于对象概念的高级编程范例，该对象可能包含字段形式的数据，通常称为属性。在OOP中，计算机程序将相关数据和功能绑定到对象中，并实现对象及其相关过程以创建软件程序。\nScala\nC++\nJava\nPython\nC#\nRuby\nScala\n数据流语言 数据流编程语言依赖于表示数据流。在数据流语言中，数据流从一条指令传递到另一条指令以执行。条件执行会跳转数据，并在过程调用中将数据路由到其他位置。\nAnalytica\nBMDFM\nHartmann pipelines\nLucid\nMax\nOz\nPrograph\nPure Data\n嵌入式语言 主要是动态脚本和编程语言。它也可以用作独立于平台的通用编程语言。嵌入式语言有两种类型：\n服务端 : 服务器端嵌入式语言更加灵活。动态生成附加标记是拥有服务器端代码片段的主要目的。服务该页面时，嵌入在网页中的服务器端是自动丢弃的代码，并由输出替换。 客户端 : 客户端嵌入式语言旨在为网页提供动态特性，从而减少重新连接服务器的开销。 服务器端\nPHP\nVBScript\nSMX\nTcl\nWebDNA\n客户端\nActionScript\nJavaScript\nVBScript\n机器语言 这些语言可由计算中央处理器直接执行。机器语言通常以八进制或十六进制形式的位模式编码。\nARM\nDEC\nx86\nIBM System/360\nMIPS\nSun, Oracle SPARC\n系统语言 这些语言用于内存管理或任务管理中使用的低级语言。与应用软件相比，通常用于系统编程的系统编程语言（例如，用于编写系统软件的语言）通常需要不同的开发方法。\nAda\nNim\nRust\nSwift\nESPOL\n并发语言 这些语言是为了在消息传递语言中并发而构造的。例如，Java显示共享内存并发。\nGo\nJava\nJulia\nclojure\nScala\n范式语言 这些类型的语言支持多种编程语言或编程范式。多范式语言允许使用多种编程风格。没有一种特定的语言能够以最简单或有效的方式解决所有问题，这就是我们使用Multiparadigm语言的原因。\nAda\nAPL\nBETA\nC++\nC#\nCobra\n扩展语言 这些语言用作其他语言的扩展。扩展编程语言嵌入到另一个程序中，并用于在扩展脚本中利用其功能。\nAutoLISP\nBeanShell\nPerl\nPike\nRuby\n迭代语言 这些语言围绕生成器提供或提供生成器。\nAldor\nAlphard\nPHP\nCLU\nCobra\n硬件描述语言 这些编程语言用于电子产品，硬件描述语言或HDL用于描述电子电路或数字逻辑电路的结构，设计和操作。Verilog和VHDL在工业中使用的各种最流行和得到良好支持的HDL品种中。\n模拟电路的HDL：\nVerilog-AMS\nVHDL-AMS\n数字电路的HDL：\nAdvanced Boolean Expression Language(ABEL)\nAltera Hardware Description Language(AHDL)\nBluespec\nLava\nELLA\n视觉语言 在Viual Languages中，用户可以以二维或多种方式指定程序，而不能使用视觉语言中的一维（文本字符串）来指定程序，我们使用图形元素和图形来开发程序。\nAnalytica\nBlockly\nDRAKON\nFabrik\nScratch\nSimulink\nSpreadsheets\n基于列表的语言 列表的语言基于列表数据结构。\n例：\nLisp\nArc\nClojure\nR\nDylan\nJoy\n同步语言 这些编程语言用于对反应系统进行编程。编程反应系统是被中断并立即响应的系统。这些系统中的一些也称为实时系统，并且被广泛使用。\nArgus\nAverest\nEsterel\nLustre\nSignal\n宏语言 这些语言用于将一个源代码文件转换为另一个。宏是一小段文本，可以扩展为更大的文本。宏语言通常用于预处理源代码。预处理程序提供文件包含等功能。\ncpp (the C preprocessor)\nm4\nML/I (general purpose macro processor)\n查询语言 数据库和信息系统中使用这些语言进行查询。\nSQL\nXPath\nAQL\nPQL\nXQuery\n元编程语言 元编程语言是编写程序，该程序编写或操纵其他程序（包括其自身）作为数据，或者完成在编译时在运行时执行的部分工作。\nC++\nCWIC\nCurl\nD\neC\nEmacs Lisp\nElixir\nF#\n基于规则的语言 当被一组数据中的条件激活时，基于规则的语言实例化规则。将选择某些集合，并执行属于那些规则的语句。\nawk\nCLIPS\nConstraint Handling Rules\nDrools\nJess\nOPS5\nProlog\n数值分析语言 在数值分析中，我们分析和实现用于数值解的算法，以解决涉及连续变量的现实数学模型的巨大问题。我们在数值分析中使用以下编程语言。\nMathematica\nMATLAB\nPROSE\nR\n语法处理语言 这些语言可帮助生成词法分析器和解析器以实现上下文无关的语法。\nANTLR\nCoco/R (EBNF with semantics)\nGNU bison (FSF\u0026rsquo;s version of Yacc)\nGNU Flex (FSF version of Lex)\nlex (Lexical Analysis, from Bell Labs)\nParsing expression grammar (PEG)\n非基于英语的语言 有几种编程语言，它们是用英语以外的其他语言开发的。在这种情况下，语言不是障碍。\nChinese BASIC - Chinese\nFjölnir - Icelandic\nLanguage Symbolique d\u0026rsquo;Enseignement - French\nLexico - Spanish\nRapira - Russian\nChaScript-Bengali\nezhil-Tamil\n基于XML的语言 这些语言用于将XML文档转换为人类可读的格式。\nAnt\nC?\nXPath\nXQuery\nXProc\n","permalink":"https://WFUing.github.io/posts/tech/language/programming-language-pool/","summary":"下面列出了所有类型的编程语言的完整分类列表。编程语言没有严格的分类方案。因此，我们可以将一种语言视为不止一种编程语言的示例。\n让我们一一理解这些编程语言。由于列表很大，因此不可能详细讨论所有这些内容。在这里，我正在用所有这些各种编程语言的示例编写简短的介绍。\n编程语言流行度排名 编译语言 编译语言是一种编程语言，其中我们使用编译器来编译和执行代码。编译器通常是从我们的书面源代码生成机器级代码的翻译器。\nC\nC ++\nC＃\nALGOL\nCobol\nFortran\nJava\nVisual Basic\nSmalltalk\n解释语言 解释语言是一种编程语言，在其中，无需将程序编译为机器语言的指令，我们就可以直接自由地执行指令。解释器逐行执行程序。语言解释为编译后的实现（如平台独立性，动态范围，动态类型等）提供了更多的灵活性。\nPython\nRuby\nPerl\nPascal\nLisp\nBASIC\nAPL\n脚本语言 脚本语言是控制应用程序的编程语言。可以在任何其他应用程序上独立执行的脚本。它们被广泛应用于它们所控制的应用中，并被用于自动化领域。\nPHP\nVBScript\nWindows PowerShell\nF-Script\nBeanShell\nAutoIt\nR\nGame Maker Language\n标记语言 标记语言是一种人工语言，用于对文档进行注释，以便在语法上与文本（可定义文本显示方式的文本）区分开。\nHTML\nXML\nXHTML\nSGML\nCurl\n程序语言 程序（命令式）编程意味着指定程序达到预期状态应采取的步骤。过程不过是一组可以通过过程调用引用的指令。这有助于代码的重用。这种类型的编程使程序结构化并易于跟踪程序流。\nHyperTalk\nGo\nPL/C\nPL/I\nMATLAB\nCurl\nMathematica\nMATLAB\n函数式语言 函数式编程语言将每次计算都定义为数学评估。他们专注于函数的应用。一些函数式编程语言是纯函数式语言，但是许多所谓的函数式语言是不纯净的，包含命令式功能，它们不是纯函数式语言。\nPure Functional\nAgda\nSAC\nSASL\nCuneiform\nCurry\nFuthark\nHaskell\n不纯功能语言 APL\nC++ (since C++11)","title":"Programming Language List"},{"content":"Resources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 博客 ZooKeeper源码阅读心得分享+源码基本结构+源码环境搭建 手摸手教你阅读和调试大型开源项目 ZooKeeper ","permalink":"https://WFUing.github.io/posts/tech/architecture/distributed/zookeeper/zookeeper-code/","summary":"Resources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 博客 ZooKeeper源码阅读心得分享+源码基本结构+源码环境搭建 手摸手教你阅读和调试大型开源项目 ZooKeeper ","title":"Zookeeper Code"},{"content":"ZooKeeper 简介 ZooKeeper 是什么 ZooKeeper 是 Apache 的顶级项目。ZooKeeper 为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名服务、配置管理和分布式锁等分布式的基础服务。在解决分布式数据一致性方面，ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。\nZooKeeper 主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是 ZooKeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控存储数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。\n很多大名鼎鼎的框架都基于 ZooKeeper 来实现分布式高可用，如：Dubbo、Kafka 等。\nZooKeeper 官方支持 Java 和 C 的 Client API。ZooKeeper 社区为大多数语言（.NET，python 等）提供非官方 API。\nZooKeeper 的应用场景 配置管理 集群节点可以通过中心源获取启动配置 更简单的部署 分布式集群管理 节点加入/离开 节点的实时状态 命名服务，如：DNS 分布式同步：如锁、栅栏、队列 分布式系统的选主 中心化和高可靠的数据注册 ZooKeeper 的特性 ZooKeeper 具有以下特性：\n顺序一致性 - 所有客户端看到的服务端数据模型都是一致的。从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。具体的实现可见：原子广播 原子性 - 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 实现方式可见：事务 单一视图 - 无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 高性能 - ZooKeeper 将数据全量存储在内存中，所以其性能很高。需要注意的是：由于 ZooKeeper 的所有更新和删除都是基于事务的，因此 ZooKeeper 在读多写少的应用场景中有性能表现较好，如果写操作频繁，性能会大大下滑。 高可用 - ZooKeeper 的高可用是基于副本机制实现的，此外 ZooKeeper 支持故障恢复，可见：选举 Leader ZooKeeper 的设计目标 简单的数据模型：ZooKeeper 的数据模型是一个树形结构的文件系统，树中的节点被称为 znode。 可以构建集群：ZooKeeper 支持集群模式，可以通过伸缩性，来控制集群的吞吐量。需要注意的是：由于 ZooKeeper 采用一主多从架构，所以其写性能是有上限的，比较适合于读多写少的场景。 顺序访问：对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事务请求的先后顺序。 高性能、高可用：ZooKeeper 将数据存全量储在内存中以保持高性能，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是基于事务的，所以其在读多写少的应用场景中有着很高的性能表现。 ZooKeeper 核心概念 服务 Zookeeper 服务是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。\n客户端只会连接一个 ZooKeeper 服务器节点，并维持 TCP 连接。\n数据模型 ZooKeeper 的数据模型是一个树形结构的文件系统。\n树中的节点被称为 znode，其中根节点为 /，每个节点上都会保存自己的数据和节点信息。znode 可以用于存储数据，并且有一个与之相关联的 ACL（详情可见 ACL）。ZooKeeper 的设计目标是实现协调服务，而不是真的作为一个文件存储，因此 znode 存储数据的大小被限制在 1MB 以内。\n数据模型 ZooKeeper 的数据访问具有原子性。其读写操作都是要么全部成功，要么全部失败。\nznode 通过路径被引用。znode 节点路径必须是绝对路径。\nznode 有两种类型：\n临时的（ EPHEMERAL ） - 户端会话结束时，ZooKeeper 就会删除临时的 znode。不允许有子节点。 持久的（PERSISTENT ） - 除非客户端主动执行删除操作，否则 ZooKeeper 不会删除持久的 znode。 节点信息 znode 上有一个顺序标志（ SEQUENTIAL ）。如果在创建 znode 时，设置了顺序标志（ SEQUENTIAL ），那么 ZooKeeper 会使用计数器为 znode 添加一个单调递增的数值，即 zxid。ZooKeeper 正是利用 zxid 实现了严格的顺序访问控制能力。\n每个 znode 节点在存储数据的同时，都会维护一个叫做 Stat 的数据结构，里面存储了关于该节点的全部状态信息。如下：\n状态属性 说明 czxid 数据节点创建时的事务 ID ctime 数据节点创建时的时间 mzxid 数据节点最后一次更新时的事务 ID mtime 数据节点最后一次更新时的时间 pzxid 数据节点的子节点最后一次被修改时的事务 ID cversion 子节点的更改次数 version 节点数据的更改次数 aversion 节点的 ACL 的更改次数 ephemeralOwner 如果节点是临时节点，则表示创建该节点的会话的 SessionID；如果节点是持久节点，则该属性值为 0 dataLength 数据内容的长度 numChildren 数据节点当前的子节点个数 集群角色 Zookeeper 集群是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。此外，每个服务器节点承担如下三种角色中的一种：\nLeader - 它负责 发起并维护与各 Follwer 及 Observer 间的心跳。所有的写操作必须要通过 Leader 完成再由 Leader 将写操作广播给其它服务器。一个 Zookeeper 集群同一时间只会有一个实际工作的 Leader。 Follower - 它会响应 Leader 的心跳。Follower 可直接处理并返回客户端的读请求，同时会将写请求转发给 Leader 处理，并且负责在 Leader 处理写请求时对请求进行投票。一个 Zookeeper 集群可能同时存在多个 Follower。 Observer - 角色与 Follower 类似，但是无投票权。 客户端可以从任意 ZooKeeper 服务器节点读取数据，但只能通过 Leader 服务写数据并需要半数以上 Follower 的 ACK，才算写入成功。记住这个重要的知识点，下文会详细讲述。\nACL ZooKeeper 采用 ACL（Access Control Lists）策略来进行权限控制。\n每个 znode 创建时都会带有一个 ACL 列表，用于决定谁可以对它执行何种操作。\nACL 依赖于 ZooKeeper 的客户端认证机制。ZooKeeper 提供了以下几种认证方式：\ndigest - 用户名和密码 来识别客户端 sasl - 通过 kerberos 来识别客户端 ip - 通过 IP 来识别客户端 ZooKeeper 定义了如下五种权限：\nCREATE - 允许创建子节点； READ - 允许从节点获取数据并列出其子节点； WRITE - 允许为节点设置数据； DELETE - 允许删除子节点； ADMIN - 允许为节点设置权限。 ZooKeeper 工作原理 读操作 Leader/Follower/Observer 都可直接处理读请求，从本地内存中读取数据并返回给客户端即可。\n由于处理读请求不需要服务器之间的交互，Follower/Observer 越多，整体系统的读请求吞吐量越大，也即读性能越好。\n写操作 所有的写请求实际上都要交给 Leader 处理。Leader 将写请求以事务形式发给所有 Follower 并等待 ACK，一旦收到半数以上 Follower 的 ACK，即认为写操作成功。\n写 Leader 由上图可见，通过 Leader 进行写操作，主要分为五步：\n客户端向 Leader 发起写请求 Leader 将写请求以事务 Proposal 的形式发给所有 Follower 并等待 ACK Follower 收到 Leader 的事务 Proposal 后返回 ACK Leader 得到过半数的 ACK（Leader 对自己默认有一个 ACK）后向所有的 Follower 和 Observer 发送 Commmit Leader 将处理结果返回给客户端 注意\nLeader 不需要得到 Observer 的 ACK，即 Observer 无投票权 Leader 不需要得到所有 Follower 的 ACK，只要收到过半的 ACK 即可，同时 Leader 本身对自己有一个 ACK。上图中有 4 个 Follower，只需其中两个返回 ACK 即可，因为 $$\\frac{2+1}{4+1} \u0026gt; \\frac{1}{2}$$ Observer 虽然无投票权，但仍须同步 Leader 的数据从而在处理读请求时可以返回尽可能新的数据 写 Follower/Observer Follower/Observer 均可接受写请求，但不能直接处理，而需要将写请求转发给 Leader 处理。 除了多了一步请求转发，其它流程与直接写 Leader 无任何区别。 事务 对于来自客户端的每个更新请求，ZooKeeper 具备严格的顺序访问控制能力。\n为了保证事务的顺序一致性，ZooKeeper 采用了递增的事务 id 号（zxid）来标识事务。\nLeader 服务会为每一个 Follower 服务器分配一个单独的队列，然后将事务 Proposal 依次放入队列中，并根据 FIFO(先进先出) 的策略进行消息发送。Follower 服务在接收到 Proposal 后，会将其以事务日志的形式写入本地磁盘中，并在写入成功后反馈给 Leader 一个 Ack 响应。当 Leader 接收到超过半数 Follower 的 Ack 响应后，就会广播一个 Commit 消息给所有的 Follower 以通知其进行事务提交，之后 Leader 自身也会完成对事务的提交。而每一个 Follower 则在接收到 Commit 消息后，完成事务的提交。\n所有的提议（proposal）都在被提出的时候加上了 zxid。zxid 是一个 64 位的数字，它的高 32 位是 epoch 用来标识 Leader 关系是否改变，每次一个 Leader 被选出来，它都会有一个新的 epoch，标识当前属于那个 leader 的统治时期。低 32 位用于递增计数。\n详细过程如下：\nLeader 等待 Server 连接； Follower 连接 Leader，将最大的 zxid 发送给 Leader； Leader 根据 Follower 的 zxid 确定同步点； 完成同步后通知 follower 已经成为 uptodate 状态； Follower 收到 uptodate 消息后，又可以重新接受 client 的请求进行服务了。 观察 ZooKeeper 允许客户端监听它关心的 znode，当 znode 状态发生变化（数据变化、子节点增减变化）时，ZooKeeper 服务会通知客户端。\n客户端和服务端保持连接一般有两种形式：\n客户端向服务端不断轮询 服务端向客户端推送状态 Zookeeper 的选择是服务端主动推送状态，也就是观察机制（ Watch ）。\nZooKeeper 的观察机制允许用户在指定节点上针对感兴趣的事件注册监听，当事件发生时，监听器会被触发，并将事件信息推送到客户端。\n监听器实时触发 监听器总是有序的 创建新的 znode 数据前，客户端就能收到监听事件。 客户端使用 getData 等接口获取 znode 状态时传入了一个用于处理节点变更的回调，那么服务端就会主动向客户端推送节点的变更：\n1 public byte[] getData(final String path, Watcher watcher, Stat stat) 从这个方法中传入的 Watcher 对象实现了相应的 process 方法，每次对应节点出现了状态的改变，WatchManager 都会通过以下的方式调用传入 Watcher 的方法：\n1 2 3 4 5 6 7 8 9 10 11 Set\u0026lt;Watcher\u0026gt; triggerWatch(String path, EventType type, Set\u0026lt;Watcher\u0026gt; supress) { WatchedEvent e = new WatchedEvent(type, KeeperState.SyncConnected, path); Set\u0026lt;Watcher\u0026gt; watchers; synchronized (this) { watchers = watchTable.remove(path); } for (Watcher w : watchers) { w.process(e); } return watchers; } Zookeeper 中的所有数据其实都是由一个名为 DataTree 的数据结构管理的，所有的读写数据的请求最终都会改变这颗树的内容，在发出读请求时可能会传入 Watcher 注册一个回调函数，而写请求就可能会触发相应的回调，由 WatchManager 通知客户端数据的变化。\n通知机制的实现其实还是比较简单的，通过读请求设置 Watcher 监听事件，写请求在触发事件时就能将通知发送给指定的客户端。\n会话 ZooKeeper 客户端通过 TCP 长连接连接到 ZooKeeper 服务集群。会话 (Session) 从第一次连接开始就已经建立，之后通过心跳检测机制来保持有效的会话状态。通过这个连接，客户端可以发送请求并接收响应，同时也可以接收到 Watch 事件的通知。\n每个 ZooKeeper 客户端配置中都配置了 ZooKeeper 服务器集群列表。启动时，客户端会遍历列表去尝试建立连接。如果失败，它会尝试连接下一个服务器，依次类推。\n一旦一台客户端与一台服务器建立连接，这台服务器会为这个客户端创建一个新的会话。每个会话都会有一个超时时间，若服务器在超时时间内没有收到任何请求，则相应会话被视为过期。一旦会话过期，就无法再重新打开，且任何与该会话相关的临时 znode 都会被删除。\n通常来说，会话应该长期存在，而这需要由客户端来保证。客户端可以通过心跳方式（ping）来保持会话不过期。\nZooKeeper 的会话具有四个属性：\nsessionID - 会话 ID，唯一标识一个会话，每次客户端创建新的会话时，Zookeeper 都会为其分配一个全局唯一的 sessionID。 TimeOut - 会话超时时间，客户端在构造 Zookeeper 实例时，会配置 sessionTimeout 参数用于指定会话的超时时间，Zookeeper 客户端向服务端发送这个超时时间后，服务端会根据自己的超时时间限制最终确定会话的超时时间。 TickTime - 下次会话超时时间点，为了便于 Zookeeper 对会话实行分桶策略管理，同时为了高效低耗地实现会话的超时检查与清理，Zookeeper 会为每个会话标记一个下次会话超时时间点，其值大致等于当前时间加上 TimeOut。 isClosing - 标记一个会话是否已经被关闭，当服务端检测到会话已经超时失效时，会将该会话的 isClosing 标记为已关闭，这样就能确保不再处理来自该会话的心情求了。 Zookeeper 的会话管理主要是通过 SessionTracker 来负责，其采用了分桶策略（将类似的会话放在同一区块中进行管理）进行管理，以便 Zookeeper 对会话进行不同区块的隔离处理以及同一区块的统一处理。\nZAB 协议 ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。ZAB 协议不是 Paxos 算法，只是比较类似，二者在操作上并不相同。Multi-Paxos 实现的是一系列值的共识，不关心最终达成共识的值是什么，不关心各值的顺序。而 ZooKeeper 需要确保操作的顺序性。\nZAB 协议是 Zookeeper 专门设计的一种支持崩溃恢复的原子广播协议。\nZAB 协议是 ZooKeeper 的数据一致性和高可用解决方案。\nZAB 协议定义了两个可以无限循环的流程：\n选举 Leader - 用于故障恢复，从而保证高可用。 原子广播 - 用于主从同步，从而保证数据一致性。 选举 Leader ZooKeeper 的故障恢复\nZooKeeper 集群采用一主（称为 Leader）多从（称为 Follower）模式，主从节点通过副本机制保证数据一致。\n如果 Follower 节点挂了 - ZooKeeper 集群中的每个节点都会单独在内存中维护自身的状态，并且各节点之间都保持着通讯，只要集群中有半数机器能够正常工作，那么整个集群就可以正常提供服务。 如果 Leader 节点挂了 - 如果 Leader 节点挂了，系统就不能正常工作了。此时，需要通过 ZAB 协议的选举 Leader 机制来进行故障恢复。 ZAB 协议的选举 Leader 机制简单来说，就是：基于过半选举机制产生新的 Leader，之后其他机器将从新的 Leader 上同步状态，当有过半机器完成状态同步后，就退出选举 Leader 模式，进入原子广播模式。\n术语 myid - 每个 Zookeeper 服务器，都需要在数据文件夹下创建一个名为 myid 的文件，该文件包含整个 Zookeeper 集群唯一的 ID（整数）。 zxid - 类似于 RDBMS 中的事务 ID，用于标识一次更新操作的 Proposal ID。为了保证顺序性，该 zxid 必须单调递增。因此 Zookeeper 使用一个 64 位的数来表示，高 32 位是 Leader 的 epoch，从 1 开始，每次选出新的 Leader，epoch 加一。低 32 位为该 epoch 内的序号，每次 epoch 变化，都将低 32 位的序号重置。这样保证了 zxid 的全局递增性。 服务器状态 LOOKING - 不确定 Leader 状态。该状态下的服务器认为当前集群中没有 Leader，会发起 Leader 选举 FOLLOWING - 跟随者状态。表明当前服务器角色是 Follower，并且它知道 Leader 是谁 LEADING - 领导者状态。表明当前服务器角色是 Leader，它会维护与 Follower 间的心跳 OBSERVING - 观察者状态。表明当前服务器角色是 Observer，与 Folower 唯一的不同在于不参与选举，也不参与集群写操作时的投票 选票数据结构 每个服务器在进行领导选举时，会发送如下关键信息\nlogicClock - 每个服务器会维护一个自增的整数，名为 logicClock，它表示这是该服务器发起的第多少轮投票 state - 当前服务器的状态 self_id - 当前服务器的 myid self_zxid - 当前服务器上所保存的数据的最大 zxid vote_id - 被推举的服务器的 myid vote_zxid - 被推举的服务器上所保存的数据的最大 zxid 投票流程 自增选举轮次 - Zookeeper 规定所有有效的投票都必须在同一轮次中。每个服务器在开始新一轮投票时，会先对自己维护的 logicClock 进行自增操作。 初始化选票 - 每个服务器在广播自己的选票前，会将自己的投票箱清空。该投票箱记录了所收到的选票。例：服务器 2 投票给服务器 3，服务器 3 投票给服务器 1，则服务器 1 的投票箱为(2, 3), (3, 1), (1, 1)。票箱中只会记录每一投票者的最后一票，如投票者更新自己的选票，则其它服务器收到该新选票后会在自己票箱中更新该服务器的选票。 发送初始化选票 - 每个服务器最开始都是通过广播把票投给自己。 接收外部投票 - 服务器会尝试从其它服务器获取投票，并记入自己的投票箱内。如果无法获取任何外部投票，则会确认自己是否与集群中其它服务器保持着有效连接。如果是，则再次发送自己的投票；如果否，则马上与之建立连接。 判断选举轮次 - 收到外部投票后，首先会根据投票信息中所包含的 logicClock 来进行不同处理 外部投票的 logicClock 大于自己的 logicClock。说明该服务器的选举轮次落后于其它服务器的选举轮次，立即清空自己的投票箱并将自己的 logicClock 更新为收到的 logicClock，然后再对比自己之前的投票与收到的投票以确定是否需要变更自己的投票，最终再次将自己的投票广播出去。 外部投票的 logicClock 小于自己的 logicClock。当前服务器直接忽略该投票，继续处理下一个投票。 外部投票的 logickClock 与自己的相等。当时进行选票 PK。 选票 PK - 选票 PK 是基于(self_id, self_zxid) 与 (vote_id, vote_zxid) 的对比 外部投票的 logicClock 大于自己的 logicClock，则将自己的 logicClock 及自己的选票的 logicClock 变更为收到的 logicClock 若 logicClock 一致，则对比二者的 vote_zxid，若外部投票的 vote_zxid 比较大，则将自己的票中的 vote_zxid 与 vote_myid 更新为收到的票中的 vote_zxid 与 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱。如果票箱内已存在(self_myid, self_zxid)相同的选票，则直接覆盖 若二者 vote_zxid 一致，则比较二者的 vote_myid，若外部投票的 vote_myid 比较大，则将自己的票中的 vote_myid 更新为收到的票中的 vote_myid 并广播出去，另外将收到的票及自己更新后的票放入自己的票箱 统计选票 - 如果已经确定有过半服务器认可了自己的投票（可能是更新后的投票），则终止投票。否则继续接收其它服务器的投票。 更新服务器状态 - 投票终止后，服务器开始更新自身状态。若过半的票投给了自己，则将自己的服务器状态更新为 LEADING，否则将自己的状态更新为 FOLLOWING 通过以上流程分析，我们不难看出：要使 Leader 获得多数 Server 的支持，则 ZooKeeper 集群节点数必须是奇数。且存活的节点数目不得少于 N + 1 。\n每个 Server 启动后都会重复以上流程。在恢复模式下，如果是刚从崩溃状态恢复的或者刚启动的 server 还会从磁盘快照中恢复数据和会话信息，zk 会记录事务日志并定期进行快照，方便在恢复时进行状态恢复。\n原子广播（Atomic Broadcast） ZooKeeper 通过副本机制来实现高可用。\n那么，ZooKeeper 是如何实现副本机制的呢？答案是：ZAB 协议的原子广播。\nZAB 协议的原子广播要求：\n所有的写请求都会被转发给 Leader，Leader 会以原子广播的方式通知 Follow。当半数以上的 Follow 已经更新状态持久化后，Leader 才会提交这个更新，然后客户端才会收到一个更新成功的响应。这有些类似数据库中的两阶段提交协议。\n在整个消息的广播过程中，Leader 服务器会每个事务请求生成对应的 Proposal，并为其分配一个全局唯一的递增的事务 ID(ZXID)，之后再对其进行广播。\nZAB 是通过一切以领导者为准的强领导者模型和严格按照顺序提交日志，来实现操作的顺序性的，这一点和 Raft 是一样的。\nZooKeeper 应用 ZooKeeper 可以用于发布/订阅、负载均衡、命令服务、分布式协调/通知、集群管理、Master 选举、分布式锁和分布式队列等功能 。\n命名服务 在分布式系统中，通常需要一个全局唯一的名字，如生成全局唯一的订单号等，ZooKeeper 可以通过顺序节点的特性来生成全局唯一 ID，从而可以对分布式系统提供命名服务。\n配置管理 利用 ZooKeeper 的观察机制，可以将其作为一个高可用的配置存储器，允许分布式应用的参与者检索和更新配置文件。\n分布式锁 可以通过 ZooKeeper 的临时节点和 Watcher 机制来实现分布式排它锁。\n举例来说，有一个分布式系统，有三个节点 A、B、C，试图通过 ZooKeeper 获取分布式锁。\n（1）访问 /lock （这个目录路径由程序自己决定），创建 带序列号的临时节点（EPHEMERAL） 。\n（2）每个节点尝试获取锁时，拿到 /locks节点下的所有子节点（id_0000,id_0001,id_0002），判断自己创建的节点是不是序列号最小的\n如果序列号是最小的，则成功获取到锁。 释放锁：执行完操作后，把创建的节点给删掉。 如果不是，则监听比自己要小 1 的节点变化。 （3）释放锁，即删除自己创建的节点。\n图中，NodeA 删除自己创建的节点 id_0000，NodeB 监听到变化，发现自己的节点已经是最小节点，即可获取到锁。\n集群管理 ZooKeeper 还能解决大多数分布式系统中的问题：\n如可以通过创建临时节点来建立心跳检测机制。如果分布式系统的某个服务节点宕机了，则其持有的会话会超时，此时该临时节点会被删除，相应的监听事件就会被触发。 分布式系统的每个服务节点还可以将自己的节点状态写入临时节点，从而完成状态报告或节点工作进度汇报。 通过数据的订阅和发布功能，ZooKeeper 还能对分布式系统进行模块的解耦和任务的调度。 通过监听机制，还能对分布式系统的服务节点进行动态上下线，从而实现服务的动态扩容。 选举 Leader 节点 分布式系统一个重要的模式就是主从模式 (Master/Salves)，ZooKeeper 可以用于该模式下的 Matser 选举。可以让所有服务节点去竞争性地创建同一个 ZNode，由于 ZooKeeper 不能有路径相同的 ZNode，必然只有一个服务节点能够创建成功，这样该服务节点就可以成为 Master 节点。\n队列管理 ZooKeeper 可以处理两种类型的队列：\n当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达，这种是同步队列。 队列按照 FIFO 方式进行入队和出队操作，例如实现生产者和消费者模型。 同步队列用 ZooKeeper 实现的实现思路如下：\n创建一个父目录 /synchronizing，每个成员都监控标志（Set Watch）位目录 /synchronizing/start 是否存在，然后每个成员都加入这个队列，加入队列的方式就是创建 /synchronizing/member_i 的临时目录节点，然后每个成员获取 /synchronizing 目录的所有目录节点，也就是 member_i。判断 i 的值是否已经是成员的个数，如果小于成员个数等待 /synchronizing/start 的出现，如果已经相等就创建 /synchronizing/start。\nZooKeeper 的缺点 ZooKeeper 的监听是一次性的。\nZooKeeper 不是为高可用性设计的 生产环境中常常需要通过多机房部署来容灾。出于成本考虑，一般多机房都是同时提供服务的，即一个机房撑不住所有流量。ZooKeeper 集群只能有一个 Leader，一旦机房之间连接出现故障，那么只有 Leader 所在的机房可以正常工作，其他机房只能停摆。于是所有流量集中到 Leader 所在的机房，由于处理不过来而导致崩溃。\n即使是在同一个机房里面，由于网段的不同，在调整机房交换机的时候偶尔也会发生网段隔离的情况。实际上机房每个月基本上都会发生短暂的网络隔离之类的子网段调整。在那个时刻 ZooKeeper 将处于不可用状态。如果业务系统重度依赖 ZooKeeper（比如用 Dubbo 作为 RPC，且使用 ZooKeeper 作为注册中心），则系统的可用性将非常脆弱。\n由于 ZooKeeper 对于网络隔离的极度敏感，导致 ZooKeeper 对于网络的任何风吹草动都会做出激烈反应。这使得 ZooKeeper 的不可用时间比较多。我们不能让 ZooKeeper 的不可用，变成系统的不可用。\nZooKeeper 的选举过程速度很慢 互联网环境中，网络不稳定几乎是必然的，而 ZooKeeper 网络隔离非常敏感。一旦出现网络隔离，zookeeper 就要发起选举流程。\nZooKeeper 的选举流程通常耗时 30 到 120 秒，期间 ZooKeeper 由于没有 Leader，都是不可用的。\n对于网络里面偶尔出现的，比如半秒一秒的网络隔离，ZooKeeper 会由于选举过程，而把不可用时间放大几十倍。\nZooKeeper 的性能是有限的 典型的 ZooKeeper 的 TPS 大概是一万多，无法支撑每天动辄几十亿次的调用。因此，每次请求都去 ZooKeeper 获取业务系统信息是不可能的。\n为此，ZooKeeper 的 client 必须自己缓存业务系统的信息。这就导致 ZooKeeper 提供的强一致性实际上是做不到的。如果我们需要强一致性，还需要其他机制来进行保障：比如用自动化脚本把业务系统的 old master 给 kill 掉，但是这可能会引发很多其他问题。\nZooKeeper 无法进行有效的权限控制 ZooKeeper 的权限控制非常弱。在大型的复杂系统里面，使用 ZooKeeper 必须自己再额外的开发一套权限控制系统，通过那套权限控制系统再访问 ZooKeeper。\n额外的权限控制系统不但增加了系统复杂性和维护成本，而且降低了系统的总体性能。\n即使有了 ZooKeeper 也很难避免业务系统的数据不一致 由于 ZooKeeper 的性能限制，我们无法让每次系统内部调用都走 ZooKeeper，因此总有某些时刻，业务系统会存在两份数据（业务系统 client 那边缓存的业务系统信息是定时从 ZooKeeper 更新的，因此会有更新不同步的问题）。\n如果要保持数据的强一致性，唯一的方法是先 kill 掉当前 Leader，再在 ZooKeeper 上更新 Leader 信息。是否要 kill 掉当前 Leader 这个问题上，程序是无法完全自动决定的（因为网络隔离的时候 ZooKeeper 已经不可用了，自动脚本没有全局信息，不管怎么做都可能是错的，什么都不做也可能是错的。当网络故障的时候，只有运维人员才有全局信息，程序是无法得知其他机房的情况的）。因此系统无法自动的保障数据一致性，必须要人工介入。而人工介入的典型时间是半个小时以上，我们不能让系统这么长时间不可用。因此我们必须在某个方向上进行妥协，最常见的妥协方式是放弃强一致性，而接受最终一致性。\n如果我们需要人工介入才能保证可靠的强一致性，那么 ZooKeeper 的价值就大打折扣。\nResources 官方 ZooKeeper 官网 ZooKeeper 官方文档 ZooKeeper Github 书籍 《Hadoop 权威指南（第四版）》 《从 Paxos 到 Zookeeper 分布式一致性原理与实践》 文章 分布式服务框架 ZooKeeper \u0026ndash; 管理分布式环境中的数据 ZooKeeper 的功能以及工作原理 ZooKeeper 简介及核心概念 详解分布式协调服务 ZooKeeper 深入浅出 Zookeeper（一） Zookeeper 架构及 FastLeaderElection 机制 Introduction to Apache ZooKeeper Zookeeper 的优缺点 ","permalink":"https://WFUing.github.io/posts/tech/architecture/distributed/zookeeper/zookeeper-theory/","summary":"ZooKeeper 简介 ZooKeeper 是什么 ZooKeeper 是 Apache 的顶级项目。ZooKeeper 为分布式应用提供了高效且可靠的分布式协调服务，提供了诸如统一命名服务、配置管理和分布式锁等分布式的基础服务。在解决分布式数据一致性方面，ZooKeeper 并没有直接采用 Paxos 算法，而是采用了名为 ZAB 的一致性协议。\nZooKeeper 主要用来解决分布式集群中应用系统的一致性问题，它能提供基于类似于文件系统的目录节点树方式的数据存储。但是 ZooKeeper 并不是用来专门存储数据的，它的作用主要是用来维护和监控存储数据的状态变化。通过监控这些数据状态的变化，从而可以达到基于数据的集群管理。\n很多大名鼎鼎的框架都基于 ZooKeeper 来实现分布式高可用，如：Dubbo、Kafka 等。\nZooKeeper 官方支持 Java 和 C 的 Client API。ZooKeeper 社区为大多数语言（.NET，python 等）提供非官方 API。\nZooKeeper 的应用场景 配置管理 集群节点可以通过中心源获取启动配置 更简单的部署 分布式集群管理 节点加入/离开 节点的实时状态 命名服务，如：DNS 分布式同步：如锁、栅栏、队列 分布式系统的选主 中心化和高可靠的数据注册 ZooKeeper 的特性 ZooKeeper 具有以下特性：\n顺序一致性 - 所有客户端看到的服务端数据模型都是一致的。从一个客户端发起的事务请求，最终都会严格按照其发起顺序被应用到 ZooKeeper 中。具体的实现可见：原子广播 原子性 - 所有事务请求的处理结果在整个集群中所有机器上的应用情况是一致的，即整个集群要么都成功应用了某个事务，要么都没有应用。 实现方式可见：事务 单一视图 - 无论客户端连接的是哪个 Zookeeper 服务器，其看到的服务端数据模型都是一致的。 高性能 - ZooKeeper 将数据全量存储在内存中，所以其性能很高。需要注意的是：由于 ZooKeeper 的所有更新和删除都是基于事务的，因此 ZooKeeper 在读多写少的应用场景中有性能表现较好，如果写操作频繁，性能会大大下滑。 高可用 - ZooKeeper 的高可用是基于副本机制实现的，此外 ZooKeeper 支持故障恢复，可见：选举 Leader ZooKeeper 的设计目标 简单的数据模型：ZooKeeper 的数据模型是一个树形结构的文件系统，树中的节点被称为 znode。 可以构建集群：ZooKeeper 支持集群模式，可以通过伸缩性，来控制集群的吞吐量。需要注意的是：由于 ZooKeeper 采用一主多从架构，所以其写性能是有上限的，比较适合于读多写少的场景。 顺序访问：对于来自客户端的每个更新请求，Zookeeper 都会分配一个全局唯一的递增 ID，这个 ID 反映了所有事务请求的先后顺序。 高性能、高可用：ZooKeeper 将数据存全量储在内存中以保持高性能，并通过服务集群来实现高可用，由于 Zookeeper 的所有更新和删除都是基于事务的，所以其在读多写少的应用场景中有着很高的性能表现。 ZooKeeper 核心概念 服务 Zookeeper 服务是一个基于主从复制的高可用集群，集群中每个节点都存储了一份数据副本（内存中）。","title":"Zookeeper 原理"},{"content":"什么是分布式系统 将硬件或软件组件(服务)分布在不同的网络计算机上，并且通过消息传递进行通信和协调。\n特点\n分布性 对等性 平等: 无主从之分 独立: 拥有自己的CPU和内存，独立处理数据 并发性 外部: 承载多个客户端的并发访问 内部: 作业(Job)被分解成多个任务(Task)，并发运行在不同的节点上 故障独立性 部分节点出现故障不影响整个系统的正常使用 split-brain 问题 对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房。正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，但机房之间无法通信。如果不考虑过半机制，那么就会出现每个机房内部都将选出一个Leader。这就相当于原本一个集群，被分成了两个集群，出现了两个大脑，这就是脑裂。\n脑裂 对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。\nCAP定理 C(Consistency，一致性) 含义: 同一时刻，数据在不同节点的多个副本是否具有完全相同的值 类型 强一致性: 数据更新完成后，同一时刻，不同的读操作都能获得最新的值 弱一致性: 数据更新完成后，同一时刻，不同的读操作不一定都能获得最新的值，也无法保证多长时间之后可以获得最新的值 A(Availability，可用性) 含义: 对于每一次请求，系统是否都能在有限(指定)的时间内做出响应 P(Partition Tolerance，分区容错性) 含义: 当发生网络分区时，系统仍能对外提供满足 一致性C 和 可用性A 的服务 CAP定理 分布式系统在同一时间片段内，不可能同时满足一致性C、可用性A和分区容错性P，最多只能满足其中的两项。\n满足意味着100%， 满足C -\u0026gt; 满足强一致性 满足A -\u0026gt; 满足绝对可用性 对分布式系统而言，网络分区无法避免，满足P是前提条件，所以不可能选择CA架构，只能选择CP或AP架构 例如: 发生网络分区时，某个节点正在进行写操作 如果为了保证C，必须禁止其他节点的读写操作，那就与A冲突了 如果为了保证A，其他节点正常读写，那就与C冲突了 选择CP或AP架构，关键在业务场景 例如: 对于必须确保强一致性的银行业务，只能选择CP BASE理论 BA(Basically Availability，基本可用性) 当系统发生故障时，在确保核心功能和指标有效的提前下，允许损失部分可用性，包括响应时间上的损失、非核心功能上的损失等 S(Soft State，软状态) 允许数据存在中间状态(暂时未更新)，且该状态不会影响整体可用性 允许不同节点上的数据副本的同步过程存在一定延时 EC(Eventually Consistency，最终一致性) 分布在不同节点上的数据副本，在经过一定时间的同步后，最终达到一致状态 例如: Zookeeper、HDFS QJM写事务的过半策略 弱一致性的升级版 BASE定理 分布式系统在满足分区容错性P的同时，允许数据软状态S的存在，并实现基本可用性BA和最终一致性EC\n在满足P的前提下，对CAP中的强一致性A和绝对可用性C进行适度妥协 A -\u0026gt; BA ，C -\u0026gt; EC 通过容忍部分数据的暂时不一致(软状态)，即牺牲数据的强一致性(确保最终一致性)，以确保系统的核心功能和指标有效(基本可用) CAP定理的延伸，CAP的 C+P / A+P -\u0026gt; BASE的EC+BA+P 对大规模互联网系统分布式实践的总结 ","permalink":"https://WFUing.github.io/posts/tech/architecture/distributed/overview/","summary":"什么是分布式系统 将硬件或软件组件(服务)分布在不同的网络计算机上，并且通过消息传递进行通信和协调。\n特点\n分布性 对等性 平等: 无主从之分 独立: 拥有自己的CPU和内存，独立处理数据 并发性 外部: 承载多个客户端的并发访问 内部: 作业(Job)被分解成多个任务(Task)，并发运行在不同的节点上 故障独立性 部分节点出现故障不影响整个系统的正常使用 split-brain 问题 对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，比如现在有一个由6台zkServer所组成的一个集群，部署在了两个机房。正常情况下，此集群只会有一个Leader，那么如果机房之间的网络断了之后，两个机房内的zkServer还是可以相互通信的，但机房之间无法通信。如果不考虑过半机制，那么就会出现每个机房内部都将选出一个Leader。这就相当于原本一个集群，被分成了两个集群，出现了两个大脑，这就是脑裂。\n脑裂 对于这种情况，我们也可以看出来，原本应该是统一的一个集群对外提供服务的，现在变成了两个集群同时对外提供服务，如果过了一会，断了的网络突然联通了，那么此时就会出现问题了，两个集群刚刚都对外提供服务了，数据该怎么合并，数据冲突怎么解决等等问题。\nCAP定理 C(Consistency，一致性) 含义: 同一时刻，数据在不同节点的多个副本是否具有完全相同的值 类型 强一致性: 数据更新完成后，同一时刻，不同的读操作都能获得最新的值 弱一致性: 数据更新完成后，同一时刻，不同的读操作不一定都能获得最新的值，也无法保证多长时间之后可以获得最新的值 A(Availability，可用性) 含义: 对于每一次请求，系统是否都能在有限(指定)的时间内做出响应 P(Partition Tolerance，分区容错性) 含义: 当发生网络分区时，系统仍能对外提供满足 一致性C 和 可用性A 的服务 CAP定理 分布式系统在同一时间片段内，不可能同时满足一致性C、可用性A和分区容错性P，最多只能满足其中的两项。\n满足意味着100%， 满足C -\u0026gt; 满足强一致性 满足A -\u0026gt; 满足绝对可用性 对分布式系统而言，网络分区无法避免，满足P是前提条件，所以不可能选择CA架构，只能选择CP或AP架构 例如: 发生网络分区时，某个节点正在进行写操作 如果为了保证C，必须禁止其他节点的读写操作，那就与A冲突了 如果为了保证A，其他节点正常读写，那就与C冲突了 选择CP或AP架构，关键在业务场景 例如: 对于必须确保强一致性的银行业务，只能选择CP BASE理论 BA(Basically Availability，基本可用性) 当系统发生故障时，在确保核心功能和指标有效的提前下，允许损失部分可用性，包括响应时间上的损失、非核心功能上的损失等 S(Soft State，软状态) 允许数据存在中间状态(暂时未更新)，且该状态不会影响整体可用性 允许不同节点上的数据副本的同步过程存在一定延时 EC(Eventually Consistency，最终一致性) 分布在不同节点上的数据副本，在经过一定时间的同步后，最终达到一致状态 例如: Zookeeper、HDFS QJM写事务的过半策略 弱一致性的升级版 BASE定理 分布式系统在满足分区容错性P的同时，允许数据软状态S的存在，并实现基本可用性BA和最终一致性EC","title":"分布式系统概述"},{"content":"Background IIoT（工业物联网）架构通常是分布式和异步的，通信由事件驱动，如消息的发布（和相应的订阅）。这些异步架构提高了可扩展性和对变化的耐受性，但也引发了互操作性问题，因为架构各元素之间对消息内部结构及其分类（主题）的明确知识被稀释了。\n事实上，这也是 REST 应用程序接口面临的一个问题，直到业界联合起来，提出了一种定义同步应用程序接口结构和模式的标准方法：OpenAPI（源自 Swagger）。\nIntroduction 对于异步架构，受 OpenAPI 的启发，AsyncAPI 的出现解决了这一问题：\nAsyncAPI 提供了一种规范，允许您以机器可读的格式定义消息驱动的 API。它与协议无关，因此可以用于通过 Kafka、MQTT、AMQP、WebSockets、STOMP 等工作的 API。该规范与 OpenAPI/Swagger 非常相似，所以如果你熟悉它，AsyncAPI 对你来说应该很容易。\n在 AsyncAPI 中，API 的规格可以用 YAML 或 JSON 定义，例如可以指定消息代理、感兴趣的主题或与每个主题相关的不同消息格式等。不过，AsyncAPI 还处于开发的早期阶段，AsyncAPI 工具市场还不发达，主要局限于生成供人类使用的文档。\nAsyncAPI 最初的贡献就是上图中展示的方法。\nAsyncAPI Toolkit 如上图所示，AsyncAPI 团队扩展了这一初始框架。基于 AsyncAPI 规范在 Xtext 中开发 AsyncAPI JSON 语法的，该语法可验证符合 AsyncAPI 规范的消息驱动 API 定义。同样，根据该语法，Xtext 会自动生成相应的 AsyncAPI 元模型和所有工具（带内容辅助功能的编辑器、解析器等），以便轻松创建 AsyncAPI JSON 定义并将其转换为符合 AsyncAPI 元模型的 AsyncAPI 模型。\n有了 AsyncAPI 元模型和作为符合模型的应用程序接口规范，就可以通过执行 M2T 转换（生成内部 DSL）来继续工作流程。目前，AsyncAPI Toolkit 支持 Java 语言，并生成一个库，通过提供流畅的 API 来协助开发人员创建、发布和接收格式良好的消息。\n值得注意的是，由于这些架构都是基于 message 的，因此数据建模起着至关重要的作用。因此，我们在上述工作流程中使用了另一种（图形化）具体语法，重点是对要交换的消息进行建模。这可用于引导 AsyncAPI JSON 定义，随后可对其进行手动完善。\nImporting / Modeling an AsyncAPI 规范 首先，基于 AsyncAPI 规范，我们创建了一个 Xtext 语法。根据该语法，我们自动生成了一个 Ecore metamodel，以及一套编辑器和基于 Eclipse 的工具。这些编辑器允许使用 AsyncAPI 创建基于 JSON 的消息驱动 API 规范。使用这些编辑器创建的规范会被自动解析并重新整合为 AsyncAPI 元模型的实例。\n生成代码，轻松处理 AsyncAPI 规范中的信息 此外，原型还能生成 Java 代码，支持根据建模的 AsyncAPI（包括嵌套 JSON 对象）创建和序列化基于 JSON 的消息有效载荷。但目前还不支持数组。下面的节选显示了原型支持的 AsyncAPI 规范示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 { \u0026#34;asyncapi\u0026#34;: \u0026#34;1.2.0\u0026#34;, \u0026#34;info\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Sample AsyncAPI specification\u0026#34;, \u0026#34;version\u0026#34;: \u0026#34;0.1.0\u0026#34;, }, \u0026#34;servers\u0026#34;: [ { \u0026#34;url\u0026#34;: \u0026#34;broker.url:{port}\u0026#34;, \u0026#34;scheme\u0026#34;: \u0026#34;mqtt\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;This is an example description\u0026#34;, \u0026#34;variables\u0026#34;: { \u0026#34;port\u0026#34;: { \u0026#34;default\u0026#34;: \u0026#34;1883\u0026#34;, \u0026#34;enum\u0026#34;: [ \u0026#34;1883\u0026#34;, \u0026#34;8883\u0026#34; ] } } } ], \u0026#34;topics\u0026#34;: { \u0026#34;messages/device2controller\u0026#34;: { \u0026#34;publish\u0026#34;: { \u0026#34;$ref\u0026#34; : \u0026#34;#/components/messages/request\u0026#34; } } } }, \u0026#34;components\u0026#34;: { \u0026#34;schemas\u0026#34;: { \u0026#34;protocol_version\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Protocol version\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;integer\u0026#34;, \u0026#34;default\u0026#34;: 2, \u0026#34;x-friendly-name\u0026#34;: \u0026#34;ProtocolVersion\u0026#34; }, \u0026#34;id\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;ID\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;format\u0026#34;: \u0026#34;XXXXXX YY ZZZZZZ W\u0026#34; }, \u0026#34;status\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Status\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;OK\u0026#34;, \u0026#34;ERROR\u0026#34;], \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Status\u0026#34; }, \u0026#34;environment\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Environment\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;enum\u0026#34;: [\u0026#34;DEV\u0026#34;, \u0026#34;STAG\u0026#34;,\u0026#34;PROD\u0026#34; ], \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Environment\u0026#34; } }, \u0026#34;messages\u0026#34; : { \u0026#34;request\u0026#34; : { \u0026#34;summary\u0026#34; : \u0026#34;Request connectivity.\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Request connectivity when status changes\u0026#34;, \u0026#34;payload\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;object\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;P\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/protocol_version\u0026#34; }, \u0026#34;ID\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/id\u0026#34; }, \u0026#34;E\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/environment\u0026#34; }, \u0026#34;M\u0026#34;: { \u0026#34;x-friendly-name\u0026#34; : \u0026#34;Message\u0026#34;, \u0026#34;properties\u0026#34;: { \u0026#34;S\u0026#34;: { \u0026#34;$ref\u0026#34;: \u0026#34;#/components/schemas/status\u0026#34; }, \u0026#34;C\u0026#34;: { \u0026#34;title\u0026#34;: \u0026#34;Content\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;string\u0026#34;, \u0026#34;x-friendly-name\u0026#34;: \u0026#34;Content\u0026#34; } } } } } } } } 根据上述规范，可以生成如下信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 package tests; import messages.device2controller.Request; import messages.device2controller.Request.Payload.Environment; import messages.device2controller.Request.Payload.Message; import messages.device2controller.Request.Payload.PayloadBuilder; import messages.device2controller.Request.Payload.Message.Status; public class Test { public static void main(String[] args) { PayloadBuilder builder = Request.payloadBuilder(); Request.Payload payload = builder .withProtocolVersion(2) .withEnvironment(Environment.DEV) .withID(\u0026#34;id\u0026#34;) .withMessage( Message.newBuilder() .withStatus(Status.OK) .withContent(\u0026#34;Content\u0026#34;) .build() ).build(); System.out.println(payload.toJson(true)); System.out.println(Request.Payload.fromJson(payload.toJson()).toJson(true)); } } 从 Ecore 模型生成新的 AsyncAPI 在此之前，我们假设您要么已经有一个 AsyncAPI 文件要导入，要么您将使用我们的 AsyncAPI 编辑器创建一个文件。事实上，还有第三种选择：使用现有的 Ecore 模型，并从中生成一个骨架 AsyncAPI 规范。\n生成器将为每个领域类创建一个可重复使用的 JSON 模式。通道将由注释过的 EClasses 创建。此外，还可通过 EAnnotations 指定主机信息。\n除了其局限性外，获得基于 JSON 的 Ecore 模型表示法还有几个优点：\n允许开发人员和架构师创建一个可用的 AsyncAPI 定义，而无需深入了解规范， 同时保持建模环境的简单性和可管理性； 以及让不熟悉建模的人也能遵守 AsyncAPI 规范还能让有经验的开发人员和架构师完善和完成无法用 Ecore 轻松捕获的架构细节 为了在建议的开发工作流程中集成数据模型，定义了 Ecore 到 AsyncAPI 的模型到模型（M2M）和 AsyncAPI 到 JSON 的 M2T 转换。\n例子\nResources tutorial: https://modeling-languages.com/asyncapi-modeling-editor-code-generator/ A model-based approach for developing event-driven architectures with AsyncAPI Model-driven development of asynchronous message-driven architectures with AsyncAPI Grammar 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 grammar io.github.abelgomez.asyncapi.AsyncApi hidden(WS) generate asyncApi \u0026#34;http://io.github.abelgomez/asyncapi/AsyncApi\u0026#34; import \u0026#34;http://www.eclipse.org/emf/2002/Ecore\u0026#34; as ecore AsyncAPI: {AsyncAPI} \u0026#39;{\u0026#39;\t( ( \u0026#39;\u0026#34;asyncapi\u0026#34;\u0026#39; \u0026#39;:\u0026#39; version=VersionNumber \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;info\u0026#34;\u0026#39; \u0026#39;:\u0026#39; info=Info \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;servers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; servers+=Server (\u0026#39;,\u0026#39; servers+=Server)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;channels\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; channels+=Channel (\u0026#39;,\u0026#39; channels+=Channel)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;components\u0026#34;\u0026#39; \u0026#39;:\u0026#39; components=Components \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-sla\u0026#34;\u0026#39; \u0026#39;:\u0026#39; sla=Sla \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Info: {Info} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;version\u0026#34;\u0026#39; \u0026#39;:\u0026#39; version=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;termsOfService\u0026#34;\u0026#39; \u0026#39;:\u0026#39; termsOfService=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;contact\u0026#34;\u0026#39; \u0026#39;:\u0026#39; contact=Contact \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;license\u0026#34;\u0026#39; \u0026#39;:\u0026#39; license=License \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-basePackage\u0026#34;\u0026#39; \u0026#39;:\u0026#39; basePackage=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Contact: {Contact} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;email\u0026#34;\u0026#39; \u0026#39;:\u0026#39; email=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; License: {License} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Server: {Server} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;url\u0026#34;\u0026#39; \u0026#39;:\u0026#39; url=AnyString \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;protocol\u0026#34;\u0026#39; \u0026#39;:\u0026#39; protocol=Protocol \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;variables\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; variables+=Variable (\u0026#39;,\u0026#39; variables+=Variable)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-isMonitored\u0026#34;\u0026#39; \u0026#39;:\u0026#39; isMonitored=Boolean \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Variable: {Variable} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;default\u0026#34;\u0026#39; \u0026#39;:\u0026#39; default=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; ^enum+=AnyString (\u0026#39;,\u0026#39; ^enum+=AnyString)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Channel: {Channel} name=AnyString \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;publish\u0026#34;\u0026#39; \u0026#39;:\u0026#39; publish=Operation \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;subscribe\u0026#34;\u0026#39; \u0026#39;:\u0026#39; subscribe=Operation \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; parameters+=NamedParameter (\u0026#39;,\u0026#39; parameters+=NamedParameter)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Operation: {Operation} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operationId=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;message\u0026#34;\u0026#39; \u0026#39;:\u0026#39; message=AbstractMessage \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; traits+=AbstractOperationTrait ( \u0026#39;,\u0026#39; traits+=AbstractOperationTrait )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; AbstractMessage: Reference | Message; Message: {Message} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; \u0026#39;:\u0026#39; deprecated=Boolean \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; headers=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; tags+=Tag ( \u0026#39;,\u0026#39; tags+=Tag )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;payload\u0026#34;\u0026#39; \u0026#39;:\u0026#39; payload=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; traits+=AbstractMessageTrait ( \u0026#39;,\u0026#39; traits+=AbstractMessageTrait )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-identifier\u0026#34;\u0026#39; \u0026#39;:\u0026#39; identifier=MessageIdentifier )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedMessage: {NamedMessage} name=AnyString \u0026#39;:\u0026#39; message=AbstractMessage; Tag: {Tag} \u0026#39;{\u0026#39; ( (\u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;?)? \u0026amp; (\u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;?)? //\t\u0026amp; ( GenericJsonTuple \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; AbstractSchema: Reference | Schema; Schema: {Schema} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;title\u0026#34;\u0026#39; \u0026#39;:\u0026#39; title=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;type\u0026#34;\u0026#39; \u0026#39;:\u0026#39; type=JsonType \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;format\u0026#34;\u0026#39; \u0026#39;:\u0026#39; format=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;minimum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; minimum=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;maximum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; maximum=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;minItems\u0026#34;\u0026#39; \u0026#39;:\u0026#39; minItems=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;maxItems\u0026#34;\u0026#39; \u0026#39;:\u0026#39; maxItems=INT \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;default\u0026#34;\u0026#39; \u0026#39;:\u0026#39; default=PrimitiveValue\u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;properties\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; properties+=NamedSchema (\u0026#39;,\u0026#39; properties+=NamedSchema)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; ^enum+=PrimitiveValue (\u0026#39;,\u0026#39; ^enum+=PrimitiveValue)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;items\u0026#34;\u0026#39; \u0026#39;:\u0026#39; items=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;required\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; required+=AnyString (\u0026#39;,\u0026#39; required+=AnyString)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedSchema: {NamedSchema} name=AnyString \u0026#39;:\u0026#39; schema=AbstractSchema; AbstractParameter: Reference | Parameter; Parameter: {Parameter} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;schema\u0026#34;\u0026#39; \u0026#39;:\u0026#39; schema=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;location\u0026#34;\u0026#39; \u0026#39;:\u0026#39; location=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedParameter: {NamedParameter} name=AnyString \u0026#39;:\u0026#39; parameter=AbstractParameter; AbstractOperationTrait: Reference | OperationTrait; OperationTrait: {OperationTrait} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operationId=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedOperationTrait: {NamedOperationTrait} name=AnyString \u0026#39;:\u0026#39; operationTrait=AbstractOperationTrait; AbstractMessageTrait: Reference | MessageTrait; MessageTrait: {MessageTrait} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; \u0026#39;:\u0026#39; summary=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; \u0026#39;:\u0026#39; deprecated=Boolean \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; \u0026#39;:\u0026#39; headers=AbstractSchema \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; tags+=Tag ( \u0026#39;,\u0026#39; tags+=Tag )* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; NamedMessageTrait: {NamedMessageTrait} name=AnyString \u0026#39;:\u0026#39; messageTrait=AbstractMessageTrait; Components: {Components} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;schemas\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; schemas+=NamedSchema (\u0026#39;,\u0026#39; schemas+=NamedSchema)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; messages+=NamedMessage (\u0026#39;,\u0026#39; messages+=NamedMessage)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; parameters+=NamedParameter (\u0026#39;,\u0026#39; parameters+=NamedParameter)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;operationTraits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; operationTraits+=NamedOperationTrait (\u0026#39;,\u0026#39; operationTraits+=NamedOperationTrait)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;messageTraits\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; messageTraits+=NamedMessageTrait (\u0026#39;,\u0026#39; messageTraits+=NamedMessageTrait)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;x-qosMetrics\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; qosMetrics+=QoSMetric (\u0026#39;,\u0026#39; qosMetrics+=QoSMetric)* \u0026#39;]\u0026#39; \u0026#39;,\u0026#39;? )? //\t\u0026amp; ( GenericJsonTupleButRef \u0026#39;,\u0026#39;? )* ) \u0026#39;}\u0026#39;; Sla: {Sla} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;guaranteeTerm\u0026#34;\u0026#39; \u0026#39;:\u0026#39; guaranteeTerm+=GuaranteeTerm (\u0026#39;,\u0026#39; guaranteeTerm+=GuaranteeTerm)* ) ) \u0026#39;}\u0026#39;; GuaranteeTerm: {GuaranteeTerm} \u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;scopes\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; scopes+=Scope (\u0026#39;,\u0026#39; scopes+=Scope)* \u0026#39;}\u0026#39; \u0026#39;,\u0026#39; ) ( \u0026#39;\u0026#34;qualifyingConditions\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; qualifyingConditions+=QualifyingCondition (\u0026#39;,\u0026#39; qualifyingConditions+=QualifyingCondition)* \u0026#39;}\u0026#39;\u0026#39;,\u0026#39;)? ( \u0026#39;\u0026#34;slos\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; slos+=Slo (\u0026#39;,\u0026#39; slos+=Slo)* \u0026#39;}\u0026#39;)\t) \u0026#39;}\u0026#39;; Scope: {Scope}( name=AnyString \u0026#39;:\u0026#39; reference= [Channel|AnyString] ); QualifyingCondition: {QualifyingCondition} name=AnyString \u0026#39;:\u0026#39; condition=BooleanExpression ; Slo: {Slo} name=AnyString \u0026#39;:\u0026#39; condition=BooleanExpression ;\tAbstractQoSMetric: QoSMetricReference | QoSMetric; QoSMetricReference: metric= [QoSMetric|AnyString]\t; QoSMetric: (\u0026#39;{\u0026#39; ( ( \u0026#39;\u0026#34;name\u0026#34;\u0026#39; \u0026#39;:\u0026#39; name=AnyString \u0026#39;,\u0026#39;? )\t\u0026amp; ( \u0026#39;\u0026#34;metricType\u0026#34;\u0026#39; \u0026#39;:\u0026#39; metricType=QoSMetricType \u0026#39;,\u0026#39;? )\t\u0026amp; ( \u0026#39;\u0026#34;description\u0026#34;\u0026#39; \u0026#39;:\u0026#39; description=AnyString \u0026#39;,\u0026#39;? )? \u0026amp; ( \u0026#39;\u0026#34;unit\u0026#34;\u0026#39; \u0026#39;:\u0026#39; unit=QoSMetricUnit \u0026#39;,\u0026#39;? ) \u0026amp; ( \u0026#39;\u0026#34;groupedByEvent\u0026#34;\u0026#39; \u0026#39;:\u0026#39; groupedByEvent=Boolean \u0026#39;,\u0026#39;? )\t) (DerivedQoSMetric)?\t// Això està al final de tot, pq Xtext es queixa que no pot haver-hi una unasssigned rule dins d\u0026#39;una unordered list.\t\u0026#39;}\u0026#39;); DerivedQoSMetric: {DerivedQoSMetric}( \u0026#39;\u0026#34;derivedQoSMetricDefinition\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;{\u0026#39; ( (\u0026#39;\u0026#34;window\u0026#34;\u0026#39; \u0026#39;:\u0026#39; window = AnyString \u0026#39;,\u0026#39;? ) \u0026amp; (\u0026#39;\u0026#34;windowUnit\u0026#34;\u0026#39; \u0026#39;:\u0026#39; windowUnit = WindowUnit \u0026#39;,\u0026#39;? ) \u0026amp; (\u0026#39;\u0026#34;aggregationFunction\u0026#34;\u0026#39; \u0026#39;:\u0026#39; aggregationFunction = AggregationFunction \u0026#39;,\u0026#39;? ) ) \u0026#39;}\u0026#39; ) ; BooleanExpression: AndExpression | OrExpression | ComparisonExpression; AndExpression: {AndExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;AND\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; conditions+=BooleanExpression (\u0026#39;,\u0026#39; conditions+=BooleanExpression)* \u0026#39;]\u0026#39; \u0026#39;}\u0026#39; ; OrExpression: {OrExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;OR\u0026#34;\u0026#39; \u0026#39;:\u0026#39; \u0026#39;[\u0026#39; conditions+=BooleanExpression (\u0026#39;,\u0026#39; conditions+=BooleanExpression)* \u0026#39;]\u0026#39; \u0026#39;}\u0026#39;; ComparisonExpression: {ComparisonExpression} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;qosMetric\u0026#34;\u0026#39; \u0026#39;:\u0026#39; qosMetric = AbstractQoSMetric \u0026#39;,\u0026#39; \u0026#39;\u0026#34;operator\u0026#34;\u0026#39; \u0026#39;:\u0026#39; operator = Operator \u0026#39;,\u0026#39; \u0026#39;\u0026#34;value\u0026#34;\u0026#39; \u0026#39;:\u0026#39; value = AnyString \u0026#39;}\u0026#39; ; Reference: {Reference} \u0026#39;{\u0026#39; \u0026#39;\u0026#34;$ref\u0026#34;\u0026#39; \u0026#39;:\u0026#39; uri=AnyString \u0026#39;}\u0026#39;; //GenericJsonExpression: //\tPrimitiveValue //\t| GenericJsonObject //\t| GenericJsonArray; // //GenericJsonObject: //\t\u0026#39;{\u0026#39; \u0026#39;}\u0026#39; | \u0026#39;{\u0026#39; GenericJsonTuple (\u0026#39;,\u0026#39; GenericJsonTuple)* \u0026#39;}\u0026#39;; // //GenericJsonArray: //\t\u0026#39;[\u0026#39; \u0026#39;]\u0026#39; | \u0026#39;[\u0026#39; GenericJsonExpression (\u0026#39;,\u0026#39; GenericJsonExpression)* \u0026#39;]\u0026#39;; // //GenericJsonTuple: AnyString \u0026#39;:\u0026#39; GenericJsonExpression; // //GenericJsonTupleButRef: AnyStringButRef \u0026#39;:\u0026#39; GenericJsonExpression; enum WindowUnit: seconds = \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | minutes = \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | hours = \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | days = \u0026#39;\u0026#34;days\u0026#34;\u0026#39; | messages = \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; ; enum AggregationFunction: AVG = \u0026#39;\u0026#34;AVG\u0026#34;\u0026#39; | MEDIAN = \u0026#39;\u0026#34;MEDIAN\u0026#34;\u0026#39; | MAX = \u0026#39;\u0026#34;MAX\u0026#34;\u0026#39; | MIN = \u0026#39;\u0026#34;MIN\u0026#34;\u0026#39; ; enum QoSMetricType: availability = \u0026#39;\u0026#34;availability\u0026#34;\u0026#39; | bandwith = \u0026#39;\u0026#34;bandwith\u0026#34;\u0026#39; | cpu = \u0026#39;\u0026#34;cpu\u0026#34;\u0026#39; | capacity = \u0026#39;\u0026#34;capacity\u0026#34;\u0026#39; | disaster = \u0026#39;\u0026#34;disaster\u0026#34;\u0026#39; | resiliance = \u0026#39;\u0026#34;resiliance\u0026#34;\u0026#39; | discoverability = \u0026#39;\u0026#34;discoverability\u0026#34;\u0026#39; | documentation = \u0026#39;\u0026#34;documentation\u0026#34;\u0026#39; | exception_handling = \u0026#39;\u0026#34;exception_handling\u0026#34;\u0026#39; | expected_failures = \u0026#39;\u0026#34;expected_failures\u0026#34;\u0026#39; | failover = \u0026#39;\u0026#34;failover\u0026#34;\u0026#39; | jitter = \u0026#39;\u0026#34;jitter\u0026#34;\u0026#39; | latency = \u0026#39;\u0026#34;latency\u0026#34;\u0026#39; | load_balancing = \u0026#39;\u0026#34;load_balancing\u0026#34;\u0026#39; | maximum_throughput = \u0026#39;\u0026#34;maximum_throughput\u0026#34;\u0026#39; | memory_aapacity = \u0026#39;\u0026#34;memory_aapacity\u0026#34;\u0026#39; | packet_loss = \u0026#39;\u0026#34;packet_loss\u0026#34;\u0026#39; | precision = \u0026#39;\u0026#34;precision\u0026#34;\u0026#39; | probability_of_correctness = \u0026#39;\u0026#34;probability_of_correctness\u0026#34;\u0026#39; | round_trip_time = \u0026#39;\u0026#34;round_trip_time\u0026#34;\u0026#39; | throughput = \u0026#39;\u0026#34;throughput\u0026#34;\u0026#39; | time_to_tail = \u0026#39;\u0026#34;time_to_tail\u0026#34;\u0026#39; | time_to_tepair = \u0026#39;\u0026#34;time_to_tepair\u0026#34;\u0026#39; | type_consistency = \u0026#39;\u0026#34;type_consistency\u0026#34;\u0026#39; | uptime = \u0026#39;\u0026#34;uptime\u0026#34;\u0026#39; | up_to_dateness = \u0026#39;\u0026#34;up-to-dateness\u0026#34;\u0026#39; ; enum QoSMetricUnit: milliseconds = \u0026#39;\u0026#34;milliseconds\u0026#34;\u0026#39; | seconds = \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | minutes = \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | hours = \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | null = \u0026#39;\u0026#34;null\u0026#34;\u0026#39; ; enum Operator: greater = \u0026#39;\u0026#34;\u0026gt;\u0026#34;\u0026#39; | greater_equal = \u0026#39;\u0026#34;\u0026gt;=\u0026#34;\u0026#39; | equal = \u0026#39;\u0026#34;=\u0026#34;\u0026#39; | less_equal = \u0026#39;\u0026#34;\u0026lt;=\u0026#34;\u0026#39; | less = \u0026#39;\u0026#34;\u0026lt;\u0026#34;\u0026#39;\t; enum JsonType: string = \u0026#39;\u0026#34;string\u0026#34;\u0026#39; | number = \u0026#39;\u0026#34;number\u0026#34;\u0026#39; | integer = \u0026#39;\u0026#34;integer\u0026#34;\u0026#39; | boolean = \u0026#39;\u0026#34;boolean\u0026#34;\u0026#39; | object = \u0026#39;\u0026#34;object\u0026#34;\u0026#39; | array = \u0026#39;\u0026#34;array\u0026#34;\u0026#39; | any = \u0026#39;\u0026#34;any\u0026#34;\u0026#39; | null = \u0026#39;\u0026#34;null\u0026#34;\u0026#39;; enum Boolean: _false = \u0026#34;false\u0026#34; | _true = \u0026#34;true\u0026#34;; enum VersionNumber: _200 = \u0026#39;\u0026#34;2.0.0\u0026#34;\u0026#39;; enum MessageIdentifier: none =\u0026#39;\u0026#34;none\u0026#34;\u0026#39; | generated = \u0026#39;\u0026#34;generated\u0026#34;\u0026#39; | md5 = \u0026#39;\u0026#34;md5\u0026#34;\u0026#39; | sha256 = \u0026#39;\u0026#34;sha-256\u0026#34;\u0026#39;; enum Protocol: amqp = \u0026#39;\u0026#34;amqp\u0026#34;\u0026#39; | amqps = \u0026#39;\u0026#34;amqps\u0026#34;\u0026#39; | http = \u0026#39;\u0026#34;http\u0026#34;\u0026#39; | https = \u0026#39;\u0026#34;https\u0026#34;\u0026#39; | jms = \u0026#39;\u0026#34;jms\u0026#34;\u0026#39; | kafka = \u0026#39;\u0026#34;kafka\u0026#34;\u0026#39; | kafka_secure = \u0026#39;\u0026#34;kafka-secure\u0026#34;\u0026#39; | mqtt = \u0026#39;\u0026#34;mqtt\u0026#34;\u0026#39; | secure_mqtt = \u0026#39;\u0026#34;secure-mqtt\u0026#34;\u0026#39; | ws = \u0026#39;\u0026#34;ws\u0026#34;\u0026#39; | wss = \u0026#39;\u0026#34;wss\u0026#34;\u0026#39; | stomp = \u0026#39;\u0026#34;stomp\u0026#34;\u0026#39; | stomps = \u0026#39;\u0026#34;stomps\u0026#34;\u0026#39;; PrimitiveValue: AnyString | \u0026#34;true\u0026#34; | \u0026#34;false\u0026#34; | INT; AnyStringButRef: STRING | Keyword; AnyString: STRING | \u0026#39;\u0026#34;$ref\u0026#34;\u0026#39; | Keyword; terminal ID: \u0026#39;^\u0026#39;?(\u0026#39;a\u0026#39;..\u0026#39;z\u0026#39;|\u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;|\u0026#39;_\u0026#39;) (\u0026#39;a\u0026#39;..\u0026#39;z\u0026#39;|\u0026#39;A\u0026#39;..\u0026#39;Z\u0026#39;|\u0026#39;_\u0026#39;|\u0026#39;0\u0026#39;..\u0026#39;9\u0026#39;)*; terminal INT returns ecore::EInt: (\u0026#39;0\u0026#39;..\u0026#39;9\u0026#39;)+; terminal STRING: \u0026#39;\u0026#34;\u0026#39; ( \u0026#39;\\\\\u0026#39; . | !(\u0026#39;\\\\\u0026#39;|\u0026#39;\u0026#34;\u0026#39;) )* \u0026#39;\u0026#34;\u0026#39; | \u0026#34;\u0026#39;\u0026#34; ( \u0026#39;\\\\\u0026#39; . | !(\u0026#39;\\\\\u0026#39;|\u0026#34;\u0026#39;\u0026#34;) )* \u0026#34;\u0026#39;\u0026#34;; terminal WS: (\u0026#39; \u0026#39;|\u0026#39;\\t\u0026#39;|\u0026#39;\\r\u0026#39;|\u0026#39;\\n\u0026#39;)+; Keyword: \u0026#39;\u0026#34;2.0.0\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026lt;\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026lt;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026gt;\u0026#34;\u0026#39; | \u0026#39;\u0026#34;\u0026gt;=\u0026#34;\u0026#39; | \u0026#39;\u0026#34;AND\u0026#34;\u0026#39; | \u0026#39;\u0026#34;AVG\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MAX\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MEDIAN\u0026#34;\u0026#39; | \u0026#39;\u0026#34;MIN\u0026#34;\u0026#39; | \u0026#39;\u0026#34;OR\u0026#34;\u0026#39; | \u0026#39;\u0026#34;aggregationFunction\u0026#34;\u0026#39; | \u0026#39;\u0026#34;amqp\u0026#34;\u0026#39; | \u0026#39;\u0026#34;amqps\u0026#34;\u0026#39; | \u0026#39;\u0026#34;any\u0026#34;\u0026#39; | \u0026#39;\u0026#34;array\u0026#34;\u0026#39; | \u0026#39;\u0026#34;asyncapi\u0026#34;\u0026#39; | \u0026#39;\u0026#34;availability\u0026#34;\u0026#39; | \u0026#39;\u0026#34;bandwith\u0026#34;\u0026#39; | \u0026#39;\u0026#34;boolean\u0026#34;\u0026#39; | \u0026#39;\u0026#34;capacity\u0026#34;\u0026#39; | \u0026#39;\u0026#34;channels\u0026#34;\u0026#39; | \u0026#39;\u0026#34;components\u0026#34;\u0026#39; | \u0026#39;\u0026#34;contact\u0026#34;\u0026#39; | \u0026#39;\u0026#34;cpu\u0026#34;\u0026#39; | \u0026#39;\u0026#34;dataType\u0026#34;\u0026#39; | \u0026#39;\u0026#34;days\u0026#34;\u0026#39; | \u0026#39;\u0026#34;default\u0026#34;\u0026#39; | \u0026#39;\u0026#34;deprecated\u0026#34;\u0026#39; | \u0026#39;\u0026#34;derivedQoSMetricDefinition\u0026#34;\u0026#39; | \u0026#39;\u0026#34;description\u0026#34;\u0026#39; | \u0026#39;\u0026#34;disaster\u0026#34;\u0026#39; | \u0026#39;\u0026#34;discoverability\u0026#34;\u0026#39; | \u0026#39;\u0026#34;documentation\u0026#34;\u0026#39; | \u0026#39;\u0026#34;email\u0026#34;\u0026#39; | \u0026#39;\u0026#34;enum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;exception_handling\u0026#34;\u0026#39; | \u0026#39;\u0026#34;expected_failures\u0026#34;\u0026#39; | \u0026#39;\u0026#34;failover\u0026#34;\u0026#39; | \u0026#39;\u0026#34;format\u0026#34;\u0026#39; | \u0026#39;\u0026#34;groupedByEvent\u0026#34;\u0026#39; | \u0026#39;\u0026#34;guaranteeTerm\u0026#34;\u0026#39; | \u0026#39;\u0026#34;headers\u0026#34;\u0026#39; | \u0026#39;\u0026#34;hours\u0026#34;\u0026#39; | \u0026#39;\u0026#34;http\u0026#34;\u0026#39; | \u0026#39;\u0026#34;https\u0026#34;\u0026#39; | \u0026#39;\u0026#34;info\u0026#34;\u0026#39; | \u0026#39;\u0026#34;integer\u0026#34;\u0026#39; | \u0026#39;\u0026#34;items\u0026#34;\u0026#39; | \u0026#39;\u0026#34;jitter\u0026#34;\u0026#39; | \u0026#39;\u0026#34;jms\u0026#34;\u0026#39; | \u0026#39;\u0026#34;kafka\u0026#34;\u0026#39; | \u0026#39;\u0026#34;kafka-secure\u0026#34;\u0026#39; | \u0026#39;\u0026#34;latency\u0026#34;\u0026#39; | \u0026#39;\u0026#34;license\u0026#34;\u0026#39; | \u0026#39;\u0026#34;load_balancing\u0026#34;\u0026#39; | \u0026#39;\u0026#34;location\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maxItems\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maximum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;maximum_throughput\u0026#34;\u0026#39; | \u0026#39;\u0026#34;memory_aapacity\u0026#34;\u0026#39; | \u0026#39;\u0026#34;message\u0026#34;\u0026#39; | \u0026#39;\u0026#34;messageTraits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;messages\u0026#34;\u0026#39; | \u0026#39;\u0026#34;metricType\u0026#34;\u0026#39; | \u0026#39;\u0026#34;milliseconds\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minItems\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minimum\u0026#34;\u0026#39; | \u0026#39;\u0026#34;minutes\u0026#34;\u0026#39; | \u0026#39;\u0026#34;mqtt\u0026#34;\u0026#39; | \u0026#39;\u0026#34;mqtts\u0026#34;\u0026#39; | \u0026#39;\u0026#34;name\u0026#34;\u0026#39; | \u0026#39;\u0026#34;null\u0026#34;\u0026#39; | \u0026#39;\u0026#34;number\u0026#34;\u0026#39; | \u0026#39;\u0026#34;object\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operationId\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operationTraits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;operator\u0026#34;\u0026#39; | \u0026#39;\u0026#34;packet_loss\u0026#34;\u0026#39; | \u0026#39;\u0026#34;parameters\u0026#34;\u0026#39; | \u0026#39;\u0026#34;payload\u0026#34;\u0026#39; | \u0026#39;\u0026#34;precision\u0026#34;\u0026#39; | \u0026#39;\u0026#34;probability_of_correctness\u0026#34;\u0026#39; | \u0026#39;\u0026#34;properties\u0026#34;\u0026#39; | \u0026#39;\u0026#34;protocol\u0026#34;\u0026#39; | \u0026#39;\u0026#34;publish\u0026#34;\u0026#39; | \u0026#39;\u0026#34;qosMetric\u0026#34;\u0026#39; | \u0026#39;\u0026#34;qualifyingConditions\u0026#34;\u0026#39; | \u0026#39;\u0026#34;required\u0026#34;\u0026#39; | \u0026#39;\u0026#34;resiliance\u0026#34;\u0026#39; | \u0026#39;\u0026#34;round_trip_time\u0026#34;\u0026#39; | \u0026#39;\u0026#34;schema\u0026#34;\u0026#39; | \u0026#39;\u0026#34;schemas\u0026#34;\u0026#39; | \u0026#39;\u0026#34;scopes\u0026#34;\u0026#39; | \u0026#39;\u0026#34;seconds\u0026#34;\u0026#39; | \u0026#39;\u0026#34;secure-mqtt\u0026#34;\u0026#39; | \u0026#39;\u0026#34;servers\u0026#34;\u0026#39; | \u0026#39;\u0026#34;slos\u0026#34;\u0026#39; | \u0026#39;\u0026#34;stomp\u0026#34;\u0026#39; | \u0026#39;\u0026#34;stomps\u0026#34;\u0026#39; | \u0026#39;\u0026#34;string\u0026#34;\u0026#39; | \u0026#39;\u0026#34;subscribe\u0026#34;\u0026#39; | \u0026#39;\u0026#34;summary\u0026#34;\u0026#39; | \u0026#39;\u0026#34;tags\u0026#34;\u0026#39; | \u0026#39;\u0026#34;termsOfService\u0026#34;\u0026#39; | \u0026#39;\u0026#34;throughput\u0026#34;\u0026#39; | \u0026#39;\u0026#34;time_to_tail\u0026#34;\u0026#39; | \u0026#39;\u0026#34;time_to_tepair\u0026#34;\u0026#39; | \u0026#39;\u0026#34;title\u0026#34;\u0026#39; | \u0026#39;\u0026#34;traits\u0026#34;\u0026#39; | \u0026#39;\u0026#34;type\u0026#34;\u0026#39; | \u0026#39;\u0026#34;type_consistency\u0026#34;\u0026#39; | \u0026#39;\u0026#34;unit\u0026#34;\u0026#39; | \u0026#39;\u0026#34;up-to-dateness\u0026#34;\u0026#39; | \u0026#39;\u0026#34;uptime\u0026#34;\u0026#39; | \u0026#39;\u0026#34;url\u0026#34;\u0026#39; | \u0026#39;\u0026#34;value\u0026#34;\u0026#39; | \u0026#39;\u0026#34;variables\u0026#34;\u0026#39; | \u0026#39;\u0026#34;version\u0026#34;\u0026#39; | \u0026#39;\u0026#34;window\u0026#34;\u0026#39; | \u0026#39;\u0026#34;windowUnit\u0026#34;\u0026#39; | \u0026#39;\u0026#34;ws\u0026#34;\u0026#39; | \u0026#39;\u0026#34;wss\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-basePackage\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-qosMetrics\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-sla\u0026#34;\u0026#39; | \u0026#39;\u0026#34;x-title\u0026#34;\u0026#39;; ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/asyncapi-code-generator/","summary":"Background IIoT（工业物联网）架构通常是分布式和异步的，通信由事件驱动，如消息的发布（和相应的订阅）。这些异步架构提高了可扩展性和对变化的耐受性，但也引发了互操作性问题，因为架构各元素之间对消息内部结构及其分类（主题）的明确知识被稀释了。\n事实上，这也是 REST 应用程序接口面临的一个问题，直到业界联合起来，提出了一种定义同步应用程序接口结构和模式的标准方法：OpenAPI（源自 Swagger）。\nIntroduction 对于异步架构，受 OpenAPI 的启发，AsyncAPI 的出现解决了这一问题：\nAsyncAPI 提供了一种规范，允许您以机器可读的格式定义消息驱动的 API。它与协议无关，因此可以用于通过 Kafka、MQTT、AMQP、WebSockets、STOMP 等工作的 API。该规范与 OpenAPI/Swagger 非常相似，所以如果你熟悉它，AsyncAPI 对你来说应该很容易。\n在 AsyncAPI 中，API 的规格可以用 YAML 或 JSON 定义，例如可以指定消息代理、感兴趣的主题或与每个主题相关的不同消息格式等。不过，AsyncAPI 还处于开发的早期阶段，AsyncAPI 工具市场还不发达，主要局限于生成供人类使用的文档。\nAsyncAPI 最初的贡献就是上图中展示的方法。\nAsyncAPI Toolkit 如上图所示，AsyncAPI 团队扩展了这一初始框架。基于 AsyncAPI 规范在 Xtext 中开发 AsyncAPI JSON 语法的，该语法可验证符合 AsyncAPI 规范的消息驱动 API 定义。同样，根据该语法，Xtext 会自动生成相应的 AsyncAPI 元模型和所有工具（带内容辅助功能的编辑器、解析器等），以便轻松创建 AsyncAPI JSON 定义并将其转换为符合 AsyncAPI 元模型的 AsyncAPI 模型。\n有了 AsyncAPI 元模型和作为符合模型的应用程序接口规范，就可以通过执行 M2T 转换（生成内部 DSL）来继续工作流程。目前，AsyncAPI Toolkit 支持 Java 语言，并生成一个库，通过提供流畅的 API 来协助开发人员创建、发布和接收格式良好的消息。\n值得注意的是，由于这些架构都是基于 message 的，因此数据建模起着至关重要的作用。因此，我们在上述工作流程中使用了另一种（图形化）具体语法，重点是对要交换的消息进行建模。这可用于引导 AsyncAPI JSON 定义，随后可对其进行手动完善。","title":"A Modeling Editor and Code Generator for message-driven architectures with AsyncAPI"},{"content":"OpenAPI Generator 可根据 OpenAPI yaml 规范生成代码，并支持多种语言。\n如何使用 OpenAPI 本节介绍如何创建一个基本的 OpenAPI yaml 规范，并用它为 Spring Boot 应用程序生成服务器端代码。\nCreate OpenAPI spec 首先要做的是为您的应用程序设计 OpenAPI 规范。您将设计一个客户 API。该 API 允许您创建一个客户，并根据其 ID 检索该客户。现实生活中的应用程序接口会更加复杂，但我们还是保持简单。\n使用 Swagger 编辑器 是设计 API 的简便方法。它会立即反馈您的规范是否有错误，并即时生成 Swagger 文档。\nOpenAPI 规范的 header 包含一些有关 API 的元数据，如标题、版本、API 运行的服务器等。标签可用于对资源进行分组，从而为您提供更多概览。\n1 2 3 4 5 6 7 8 9 openapi: \u0026#34;3.0.2\u0026#34; info: title: API Customer version: \u0026#34;1.0\u0026#34; servers: - url: https://localhost:8080 tags: - name: Customer description: Customer specific data. paths 部分包含资源规范。您定义的第一个资源是创建 Customer 的资源，将通过包含 JSON 主体的 POST 方式创建。生成器将使用 operationId 为该资源创建方法名称。为简单起见，只考虑成功响应。模式指的是 JSON 主体，将在本节后面介绍。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 /customer: post: tags: - Customer summary: Create Customer operationId: createCustomer requestBody: content: application/json: schema: $ref: \u0026#39;#/components/schemas/Customer\u0026#39; responses: \u0026#39;200\u0026#39;: description: OK content: \u0026#39;application/json\u0026#39;: schema: $ref: \u0026#39;#/components/schemas/CustomerFullData\u0026#39; 第二个资源允许您检索客户。该资源也需要一个包含要检索的 customerId 的路径参数。如果 ID 不存在，将返回 NOT FOUND 的响应。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 /customer/{customerId}: get: tags: - Customer summary: Retrieve Customer operationId: getCustomer parameters: - name: customerId in: path required: true schema: type: integer format: int64 responses: \u0026#39;200\u0026#39;: description: OK content: \u0026#39;application/json\u0026#39;: schema: $ref: \u0026#39;#/components/schemas/CustomerFullData\u0026#39; \u0026#39;404\u0026#39;: description: NOT FOUND 最后，在组件部分，定义了使用的模式。除了 ID 之外，Customer 模式和 CustomerFullData 模式共享所有属性。为了提高可维护性，可以使用 allOf 属性。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 components: schemas: Customer: type: object properties: firstName: type: string description: First name of the customer lastName: type: string description: Last name of the customer CustomerFullData: allOf: - $ref: \u0026#39;#/components/schemas/Customer\u0026#39; - type: object properties: customerId: type: integer description: The ID of the customer format: int64 description: Full data of the customer. 该应用程序的 OpenAPI 规范现已完成。\nCreate Spring Boot Application 要创建 Spring Boot 应用程序，请访问 start.spring.io，选择最新稳定的 Spring Boot 版本、Java 17 并添加 Spring Web 依赖关系。下载生成的项目并将其打开到您喜欢的集成开发环境中。在 src/main/resources 目录中添加 OpenAPI 规范，名称为 customer.yml。\n您将使用 Open API Generator Maven 插件，因此请将该插件添加到 pom 文件的构建部分。由于您使用的是 Spring Boot 应用程序，因此使用 spring 作为 generatorName，并使用 inputSpec 属性设置 customer.yml 文件的路径。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.openapitools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;openapi-generator-maven-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;5.3.0\u0026lt;/version\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;generate\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/customer.yml\u0026lt;/inputSpec\u0026gt; \u0026lt;generatorName\u0026gt;spring\u0026lt;/generatorName\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; 执行以下命令生成代码：\n1 $ mvn clean compile 编译失败，出现以下错误：\n1 2 3 4 package io.swagger.annotations does not exist package io.swagger.annotations does not exist package org.openapitools.jackson.nullable does not exist cannot find symbol 为了解决这些问题，需要在 pom 文件中添加以下依赖项：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.swagger\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;swagger-annotations\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.6.3\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;javax.validation\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;validation-api\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.0.1.Final\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openapitools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jackson-databind-nullable\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.2.1\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 再次运行编译会出现以下错误：\n1 2 3 4 5 6 7 8 9 package springfox.documentation.builders does not exist package springfox.documentation.builders does not exist package springfox.documentation.service does not exist package springfox.documentation.service does not exist package springfox.documentation.spi does not exist package springfox.documentation.spring.web.paths does not exist package springfox.documentation.spring.web.paths does not exist package springfox.documentation.spring.web.plugins does not exist package springfox.documentation.swagger2.annotations does not exist 在 pom 文件中添加以下依赖项可以解决这些错误：\n1 2 3 4 5 6 7 8 9 10 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-swagger-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.springfox\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springfox-swagger2\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;2.6.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 仔细看看生成了什么。导航至 target/generated-sources/open-api 目录，在该目录中可以找到生成的文件。以下目录包含生成的文件：\nsrc/main/org/openapitools/api : 是 Spring 控制器的一个接口，也是一个实现 src/main/org/openapitools/configuration : 是 Swagger 文档的控制器 src/main/org/openapitools/model : 基于 API 规范的 API 模型 src/main/org/openapitools : OpenAPI2SpringBoot 是一个 SpringBootApplication 当你想运行 Spring Boot 应用程序时，你会遇到一个错误，因为 Spring Boot 无法确定它需要运行哪个 SpringBootApplication :\n1 $ mvn spring-boot:run 由此产生的错误是 :\n1 Unable to find a single main class from the following candidates [org.openapitools.OpenAPI2SpringBoot, com.mydeveloperplanet.myopenapiplanet.MyOpenApiPlanetApplication 默认情况下会生成大量代码，也许比你需要的还要多。下一段将介绍如何调整配置。\nConfigure OpenAPI plugin 除了 OpenAPI 插件的 Maven 部分记录的所有选项外，还有许多额外的选项可在 OpenAPI 插件配置部分的 configOptions 部分进行配置。可通过在配置部分添加 configHelp 属性来显示可用选项。\n1 2 3 4 5 \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/customer.yml\u0026lt;/inputSpec\u0026gt; \u0026lt;generatorName\u0026gt;spring\u0026lt;/generatorName\u0026gt; \u0026lt;configHelp\u0026gt;true\u0026lt;/configHelp\u0026gt; \u0026lt;/configuration\u0026gt; 在此列表中，您将使用 interfaceOnly 属性，它只会为控制器和 API 模型生成接口。\n1 2 3 4 5 6 \u0026lt;configuration\u0026gt; ... \u0026lt;configOptions\u0026gt; \u0026lt;interfaceOnly\u0026gt;true\u0026lt;/interfaceOnly\u0026gt; \u0026lt;/configOptions\u0026gt; \u0026lt;/configuration\u0026gt; 此时，还可以删除之前添加的 Springfox 依赖项。这些都不再需要了。\n从生成的代码中还可以看到，代码是在 org.openapitools 包中生成的。你可能希望这是你自己的软件包名称，这可以通过一些基本属性来配置。通过 packageName 属性，您可以设置默认的软件包名称。不过，还必须设置 apiPackage 和 modelPackage 属性，否则这些属性仍将在 org.openapitools 包中生成。在配置部分添加以下内容。\n1 2 3 4 5 6 7 \u0026lt;configuration\u0026gt; .... \u0026lt;packageName\u0026gt;com.mydeveloperplanet.myopenapiplanet\u0026lt;/packageName\u0026gt; \u0026lt;apiPackage\u0026gt;com.mydeveloperplanet.myopenapiplanet.api\u0026lt;/apiPackage\u0026gt; \u0026lt;modelPackage\u0026gt;com.mydeveloperplanet.myopenapiplanet.model\u0026lt;/modelPackage\u0026gt; .... \u0026lt;/configuration\u0026gt; 生成的控制器界面如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 @javax.annotation.Generated(value = \u0026#34;org.openapitools.codegen.languages.SpringCodegen\u0026#34;, date = \u0026#34;2022-01-15T12:51:43.809971036+01:00[Europe/Amsterdam]\u0026#34;) @Validated @Api(value = \u0026#34;customer\u0026#34;, description = \u0026#34;the customer API\u0026#34;) public interface CustomerApi { default Optional\u0026lt;NativeWebRequest\u0026gt; getRequest() { return Optional.empty(); } /** * POST /customer : Create Customer * * @param customer (optional) * @return OK (status code 200) */ @ApiOperation(value = \u0026#34;Create Customer\u0026#34;, nickname = \u0026#34;createCustomer\u0026#34;, notes = \u0026#34;\u0026#34;, response = CustomerFullData.class, tags={ \u0026#34;Customer\u0026#34;, }) @ApiResponses(value = { @ApiResponse(code = 200, message = \u0026#34;OK\u0026#34;, response = CustomerFullData.class) }) @RequestMapping( method = RequestMethod.POST, value = \u0026#34;/customer\u0026#34;, produces = { \u0026#34;application/json\u0026#34; }, consumes = { \u0026#34;application/json\u0026#34; } ) default ResponseEntity\u0026lt;CustomerFullData\u0026gt; createCustomer(@ApiParam(value = \u0026#34;\u0026#34;) @Valid @RequestBody(required = false) Customer customer) { getRequest().ifPresent(request -\u0026gt; { for (MediaType mediaType: MediaType.parseMediaTypes(request.getHeader(\u0026#34;Accept\u0026#34;))) { if (mediaType.isCompatibleWith(MediaType.valueOf(\u0026#34;application/json\u0026#34;))) { String exampleString = \u0026#34;null\u0026#34;; ApiUtil.setExampleResponse(request, \u0026#34;application/json\u0026#34;, exampleString); break; } } }); return new ResponseEntity\u0026lt;\u0026gt;(HttpStatus.NOT_IMPLEMENTED); } ... Use Generated Code 在应用程序中，首先要在包 domain 中创建一个 Customer 类。\n1 2 3 4 5 6 public class Customer { private Long customerId; private String firstName; private String lastName; // Getters and setters } 创建一个 CustomerController，实现生成的 CustomerApi 接口。\n创建 Customer 是一种基本的实现方式，您可以将 Customer 添加到 HashMap 中：计算索引是键，域客户对象是值。在实际应用中，您将把客户保存到数据库中。\n检索客户时，首先要检查所请求的 ID 是否存在于 HashMap 中。找到 ID 后，Customer 域对象将转换为 Customer API 模型对象并返回给请求者。如果未找到 ID，则会返回 NOT FOUND 响应。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 @RestController public class CustomerController implements CustomerApi { private final HashMap\u0026lt;Long, com.mydeveloperplanet.myopenapiplanet.domain.Customer\u0026gt; customers = new HashMap\u0026lt;\u0026gt;(); private Long index = 0L; @Override public ResponseEntity\u0026lt;CustomerFullData\u0026gt; createCustomer(Customer apiCustomer) { com.mydeveloperplanet.myopenapiplanet.domain.Customer customer = new com.mydeveloperplanet.myopenapiplanet.domain.Customer(); customer.setCustomerId(index); customer.setFirstName(apiCustomer.getFirstName()); customer.setLastName(apiCustomer.getLastName()); customers.put(index, customer); index++; return ResponseEntity.ok(domainToApi(customer)); } @Override public ResponseEntity\u0026lt;CustomerFullData\u0026gt; getCustomer(Long customerId) { if (customers.containsKey(customerId)) { return ResponseEntity.ok(domainToApi(customers.get(customerId))); } else { return new ResponseEntity\u0026lt;\u0026gt;(HttpStatus.NOT_FOUND); } } private CustomerFullData domainToApi(com.mydeveloperplanet.myopenapiplanet.domain.Customer customer) { CustomerFullData cfd = new CustomerFullData(); cfd.setCustomerId(customer.getCustomerId()); cfd.setFirstName(customer.getFirstName()); cfd.setLastName(customer.getLastName()); return cfd; } } 运行 Spring Boot 应用程序：\n1 $ mvn spring-boot:run 添加 Consumer，并查找\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 $ curl -i -X \u0026#39;POST\u0026#39; \\ \u0026gt; \u0026#39;http://localhost:8080/customer\u0026#39; \\ \u0026gt; -H \u0026#39;accept: application/json\u0026#39; \\ \u0026gt; -H \u0026#39;Content-Type: application/json\u0026#39; \\ \u0026gt; -d \u0026#39;{ \u0026gt; \u0026#34;firstName\u0026#34;: \u0026#34;Foo\u0026#34;, \u0026gt; \u0026#34;lastName\u0026#34;: \u0026#34;Bar\u0026#34; \u0026gt; }\u0026#39; HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:42:47 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;Foo\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Bar\u0026#34;,\u0026#34;customerId\u0026#34;:0} $ curl -i -X \u0026#39;POST\u0026#39; \\ \u0026gt; \u0026#39;http://localhost:8080/customer\u0026#39; \\ \u0026gt; -H \u0026#39;accept: application/json\u0026#39; \\ \u0026gt; -H \u0026#39;Content-Type: application/json\u0026#39; \\ \u0026gt; -d \u0026#39;{ \u0026gt; \u0026#34;firstName\u0026#34;: \u0026#34;John\u0026#34;, \u0026gt; \u0026#34;lastName\u0026#34;: \u0026#34;Doe\u0026#34; \u0026gt; }\u0026#39; HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:43:11 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34;,\u0026#34;customerId\u0026#34;:1} $ curl -i http://localhost:8080/customer/1 HTTP/1.1 200 Content-Type: application/json Transfer-Encoding: chunked Date: Sat, 15 Jan 2022 11:45:21 GMT {\u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34;,\u0026#34;customerId\u0026#34;:1} $ curl -i http://localhost:8080/customer/2 HTTP/1.1 404 Content-Length: 0 Date: Sat, 15 Jan 2022 11:46:18 GMT Add OpenAPI Documentation https://springdoc.org/ 1 2 3 4 5 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;springdoc-openapi-ui\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.5.12\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 在浏览器中导航至 http://localhost:8080/swagger-ui.html，即可显示 OpenAPI 文档，并可在此处下载 OpenAPI yaml 规范。\n当你仔细查看文档时，会发现它与 Swagger 编辑器中显示的文档有所不同。springdoc 依赖项默认会从源代码生成文档，并使用生成的文档。如何配置 springdoc 以使用 customer.yml 文件？\n首先，您需要将 customer.yml 文件移至 src/main/resources/static/customer.yml 目录。这也意味着你需要更改 pom 中的 Open API 生成器配置。\n1 2 3 4 \u0026lt;configuration\u0026gt; \u0026lt;inputSpec\u0026gt;${project.basedir}/src/main/resources/static/customer.yml\u0026lt;/inputSpec\u0026gt; ... \u0026lt;/configuration\u0026gt; 在 application.properties 文件中添加以下属性\n1 springdoc.swagger-ui.url=/customer.yml URL 现在显示的是您创建的 customer.yml 中定义的 API\nResources 官方 OpenAPI Specification v3.1.0 repo https://tools.openapis.org/categories/code-generators.html Blogs Open API Server Implementation Using OpenAPI Generator Generate Server Code Using OpenAPI Generator ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/openapi-code-generator/","summary":"OpenAPI Generator 可根据 OpenAPI yaml 规范生成代码，并支持多种语言。\n如何使用 OpenAPI 本节介绍如何创建一个基本的 OpenAPI yaml 规范，并用它为 Spring Boot 应用程序生成服务器端代码。\nCreate OpenAPI spec 首先要做的是为您的应用程序设计 OpenAPI 规范。您将设计一个客户 API。该 API 允许您创建一个客户，并根据其 ID 检索该客户。现实生活中的应用程序接口会更加复杂，但我们还是保持简单。\n使用 Swagger 编辑器 是设计 API 的简便方法。它会立即反馈您的规范是否有错误，并即时生成 Swagger 文档。\nOpenAPI 规范的 header 包含一些有关 API 的元数据，如标题、版本、API 运行的服务器等。标签可用于对资源进行分组，从而为您提供更多概览。\n1 2 3 4 5 6 7 8 9 openapi: \u0026#34;3.0.2\u0026#34; info: title: API Customer version: \u0026#34;1.0\u0026#34; servers: - url: https://localhost:8080 tags: - name: Customer description: Customer specific data. paths 部分包含资源规范。您定义的第一个资源是创建 Customer 的资源，将通过包含 JSON 主体的 POST 方式创建。生成器将使用 operationId 为该资源创建方法名称。为简单起见，只考虑成功响应。模式指的是 JSON 主体，将在本节后面介绍。","title":"Openapi Code Generator"},{"content":"REST 全称是 Representational State Transfer（表现层状态转化），更具体的全称是 Resource Representational State Transfer（资源表现层状态转化），具体可以见 Roy Thomas Fielding 的博士论文 https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm 这一章。\nREST 指的是一组架构约束条件和原则：\n为设计一个功能强、性能好、适宜通信的 web 应用 如果一个架构符合 REST 的约束条件和原则，我们就称它为 RESTful 结构 Resources restful petclinic tutorial docter paper bilibili-软件体系结构-2022.7-REST Create REST APIs with JAX-RS 核心概念 资源（Resources） 表现层（Representation） 状态转化（State Transfer） 资源 网络上的一个实体，或者说是网络上的一个具体信息，任何事物，只要有被引用到的必要，它就是一个资源。\n一段文本，一张图片，一首歌曲 数据库中的一行数据 一个手机号码，某用户的个人信息 一种服务 资源标识 要让一个资源可以被识别，需要有个唯一标识，在Web中这个唯一标识就是URI（Uniform Resource Identifier）。例如：\nhttps://www.ex.com/software/releases/latest.tar.gz https://www.ex.com/map/roads/USA/CA/17_mile_drive https://www.ex.com/search/cs578 URI 设计原则\n易读： https://www.oschina.net/news/38119/oschina-translate-reward-plan 表达资源的层级关系： https://github.com/git/git/commit/e3ae056f87e1d675913d08/orders/2012/10 表示资源的同级关系： /git/block-sha1/sha1.h/compare/e3af72cda056f87e;bd63e61bdf38eb264 表达资源的过滤： https://github.com/git/git/pulls?q=is%3Aclosed 统一资源接口\nRESTful 架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的 HTTP 方法如 GET，PUT 和 POST，并遵循这些方法的语义 如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性 GET和HEAD请求是安全的，无论请求多少次，都不改变服务器状态 GET、HEAD、PUT和DELETE请求是幂等的，无论对资源操作多少次，结果总是一样的，后面的请求并不会产生比第一次更多的影响 GET 获取表示，变更时获取表示（缓存）。安全且幂等。\n200: OK，表示已在响应中发出 204: 无内容，资源有空表示 301: Moved Permanently，资源的URI已被更新 303: See Other，其他（如，负载均衡） 304: not modified，资源未更改（缓存） 400: bad request，指代坏请求（如，参数错误） 404: not found，资源不存在 406: not acceptable，服务端不支持所需表示 500: internal server error，通用错误响应 503: Service Unavailable，服务端当前无法处理请求 POST 使用服务端管理的（自动产生）的实例号创建资源，或创建子资源，部分更新资源，如果没有被修改，则不过更新资源（乐观锁）。不安全且不幂等。\n406: not acceptable，服务端不支持所需表示 409: conflict，通用冲突 412: Precondition Failed，前置条件失败（如执行条件更新时的冲突） 415: unsupported media type，接受到的表示不受支持 500: internal server error，通用错误响应 503: Service Unavailable，服务当前无法处理请求 PUT 用客户端管理的实例号创建一个资源，通过替换的方式更新资源，如果未被修改，则更新资源（乐观锁）。不安全但幂等。\n200: OK，如果已存在资源被更改 201: created，如果新资源被创建 301: Moved Permanently，资源的URI已更改 303: See Other，其他（如，负载均衡） 400: bad request，指代坏请求 404: not found，资源不存在 DELETE 删除资源。不安全但幂等。\n200: OK，资源已被删除 301: Moved Permanently，资源的URI已更改 303: See Other，其他，如负载均衡 400: bad request，指代坏请求 404: not found，资源不存在 409: conflict，通用冲突 500: internal server error，通用错误响应 503: Service Unavailable，服务端当前无法处理请求 指导意义 统一资源接口要求使用标准的HTTP方法对资源进行操作，所以URI只应该来表示资源的名称，而不应该包括资源的操作。通俗来说，URI不应该使用动作来描述。例如：\nPOST /getUser?id=1 $\\rightarrow$ GET /Uset/1 GET /newUser $\\rightarrow$ POST /User GET /updateUser $\\rightarrow$ PUT /User/1 GET /deleteUser?id=2 $\\rightarrow$ DELETE /User/2 表现 (Representation) \u0026ldquo;资源\u0026quot;是一种信息实体，它可以有多种外在表现形式。我们把\u0026quot;资源\u0026quot;具体呈现出来的形式，叫做它的\u0026quot;表现层\u0026rdquo;（Representation）\n文本可以用txt格式表现，也可以用HTML格式、XMIL格式、JSON格式表现，甚至可以采用二进制格式 图片可以用JPG格式表现，也可以用PNG格式表示 资源表述 URI只代表资源的实体，不代表它的形式。严格地说，有些网址最后的 .html 后缀名是不必要的，因为这个后缀名表示格式，属于 \u0026ldquo;表现层\u0026rdquo; 范畴，而URI应该只代表 \u0026ldquo;资源\u0026rdquo; 的位置。\n资源的表述包括数据和描述数据的元数据，例如，HTTP头 \u0026ldquo;Content-Type\u0026rdquo; 就是这样一个元数据属性\n客户端可以通过 Accept 头请求一种特定格式的表述，服务端则通过 Content-Type 告诉客户端资源的表述形式\n支持的表达\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 ~ » http get https://api.github.com/orgs/github \u0026#39;Accept: application/json\u0026#39; HTTP/1.1 200 OK Content-Type: application/json; charset=utf-8 { \u0026#34;archived_at\u0026#34;: null, \u0026#34;avatar_url\u0026#34;: \u0026#34;https://avatars.githubusercontent.com/u/9919?v=4\u0026#34;, \u0026#34;blog\u0026#34;: \u0026#34;https://github.com/about\u0026#34;, \u0026#34;company\u0026#34;: null, \u0026#34;created_at\u0026#34;: \u0026#34;2008-05-11T04:37:31Z\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;How people build software.\u0026#34;, \u0026#34;email\u0026#34;: null, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/events\u0026#34;, \u0026#34;followers\u0026#34;: 29993, \u0026#34;following\u0026#34;: 0, \u0026#34;has_organization_projects\u0026#34;: true, \u0026#34;has_repository_projects\u0026#34;: true, \u0026#34;hooks_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/hooks\u0026#34;, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github\u0026#34;, \u0026#34;id\u0026#34;: 9919, \u0026#34;is_verified\u0026#34;: true, \u0026#34;issues_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/issues\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;San Francisco, CA\u0026#34;, \u0026#34;login\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;members_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/members{/member}\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;GitHub\u0026#34;, \u0026#34;node_id\u0026#34;: \u0026#34;MDEyOk9yZ2FuaXphdGlvbjk5MTk=\u0026#34;, \u0026#34;public_gists\u0026#34;: 0, \u0026#34;public_members_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/public_members{/member}\u0026#34;, \u0026#34;public_repos\u0026#34;: 477, \u0026#34;repos_url\u0026#34;: \u0026#34;https://api.github.com/orgs/github/repos\u0026#34;, \u0026#34;twitter_username\u0026#34;: null, \u0026#34;type\u0026#34;: \u0026#34;Organization\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2022-11-29T19:44:55Z\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/orgs/github\u0026#34; } 不支持的表达\n1 2 3 4 5 6 7 8 ~ » http get https://api.github.com/orgs/github \u0026#39;Accept: text/xml\u0026#39; HTTP/1.1 415 Unsupported Media Type Content-Type: application/json; charset=utf-8 { \u0026#34;documentation_url\u0026#34;: \u0026#34;https://docs.github.com/v3/media\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;Unsupported \u0026#39;Accept\u0026#39; header: \u0026#39;text/xml\u0026#39;. Must accept \u0026#39;application/json\u0026#39;.\u0026#34; } 资源链接 当你浏览Web网页时，从一个连接跳到一个页面，再从另一个连接跳到另外一冬页面，就是利用了超媒体的概念：把一个个把资源链接起来。\n同样，我们在表述格式里边加入链接来引导客户端：\n在Link头告诉客户端怎么访问下一页和最后一页的记录； 在响应体里用url来链接项目所有者和项目地址 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 ~ » http -h get https://api.github.com/orgs/github/repos HTTP/1.1 200 OK Content-Type: application/json; charset=utf-8 Link: \u0026lt;https://api.github.com/organizations/9919/repos?page=2\u0026gt;; rel=\u0026#34;next\u0026#34;, \u0026lt;https://api.github.com/organizations/9919/repos?page=16\u0026gt;; rel=\u0026#34;last\u0026#34; [ { \u0026#34;id\u0026#34;: 3222, \u0026#34;node_id\u0026#34;: \u0026#34;MDEwOlJlcG9zaXRvcnkzMjIy\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;media\u0026#34;, \u0026#34;full_name\u0026#34;: \u0026#34;github/media\u0026#34;, \u0026#34;private\u0026#34;: false, \u0026#34;owner\u0026#34;: { \u0026#34;login\u0026#34;: \u0026#34;github\u0026#34;, \u0026#34;id\u0026#34;: 9919, \u0026#34;node_id\u0026#34;: \u0026#34;MDEyOk9yZ2FuaXphdGlvbjk5MTk=\u0026#34;, \u0026#34;avatar_url\u0026#34;: \u0026#34;https://avatars.githubusercontent.com/u/9919?v=4\u0026#34;, \u0026#34;gravatar_id\u0026#34;: \u0026#34;\u0026#34;, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/users/github\u0026#34;, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github\u0026#34;, \u0026#34;followers_url\u0026#34;: \u0026#34;https://api.github.com/users/github/followers\u0026#34;, \u0026#34;following_url\u0026#34;: \u0026#34;https://api.github.com/users/github/following{/other_user}\u0026#34;, \u0026#34;gists_url\u0026#34;: \u0026#34;https://api.github.com/users/github/gists{/gist_id}\u0026#34;, \u0026#34;starred_url\u0026#34;: \u0026#34;https://api.github.com/users/github/starred{/owner}{/repo}\u0026#34;, \u0026#34;subscriptions_url\u0026#34;: \u0026#34;https://api.github.com/users/github/subscriptions\u0026#34;, \u0026#34;organizations_url\u0026#34;: \u0026#34;https://api.github.com/users/github/orgs\u0026#34;, \u0026#34;repos_url\u0026#34;: \u0026#34;https://api.github.com/users/github/repos\u0026#34;, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/users/github/events{/privacy}\u0026#34;, \u0026#34;received_events_url\u0026#34;: \u0026#34;https://api.github.com/users/github/received_events\u0026#34;, \u0026#34;type\u0026#34;: \u0026#34;Organization\u0026#34;, \u0026#34;site_admin\u0026#34;: false }, \u0026#34;html_url\u0026#34;: \u0026#34;https://github.com/github/media\u0026#34;, \u0026#34;description\u0026#34;: \u0026#34;Media files for use in your GitHub integration projects\u0026#34;, \u0026#34;fork\u0026#34;: false, \u0026#34;url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media\u0026#34;, \u0026#34;forks_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/forks\u0026#34;, \u0026#34;keys_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/keys{/key_id}\u0026#34;, \u0026#34;collaborators_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/collaborators{/collaborator}\u0026#34;, \u0026#34;teams_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/teams\u0026#34;, \u0026#34;hooks_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/hooks\u0026#34;, \u0026#34;issue_events_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues/events{/number}\u0026#34;, \u0026#34;events_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/events\u0026#34;, \u0026#34;assignees_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/assignees{/user}\u0026#34;, \u0026#34;branches_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/branches{/branch}\u0026#34;, \u0026#34;tags_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/tags\u0026#34;, \u0026#34;blobs_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/blobs{/sha}\u0026#34;, \u0026#34;git_tags_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/tags{/sha}\u0026#34;, \u0026#34;git_refs_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/refs{/sha}\u0026#34;, \u0026#34;trees_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/trees{/sha}\u0026#34;, \u0026#34;statuses_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/statuses/{sha}\u0026#34;, \u0026#34;languages_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/languages\u0026#34;, \u0026#34;stargazers_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/stargazers\u0026#34;, \u0026#34;contributors_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/contributors\u0026#34;, \u0026#34;subscribers_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/subscribers\u0026#34;, \u0026#34;subscription_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/subscription\u0026#34;, \u0026#34;commits_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/commits{/sha}\u0026#34;, \u0026#34;git_commits_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/git/commits{/sha}\u0026#34;, \u0026#34;comments_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/comments{/number}\u0026#34;, \u0026#34;issue_comment_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues/comments{/number}\u0026#34;, \u0026#34;contents_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/contents/{+path}\u0026#34;, \u0026#34;compare_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/compare/{base}...{head}\u0026#34;, \u0026#34;merges_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/merges\u0026#34;, \u0026#34;archive_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/{archive_format}{/ref}\u0026#34;, \u0026#34;downloads_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/downloads\u0026#34;, \u0026#34;issues_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/issues{/number}\u0026#34;, \u0026#34;pulls_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/pulls{/number}\u0026#34;, \u0026#34;milestones_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/milestones{/number}\u0026#34;, \u0026#34;notifications_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/notifications{?since,all,participating}\u0026#34;, \u0026#34;labels_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/labels{/name}\u0026#34;, \u0026#34;releases_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/releases{/id}\u0026#34;, \u0026#34;deployments_url\u0026#34;: \u0026#34;https://api.github.com/repos/github/media/deployments\u0026#34;, \u0026#34;created_at\u0026#34;: \u0026#34;2008-03-09T22:43:49Z\u0026#34;, \u0026#34;updated_at\u0026#34;: \u0026#34;2023-09-23T01:50:37Z\u0026#34;, \u0026#34;pushed_at\u0026#34;: \u0026#34;2015-02-27T17:31:20Z\u0026#34;, \u0026#34;git_url\u0026#34;: \u0026#34;git://github.com/github/media.git\u0026#34;, \u0026#34;ssh_url\u0026#34;: \u0026#34;git@github.com:github/media.git\u0026#34;, \u0026#34;clone_url\u0026#34;: \u0026#34;https://github.com/github/media.git\u0026#34;, \u0026#34;svn_url\u0026#34;: \u0026#34;https://github.com/github/media\u0026#34;, \u0026#34;homepage\u0026#34;: \u0026#34;https://github.com/logos\u0026#34;, \u0026#34;size\u0026#34;: 4484, \u0026#34;stargazers_count\u0026#34;: 293, \u0026#34;watchers_count\u0026#34;: 293, \u0026#34;language\u0026#34;: null, \u0026#34;has_issues\u0026#34;: false, \u0026#34;has_projects\u0026#34;: true, \u0026#34;has_downloads\u0026#34;: true, \u0026#34;has_wiki\u0026#34;: false, \u0026#34;has_pages\u0026#34;: false, \u0026#34;has_discussions\u0026#34;: false, \u0026#34;forks_count\u0026#34;: 69, \u0026#34;mirror_url\u0026#34;: null, \u0026#34;archived\u0026#34;: true, \u0026#34;disabled\u0026#34;: false, \u0026#34;open_issues_count\u0026#34;: 0, \u0026#34;license\u0026#34;: null, \u0026#34;allow_forking\u0026#34;: true, \u0026#34;is_template\u0026#34;: false, \u0026#34;web_commit_signoff_required\u0026#34;: false, \u0026#34;topics\u0026#34;: [], \u0026#34;visibility\u0026#34;: \u0026#34;public\u0026#34;, \u0026#34;forks\u0026#34;: 69, \u0026#34;open_issues\u0026#34;: 0, \u0026#34;watchers\u0026#34;: 293, \u0026#34;default_branch\u0026#34;: \u0026#34;master\u0026#34;, \u0026#34;permissions\u0026#34;: { \u0026#34;admin\u0026#34;: false, \u0026#34;maintain\u0026#34;: false, \u0026#34;push\u0026#34;: false, \u0026#34;triage\u0026#34;: false, \u0026#34;pull\u0026#34;: true } }, ... ] 状态转移（State Transfer） 状态应该区分应用状态和资源状态，\n客户端负责维护应用状态， 而服务端维护资源状态。 客户端与服务端的交互必须是无状态的，并在每一次请求中包含处理该请求所需的一切信息。服务端不需要在请求间保留应用状态，只有在接受到实际请求的时候，服务端才会关注应用状态。这种无状态通信原则，使得服务端和中介能够理解独立的请求和响应。在多次请求中，同一客户端也不再需要依赖于同一服务器，方便实现高可扩展和高可用性的服务端。\n客户端应用状态在服务端提供的超媒体的指引下发生变迁。服务端通过超媒体告诉客户端当前状态有哪些后续状态可以进入。\n","permalink":"https://WFUing.github.io/posts/tech/network/restful/","summary":"REST 全称是 Representational State Transfer（表现层状态转化），更具体的全称是 Resource Representational State Transfer（资源表现层状态转化），具体可以见 Roy Thomas Fielding 的博士论文 https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm 这一章。\nREST 指的是一组架构约束条件和原则：\n为设计一个功能强、性能好、适宜通信的 web 应用 如果一个架构符合 REST 的约束条件和原则，我们就称它为 RESTful 结构 Resources restful petclinic tutorial docter paper bilibili-软件体系结构-2022.7-REST Create REST APIs with JAX-RS 核心概念 资源（Resources） 表现层（Representation） 状态转化（State Transfer） 资源 网络上的一个实体，或者说是网络上的一个具体信息，任何事物，只要有被引用到的必要，它就是一个资源。\n一段文本，一张图片，一首歌曲 数据库中的一行数据 一个手机号码，某用户的个人信息 一种服务 资源标识 要让一个资源可以被识别，需要有个唯一标识，在Web中这个唯一标识就是URI（Uniform Resource Identifier）。例如：\nhttps://www.ex.com/software/releases/latest.tar.gz https://www.ex.com/map/roads/USA/CA/17_mile_drive https://www.ex.com/search/cs578 URI 设计原则\n易读： https://www.oschina.net/news/38119/oschina-translate-reward-plan 表达资源的层级关系： https://github.com/git/git/commit/e3ae056f87e1d675913d08/orders/2012/10 表示资源的同级关系： /git/block-sha1/sha1.h/compare/e3af72cda056f87e;bd63e61bdf38eb264 表达资源的过滤： https://github.com/git/git/pulls?q=is%3Aclosed 统一资源接口\nRESTful 架构应该遵循统一接口原则，统一接口包含了一组受限的预定义的操作，不论什么样的资源，都是通过使用相同的接口进行资源的访问。接口应该使用标准的 HTTP 方法如 GET，PUT 和 POST，并遵循这些方法的语义 如果按照HTTP方法的语义来暴露资源，那么接口将会拥有安全性和幂等性的特性 GET和HEAD请求是安全的，无论请求多少次，都不改变服务器状态 GET、HEAD、PUT和DELETE请求是幂等的，无论对资源操作多少次，结果总是一样的，后面的请求并不会产生比第一次更多的影响 GET 获取表示，变更时获取表示（缓存）。安全且幂等。","title":"Restful API Tutorial"},{"content":"Actor Model CPU 上有多个内核。如果我们想充分利用现有的这些硬件，就需要一种并发运行代码的方法。数十年来无法追踪的错误和开发人员的沮丧都表明，线程并不是解决问题的办法。不过不用担心，我们还有其他很好的选择，今天我要向你展示的就是其中之一：actor model。\nactor model actor model 是一种处理并发计算的概念模型。它为系统组件的行为和交互方式定义了一些通用规则。\nactors actor 是计算的原始单元。它接收 message，并根据 message进行某种计算。\n这种想法与面向对象语言（object-oriented languages）中的想法非常相似：对象接收 message（方法调用），并根据接收到的 message（我们调用的方法）进行操作。\n主要区别在于，actors 之间是完全隔离的，它们永远不会共享内存。值得注意的是，一个 actor 可以保持一个私有状态，其他 actor 永远无法直接改变该状态。\n一个 actor 不是 actor。它们是以系统的形式出现的。在 actor model 中，一切都是 actor，它们需要有地址，这样一个行为者才能向另一个 actor 发送 message。\nmailbox 虽然多个 actor 可以同时运行，但一个 actor 会按顺序处理给定的 message。这意味着，如果你向同一个 actor 发送 3 条 message，它只会一次执行一条。要同时执行这 3 条 message，你需要创建 3 个 actor，每个 actor 发送一条 message。\nmessage 是异步发送给角色的，角色在处理另一条消息时需要将消息存储在某个地方。mailbox 就是存储这些 message 的地方。\nactor 之间通过发送异步消息进行通信。这些 message 会保存在其他 actor 的 mailbox 中，直到它们被处理。\nWhat actors do 当 actor 收到 message 时，它可以做以下三件事中的一件：\nCreate more actors Send messages to other actors Designate what to do with the next message：指定义这个状态在收到下一条信息时的样子，行为体如何改变状态。假设我们有一个行为类似于计算器的行为体，它的初始状态是简单的数字 0。当这个行为体收到 add(1) 消息时，它不会改变自己的原始状态，而是指定在收到下一条消息时，状态将是 1。 Fault tolerance Erlang 引入了 \u0026ldquo;let it crash\u0026rdquo; 的理念。其理念是，你不需要进行防御性编程，试图预测所有可能发生的问题，并找到处理它们的方法，因为根本不可能考虑到每一个故障点。\nErlang 所做的就是简单地让它崩溃，但让这些关键代码由某个人监管，而这个人唯一的责任就是知道当崩溃发生时该做什么（比如将代码单元重置为稳定状态），而使这一切成为可能的就是 actor model。\n每段代码都运行在一个进程中（这也是 Erlang 对其角色的基本称呼）。这个进程是完全孤立的，这意味着它的状态不会影响任何其他进程。我们有一个 \u0026ldquo;监督者\u0026rdquo;，它基本上是另一个进程（所有东西都是行为体，还记得吗？），当被监督的进程崩溃时，它会收到通知，然后可以采取一些措施。\n这就使得创建 \u0026ldquo;self heal\u0026rdquo; 系统成为可能，也就是说，如果一个行为体由于某种原因进入了异常状态并崩溃，那么监管者就可以采取一些措施，尝试将其恢复到一致的状态（有多种策略可以做到这一点，最常见的就是以初始状态重新启动行为体）。\nActor Model For IoT 物联网（IoT）由许多节点组成，通常功能有限。通过互联网协议标准进行通信的小型软件组件通常在机器之间形成高度分布式的工作流程，人与机器之间的互动极少。一般的应用场景包括监控环境条件等数据的传感器。复杂的应用则使用传感器和执行器，例如：家庭自动化和健康数据跟踪。这些系统使机器能够将数据上传到互联网服务器。因此，它们可以随时随地跟踪数据。\n典型 IoT 系统的主要特点之一是涉及大量受管设备，每个设备的内部状态都在不断变化。在许多情况下，这些设备都是在一些简单的网络协议上运行的原始硬件。这种 \u0026ldquo;极简\u0026rdquo; 要求与 actor model 非常吻合，因为 actor model 的基本原则之一就是将业务逻辑分解成最小的任务，由各个 actor 来处理。\nactor 具有 delivery guarantees 和 isolation 特性，非常适合物联网世界，是模拟数百万个并发连接的传感器生成实时数据的绝佳工具。它们设计轻巧，因此可以在不消耗过多计算资源的情况下进行扩展。\n以下是行动者适合物联网的特征属性：\nScalability：物联网带来了许多挑战，如何处理所有同时连接的设备产生的大量数据，并对其进行检索、汇总、分析和推送，同时保持设备的响应速度。面临的挑战包括管理高峰期接收传感器数据的巨大突发流量、批处理和实时处理这些海量数据，以及进行模拟真实世界使用模式的大规模仿真。一些物联网部署还要求后端服务管理设备，而不仅仅是吸收设备发送的数据。管理这一切的后端系统需要能够按需扩展，并具有完全的弹性。这非常适合 reactive architectures ，尤其是 Akka。\nConcurrency：物联网应用网关是系统中将本地传感器和执行器连接到云的点（例如路边站、运输过程中的车载设备或家庭自动化网关）。即使一个应用程序在传感器、执行器和云服务之间 \u0026ldquo;只转发数据\u0026rdquo;，也会有并发事件。物联网应用网关需要处理在其环境中发生的事件流和到达其接口的数据流。环境以自己的速度产生数据并要求输出。Actor model 通过消息传递实现了对来自设备的消息的高性能并发处理，从而解决了上述问题。message-processing models的优势之一是，传统的并发问题（主要是共享状态的同步）不再是问题。行为体可以保留设备内部状态或活动会话等私有状态，并在没有锁的情况下自由更新。Actor model 可确保一次只处理一条消息。\nFault Tolerance：在构建可能被数百万联网设备使用的服务时，您需要一个应对信息流的模型。您需要对设备故障、信息丢失和服务失败时的情况进行抽象。今天，我们常常认为调用堆栈是理所当然的。但是，它们发明的年代，由于多 CPU 系统并不常见，并发编程并不那么重要。调用栈不能跨线程，因此不能模拟异步调用链。 上图显示了一个严重的问题。工作线程如何处理这种情况？它很可能无法解决问题，因为它通常不知道失败任务的目的。调用者 \u0026ldquo;线程需要得到通知，但没有调用栈可以释放异常。失败通知只能通过侧通道完成，例如，在 \u0026ldquo;调用者 \u0026ldquo;线程希望得到结果的地方放置一个错误代码。如果没有这种通知，\u0026ldquo;调用者 \u0026ldquo;就永远不会收到失败通知，任务也就丢失了！这与网络系统的工作原理惊人地相似，在网络系统中，信息/请求可能在没有任何通知的情况下丢失/失败。\n有了 actor，我们可以将 actor 组织成监管层次，因此，单个 actor 的错误不会导致整个系统瘫痪。\nLightWeight：基准测试表明，Akka 模型每千兆字节堆内存可处理 250 万个角色，单机每秒可处理 5000 万条消息。\nNetwork Protocol Decoupling：利用 actor model ，我们可以利用容错功能，将代表设备的角色与底层通信协议分离开来。这样，代表设备和设备状态的角色就可以从代表通信协议的 actor 中分离出来，从而使设备 actor 免受网络错误的影响，并提高各个 actor 的功能一致性。\nNon-blocking communications：物联网应用 \u0026ldquo;必须 \u0026ldquo;具有反应性和异步性。大多数物联网应用程序都应能够处理来自设备的许多连接以及从设备中获取的所有信息。异步消息传递广泛应用于机器对机器通信。异步通信具有灵活性：应用程序可以发送一条信息，然后继续处理其他事情。actor 是唯一可寻址的，拥有自己独立的邮箱或消息队列。它们通过消息传递支持非阻塞通信，因此适合构建非阻塞和分布式计算系统。\nCustomization：所有行为体都有一个定义明确的生命周期，并配有精致的钩子，如用于生命周期逻辑控制的 preStart()、postRestart() 和 postStop()。在模拟物联网设备时，可以轻松地将自定义初始化和终止例程锚定到相应的钩子上。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 object Device { def props(deviceType: String, mqttPubSub: ActorRef) = //... } class Device(deviceType: String, mqttPubSub: ActorRef) extends Actor { import Device._ private var opState: OpState = InitialState(deviceType) override def preStart(): Unit = //Initialize device\u0026#39;s op-state... override def postStop(): Unit = //Reset/Shutdown device... def receive = { case ReportOpState =\u0026gt; //Assemble report data with OpState mqttPubSub ! new Publish(Mqtt.topicReport, reportData) case UpdateOpState(newState) =\u0026gt; //Update opState with newState mqttPubSub ! new Publish(Mqtt.topicUpdate, updateResult) case PowerOff =\u0026gt; //Shutdown device... } } view raw 上面的片段展示了如何在 Scala/Akka 中构建一个设备角色，使用行业标准 MQTT（消息队列遥测传输）发布-订阅消息协议向订阅者发布其运行状态信息。这里的目的并不是研究如何用 Scala 或 Akka 编程，而是提供一个简单的示例，说明 Akka 角色易于理解的逻辑流程。\nResources https://www.brianstorti.com/the-actor-model/ http://akshantalpm.github.io/Actor-Model-For-IoT/ https://www.infoworld.com/article/3209728/why-akka-and-the-actor-model-shine-for-iot-applications.html ","permalink":"https://WFUing.github.io/posts/tech/architecture/distributed/iot/actor/","summary":"Actor Model CPU 上有多个内核。如果我们想充分利用现有的这些硬件，就需要一种并发运行代码的方法。数十年来无法追踪的错误和开发人员的沮丧都表明，线程并不是解决问题的办法。不过不用担心，我们还有其他很好的选择，今天我要向你展示的就是其中之一：actor model。\nactor model actor model 是一种处理并发计算的概念模型。它为系统组件的行为和交互方式定义了一些通用规则。\nactors actor 是计算的原始单元。它接收 message，并根据 message进行某种计算。\n这种想法与面向对象语言（object-oriented languages）中的想法非常相似：对象接收 message（方法调用），并根据接收到的 message（我们调用的方法）进行操作。\n主要区别在于，actors 之间是完全隔离的，它们永远不会共享内存。值得注意的是，一个 actor 可以保持一个私有状态，其他 actor 永远无法直接改变该状态。\n一个 actor 不是 actor。它们是以系统的形式出现的。在 actor model 中，一切都是 actor，它们需要有地址，这样一个行为者才能向另一个 actor 发送 message。\nmailbox 虽然多个 actor 可以同时运行，但一个 actor 会按顺序处理给定的 message。这意味着，如果你向同一个 actor 发送 3 条 message，它只会一次执行一条。要同时执行这 3 条 message，你需要创建 3 个 actor，每个 actor 发送一条 message。\nmessage 是异步发送给角色的，角色在处理另一条消息时需要将消息存储在某个地方。mailbox 就是存储这些 message 的地方。\nactor 之间通过发送异步消息进行通信。这些 message 会保存在其他 actor 的 mailbox 中，直到它们被处理。","title":"Actor"},{"content":"Resources Demos https://github.com/gofireflyio/aiac https://github.com/JustAIGithub/AI-Code-Convert Blogs 25 Best AI Code Generators ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/ai-code-generators/","summary":"Resources Demos https://github.com/gofireflyio/aiac https://github.com/JustAIGithub/AI-Code-Convert Blogs 25 Best AI Code Generators ","title":"AI Code Generators"},{"content":"Resources git tutorial: https://wyag.thb.lt/ 动图展示10大Git命令: https://zhuanlan.zhihu.com/p/132573100 git intro: https://missing.csail.mit.edu/2020/version-control/ book: https://git-scm.com/book/en/v2 commit convention 规范: https://www.conventionalcommits.org/en/v1.0.0/#summary Write yourself a Git：https://wyag.thb.lt/ 如何编写Git Commit Message? 为了创建一个有用的 revision history ，团队应该首先就 commit message convention 达成一致，至少要定义以下三点：\nStyle：标记语法Markup syntax, 流式布局wrap margins, 语法grammar, 大小写capitalization, 标点符号punctuation。把这些东西写出来，去掉猜测，让一切尽可能简单。 Content：提交消息的正文应该包含什么样的信息？不应该包含什么？ Metadata：如何引用 issue tracking IDs、pull request numbers 等？ 幸运的是，Git提交信息的规范已经有了很好的约定。事实上，很多 Git 命令的功能中就包含了这些约定。您不需要重新发明什么。只要遵循下面的七条规则，您就能像专家一样 commit message 了。\nThe seven rules of a great Git commit message\nSeparate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs. how For example:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Summarize changes in around 50 characters or less More detailed explanatory text, if necessary. Wrap it to about 72 characters or so. In some contexts, the first line is treated as the subject of the commit and the rest of the text as the body. The blank line separating the summary from the body is critical (unless you omit the body entirely); various tools like `log`, `shortlog` and `rebase` can get confused if you run the two together. Explain the problem that this commit is solving. Focus on why you are making this change as opposed to how (the code explains that). Are there side effects or other unintuitive consequences of this change? Here\u0026#39;s the place to explain them. Further paragraphs come after blank lines. - Bullet points are okay, too - Typically a hyphen or asterisk is used for the bullet, preceded by a single space, with blank lines in between, but conventions vary here If you use an issue tracker, put references to them at the bottom, like this: Resolves: #123 See also: #456, #789 1. Separate subject from body with a blank line From the git commit manpage:\n1 Though not required, it\u0026#39;s a good idea to begin the commit message with a single short (less than 50 character) line summarizing the change, followed by a blank line and then a more thorough description. The text up to the first blank line in a commit message is treated as the commit title, and that title is used throughout Git. For example, Git-format-patch(1) turns a commit into email, and it uses the title on the Subject line and the rest of the commit in the body. 首先，并非每次提交都需要主题和正文。有时一行就够了，特别是当修改非常简单，不需要更多上下文的时候。\n1 Fix typo in introduction to user guide 如果读者想知道错别字是什么，可以直接查 typo 本身，即使用 git show 或 git diff 或 git log -p。\n如果您在命令行提交类似的内容，使用 git commit 的 -m 选项也很方便\n1 $ git commit -m \u0026#34;Fix typo in introduction to user guide\u0026#34; 然而，当一个提交需要一些解释和上下文时，你需要写一个正文。例如：\n1 2 3 4 5 Derezz the master control program MCP turned out to be evil and had become intent on world domination. This commit throws Tron\u0026#39;s disc into MCP (causing its deresolution) and turns it back into a chess game. 使用 -m 选项编写带正文的提交信息并不容易。最好使用合适的文本编辑器来编写。\n在浏览日志时，主体与主体的分离是有好处的。以下是完整的日志记录：\n1 2 3 4 5 6 7 8 9 10 $ git log commit 42e769bdf4894310333942ffc5a15151222a87be Author: Kevin Flynn \u0026lt;kevin@flynnsarcade.com\u0026gt; Date: Fri Jan 01 00:00:00 1982 -0200 Derezz the master control program MCP turned out to be evil and had become intent on world domination. This commit throws Tron\u0026#39;s disc into MCP (causing its deresolution) and turns it back into a chess game. 现在只打印主题行 git log --oneline ：\n1 2 $ git log --oneline 42e769 Derezz the master control program 或者，按用户分组提交，同样只显示主题行，git shortlog：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ git shortlog Kevin Flynn (1): Derezz the master control program Alan Bradley (1): Introduce security program \u0026#34;Tron\u0026#34; Ed Dillinger (3): Rename chess program to \u0026#34;MCP\u0026#34; Modify chess program Upgrade chess program Walter Gibbs (1): Introduce protoype chess program 在Git中，主题行和正文之间的区别还有很多，但如果中间没有空行，它们都无法正常工作。\n2. Limit the subject line to 50 characters 50个字符不是硬性限制，只是一个经验法则。将主题行保持在这一长度可确保其可读性，并迫使作者思考如何以最简洁的方式说明内容。\n1 Tip: If you\u0026#39;re having a hard time summarizing, you might be committing too many changes at once. Strive for atomic commits (a topic for a separate post). GitHub\u0026rsquo;s UI is fully aware of these conventions. It will warn you if you go past the 50 character limit and will truncate any subject line longer than 72 characters with an ellipsis.\n3. Capitalize the subject line This is as simple as it sounds. Begin all subject lines with a capital letter.\nFor example:\nAccelerate to 88 miles per hour Instead of:\naccelerate to 88 miles per hour 4. Do not end the subject line with a period Trailing punctuation is unnecessary in subject lines. Besides, space is precious when you\u0026rsquo;re trying to keep them to 50 chars or less.\nExample:\nOpen the pod bay doors Instead of:\nOpen the pod bay doors. 5. Use the imperative mood in the subject line Imperative mood just means \u0026ldquo;spoken or written as if giving a command or instruction\u0026rdquo;. A few examples:\nClean your room Close the door Take out the trash Git itself uses the imperative whenever it creates a commit on your behalf.\n例如，使用 git merge 时创建的默认信息如下\n1 Merge branch \u0026#39;myfeature\u0026#39; 当使用 git revert 时，\n1 2 3 Revert \u0026#34;Add the thing with the stuff\u0026#34; This reverts commit cc87791524aedd593cff5a74532befe7ab69ce9d. 或 点击 GitHub 拉取请求上的 Merge 按钮时：\n1 Merge pull request #123 from someuser/somebranch 因此，当您在命令行中编写提交信息时，您遵循的是 Git 自带的约定。例如，\nRefactor subsystem X for readability Update getting started documentation Remove deprecated methods Release version 1.0.0 这样写一开始可能会有点尴尬。我们更习惯于用指示语气说话，而指示语气则是报告事实。这就是为什么提交的信息经常读起来像这样：\nFixed bug with Y Changing behavior of X 有时承诺信息会被写成内容描述：\nMore fixes for broken stuff Sweet new API methods 为了消除任何混淆，这里有一个简单的规则，以便每次都能正确操作。\n一个正确的Git提交主题行应该能够完成以下句子：\nIf applied, this commit will your subject line here For example:\nIf applied, this commit will refactor subsystem X for readability If applied, this commit will update getting started documentation If applied, this commit will remove deprecated methods If applied, this commit will release version 1.0.0 If applied, this commit will merge pull request #123 from user/branch Remember: Use of the imperative is important only in the subject line. You can relax this restriction when you\u0026rsquo;re writing the body.\n6. Wrap the body at 72 characters Git 不会自动换行。当您写提交信息的正文时，必须注意右边距，并手动换行。\n建议在72个字符时进行，这样Git就有足够的空间缩进文本，同时又能将所有内容保持在80个字符以内。\n7. Use the body to explain what and why vs. how Bitcoin Core 的这个 commit 是一个很好的例子，它解释了改变的内容和原因：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 commit eb0b56b19017ab5c16c745e6da39c53126924ed6 Author: Pieter Wuille \u0026lt;pieter.wuille@gmail.com\u0026gt; Date: Fri Aug 1 22:57:55 2014 +0200 Simplify serialize.h\u0026#39;s exception handling Remove the \u0026#39;state\u0026#39; and \u0026#39;exceptmask\u0026#39; from serialize.h\u0026#39;s stream implementations, as well as related methods. As exceptmask always included \u0026#39;failbit\u0026#39;, and setstate was always called with bits = failbit, all it did was immediately raise an exception. Get rid of those variables, and replace the setstate with direct exception throwing (which also removes some dead code). As a result, good() is never reached after a failure (there are only 2 calls, one of which is in tests), and can just be replaced by !eof(). fail(), clear(n) and exceptions() are just never called. Delete them. 看看完整的差异，想想作者花时间在此时此地提供这些上下文，为同事和未来的提交者节省了多少时间。如果他不这样做，这些内容可能会永远丢失。\n在大多数情况下，您可以省略关于如何修改的细节。在这方面，代码通常是不言自明的，如果代码非常复杂，需要用散文来解释，那就是源注释的作用。只需重点说明您首先进行修改的原因\u0026ndash;(修改前的工作方式以及有什么问题)、现在的工作方式，以及您为什么决定以这种方式解决问题。\n未来感谢您的维护者可能就是您自己！\n","permalink":"https://WFUing.github.io/posts/tech/architecture/git/how-to-write-a-git-commit-message/","summary":"Resources git tutorial: https://wyag.thb.lt/ 动图展示10大Git命令: https://zhuanlan.zhihu.com/p/132573100 git intro: https://missing.csail.mit.edu/2020/version-control/ book: https://git-scm.com/book/en/v2 commit convention 规范: https://www.conventionalcommits.org/en/v1.0.0/#summary Write yourself a Git：https://wyag.thb.lt/ 如何编写Git Commit Message? 为了创建一个有用的 revision history ，团队应该首先就 commit message convention 达成一致，至少要定义以下三点：\nStyle：标记语法Markup syntax, 流式布局wrap margins, 语法grammar, 大小写capitalization, 标点符号punctuation。把这些东西写出来，去掉猜测，让一切尽可能简单。 Content：提交消息的正文应该包含什么样的信息？不应该包含什么？ Metadata：如何引用 issue tracking IDs、pull request numbers 等？ 幸运的是，Git提交信息的规范已经有了很好的约定。事实上，很多 Git 命令的功能中就包含了这些约定。您不需要重新发明什么。只要遵循下面的七条规则，您就能像专家一样 commit message 了。\nThe seven rules of a great Git commit message\nSeparate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs.","title":"How to Write a Git Commit Message"},{"content":"Linux 的命令确实非常多，然而熟悉 Linux 的人从来不会因为 Linux 的命令太多而烦恼。因为我们仅仅只需要掌握常用命令，就完全可以驾驭 Linux。\n接下来，让我们一起来看看都有那些常用的 Linux 命令吧！\n一、文件目录操作 1.ls 命令 ls 命令不仅可以查看 linux 文件夹包含的文件而且可以查看文件权限（包括目录、文件夹、文件权限）查看目录信息等等。\n命令格式\n1 ls [选项][目录名] 常用参数\n-l ：列出长数据串，包含文件的属性与权限数据等 -a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用） -d ：仅列出目录本身，而不是列出目录的文件数据 -h ：将文件容量以较易读的方式（GB，kB等）列出来 -R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来 使用实例\n1.列出 home 目录下的所有文件和目录的详细资料。\n1 2 ls -a -l /home ls -al /home 2.列出当前目录下所有以\u0026quot;d\u0026quot;开头的文件目录详情内容。\n1 ls -l d* 2.cd命令 最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。用于切换当前目录至dirName。\n命令格式\n1 cd [目录名] 操作案例\n1.从当前目录进入系统根目录。\n1 cd / 2.跳转到 home/Code 目录。\n1 cd /home/Code 3.pwd 命令 查看\u0026quot;当前工作目录\u0026quot;的完整路径。\n命令格式\n1 pwd [选项] 常用参数\n-P :显示实际物理路径，而非使用连接（link）路径 -L :当目录为连接路径时，显示连接路径 操作案例\n1.显示当前所在路径。\n1 pwd 4.mkdir 命令 用来创建指定的名称的目录，要求创建目录的用户在当前目录中具有写权限，并且指定的目录名不能是当前目录中已有的目录。\n命令格式\n1 mkdir [选项] 目录 常用参数\n-m, \u0026ndash;mode=模式，设定权限\u0026lt;模式\u0026gt; (类似 chmod)，而不是 rwxrwxrwx 减 umask -p, \u0026ndash;parents 可以是一个路径名称。此时若路径中的某些目录尚不存在,加上此选项后,系统将自动建立好那些尚不存在的目录,即一次可以建立多个目录; -v, \u0026ndash;verbose 每次创建新目录都显示信息 \u0026ndash;help 显示此帮助信息并退出 \u0026ndash;version 输出版本信息并退出 使用实例\n1.创建一个空目录。\n1 mkdir test 2.递归创建多个目录。\n1 mkdir test/test1 3.创建权限为777的目录。\n1 mkdir -m 777 test2 4.创建目录都显示信息。\n1 mkdir -v test4 5.rm 命令 删除一个目录中的一个或多个文件或目录，如果没有使用- r选项，则rm不会删除目录。如果使用 rm 来删除文件，通常仍可以将该文件恢复原状。\n命令格式\n1 rm [选项] 文件 常用参数\n-f, \u0026ndash;force 忽略不存在的文件，从不给出提示。 -i, \u0026ndash;interactive 进行交互式删除 -r, -R, \u0026ndash;recursive 指示rm将参数中列出的全部目录和子目录均递归地删除。 -v, \u0026ndash;verbose 详细显示进行的步骤 \u0026ndash;help 显示此帮助信息并退出 \u0026ndash;version 输出版本信息并退出 使用实例\n1.删除文件 test.txt,系统会提示是否删除。\n1 rm test.txt 2.强制删除 test.txt，系统不再提示。\n1 rm -f test.txt 3.将 test 子目录及目录中所有档案删除。\n1 rm -r test 6.rmdir 命令 该命令从一个目录中删除一个或多个子目录项，删除某目录时也必须具有对父目录的写权限。\n命令格式\n1 rmdir [选项] 目录 常用参数\n-p 递归删除目录dirname，当子目录删除后其父目录为空时，也一同被删除。如果整个路径被删除或者由于某种原因保留部分路径，则系统在标准输出上显示相应的信息。 -v, \u0026ndash;verbose 显示指令执行过程 使用实例\n1.删除空目录 test1，非空目录无法删除。\n1 rmdir test1 2.当子目录被删除后使它也成为空目录的话，则顺便一并删除\n1 rmdir -p test2 # test 目录下仅有 test2 7. mv 命令 可以用来移动文件或者将文件改名（move (rename) files）。当第二个参数类型是文件时，mv命令完成文件重命名。当第二个参数是已存在的目录名称时，源文件或目录参数可以有多个，mv命令将各参数指定的源文件均移至目标目录中。\n命令格式\n1 mv [选项] 源文件或目录 目标文件或目录 常用参数\n-b ：若需覆盖文件，则覆盖前先行备份 -f ：force 强制的意思，如果目标文件已经存在，不会询问而直接覆盖 -i ：若目标文件 (destination) 已经存在时，就会询问是否覆盖 -u ：若目标文件已经存在，且 source 比较新，才会更新(update) -t ： \u0026ndash;target-directory=DIRECTORY move all SOURCE arguments into DIRECTORY，即指定mv的目标目录，该选项适用于移动多个源文件到一个目录的情况，此时目标目录在前，源文件在后 使用实例\n1.将 test1.txt 重命名为 test2.txt。\n1 mv test1.txt test2.txt 2.移动文件 test1.txt 到目录 test2\n1 mv test1.txt test2 3.将文件 test1.txt、test2.txt、test3.txt 移动到目录 test3。\n1 mv test1.txt test2.txt test3.txt test3 8.cp 命令 将源文件复制至目标文件，或将多个源文件复制至目标目录。\n命令格式\n1 cp [选项] 源文件 目录 或 cp [选项] -t 目录 源文件 常用参数\n-t \u0026ndash;target-directory 指定目标目录 -i \u0026ndash;interactive 覆盖前询问（使前面的 -n 选项失效） -n \u0026ndash;no-clobber 不要覆盖已存在的文件（使前面的 -i 选项失效） -f \u0026ndash;force 强行复制文件或目录，不论目的文件或目录是否已经存在 -u \u0026ndash;update 使用这项参数之后，只会在源文件的修改时间较目的文件更新时，或是对应的目的文件并不存在，才复制文件 使用实例\n1.复制文件 test1.txt 到 test1 目录\n1 cp test1.txt test1 # 若文件存在，会提示是否覆盖。若不存在直接完成复制 复制 test1 整个目录到 test2\n1 cp -a test1 test2 9.touch 命令 touch命令参数可更改文档或目录的日期时间，包括存取时间和更改时间。\n命令格式\n1 touch [选项] 文件 常用参数\n-a 或\u0026ndash;time=atime或\u0026ndash;time=access或\u0026ndash;time=use 只更改存取时间 -c 或\u0026ndash;no-create 不建立任何文档 -d 使用指定的日期时间，而非现在的时间 -f 此参数将忽略不予处理，仅负责解决BSD版本touch指令的兼容性问题 -m 或\u0026ndash;time=mtime或\u0026ndash;time=modify 只更改变动时间 -r 把指定文档或目录的日期时间，统统设成和参考文档或目录的日期时间相同 -t 使用指定的日期时间，而非现在的时间 使用实例\n1.创建不存在的文件test.txt\n1 touch test.txt 2.更新 test.txt 的实践和 test1.txt 时间戳相同\n1 touch -r test.txt test1.txt 10.cat 命令 用来显示文件内容，或者将几个文件连接起来显示，或者从标准输入读取内容并显示，它常与重定向符号配合使用。\n命令格式\n1 cat [选项] [文件] 常用参数\n-A, \u0026ndash;show-all 等价于 -vET -b, \u0026ndash;number-nonblank 对非空输出行编号 -e 等价于 -vE -E, \u0026ndash;show-ends 在每行结束处显示 $ -n, \u0026ndash;number 对输出的所有行编号,由1开始对所有输出的行数编号 -s, \u0026ndash;squeeze-blank 有连续两行以上的空白行，就代换为一行的空白行 -t 与 -vT 等价 -T, \u0026ndash;show-tabs 将跳格字符显示为 ^I -u (被忽略) -v, \u0026ndash;show-nonprinting 使用 ^ 和 M- 引用，除了 LFD 和 TAB 之外 使用实例\n1.把 test.log 的文件内容加上行号后输入 test1.log 这个文件里。\n1 cat -n test.log test1.log 将 test.log 的文件内容反向显示。\n1 tac test.log 11.nl 命令 输出的文件内容自动的加上行号！其默认的结果与 cat -n 有点不太一样， nl 可以将行号做比较多的显示设计，包括位数与是否自动补齐 0 等等的功能。\n命令格式\n1 nl [选项] [文件] 常用参数\n-b ：指定行号指定的方式，主要有两种： -b a ：表示不论是否为空行，也同样列出行号(类似 cat -n) -b t ：如果有空行，空的那一行不要列出行号(默认值) -n ：列出行号表示的方法，主要有三种： -n ln ：行号在萤幕的最左方显示 -n rn ：行号在自己栏位的最右方显示，且不加 0 -n rz ：行号在自己栏位的最右方显示，且加 0 -w ：行号栏位的占用的位数 使用实例\n用 nl 列出 test.log 的内容。\n1 nl test.log 用 nl 列出 test.log 的内容，空本行也加上行号。\n1 nl -b a test.log 12.more 命令 more 命令和 cat 的功能一样都是查看文件里的内容，但有所不同的是more可以按页来查看文件的内容，还支持直接跳转行等功能。\n命令格式\n1 more [-dlfpcsu ] [-num ] [+/ pattern] [+ linenum] [file ... ] 常用参数\n+n 从笫n行开始显示 -n 定义屏幕大小为n行 +/pattern 在每个档案显示前搜寻该字串（pattern），然后从该字串前两行之后开始显示 -c 从顶部清屏，然后显示 -d 提示Press space to continue，'q' to quit（按空格键继续，按q键退出），禁用响铃功能 -l 忽略Ctrl+l（换页）字符 -p 通过清除窗口而不是滚屏来对文件进行换页，与-c选项相似 -s 把连续的多个空行显示为一行 -u 把文件内容中的下画线去掉 操作指令\nEnter：向下n行，需要定义。默认为1行 Ctrl+F：向下滚动一屏 空格键：向下滚动一屏 Ctrl+B：返回上一屏 = ：输出当前行的行号 ：f ：输出文件名和当前行的行号 V ：调用vi编辑器 !命令 ：调用Shell，并执行命令 q ：退出more 使用实例\n1.显示文件 test.log 第3行起内容。\n1 more +3 test.log 2.从文件 test.log 查找第一个出现\u0026quot;day3\u0026quot;字符串的行，并从该处前2行开始显示输出。\n1 more +/day3 test.log 设置每屏显示行数\n1 more -5 test.log 13.less 命令 less 与 more 类似，但使用 less 可以随意浏览文件，而 more 仅能向前移动，却不能向后移动，而且 less 在查看之前不会加载整个文件。\n命令格式\n1 less [参数] 文件 常用参数\n-b \u0026lt;缓冲区大小\u0026gt; 设置缓冲区的大小 -e 当文件显示结束后，自动离开 -f 强迫打开特殊文件，例如外围设备代号、目录和二进制文件 -g 只标志最后搜索的关键词 -i 忽略搜索时的大小写 -m 显示类似more命令的百分比 -N 显示每行的行号 -o \u0026lt;文件名\u0026gt; 将less 输出的内容在指定文件中保存起来 -Q 不使用警告音 -s 显示连续空行为一行 -S 行过长时间将超出部分舍弃 -x \u0026lt;数字\u0026gt; 将\u0026quot;tab\u0026quot;键显示为规定的数字空格 操作命令\n/字符串：向下搜索\u0026quot;字符串\u0026quot;的功能 ?字符串：向上搜索\u0026quot;字符串\u0026quot;的功能 n：重复前一个搜索（与 / 或 ? 有关） N：反向重复前一个搜索（与 / 或 ? 有关） b 向后翻一页 d 向后翻半页 h 显示帮助界面 Q 退出less 命令 u 向前滚动半页 y 向前滚动一行 空格键 滚动一行 回车键 滚动一页 [pagedown]： 向下翻动一页 [pageup]： 向上翻动一页 使用实例\n1.查看文件 test.log。\n1 less test.log 14.head 命令 head 用来显示档案的开头至标准输出中，默认 head 命令打印其相应文件的开头 10 行。\n命令格式\n1 head [参数] [文件] 常用参数\n-q 隐藏文件名 -v 显示文件名 -c\u0026lt;字节\u0026gt; 显示字节数 -n\u0026lt;行数\u0026gt; 显示的行数 使用实例\n1.显示文件 test.log 的前 5 行\n1 head -n 5 test.log 2.显示文件 test.log 前 20 个字节\n1 head -c 20 test.log 15.tail 命令 显示指定文件末尾内容，不指定文件时，作为输入信息进行处理。常用查看日志文件。\n命令格式\n1 tail [必要参数] [选择参数] [文件] 常用参数\n-f 循环读取 -q 不显示处理信息 -v 显示详细的处理信息 -c\u0026lt;数目\u0026gt; 显示的字节数 -n\u0026lt;行数\u0026gt; 显示行数 \u0026ndash;pid=PID 与-f合用,表示在进程ID,PID死掉之后结束. -q, \u0026ndash;quiet, \u0026ndash;silent 从不输出给出文件名的首部 -s, \u0026ndash;sleep-interval=S 与-f合用,表示在每次反复的间隔休眠S秒 使用实例\n1.显示文件 test.log 最后 5 行内容。\n1 tail -n 5 test.log 2.循环查看文件内容\n1 tail -f test.log 二、文件查找 16.which 命令 which指令会在PATH变量指定的路径中，搜索某个系统命令的位置，并且返回第一个搜索结果。\n命令格式\n1 which 可执行文件名称 常用参数\n-n 指定文件名长度，指定的长度必须大于或等于所有文件中最长的文件名 -p 与-n参数相同，但此处的包括了文件的路径 -w 指定输出时栏位的宽度 -V 显示版本信息 使用实例\n1.查找文件、显示命令路径。\n1 which pwd 用 which 去找出 which\n1 which which 17.whereis 命令 whereis命令是定位可执行文件、源代码文件、帮助文件在文件系统中的位置。\n命令格式\n1 whereis [-bmsu] [BMS 目录名 -f ] 文件名 常用参数\n-b 定位可执行文件 -m 定位帮助文件 -s 定位源代码文件 -u 搜索默认路径下除可执行文件、源代码文件、帮助文件以外的其它文件 -B 指定搜索可执行文件的路径 -M 指定搜索帮助文件的路径 -S 指定搜索源代码文件的路径 使用实例\n1.将和 svn 文件相关的文件都查找出来。\n1 whereis svn 2.只将二进制文件查找出来。\n1 whereis -b svn 18.locate 命令 可以很快速的搜寻档案系统内是否有指定的档案。\n命令格式\n1 locate [选择参数] [样式] 常用参数\n-e 将排除在寻找的范围之外。 -1 如果 是 1．则启动安全模式。在安全模式下，使用者不会看到权限无法看到 的档案。这会始速度减慢，因为 locate 必须至实际的档案系统中取得档案的 权限资料。 -f 将特定的档案系统排除在外，例如我们没有到理要把 proc 档案系统中的档案 放在资料库中。 -q 安静模式，不会显示任何错误讯息。 -n 至多显示 n个输出。 -r 使用正规运算式 做寻找的条件。 -o 指定资料库存的名称。 -d 指定资料库的路径 使用实例\n1.查找和 pwd 相关的所有文件。\n1 locate pwd 搜索etc 目录下，所有以 m 开头的文件。\n1 bash复制代码locate /etc/m 19.find 命令 主要作用是沿着文件层次结构向下遍历，匹配符合条件的文件，并执行相应的操作。\n命令格式\n1 find [选项] [搜索路径] [表达式] 常用参数\n-print find 命令将匹配的文件输出到标准输出 -exec find 命令对匹配的文件执行该参数所给出的 shell 命令\n-name 按照文件名查找文件 -type 查找某一类型的文件 使用实例\n1.打印当前目录文件目录列表。\n1 find . -print 2.打印当前目录下所有不以.txt 结尾的文件名。\n1 find . ! -name \u0026#34;*.txt\u0026#34; 3.打印当前目录下所有权限为 777 的 php 文件。\n1 find . -type f -name \u0026#34;*.php\u0026#34; -perm 777 4.找到当前目录下所有 php 文件，并显示其详细信息。\n1 find . -name \u0026#34;*.php\u0026#34; -exec ls -l {} \\; 5.查找当前目录下所有 c 代码文件，统计总行数。\n1 find . -type f -name \u0026#34;*.c\u0026#34; | xargs wc -l xargs 命令可以从标准输入接收输入，并把输入转换为一个特定的参数列表。\n命令格式\n1 command | xargs [选项] [command] xargs 命令应该紧跟在管道操作符之后，因为它以标准输入作为主要的源数据流。\n常用参数\n-n 指定每行最大的参数数量 -d 指定分隔符 三、文件打包上传和下载 20.tar 命令 用来压缩和解压文件。tar本身不具有压缩功能。他是调用压缩功能实现的。\n命令格式\n1 tar [必要参数] [选择参数] [文件] 常用参数\n必要参数\n-A 新增压缩文件到已存在的压缩 -B 设置区块大小 -c 建立新的压缩文件 -d 记录文件的差别 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -x 从压缩的文件中提取文件 -t 显示压缩文件的内容 -z 支持gzip解压文件 -j 支持bzip2解压文件 -Z 支持compress解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -W 确认压缩文件的正确性 可选参数\n-b 设置区块数目 -C 切换到指定目录 -f 指定压缩文件 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.将文件打全部打包成tar包。\n1 2 3 4 5 tar -cvf test.tar test.log # 仅打包，不压缩！ tar -zcvf test.tar.gz test.log # 打包后，以 gzip 压缩 tar -zcvf test.tar.bz2 test.log # 打包后，以 bzip2 压缩 2.将 tar 包解压缩\n1 tar -zxvf test.tar.gz 21.gzip 命令 使用广泛的压缩程序，文件经它压缩过后，其名称后面会多出\u0026quot;.gz\u0026quot;的扩展名。\n命令格式\n1 gzip [参数] [文件或者目录] 常用参数\n-a或\u0026ndash;ascii 使用ASCII文字模式。 -c或\u0026ndash;stdout或\u0026ndash;to-stdout 把压缩后的文件输出到标准输出设备，不去更动原始文件。 -d或\u0026ndash;decompress或\u0026mdash;-uncompress 解开压缩文件。 -f或\u0026ndash;force 强行压缩文件。不理会文件名称或硬连接是否存在以及该文件是否为符号连接。 -h或\u0026ndash;help 在线帮助。 使用实例\n1.把 test1 目录下的每个文件压缩成.gz 文件。\n1 gzip * 四、文件权限设置 22.chmod 命令 用于改变linux系统文件或目录的访问权限。\n命令格式\n1 chmod [-cfvR] [--help] [--version] mode file 常用参数\n必要参数\n-c 当发生改变时，报告处理信息 -f 错误信息不输出 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细处理信息 选择参数\n\u0026ndash;reference=\u0026lt;目录或者文件\u0026gt; 设置成具有指定目录或者文件具有相同的权限 \u0026ndash;version 显示版本信息 \u0026lt;权限范围\u0026gt;+\u0026lt;权限设置\u0026gt; 使权限范围内的目录或者文件具有指定的权限 \u0026lt;权限范围\u0026gt;-\u0026lt;权限设置\u0026gt; 删除权限范围的目录或者文件的指定权限 \u0026lt;权限范围\u0026gt;=\u0026lt;权限设置\u0026gt; 设置权限范围内的目录或者文件的权限为指定的值 权限范围\nu ：目录或者文件的当前的用户 g ：目录或者文件的当前的群组 o ：除了目录或者文件的当前用户或群组之外的用户或者群组 a ：所有的用户及群组 权限代号\nr：读权限，用数字4表示 w：写权限，用数字2表示 x：执行权限，用数字1表示 -：删除权限，用数字0表示 使用实例\n1.增加文件所有用户组可执行权限\n1 chmod a+x test.log 删除所有用户的可执行权限\n1 chmod a-x test.log 23.chgrp 命令 可采用群组名称或群组识别码的方式改变文件或目录的所属群组。\n命令格式\n1 chgrp [选项] [组] [文件] 常用参数\n必要参数\n-c 当发生改变时输出调试信息 -f 不显示错误信息 -R 处理指定目录以及其子目录下的所有文件 -v 运行时显示详细的处理信息 \u0026ndash;dereference 作用于符号链接的指向，而不是符号链接本身 \u0026ndash;no-dereference 作用于符号链接本身 选择参数\n\u0026ndash;reference=\u0026lt;文件或者目录\u0026gt; \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.改变文件的群组属性\n1 chgrp -v bin test.log 2.改变文件test1.log 的群组属性，使得文件test1.log的群组属性和参考文件test.log的群组属性相同\n1 chgrp --reference=test.log test1.log 24.chown 命令 通过chown改变文件的拥有者和群组。\n命令格式\n1 chown [选项] [所有者] [:[组]] 文件 常用参数\n必要参数\n-c 显示更改的部分的信息 -f 忽略错误信息 -h 修复符号链接 -R 处理指定目录以及其子目录下的所有文件 -v 显示详细的处理信息 -deference 作用于符号链接的指向，而不是链接文件本身 选择参数\n\u0026ndash;reference=\u0026lt;目录或文件\u0026gt; 把指定的目录/文件作为参考，把操作的文件/目录设置成参考文件/目录相同拥有者和群组 \u0026ndash;from=\u0026lt;当前用户：当前群组\u0026gt; 只有当前用户和群组跟指定的用户和群组相同时才进行改变 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.改变拥有者和群组\n1 chown mail:mail test.log 五、磁盘存储 25.df 命令 显示指定磁盘文件的可用空间。\n命令格式 1 df [选项] [文件] 常用参数\n必要参数\n-a 全部文件系统列表 -h 方便阅读方式显示 -H 等于\u0026rsquo;-h\u0026rsquo;，但是计算式，1K=1000，而不是1K=1024 -i 显示inode信息 -k 区块为1024字节 -l 只显示本地文件系统 -m 区块为1048576字节 \u0026ndash;no-sync 忽略 sync 命令 -P 输出格式为POSIX \u0026ndash;sync 在取得磁盘信息前，先执行sync命令 -T 文件系统类型 选择参数\n\u0026ndash;block-size=\u0026lt;区块大小\u0026gt; 指定区块大小 -t\u0026lt;文件系统类型\u0026gt; 只显示选定文件系统的磁盘信息 -x\u0026lt;文件系统类型\u0026gt; 不显示选定文件系统的磁盘信息 \u0026ndash;help 显示帮助信息 \u0026ndash;version 显示版本信息 使用实例\n1.显示指定磁盘使用情况\n1 df -t ext3 du 命令 显示每个文件和目录的磁盘使用空间。\n命令格式\n1 du [选项] [文件] 常用参数\n-a或-all 显示目录中个别文件的大小。 -b或-bytes 显示目录或文件大小时，以byte为单位。 \u0026ndash; -c或\u0026ndash;total 除了显示个别目录或文件的大小外，同时也显示所有目录或文件的总和。 -k或\u0026ndash;kilobytes 以KB(1024bytes)为单位输出。 -m或\u0026ndash;megabytes 以MB为单位输出。 -s或\u0026ndash;summarize 仅显示总计，只列出最后加总的值。 -h或\u0026ndash;human-readable 以K，M，G为单位，提高信息的可读性。 -x或\u0026ndash;one-file-xystem 以一开始处理时的文件系统为准，若遇上其它不同的文件系统目录则略过。 -L\u0026lt;符号链接\u0026gt;或\u0026ndash;dereference\u0026lt;符号链接\u0026gt; 显示选项中所指定符号链接的源文件大小。 -S或\u0026ndash;separate-dirs 显示个别目录的大小时，并不含其子目录的大小。 -X\u0026lt;文件\u0026gt;或\u0026ndash;exclude-from=\u0026lt;文件\u0026gt; 在\u0026lt;文件\u0026gt;指定目录或文件。 \u0026ndash;exclude=\u0026lt;目录或文件\u0026gt; 略过指定的目录或文件。 -D或\u0026ndash;dereference-args 显示指定符号链接的源文件大小。 -H或\u0026ndash;si 与-h参数相同，但是K，M，G是以1000为换算单位。 -l或\u0026ndash;count-links 重复计算硬件链接的文件。 使用实例\n1.显示指定目录或文件所占空间\n1 2 du test # 目录 du test.log # 文件 六、性能监控和优化命令 27.top 命令 显示当前系统正在执行的进程的相关信息，包括进程ID、内存占用率、CPU占用率等。\n命令格式\n1 top [参数] 常见参数\n-b 批处理 -c 显示完整的治命令 -I 忽略失效过程 -s 保密模式 -S 累积模式 -i\u0026lt;时间\u0026gt; 设置间隔时间 -u\u0026lt;用户名\u0026gt; 指定用户名 -p\u0026lt;进程号\u0026gt; 指定进程 -n\u0026lt;次数\u0026gt; 循环显示的次数 使用实例\n显示进程信息\n1 top 28.free 命令 显示系统使用和空闲的内存情况，包括物理内存、交互区内存(swap)和内核缓冲区内存。\n命令格式\n1 free [参数] 常见参数\n-b 以Byte为单位显示内存使用情况 -k 以KB为单位显示内存使用情况 -m 以MB为单位显示内存使用情况 -g 以GB为单位显示内存使用情况 -o 不显示缓冲区调节列 -s \u0026lt;间隔秒数\u0026gt; 持续观察内存使用状况 -t 显示内存总和列。 -V 显示版本信息。 使用实例\n1.显示内存情况。\n1 2 3 free free -g #以GB为单位 free -m #以MB为单位 29.vmstat 用来显示虚拟内存的信息。\n命令格式\n1 2 3 4 5 6 7 vmstat [-a] [-n] [-S unit] [delay [ count]] vmstat [-s] [-n] [-S unit] vmstat [-m] [-n] [delay [ count]] vmstat [-d] [-n] [delay [ count]] vmstat [-p disk partition] [-n] [delay [ count]] vmstat [-f] vmstat [-V] 常见参数\n-a：显示活跃和非活跃内存 -f：显示从系统启动至今的fork数量 -m：显示slabinfo -n：只在开始时显示一次各字段名称 -s：显示内存相关统计信息及多种系统活动数量 delay：刷新时间间隔。如果不指定，只显示一条结果 count：刷新次数。如果不指定刷新次数，但指定了刷新时间间隔，这时刷新次数为无穷 -d：显示磁盘相关统计信息 -p：显示指定磁盘分区统计信息 -S：使用指定单位显示。参数有 k 、K 、m 、M ，分别代表1000、1024、1000000、1048576字节（byte）。默认单位为K（1024 bytes） 使用实例\n1.显示活跃和非活跃内存。\n1 vmstat -a 5 5 # 5秒时间内进行5次采样 30.lostat 命令 通过iostat方便查看CPU、网卡、tty设备、磁盘、CD-ROM 等等设备的活动情况, 负载信息。\n命令格式\n1 iostat [参数] [时间] [次数] 常见参数\n-C 显示CPU使用情况 -d 显示磁盘使用情况 -k 以 KB 为单位显示 -m 以 M 为单位显示 -N 显示磁盘阵列(LVM) 信息 -n 显示NFS 使用情况 -p[磁盘] 显示磁盘和分区的情况 -t 显示终端和CPU的信息 -x 显示详细信息 使用实例\n1.定时显示所有信息。\n1 iostat 2 3 #每隔 2秒刷新显示，且显示3次 31.lsof 命令 用于查看你进程开打的文件，打开文件的进程，进程打开的端口(TCP、UDP)。\n命令格式\n1 lsof [参数] [文件] 常见参数\n-a 列出打开文件存在的进程 -c\u0026lt;进程名\u0026gt; 列出指定进程所打开的文件 -g 列出GID号进程详情 -d\u0026lt;文件号\u0026gt; 列出占用该文件号的进程 +d\u0026lt;目录\u0026gt; 列出目录下被打开的文件 +D\u0026lt;目录\u0026gt; 递归列出目录下被打开的文件 -n\u0026lt;目录\u0026gt; 列出使用NFS的文件 -i\u0026lt;条件\u0026gt; 列出符合条件的进程。（4、6、协议、:端口、 @ip ） -p\u0026lt;进程号\u0026gt; 列出指定进程号所打开的文件 -u 列出UID号进程详情 使用实例\n1.查看谁正在使用bash文件，也就是说查找某个文件相关的进程。\n1 lsof /bin/bash 七、网络命令 32.ifconfig 命令 ifconfig 命令用来查看和配置网络设备。\n命令格式\n1 ifconfig [网络设备] [参数] 常见参数\nup 启动指定网络设备/网卡 down 关闭指定网络设备/网卡。 arp 设置指定网卡是否支持ARP协议 -promisc 设置是否支持网卡的promiscuous模式，如果选择此参数，网卡将接收网络中发给它所有的数据包 -allmulti 设置是否支持多播模式，如果选择此参数，网卡将接收网络中所有的多播数据包 -a 显示全部接口信息 -s 显示摘要信息（类似于 netstat -i） add 给指定网卡配置IPv6地址 del 删除指定网卡的IPv6地址 使用实例\n1.启动关闭指定网卡\n1 2 ifconfig eth0 up ifconfig eth0 down 2.用ifconfig修改MAC地址\n1 ifconfig eth0 hw ether 00:AA:BB:CC:DD:EE 33.route 命令 Route命令是用于操作基于内核ip路由表，它的主要作用是创建一个静态路由让指定一个主机或者一个网络通过一个网络接口，如eth0。\n命令格式\n1 route [-f] [-p] [Command [Destination] [mask Netmask] [Gateway] [metric Metric]] [if Interface]] 常见参数\n-c 显示更多信息 -n 不解析名字 -v 显示详细的处理信息 -F 显示发送信息 -C 显示路由缓存 -f 清除所有网关入口的路由表。 -p 与 add 命令一起使用时使路由具有永久性。 add:添加一条新路由。 del:删除一条路由。 -net:目标地址是一个网络。 -host:目标地址是一个主机。 netmask:当添加一个网络路由时，需要使用网络掩码。 gw:路由数据包通过网关。注意，你指定的网关必须能够达到。 metric：设置路由跳数。 Command 指定您想运行的命令 (Add/Change/Delete/Print)。 Destination 指定该路由的网络目标。 使用实例\n1.显示当前路由\n1 2 route route -n 2.添加网关/设置网关\n1 route add -net 224.0.0.0 netmask 240.0.0.0 dev eth0 ping 命令 确定网络和各外部主机的状态；跟踪和隔离硬件和软件问题；测试、评估和管理网络。\n命令格式\n1 ping [参数] [主机名或IP地址] 常见参数\n-d 使用Socket的SO_DEBUG功能 -f 极限检测。大量且快速地送网络封包给一台机器，看它的回应 -n 只输出数值 -q 不显示任何传送封包的信息，只显示最后的结果 -r 忽略普通的Routing Table，直接将数据包送到远端主机上。通常是查看本机的网络接口是否有问题 -R 记录路由过程 -v 详细显示指令的执行过程 -c 数目：在发送指定数目的包后停止 -i 秒数：设定间隔几秒送一个网络封包给一台机器，预设值是一秒送一次 -I 网络界面：使用指定的网络界面送出数据包 -l 前置载入：设置在送出要求信息之前，先行发出的数据包 -p 范本样式：设置填满数据包的范本样式 -s 字节数：指定发送的数据字节数，预设值是56，加上8字节的ICMP头，一共是64ICMP数据字节 -t 存活数值：设置存活数值TTL的大小 使用实例\nping 网关\n1 ping -b 192.168.120.1 35.traceroute 命令\n让你追踪网络数据包的路由途径，预设数据包大小是40Bytes，用户可另行设置。\n命令格式\n1 traceroute [参数] [主机] 常见参数\n-d 使用Socket层级的排错功能 -f 设置第一个检测数据包的存活数值TTL的大小 -F 设置勿离断位 -g 设置来源路由网关，最多可设置8个 -i 使用指定的网络界面送出数据包 -I 使用ICMP回应取代UDP资料信息 -m 设置检测数据包的最大存活数值TTL的大小 -n 直接使用IP地址而非主机名称 -p 设置UDP传输协议的通信端口 -r 忽略普通的Routing Table，直接将数据包送到远端主机上 -s 设置本地主机送出数据包的IP地址 -t 设置检测数据包的TOS数值 -v 详细显示指令的执行过程 -w 设置等待远端主机回报的时间 -x 开启或关闭数据包的正确性检验 使用实例\n1.traceroute 用法简单、最常用的用法\n1 traceroute www.baidu.com 跳数设置\n1 traceroute -m 10 www.baidu.com 36.netstat 命令 用于显示与IP、TCP、UDP和ICMP协议相关的统计数据，一般用于检验本机各端口的网络连接情况。\n命令格式\n1 netstat [-acCeFghilMnNoprstuvVwx] [-A\u0026lt;网络类型\u0026gt;] [--ip] 常见参数\n-a或-all 显示所有连线中的Socket -A\u0026lt;网络类型\u0026gt;或-\u0026lt;网络类型\u0026gt; 列出该网络类型连线中的相关地址 -c或-continuous 持续列出网络状态 -C或-cache 显示路由器配置的快取信息 -e或-extend 显示网络其他相关信息 -F或-fib 显示FIB -g或-groups 显示多重广播功能群组组员名单 -h或-help 在线帮助 -i或-interfaces 显示网络界面信息表单 -l或-listening 显示监控中的服务器的Socket -M或-masquerade 显示伪装的网络连线 -n或-numeric 直接使用IP地址，而不通过域名服务器 -N或-netlink或-symbolic 显示网络硬件外围设备的符号连接名称 -o或-timers 显示计时器 -p或-programs 显示正在使用Socket的程序识别码和程序名称 -r或-route 显示Routing Table -s或-statistice 显示网络工作信息统计表 -t或-tcp 显示TCP传输协议的连线状况 -u或-udp 显示UDP传输协议的连线状况 -v或-verbose 显示指令执行过程 -V或-version 显示版本信息 -w或-raw 显示RAW传输协议的连线状况 -x或-unix 此参数的效果和指定\u0026quot;-A unix\u0026quot;参数相同 -ip或-inet 此参数的效果和指定\u0026quot;-A inet\u0026quot;参数相同 使用实例\n列出所有端口\n1 netstat -a 37.telnet 命令 执行telnet指令开启终端机阶段作业，并登入远端主机。\n命令格式\n1 telnet [参数] [主机] 常见参数\n-8 允许使用8位字符资料，包括输入与输出 -a 尝试自动登入远端系统 -b\u0026lt;主机别名\u0026gt; 使用别名指定远端主机名称 -c 不读取用户专属目录里的.telnetrc文件 -d 启动排错模式 -e\u0026lt;脱离字符\u0026gt; 设置脱离字符 -E 滤除脱离字符 -f 此参数的效果和指定\u0026quot;-F\u0026quot;参数相同 使用实例\n1.远程服务器无法访问\n1 telnet 192.168.120.206 八、其他命令 38.ln 命令 为某一个文件在另外一个位置建立一个同步的链接.当我们需要在不同的目录，用到相同的文件时，我们不需要在每一个需要的目录下都放一个必须相同的文件，我们只要在某个固定的目录，放上该文件，然后在 其它的目录下用ln命令链接（link）它就可以，不必重复的占用磁盘空间。\n命令格式\n1 ln [参数] [源文件或目录] [目标文件或目录] 常用参数\n必要参数\n-b 删除，覆盖以前建立的链接 -d 允许超级用户制作目录的硬链接 -f 强制执行 -i 交互模式，文件存在则提示用户是否覆盖 -n 把符号链接视为一般目录 -s 软链接(符号链接) -v 显示详细的处理过程 选择参数\n-S -S\u0026lt;字尾备份字符串\u0026gt; 或 --suffix=\u0026lt;字尾备份字符串\u0026gt; -V -V\u0026lt;备份方式\u0026gt; 或 --version-control=\u0026lt;备份方式\u0026gt;\n使用实例\n1.为 test.log文件创建软链接linktest\n1 ln -s test.log linktest 2.为 test.log创建硬链接lntest。\n1 ln test.log lntest 39.diff 命令 比较单个文件或者目录内容。\n命令格式\n1 diff [参数] [文件1或目录1] [文件2或目录2] 常用参数\n-c 上下文模式，显示全部内文，并标出不同之处 -u 统一模式，以合并的方式来显示文件内容的不同 -a 只会逐行比较文本文件 -N 在比较目录时，若文件 A 仅出现在某个目录中，预设会显示：Only in 目录。若使用 -N 参数，则 diff 会将文件 A 与一个空白的文件比较 -r 递归比较目录下的文件 使用实例\n1.显示 test1.txt 和 test2.txt 两个文件差异。\n1 diff test1.txt test2.txt 40.grep 命令 一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。\n命令格式\n1 grep [option] pattern file 常用参数\n-c 计算找到\u0026rsquo;搜寻字符串\u0026rsquo;（即 pattern）的次数 -i 忽略大小写的不同，所以大小写视为相同 -n 输出行号 -v 反向选择，打印不匹配的行 -r 递归搜索 \u0026ndash;color=auto 将找到的关键词部分加上颜色显示 使用实例\n1.将 /etc/passwd 文件中出现 root 的行取出来，关键词部分加上颜色显示。\n1 2 grep \u0026#34;root\u0026#34; /etc/passwd --color=auto cat /etc/passwd | grep \u0026#34;root\u0026#34; --color=auto 2.将 /etc/passwd 文件中没有出现 root 和 nologin 的行取出来。\n1 grep -v \u0026#34;root\u0026#34; /etc/passwd | grep -v \u0026#34;nologin\u0026#34; 41.wc 命令 用来显示文件所包含的行、字和字节数。\n命令格式\n1 wc [选项] [文件] 常用参数\n-c 统计字节数 -l 统计行数 -m 统计字符数，这个标志不能与 -c 标志一起使用 -w 统计字数，一个字被定义为由空白、跳格或换行字符分隔的字符串 -L 打印最长行的长度 使用实例\n1.统计文件的字节数、行数和字符数。\n1 2 3 wc -c test.txt wc -l test.txt wc -m test.txt 2.统计文件的字节数、行数和字符数，只打印数字，不打印文件名。\n1 2 3 cat test.txt | wc -c cat test.txt | wc -l cat test.txt | wc -m 42.ps 命令 用来显示当前进程的状态。\n命令格式\n1 ps[参数] 常用参数\na 显示所有进程 -a 显示同一终端下的所有程序 -A 显示所有进程 c 显示进程的真实名称 -N 反向选择 -e 等于-A e 显示环境变量 f 显示程序间的关系 -H 显示树状结构 r 显示当前终端的进程 T 显示当前终端的所有程序 u 指定用户的所有进程 -au 显示较详细的资讯 -aux 显示所有包含其他使用者的行程 -C\u0026lt;命令\u0026gt; 列出指定命令的状况 \u0026ndash;lines\u0026lt;行数\u0026gt; 每页显示的行数 \u0026ndash;width\u0026lt;字符数\u0026gt; 每页显示的字符数 使用实例\n1.显示所有进程信息。\n1 ps -A 显示指定用户信息。\n1 ps -u root 显示所有进程信息，连同命令行。\n1 ps -ef 43.watch 命令\n可以将命令的输出结果输出到标准输出设备，多用于周期性执行命令/定时执行命令。\n命令格式\n1 watch [参数] [命令] 常用参数\n-n或\u0026ndash;interval watch缺省每2秒运行一下程序，可以用-n或-interval来指定间隔的时间。 -d或\u0026ndash;differences 用-d或\u0026ndash;differences 选项watch 会高亮显示变化的区域。 而-d=cumulative选项会把变动过的地方(不管最近的那次有没有变动)都高亮显示出来。 -t 或-no-title 会关闭watch命令在顶部的时间间隔,命令，当前时间的输出。 -h, \u0026ndash;help 查看帮助文档 使用实例\n1.每隔一秒高亮显示网络链接数的变化情况\n1 watch -n 1 -d netstat -ant 2.每隔一秒高亮显示http链接数的变化情况\n1 watch -n 1 -d \u0026#39;pstree|grep http\u0026#39; 44.at 命令 在一个指定的时间执行一个指定任务，只能执行一次。（需开启atd进程）\n命令格式\n1 at [参数] [时间] 常用参数\n-m 当指定的任务被完成之后，将给用户发送邮件，即使没有标准输出 -I atq的别名 -d atrm的别名 -v 显示任务将被执行的时间 -c 打印任务的内容到标准输出 -V 显示版本信息 -q\u0026lt;列队\u0026gt; 使用指定的列队 -f\u0026lt;文件\u0026gt; 从指定文件读入任务而不是从标准输入读入 -t\u0026lt;时间参数\u0026gt; 以时间参数的形式提交要运行的任务 使用实例\n1.3天后的下午5点执行/bin/ls\n1 2 3 at 5pm+3 days at\u0026gt; /bin/ls at\u0026gt; \u0026lt;EOT\u0026gt; 45.crontab 命令 在固定的间隔时间执行指定的系统指令或 shell script脚本。时间间隔的单位可以是分钟、小时、日、月、周及以上的任意组合。(需开启crond服务)\n命令格式\n1 2 crontab [-u user] file 或 crontab [-u user] [ -e | -l | -r ] 常用参数\n-u user：用来设定某个用户的crontab服务，例如，-u ixdba表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。 file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。 -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。 -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。 -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。 -i：在删除用户的crontab文件时给确认提示。 使用实例\n1.列出 crontab 文件。\n1 crontab -l 2.编辑crontab 文件。\n1 crontab -e Crontab 任务实例\n1.每1分钟执行一次command\n1 * * * * * command 2.每小时的第3和第15分钟执行\n1 3,15 * * * * command 3.在上午8点到11点的第3和第15分钟执行\n1 3,15 8-11 * * * command ","permalink":"https://WFUing.github.io/posts/tech/os/linux-instructions/","summary":"Linux 的命令确实非常多，然而熟悉 Linux 的人从来不会因为 Linux 的命令太多而烦恼。因为我们仅仅只需要掌握常用命令，就完全可以驾驭 Linux。\n接下来，让我们一起来看看都有那些常用的 Linux 命令吧！\n一、文件目录操作 1.ls 命令 ls 命令不仅可以查看 linux 文件夹包含的文件而且可以查看文件权限（包括目录、文件夹、文件权限）查看目录信息等等。\n命令格式\n1 ls [选项][目录名] 常用参数\n-l ：列出长数据串，包含文件的属性与权限数据等 -a ：列出全部的文件，连同隐藏文件（开头为.的文件）一起列出来（常用） -d ：仅列出目录本身，而不是列出目录的文件数据 -h ：将文件容量以较易读的方式（GB，kB等）列出来 -R ：连同子目录的内容一起列出（递归列出），等于该目录下的所有文件都会显示出来 使用实例\n1.列出 home 目录下的所有文件和目录的详细资料。\n1 2 ls -a -l /home ls -al /home 2.列出当前目录下所有以\u0026quot;d\u0026quot;开头的文件目录详情内容。\n1 ls -l d* 2.cd命令 最基本的命令语句，其他的命令语句要进行操作，都是建立在使用 cd 命令上的。用于切换当前目录至dirName。\n命令格式\n1 cd [目录名] 操作案例\n1.从当前目录进入系统根目录。\n1 cd / 2.跳转到 home/Code 目录。\n1 cd /home/Code 3.pwd 命令 查看\u0026quot;当前工作目录\u0026quot;的完整路径。","title":"45 个常用Linux 命令，让你轻松玩转Linux！"},{"content":"Six strategies for getting better results Write clear instructions GPT 无法读懂你的心思。如果产出太长，请要求简短回复。如果结果太简单，要求专家级的写作。如果您不喜欢格式，请演示您希望看到的格式。GPT 越少需要猜测你想要什么，你就越有可能得到它。\n在您的询问中包含详细信息，以获得更多相关答案：为了得到高度相关的回复，请确保请求提供了任何重要的细节或上下文。否则，您就只能让模型来猜测您的意思了。 要求模特采用一个角色：系统信息可用于指定模型在回复中使用的角色。 使用分隔符清楚标明输入内容的不同部分：三引号、XML 标记、章节标题等分隔符可以帮助划分需要区别对待的文本部分。 指定完成任务所需的步骤：有些任务最好以一连串的步骤来指定。明确写出这些步骤可以让模型更容易地遵循它们。 举例说明：提供适用于所有示例的一般说明通常比通过示例演示任务的所有排列组合更有效，但在某些情况下，提供示例可能更容易。例如，如果您打算让模型复制一种难以明确描述的回应用户询问的特定风格，这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。 指定所需的输出长度：您可以要求模型生成具有给定目标长度的输出。可以用字数、句数、段落数、要点数等来指定目标输出长度。但请注意，指示模型生成特定字数的精确度并不高。模型可以更可靠地生成具有特定段落数或要点数的输出结果。 Provide reference text GPT 可以自信地编造虚假答案，尤其是在被问及深奥的话题或引用和 URL 时。就像一张笔记能帮助学生在考试中取得更好的成绩一样，为 GPT 提供参考文本也能帮助他们在作答时减少无中生有的情况。\n指导模型使用参考文本作答：如果我们能为模型提供与当前查询相关的可信信息，那么我们就可以指示模型使用所提供的信息来撰写答案。 指导范例引用参考文献回答问题：如果输入内容中已经补充了相关知识，那么就可以直接要求模型通过引用所提供文档中的段落来为其答案添加引文。请注意，输出中的引用可以通过所提供文档中的字符串匹配进行编程验证。 Split complex tasks into simpler subtasks 在软件工程中，将一个复杂的系统分解成一系列模块化组件是一种很好的做法，提交给 GPT 的任务也是如此。复杂任务的错误率往往高于简单任务。此外，复杂任务通常可以重新定义为较简单任务的工作流程，其中前期任务的输出被用于构建后期任务的输入。\n使用意图分类来确定与用户查询最相关的指令：对于需要大量独立指令集来处理不同情况的任务，首先对查询类型进行分类，并利用该分类来确定需要哪些指令，可能会有所帮助。这可以通过定义固定类别和硬编码与处理特定类别任务相关的指令来实现。这一过程也可以递归应用，将任务分解为一系列阶段。这种方法的优势在于，每次查询只包含执行任务下一阶段所需的指令，与使用单次查询执行整个任务相比，错误率更低。这还可以降低成本，因为运行较大的提示需要花费更多的成本。 对于需要冗长对话的对话应用程序，总结或过滤之前的对话：由于 GPT 的上下文长度是固定的，因此用户和助手之间的对话（整个对话都包含在上下文窗口中）不可能无限期地进行下去。解决这个问题有多种变通方法，其中之一就是总结对话中的前几轮对话。一旦输入的大小达到预定的阈值长度，就会触发一个对部分对话进行总结的查询，而之前对话的总结可以作为系统消息的一部分。或者，也可以在整个对话过程中在后台异步总结之前的对话。 对长文档进行分块摘要，并递归构建完整摘要：由于 GPT 有固定的上下文长度，因此在单次查询中，GPT 无法用于摘要长度超过上下文长度减去生成摘要长度的文本。 Give GPTs time to \u0026ldquo;think\u0026rdquo; 如果要求你用 17 乘以 28，你可能不会马上知道，但花点时间还是能算出来的。同样，GPT 学生在试图立即回答而不是花时间推理出答案时，会犯更多的推理错误。在回答问题之前，要求学生进行一连串的推理，可以帮助 GPT 学生更可靠地推理出正确答案。\n在匆忙得出结论之前，指示模型自己找出解决方案：如果我们明确指示模型在得出结论之前先从第一性原理进行推理，会得到更好的结果。例如，假设我们想要一个模型来评估学生对数学问题的解答。最明显的方法是简单地问模型学生的解法是否正确。 使用内心独白或一系列查询来隐藏模型的推理过程：前面的策略表明，在回答具体问题之前，模型有时必须对问题进行详细推理。对于某些应用，模型得出最终答案的推理过程不宜与用户共享。例如，在辅导应用中，我们可能希望鼓励学生自己找出答案，但模型对学生解决方案的推理过程可能会向学生透露答案。内心独白是一种可以用来缓解这种情况的策略。内心独白的原理是指示模型将输出结果中不对用户公开的部分转化为结构化格式，以便于解析。然后，在向用户展示输出结果之前，先对输出结果进行解析，只让部分输出结果可见。 Use external tools 向 GPT 提供其他工具的输出结果，弥补 GPT 的不足。例如，文本检索系统可以告诉 GPT 相关文档的信息。代码执行引擎可以帮助 GPT 进行数学运算和运行代码。如果某项任务可以通过工具而不是 GPT 更可靠或更高效地完成，那么就将其卸载，以获得两者的最佳效果。\n利用嵌入式搜索实现高效知识检索：如果将外部信息源作为输入的一部分，模型可以利用外部信息源。这可以帮助模型生成更多信息和最新回复。例如，如果用户询问有关特定电影的问题，那么在模型输入中添加有关电影的高质量信息（如演员、导演等\u0026hellip;\u0026hellip;）可能会很有用。嵌入可用于实现高效的知识检索，以便在运行时将相关信息动态添加到模型输入中。文本嵌入是一个可以衡量文本字符串之间相关性的向量。相似或相关的字符串会比不相关的字符串靠得更近。这一事实以及快速向量搜索算法的存在，意味着嵌入可以用来实现高效的知识检索。特别是，文本语料库可以分割成若干块，每个块都可以嵌入和存储。然后，可以嵌入给定的查询，并执行矢量搜索，从语料库中找到与查询最相关的嵌入文本块（即在嵌入空间中最接近的文本块）。 使用代码执行来执行更精确的计算或调用外部应用程序接口：不能依靠 GPT 自行准确执行算术运算或长时间计算。在需要的情况下，可以指示模型编写和运行代码，而不是自己进行计算。特别是，可以指示模型将需要运行的代码放入指定格式（如三重回溯）中。产生输出后，可提取并运行代码。最后，如有必要，可将代码执行引擎（即 Python 解释器）的输出作为下一次查询的模型输入。 让模型访问特定功能：聊天完成 API 允许在请求中传递函数描述列表。这样，模型就能根据提供的模式生成函数参数。生成的函数参数由 API 以 JSON 格式返回，可用于执行函数调用。然后，函数调用提供的输出可以在下一个请求中反馈到模型中，以结束循环。这是使用 GPT 模型调用外部函数的推荐方式。 Test changes systematically 如果能对性能进行测量，提高性能就会变得更容易。在某些情况下，对提示符的修改会在一些孤立的示例上取得更好的性能，但在更具代表性的示例集上却会导致整体性能下降。因此，为了确保修改对性能的净积极影响，可能有必要定义一个综合测试套件（也称为 \u0026ldquo;评估\u0026rdquo;）。\nResources https://platform.openai.com/docs/guides/gpt-best-practices https://github.com/mattnigh/ChatGPT3-Free-Prompt-List https://style.mla.org/citing-generative-ai/ ","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/chatgpt-guide/","summary":"Six strategies for getting better results Write clear instructions GPT 无法读懂你的心思。如果产出太长，请要求简短回复。如果结果太简单，要求专家级的写作。如果您不喜欢格式，请演示您希望看到的格式。GPT 越少需要猜测你想要什么，你就越有可能得到它。\n在您的询问中包含详细信息，以获得更多相关答案：为了得到高度相关的回复，请确保请求提供了任何重要的细节或上下文。否则，您就只能让模型来猜测您的意思了。 要求模特采用一个角色：系统信息可用于指定模型在回复中使用的角色。 使用分隔符清楚标明输入内容的不同部分：三引号、XML 标记、章节标题等分隔符可以帮助划分需要区别对待的文本部分。 指定完成任务所需的步骤：有些任务最好以一连串的步骤来指定。明确写出这些步骤可以让模型更容易地遵循它们。 举例说明：提供适用于所有示例的一般说明通常比通过示例演示任务的所有排列组合更有效，但在某些情况下，提供示例可能更容易。例如，如果您打算让模型复制一种难以明确描述的回应用户询问的特定风格，这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。这就是所谓的 \u0026ldquo;少量 \u0026ldquo;提示。 指定所需的输出长度：您可以要求模型生成具有给定目标长度的输出。可以用字数、句数、段落数、要点数等来指定目标输出长度。但请注意，指示模型生成特定字数的精确度并不高。模型可以更可靠地生成具有特定段落数或要点数的输出结果。 Provide reference text GPT 可以自信地编造虚假答案，尤其是在被问及深奥的话题或引用和 URL 时。就像一张笔记能帮助学生在考试中取得更好的成绩一样，为 GPT 提供参考文本也能帮助他们在作答时减少无中生有的情况。\n指导模型使用参考文本作答：如果我们能为模型提供与当前查询相关的可信信息，那么我们就可以指示模型使用所提供的信息来撰写答案。 指导范例引用参考文献回答问题：如果输入内容中已经补充了相关知识，那么就可以直接要求模型通过引用所提供文档中的段落来为其答案添加引文。请注意，输出中的引用可以通过所提供文档中的字符串匹配进行编程验证。 Split complex tasks into simpler subtasks 在软件工程中，将一个复杂的系统分解成一系列模块化组件是一种很好的做法，提交给 GPT 的任务也是如此。复杂任务的错误率往往高于简单任务。此外，复杂任务通常可以重新定义为较简单任务的工作流程，其中前期任务的输出被用于构建后期任务的输入。\n使用意图分类来确定与用户查询最相关的指令：对于需要大量独立指令集来处理不同情况的任务，首先对查询类型进行分类，并利用该分类来确定需要哪些指令，可能会有所帮助。这可以通过定义固定类别和硬编码与处理特定类别任务相关的指令来实现。这一过程也可以递归应用，将任务分解为一系列阶段。这种方法的优势在于，每次查询只包含执行任务下一阶段所需的指令，与使用单次查询执行整个任务相比，错误率更低。这还可以降低成本，因为运行较大的提示需要花费更多的成本。 对于需要冗长对话的对话应用程序，总结或过滤之前的对话：由于 GPT 的上下文长度是固定的，因此用户和助手之间的对话（整个对话都包含在上下文窗口中）不可能无限期地进行下去。解决这个问题有多种变通方法，其中之一就是总结对话中的前几轮对话。一旦输入的大小达到预定的阈值长度，就会触发一个对部分对话进行总结的查询，而之前对话的总结可以作为系统消息的一部分。或者，也可以在整个对话过程中在后台异步总结之前的对话。 对长文档进行分块摘要，并递归构建完整摘要：由于 GPT 有固定的上下文长度，因此在单次查询中，GPT 无法用于摘要长度超过上下文长度减去生成摘要长度的文本。 Give GPTs time to \u0026ldquo;think\u0026rdquo; 如果要求你用 17 乘以 28，你可能不会马上知道，但花点时间还是能算出来的。同样，GPT 学生在试图立即回答而不是花时间推理出答案时，会犯更多的推理错误。在回答问题之前，要求学生进行一连串的推理，可以帮助 GPT 学生更可靠地推理出正确答案。\n在匆忙得出结论之前，指示模型自己找出解决方案：如果我们明确指示模型在得出结论之前先从第一性原理进行推理，会得到更好的结果。例如，假设我们想要一个模型来评估学生对数学问题的解答。最明显的方法是简单地问模型学生的解法是否正确。 使用内心独白或一系列查询来隐藏模型的推理过程：前面的策略表明，在回答具体问题之前，模型有时必须对问题进行详细推理。对于某些应用，模型得出最终答案的推理过程不宜与用户共享。例如，在辅导应用中，我们可能希望鼓励学生自己找出答案，但模型对学生解决方案的推理过程可能会向学生透露答案。内心独白是一种可以用来缓解这种情况的策略。内心独白的原理是指示模型将输出结果中不对用户公开的部分转化为结构化格式，以便于解析。然后，在向用户展示输出结果之前，先对输出结果进行解析，只让部分输出结果可见。 Use external tools 向 GPT 提供其他工具的输出结果，弥补 GPT 的不足。例如，文本检索系统可以告诉 GPT 相关文档的信息。代码执行引擎可以帮助 GPT 进行数学运算和运行代码。如果某项任务可以通过工具而不是 GPT 更可靠或更高效地完成，那么就将其卸载，以获得两者的最佳效果。","title":"chatGPT 使用指南"},{"content":"Resources github：https://github.com/fatedier/frp document：https://gofrp.org/docs/ finalshell：https://sourceforge.net/projects/finalshell/ vscode remote ssh：https://code.visualstudio.com/docs/remote/ssh 下面给出一些blog，都详细写了如何使用frp搭建内网穿透，在本文中就不再赘述。\n使用frp进行内网穿透：https://sspai.com/post/52523 基于frp docker 进行内网穿透：https://izhaong.com/pages/b387de/ CentOS7下通过frp做内网穿透：https://blog.fengdis.com/2019/12/25/CentOS%E4%B8%8B%E9%80%9A%E8%BF%87frp%E5%81%9A%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/ 这一篇blog的05节写了遇到的常见问题，这也是本文关心的。\n常见问题：https://www.derrors.cn/index.php/it-tech/frp.html Questions 大部分都是网络端口上的问题，下面先给出一张frp的原理图。\nssh: connect to host xx.xx.xx.xx port xx: Operation timed out\n使用ssh连接时，连接超时 原因：服务器防火墙未开放frp配置中对应的remote_port端口； 解决：在服务器的防火墙中开放相应端口。 ssh: connect to host xx.xx.xx.xx port xx: Connection refused\n连接被拒绝 原因：服务器防火墙未开放frp配置中对应的server_port端口； 解决：在服务器的防火墙中开放相应端口。 当然云服务器端，也会有安全组或者防火墙，需要把相应的都开起来\n1 2 3 4 5 6 7 8 9 #开放端口 firewall-cmd --zone=public --add-port=7000/tcp --permanent firewall-cmd --zone=public --add-port=6000/tcp --permanent #查看开放端口列表 firewall-cmd --permanent --zone=public --list-ports #防火墙reload firewall-cmd --reload firewalld 拓展 这边很多的问题都跟防火墙有关系，这边给出 firewalld 的相关指令。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 source: 根据源地址过滤（优先级最高） interface: 根据网卡过滤（优先级次高） service: 根据服务名过滤 port: 根据端口过滤 icmp-block: icmp 报文过滤，按照 icmp 类型配置 masquerade: ip 地址伪装 forward-port: 端口转发 rule: 自定义规则 # 查看是否开启 systemctl status firewalld.service # 打开防火墙 systemctl start firewalld.service # 停用防火墙 systemctl disable firewalld # 禁用防火墙 systemctl stop firewalld.service # 开机启动 systemctl enable firewalld # 取消开机启动 systemctl disable firewalld # 查看运行状态 firewall-cmd --state # 查看接口信息 firewall-cmd --list-all # 更新防火墙规则方法1:无需断开连接，动态更改规则 firewall-cmd --reload # 更新防火墙规则方法2:断开连接，以重启的方式更改规则 firewall-cmd --complete-reload # 查看帮助 firewall-cmd --help --zone=NAME # 指定 Zone --permanent # 为永久生效 --timeout=seconds # 持续一段时间，到期后自动移除，经常用于调试，且不能与 --permanent 同时使用 # 追加一个8181端口，永久有效 firewall-cmd --add-port=8181/tcp --permanent # 追加一段端口范围 firewall-cmd --add-port=6000-6600/tcp # 开放 ftp 服务 firewall-cmd --add-service=ftp # 添加eth0 接口至 public 信任等级，永久有效 firewall-cmd --zone=public --add-interface=eth0 --permanent # 关闭防火墙 sudo systemctl stop firewalld # 关闭端口 sudo firewall-cmd --remove-port=3000/tcp --permanent # 配置 public zone 的端口转发 firewall-cmd --zone=public --add-masquerade # 然后转发 tcp 22 端口至 9527 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=9527 # 转发 22 端口数据至另一个 ip 的相同端口上 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toaddr=192.168.1.123 # 转发 22 端口数据至另一 ip 的 9527 端口上 firewall-cmd --zone=public --add-forward-port=port=22:proto=tcp:toport=9527:toaddr=192.168.1.100 # IP 封禁 firewall-cmd --permanent --add-rich-rule=\u0026#34;rule family=\u0026#39;ipv4\u0026#39; source address=\u0026#39;192.168.1.123\u0026#39; reject\u0026#34; # 通过 ipset 来封禁 ip firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:ip firewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=192.168.1.123 # 封禁网段 firewall-cmd --permanent --zone=public --new-ipset=blacklist --type=hash:net firewall-cmd --permanent --zone=public --ipset=blacklist --add-entry=192.168.1.0/24 # 倒入 ipset 规则 blacklist，然后封禁 blacklist firewall-cmd --permanent --zone=public --new-ipset-from-file=/path/blacklist.xml firewall-cmd --permanent --zone=public --add-rich-rule=\u0026#39;rule source ipset=blacklist drop\u0026#39; ","permalink":"https://WFUing.github.io/posts/tech/network/frp-nat-traversal/","summary":"Resources github：https://github.com/fatedier/frp document：https://gofrp.org/docs/ finalshell：https://sourceforge.net/projects/finalshell/ vscode remote ssh：https://code.visualstudio.com/docs/remote/ssh 下面给出一些blog，都详细写了如何使用frp搭建内网穿透，在本文中就不再赘述。\n使用frp进行内网穿透：https://sspai.com/post/52523 基于frp docker 进行内网穿透：https://izhaong.com/pages/b387de/ CentOS7下通过frp做内网穿透：https://blog.fengdis.com/2019/12/25/CentOS%E4%B8%8B%E9%80%9A%E8%BF%87frp%E5%81%9A%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F/ 这一篇blog的05节写了遇到的常见问题，这也是本文关心的。\n常见问题：https://www.derrors.cn/index.php/it-tech/frp.html Questions 大部分都是网络端口上的问题，下面先给出一张frp的原理图。\nssh: connect to host xx.xx.xx.xx port xx: Operation timed out\n使用ssh连接时，连接超时 原因：服务器防火墙未开放frp配置中对应的remote_port端口； 解决：在服务器的防火墙中开放相应端口。 ssh: connect to host xx.xx.xx.xx port xx: Connection refused\n连接被拒绝 原因：服务器防火墙未开放frp配置中对应的server_port端口； 解决：在服务器的防火墙中开放相应端口。 当然云服务器端，也会有安全组或者防火墙，需要把相应的都开起来\n1 2 3 4 5 6 7 8 9 #开放端口 firewall-cmd --zone=public --add-port=7000/tcp --permanent firewall-cmd --zone=public --add-port=6000/tcp --permanent #查看开放端口列表 firewall-cmd --permanent --zone=public --list-ports #防火墙reload firewall-cmd --reload firewalld 拓展 这边很多的问题都跟防火墙有关系，这边给出 firewalld 的相关指令。","title":"Frp Nat Traversal"},{"content":"Resources url: https://www.telosys.org/ tutorial: https://tomassetti.me/telosys-code-generation-tool/ ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/telosys-code-generation-tool/","summary":"Resources url: https://www.telosys.org/ tutorial: https://tomassetti.me/telosys-code-generation-tool/ ","title":"Telosys: a Code Generation Tool by Laurent Guerin"},{"content":"什么是 DevOps 什么是 DevOps？DevOps 集文化理念、实践和工具于一身，它强调团队授权、跨团队沟通和协作以及技术自动化，其最终目标是优化质量和交付。\nDevOps 理念，旨在打破开发工程师和运维工程师的壁垒，强调两个团队合而为一，在产品的整个生命周期（从开发、测试、部署再到运维、运营）内相互协作，工程师不再限于单一职能。\nDevOps 始于 2007 年左右，当时的开发和运维对传统的软件开发模式提出了担忧：在这种模式下，编写代码的开发人员与负责部署的运维人员分开工作。 DevOps 一词是开发（development）和运维（operations）这两个词的组合，反映了将二者合而为一的过程。\nDevOps 如何工作 DevOps 团队包括在整个产品生命周期中协同工作的开发人员和运维人员，以提高软件部署的速度和质量。这是一种新的工作方式，一种文化转变，对团队及其工作的组织具有重要意义。\n在 DevOps 模型下，开发和运维团队不再 \u0026ldquo;孤立\u0026rdquo;。有时，这两个团队甚至会合并为一个团队，工程师在整个应用程序生命周期中工作，需要具备从开发、测试到部署和运维的复合型能力。\nDevOps 团队使用工具来自动化和优化流程，这有助于提高可靠性。 DevOps 工具链可帮助团队处理重要的 DevOps 基础知识，包括持续集成、持续交付、自动化和协作。\nDevOps 价值观也适用于开发以外的团队。如果 QA、安全团队也和开发、运维团队紧密地结合在一起，贯穿产品的整个生命周期。此时，安全成为了所有 DevOps 团队成员的工作重点，此时可以称为为 \u0026ldquo;DevSecOps\u0026rdquo;。\nDevOps 的生命周期 由于 DevOps 的连续性，可以使用无限循环来展示 DevOps 生命周期的各个阶段是如何相互关联的。尽管看起来是按顺序流动的，但循环象征着在整个生命周期中始终保持持续迭代。\nDevOps 生命周期由六个阶段组成，分别代表开发和运维所需的流程、功能和工具。在每个阶段，团队协作和沟通以保持一致性、速度和质量。\nDevOps 的优势 速度：应用 DevOps 可以更频繁地发布可交付成果，并且质量和稳定性也更高。高效的迭代，可以根据客户和市场反馈进行快速响应，以适应市场变化，有效推动业务发展。 促进协作：DevOps 的基础是开发和运维之间的协作文化，两个团队紧密协作，共同承担诸多责任，并将各自的工作流程相互融合。这有助于减少效率低下的工作，同时节约大家的时间。 快速发布：提高发布的频率和速度，以便能够更快速地进行创新并完善产品。您发布新功能和修复错误的速度越快，就越能快速地响应客户需求并建立竞争优势。持续集成和持续交付是自动执行软件发布流程（从构建到部署）的两项实践经验。 可靠性：持续集成和持续部署等实践可检验程序变更后，功能是否正常，是否安全，从而提高软件产品的交付质量。监控和日志记录可以帮助团队实时了解服务当前的运行状态。 规模：大规模运行和管理您的基础设施及开发流程。自动化和一致性可在降低风险的同时，帮助您有效管理复杂或不断变化的系统。例如，基础设施即代码能够帮助您以一种可重复且更有效的方式来管理部署、测试和生产环境。 安全性：通过将自动实施的合规性策略、精细控制和配置管理技术集成到敏捷开发和 DevOps 工作流程中，使得产品内置了安全性。 DevOps 工具 DevOps 各生命周期阶段都有合适的工具可以作为解决方案。它们通过提高协作效率、减少上下文切换、引入自动化以及实现可监控来全方位增强 DevOps 实践。\nDevOps 工具链通常遵循两种模式：完整解决方案或开放式工具链。\n完整解决方案实现了端到端的交付，流程很完备，但是一般难以兼容、集成第三方工具。 开放式工具链允许使用不同的工具进行定制。 这两种方法各有利弊。\n这里列举一些常见的 DevOps 工具：\n项目管理：Jira 文档管理：Confluence 代码管理：Gitlab、Github CI/CD：Gitlab、Jenkins 容器 Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 Kubernetes 是谷歌开源的容器集群管理系统 是用于自动部署，扩展和管理 Docker 应用程序的开源系统，简称 K8S。 日志 ELK 技术栈，通过数据采集工具 Logstack、Beats 套件、日志存储、解析服务 ElasticSearch、日志可视化工具 Kibnana，形成了一套完整的端到端日志解决方案，深受业界好评。 监控 ELK 的技术栈比较成熟，应用范围也比较广，除了可用作监控系统外，还可以用作日志查询和分析。 Prometheus 的独特之处在于它采用了拉数据的方式，对业务影响较小，同时也采用了时间序列数据库存储，而且支持独有的 PromQL 查询语言，功能强大而且简洁。 Grafana 是流行的监控数据分析和可视化套件。 Graphite 是基于时间序列数据库存储的监控系统，并且提供了功能强大的各种聚合函数比如 sum、average、top5 等可用于监控分析，而且对外提供了 API 也可以接入其他图形化监控系统如 Grafana。 链路追踪 Zipkin：Zipkin 是 Twitter 开源的调用链分析工具，目前基于 spring-cloud-sleuth 得到了广泛的使用，特点是轻量，使用、部署简单。 Pinpoint：是韩国人开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点是支持多种插件，UI 功能强大，接入端无代码侵入。 SkyWalking：是本土开源的基于字节码注入的调用链分析，以及应用监控分析工具。特点是支持多种插件，UI 功能较强，接入端无代码侵入。目前已加入 Apache 孵化器。 CAT：CAT 是美团点评开源的基于编码和配置的调用链分析，应用监控分析，日志采集，监控报警等一系列的监控平台工具。 负载均衡 Nginx 可以作为四层或七层负载均衡器。 LVS 可以作为四层负载均衡器。其负载均衡的性能要优于 Nginx。 HAProxy 可以作为 HTTP 和 TCP 负载均衡器。 F5 作为硬件负载均衡 A10 作为硬件负载均衡 网关 Kong 是一个云原生、快速、可扩展和分布式的微服务抽象层（也称为 API 网关，API 中间件）。 Zuul 是 Netflix 开源的一个 API 网关，Zuul 在云平台上提供动态路由，监控，弹性，安全等边缘服务的框架。 告警：短信、邮件、企业聊天软件、OA 参考资料 【Youtube 视频】What is DevOps? - In Simple English 【Youtube 视频】DevOps In 5 Minutes DevOps: Breaking the development-operations barrier ","permalink":"https://WFUing.github.io/posts/tech/architecture/devoops/","summary":"DevOps 集文化理念、实践和工具于一身，它强调团队授权、跨团队沟通和协作以及技术自动化，其最终目标是优化质量和交付","title":"DevOps 简介"},{"content":"动态规划 【LeetCode 55】跳跃游戏 【LeetCode 72】编辑距离 【LeetCode 115】不同的子序列 【LeetCode 124】二叉树中的最大路径和 【LeetCode 174】地下城游戏 【LeetCode 188】买卖股票的最佳时机IV 【LeetCode 198】打家劫舍 【LeetCode 213】打家劫舍II 【LeetCode 233】数字1的个数 【LeetCode 300】最长递增子序列 【LeetCode 309】最佳买卖股票时机含冷冻期 【LeetCode 312】戳气球 【LeetCode 337】打家劫舍III 【LeetCode 354】俄罗斯套娃信封问题 【LeetCode 376】摆动序列 【LeetCode 390】消除游戏 【LeetCode 689】三个无重叠子数组的最大和 【LeetCode 714】买卖股票的最佳时机含手续费 【LeetCode 907】子数组的最小值之和 【LeetCode 943】最短超级串 【LeetCode 1031】两个非重叠子数组的最大和 【LeetCode 1039】多边形三角剖分的最低得分 【LeetCode 1186】删除一次得到子数组最大和 【LeetCode 系列】买卖股票的最佳时机 【LeetCode 面试题 08.11】硬币 贪心算法 【LeetCode 55】跳跃游戏 【LeetCode 121】买卖股票的最佳时机 【LeetCode 122】买卖股票的最佳时机II 【LeetCode 123】买卖股票的最佳时机III 【LeetCode 42】接雨水 【LeetCode 135】分发糖果 ","permalink":"https://WFUing.github.io/posts/tech/algorithm/leetcode/","summary":"动态规划 【LeetCode 55】跳跃游戏 【LeetCode 72】编辑距离 【LeetCode 115】不同的子序列 【LeetCode 124】二叉树中的最大路径和 【LeetCode 174】地下城游戏 【LeetCode 188】买卖股票的最佳时机IV 【LeetCode 198】打家劫舍 【LeetCode 213】打家劫舍II 【LeetCode 233】数字1的个数 【LeetCode 300】最长递增子序列 【LeetCode 309】最佳买卖股票时机含冷冻期 【LeetCode 312】戳气球 【LeetCode 337】打家劫舍III 【LeetCode 354】俄罗斯套娃信封问题 【LeetCode 376】摆动序列 【LeetCode 390】消除游戏 【LeetCode 689】三个无重叠子数组的最大和 【LeetCode 714】买卖股票的最佳时机含手续费 【LeetCode 907】子数组的最小值之和 【LeetCode 943】最短超级串 【LeetCode 1031】两个非重叠子数组的最大和 【LeetCode 1039】多边形三角剖分的最低得分 【LeetCode 1186】删除一次得到子数组最大和 【LeetCode 系列】买卖股票的最佳时机 【LeetCode 面试题 08.11】硬币 贪心算法 【LeetCode 55】跳跃游戏 【LeetCode 121】买卖股票的最佳时机 【LeetCode 122】买卖股票的最佳时机II 【LeetCode 123】买卖股票的最佳时机III 【LeetCode 42】接雨水 【LeetCode 135】分发糖果 ","title":"Leetcode"},{"content":"DSL 和 DSL 工具的一个重要方面是代码生成。DSL 本身在形式化、指定和交流内容方面具有优势，因为它们具有特定领域的性质。但是，如果能从指定的内容中推导出实现代码，就能大大提高工作效率。\nResources blogs https://www.typefox.io/blog/code-generation-for-langium-based-dsls/ https://www.typefox.io/blog/code-generation-for-langium-based-dsls-2 https://www.typefox.io/blog/code-generation-for-langium-based-dsls-3/ github repo: https://github.com/TypeFox/langium-in-browser-codegen-example/tree/main https://github.com/eclipse-langium/langium/blob/main/examples/arithmetics 运行示例 本帖中的运行示例使用 Langium 的 Arithmetics 示例实现。Arithmetics 的 grammar 见 arithmetics.langium\n代码生成器的输入示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 MODULE priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; DEF costPerUnit: materialPerUnit + laborPerUnit; DEF expectedNoOfSales: 200; DEF costOfGoodsSold: expectedNoOfSales * costPerUnit; DEF generalExpensesAndSales: 10000; DEF desiredProfitPerUnit: 50; DEF netPrice: (costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales + desiredProfitPerUnit; DEF vat: 0.15; DEF calcGrossListPrice(net, tax): net / (1 - tax); calcGrossListPrice(netPrice, vat); 本模块介绍一种非常简单的产品价格计算方法。它包括给变量分配常量值和计算值。最后，一个名为 calcGrossListPrice 的函数被调用，参数是之前定义的 netPrice 和 tax。下图展示了 Langium 在解析输入时创建的抽象语法树（AST）。\n现在，让我们将其转化为纯 JavaScript 代码。为了合成所需的代码段，生成器需要访问 AST 并检查相应的部分。让我们通过一个纯 JavaScript 模板来定义生成器的入口函数，如下所示，它会贡献一些静态框架代码：\n1 2 3 4 5 6 7 8 function generateModule(root: Module): string { return ` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 让我们也定义 generateModuleContent(Module) 并按如下方式实现它，由于需要循环，所以这次使用经典的字符串连接：\n1 2 3 4 5 6 7 8 9 function generateModuleContent(module: Module): string { let result = `let ${lastComputableExpressionValueVarName};\\n`; for (const s of module.statements) { result += generateStatement(s) + \u0026#39;\\n\u0026#39;; } result += `\\n` result += `return ${lastComputableExpressionValueVarName};`; return result; } 问题 1：对于多行模板文字，生成的代码将包含由 ········ 在 generateModule() 中指示的空白。我添加了空白，以使生成器符合我们的格式规则。\n缺点：会使生成结果变得混乱。\n问题 2：访问列表时，我们必须在每个语句的生成片段后插入换行符。此外，我们还必须注意 for 循环前后的换行符。最后，还有 \\n 与 \\r\\n 的问题。\n虽然这个问题在这里很简单，但如果出现有条件附加的代码段或者连续多个循环，就会变得相当困难。\n问题 3：generateModuleContent() 中的字符串连接没有注意 generateModule() 中调用该函数之前的缩进。\n生成的代码将如下所示，具体取决于 generateStatement() 的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; . . . return lastComputableExpressionValue; ········}) .... 这个示例很好地说明了生成代码中的缩进是如何出错的。周围的静态代码缩进了，但不应该缩进，而括弧中的语句没有缩进，但应该缩进。\nSolution A: Smart tagged templates Solution A：Langium 提供了一个名为 expandToString 的标签函数，可智能处理空白。\n在 generateModule(Module) 第 2 行的开头回车之前直接插入 expandToString 引用，可将后续模板转换为标记模板，请参见 generateModule2(Module)：\n1 2 3 4 5 6 7 8 9 10 import { expandToString } from \u0026#39;langium\u0026#39;; function generateModule2(root: Module): string { return expandToString` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 这样就得到了下面的生成结果：\n1 2 3 4 5 6 7 8 9 10 11 \u0026#34;use strict\u0026#34;; (() =\u0026gt; { let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; . . . return lastComputableExpressionValue; }) expandToString 实现以下这些功能：\n在模板的所有非空行中识别和修剪共同的前导空格 确定用 ${} 包装的表达式的偏移量 修剪 single leading and trailing line breaks 合并模板内的换行符 因此，\n功能 1 删除了生成模块 2(Module) 中由 ········ 表示的空白，这使得静态代码从偏移量 0 开始，即生成时没有任何缩进。 功能 2 将 ${generateModuleContent(root)} 行内的额外缩进 (␣␣) 应用到替换字符串中的每一行。在我们的示例中，这将产生正确缩进的语句实现片段，而缩进只需指定一次。 功能 3 丢弃了紧随开头回车符之后的初始换行符，以及包括结尾回车符缩进在内的尾部换行符。这与生成器入口函数（如 generateModule2(Module)）关系不大，但与从其他标记模板（如 generateModuleContent(Module)）中调用的生成器函数（如 generateModuleContent(Module)）非常相关，因为周围的换行符将由调用模板决定。最后但并非最不重要的一点是， 功能 4 使所有换行符都与系统换行符一致。这一点非常可取，因为生成的代码通常会被持久化到磁盘上，并希望与平台保持一致。 现在，让我们再来看看 generateModuleContent(Module) 模块：\n1 2 3 4 5 6 7 8 9 function generateModuleContent(module: Module): string { let result = `let ${lastComputableExpressionValueVarName};\\n`; for (const s of module.statements) { result += generateStatement(s) + \u0026#39;\\n\u0026#39;; } result += `\\n` result += `return ${lastComputableExpressionValueVarName};`; return result; } 将循环重写为 map;join 表达式后，我们就可以使用标记模板和 expandToString 来实现字符串连接，如下所示：\n1 2 3 4 5 6 7 8 function generateModuleContent2(module: Module): string { return expandToString` let ${lastComputableExpressionValueVarName}; ${ module.statements.map(generateStatement).join(\u0026#39;\\n\u0026#39;) } return ${lastComputableExpressionValueVarName}; `; } 连接操作中的分隔符会被功能 4 expandToString 处理，如果在 MS Windows 机器上执行，它会用 \\r\\n 替换单个 \\n。\n我们上面的价格计算示例的整个输出结果可能如下，我在这里跳过了缺失的生成器部分。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 \u0026#34;use strict\u0026#34;; (() =\u0026gt; { let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; const expectedNoOfSales = lastComputableExpressionValue = 200; const costPerUnit = lastComputableExpressionValue = materialPerUnit + laborPerUnit; const costOfGoodsSold = lastComputableExpressionValue = expectedNoOfSales * costPerUnit; const generalExpensesAndSales = lastComputableExpressionValue = 10000; const desiredProfitPerUnit = lastComputableExpressionValue = 50; const netPrice = lastComputableExpressionValue = ((costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales) + desiredProfitPerUnit; const vat = lastComputableExpressionValue = 0.15; const calcGrossListPrice = (net, tax) =\u0026gt; net / (1 - tax); lastComputableExpressionValue = calcGrossListPrice( netPrice, vat ); return lastComputableExpressionValue; }) 除了普通关键字、标识符和运算符的连接外，我的生成器还插入了典型的括号复合表达式，比如在计算 netPrice 的值时。此外，像 calcGrossListPrice 这样的函数调用会在多行中生成，从而使参数更易于阅读。\n结论：如果我们想使用 JavaScript 模板表达式而不是普通的字符串连接来实现代码生成器，如果我们想获得正确格式化的生成代码以及正确格式化的模板，那么 expandToString 将为我们提供极大的帮助。\n备注：重要的是要保持模板行缩进一致，特别是不要混合使用制表符和空格！VS 代码提供了一个显示空白字符的便捷选项，名为 Toggle Render Whitespace。\nSolution B: two stage code generation 试想一下，如果某些行后没有添加内容，您希望跳过这些行的换行符。试想一下，您需要对代码片段的缩进进行配置，或者需要对生成的代码进行后处理和调整，以满足特定条件。在生成 Java 或 JavaScript 等语言时，可以考虑添加导入子句，同时在代码中添加符号引用。生成丰富的表达式语法也可能需要比纯字符串更多的抽象。最后但并非最不重要的一点是，我们可能希望将生成的代码段与它们在文本中代表的源定义区域关联起来。这样的要求需要一种不同的方法。\n在本部分中，将重点介绍两阶段代码生成方法，并展示如何将其与 Solution A 中使用的 Tagged Templates 整合在一起。\nGeneration tree 要满足上述要求，一种可行的方法是将生成任务一分为二，并使用比字符串更具表现力的数据结构来捕获中间结果。任务 1 建立待生成代码的描述，任务 2 则渲染所需的输出结果。\n在我们的日常实践中，事实证明树状数据结构非常有用。我们定义了以下数据类型的联盟，并将其称为 Generated 类型：\n1 2 type Generated = string | GeneratorNode | undefined; type GeneratorNode = CompositeGeneratorNode | IndentNode | NewLineNode; 生成任务 1 的结果可能已经是字符串类型，例如，如果结果非常短。通常，它的类型是 GeneratorNode。此外，它还可能是 undefined 的。这在顶层没有太大意义，但在将模板的部分内容转移到子例程时却非常有用。未定义的可能结果允许这些函数向其调用者发出信号，表明该函数不会生成任何东西，这与空字符串等其他东西不同。\nCompositeGeneratorNode 实现了复合设计模式。该类型的实例是容器，可容纳一系列其他字符串和生成器节点。IndentNode 是 CompositeGeneratorNode 的特化，提供缩进信息。NewLineNode 的实例用于描述换行，它们的严格程度是可参数化的。\n在早期的 Langium 中，我们通过以编程方式合成生成器描述来构建代码生成器，例如 Langium CLI 中包含的描述。这样一来，代码生成器的实现就会被大量的 node.append(...) 或 node.children.push(...) 指令所支配，而所需生成的代码结构很快就会被混淆。\n通过 tagged templates 在 Langium v1.0 中，发布了另一个名为 expandToNode 的标签函数，也就是我们的解决方案 B。请回顾算术语言示例中的 generateModule2 示例：\n1 2 3 4 5 6 7 8 function generateModule2(root: Module): string { return expandToString` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent(root)} ········}) `; } 将标签函数替换为 expandToNode 并将返回类型更改为 Generated，就可以轻松将其转换为两阶段生成。\n1 2 3 4 5 6 7 8 function generateModule3(root: Module): Generated { return expandToNode` ········\u0026#34;use strict\u0026#34;; ········(() =\u0026gt; { ········ ${generateModuleContent2(root)} ········}) `; } 与 expandToString 一样，模板中会自动删除 ········ 所指示的缩进。此外，还省略了开头 \\n 后的初始换行，以及结尾 \\n 前的换行和随后的空白。\n然后，必须将 generateModule3(Module) 的结果转换为字符串，这就是我上文提到的生成任务 2。为此，Langium 提供了名为 toString(unknown) 的函数。如果调用 toString 时使用了 GeneratorNode 类型的参数，它就会将该参数转换为字符串，否则就会委托 JavaScript 的默认字符串构造函数来处理。\n现在让我们看看 generateModuleContent2(Module) 的实现，这也是上次的内容：\n1 2 3 4 5 6 7 8 function generateModuleContent2(module: Module): string { return expandToString` let ${lastComputableExpressionValueVarName}; ${ module.statements.map(generateStatement).join(\u0026#39;\\n\u0026#39;) } return ${lastComputableExpressionValueVarName}; `; } 同样，我替换了上面的标记函数和返回类型。不过，我们并不想立即将语句元素的生成结果连接成一个字符串。相反，我们想为每个元素创建生成描述，并将其包含在该模板的结果中。为此，Langium 提供了 joinToNode() 函数。该函数的使用方法将在 generateModuleContent3(Module) 中进行说明：\n1 2 3 4 5 6 7 8 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; ${ joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } joinToNode 的第一个参数是一个要访问的元素集合、一个为每个元素创建生成描述的函数，以及一个可选的配置对象，用于确定分隔符或注册其他回调（如 element filter 和 prefix/suffix 提供程序）。如果输入集合为空，或者所有元素都没有生成，joinToNode 也不会返回任何结果，实际上用 undefined 来表示。\n为什么要区分 undefined ？ tl;dr：expandToNode 可以将换行符配置为可省略。如果某行的最后一个替换是未定义的或 GeneratorNode 类型的对象，它就会这样做。如果该行的剩余部分只包含空白字符，则整行将被省略，同时呈现所需的输出结果。\n1 2 3 let lastComputableExpressionValueVarName return lastComputableExpressionValueVarName; 调用 joinToNode(\u0026hellip;) 没有任何结果。不过，它的尾部换行符会被附加到生成的代码中，并产生第一个空行。然后，我们在模板中请求的空行也会被附加到生成的代码中，这样就连续生成了两行空行。不过，我个人（也许你也一样）更倾向于省略包含 joinToNode(\u0026hellip;) 调用的整行，即忽略替换后的换行。为了实现这一首选行为，expandToNode 会检查每一行是否有占位符/替换。如果包含替换，则按以下方式评估最后一个替换的值：\n如果替换值未定义或属于 GeneratorNode 类型，则配置该行的终端 NewLineNode，使其仅在前一行为非空时才显示为换行符。否则，配置 NewLineNode 为无条件换行。\n在我们的例子中，generateModuleContent3(Module) 的语句列表为空，这意味着我们将在第 1 行末尾得到一个换行符，因为该行至少包含静态字符串 let，即非空字符串。准确地说，无论其配置如何，添加到生成描述中的 NewLineNode 都会导致换行。第 2 行的占位符将解析为 undefined 的 \u0026ldquo;值\u0026rdquo;。因此，随后代表第 2 行末尾换行符的 NewLineNode 将被标记为 ifNotEmpty，如上所述。在稍后的字符串呈现过程中（任务 2），第 2 行将被评估为空，从而使结束符 NewLineNode 呈现为空。\n第 3 行仅包含一个换行符（不包含任何替换），并导致在生成描述中无条件添加一个 NewLineNode。第 4 行要求在生成说明中添加 return- 以及 lastComputableExpressionValueVarName 内容的字符串值。由于模板将在下一行关闭，因此结束符将被忽略。\n这种方法还允许对仅包含空白和可能导致 undefined 的替换的行强制执行无条件换行。只需将 ??'' 到（最后一个）替换内容中，或者在行尾再添加一个类似 ${''} 的替换。expandToNode 就会插入一个无条件的 NewLineNode。顺便说一下：后一个选项也适用于包含可能为空的 CompositeGeneratorNodes 的替换。\nBenefits 函数 expandToNode 返回 CompositeGeneratorNode 的一个实例，代表某段文本的生成描述。此类对象可任意组合，也可随意操作。元素可以添加、删除或改变顺序。此外，由于复合生成器节点（CompositeGeneratorNode）所描述的某些文本片段的具体缩进最终是在其跨容器（任务 2）的文本渲染时确定的，因此父节点和某些子节点的创建和组合可能完全独立于彼此。一个子节点甚至可能包含在同一生成描述中不同缩进级别的不同位置。此外，在要连接的字符串模板或表达式中，不再需要硬编码的换行符。\n此外，生成器实现可以在基于标记模板的实现风格和基于普通方法调用的风格之间来回切换，这取决于哪种风格最适合。由于 CompositeGeneratorNode 定义了更多的方便方法，因此这两者之间的界限并不明显。下面将提到其中一些方法，有关它们的精确定义，请参阅 Langium 代码库：\nappend(\u0026hellip;Generated[]) appendNewLine() appendNewLineIfNotEmpty() appendIf(boolean, \u0026hellip;Generated[]) appendTemplate\u0026lt;template content\u0026gt; appendTemplateIf(boolean)\u0026lt;template content\u0026gt; indent(Generated[]) … 在某些情况下，这种方式可能更好。\n1 2 3 4 5 6 7 8 9 10 11 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; `.appendNewLine() .appendIf(module.statements.length !== 0, joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) ).appendTemplate` return ${lastComputableExpressionValueVarName}; `; } The avigation between DSL source and generated code 在 Solution A 和 Solution B 中，已经使 TypeScript 和 JavaScript 中的代码生成变得简单且可扩展，现在是时候来讨论一些实际问题了，即如何处理生成的代码，而不是纯粹的字符串段连接。\n这包括在集成开发环境中导航生成的工件及其相应的源代码（例如，用于手动审查），以及在调试生成的代码时自动切换到基于 DSL 的源代码。为了在基于 DSL 的开发工具中启用这些功能，代码生成器需要收集数据，了解哪些源定义生成了哪些代码。\n用下面的截图来说明 DSL 源代码和生成代码之间的来回导航。DSL 工具的用户可能想了解代码生成器为某个专用语句生成了什么代码。DSL 开发工具可能会提供这样的审查工具，例如通过选择敏感的上下文菜单项，如第一张截图所示。当然，也可以进行其他集成：在生成的工件中，可能有多个地方会受到某个语句或定义的影响。\n另一方面，用户可能希望或需要调查为什么生成器会将某些语句放入生成的工件中，即源代码中的哪些定义。如第二张截图所示，如果有机会让开发工具说明生成代码中某些语句的原因或来源，可能会简化此类任务。\n除了这类静态代码分析外，还希望运行生成的代码，在某个入口点设置断点，并通过逐步浏览 DSL 编写的源代码来逐步实现，如下图所示。\n在这里，一个装有 Langium Arithmetics 示例语言的 Monaco editor 被添加到了一个普通网站上，并输入了在 Solution A 中介绍的正在运行的示例脚本。基于 Langium 的语言服务器已经处理了输入，确定没有验证错误，并调用了生成器。然后对获得的 JavaScript 代码和相应的源映射进行评估。源映射是根据 JavaScript 代码生成过程中捕获的跟踪数据创建的。\n获取追踪数据 为了实现上述功能，我们需要捕获跟踪数据，将源数据中的相关文本区域与 generated artifacts 中的相应文本区域关联起来。在此，我们假定源数据是以人类可读文本的形式（通常是根据某种 DSL）编制的，并保存在 disc 上的文件中（至少与某个 URI 相关联），而 generated artifacts 则假定由 a stream of characters 组成。\n回顾本系列的第二部分，我们将代码生成任务分为两项：\nthe composition of a generation description the rendering of the description into the desired text 引入了一种树形数据结构来捕获描述，它由几种不同的数据类型组成，这些数据类型都归属于联合类型 GeneratorNode。既然已经引入了这样一种专用数据结构，就可以根据自己的喜好为这些数据添加额外的信息。还记得上次的模板标签函数 expandToNode，它在任务（1）中为给定的 JavaScript 模板文字建立了 GeneratorNode 实例，以及生成器函数 generateModuleContent3(Module)：\n1 2 3 4 5 6 7 8 function generateModuleContent3(module: Module): Generated { return expandToNode` let ${lastComputableExpressionValueVarName}; ${ joinToNode(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } 无论所提供的模块中定义了哪些语句，所包含的模板都会生成静态代码，而生成的输出则代表模块所包含的语句。这些语句的生成由函数 generateStatement(Statement) 完成，该函数提供给第 4 行的 joinToNode(\u0026hellip;) 调用。因此，模板第 3 行、第 5 行和第 6 行的内容只能与 module 相关联，因为这是它们被添加到输出中的原因。与此相反，generateStatement(Statement) 产生的输出可以与 module 关联，因为这些语句包含在 module 中，但更具体地说，它们应该与 module.statements 中包含的相应 Statement 实例关联。为了实现这两个目的，Langium 提供了以下函数：\nexpandTracedToNode\u0026lt;T extends AstNode\u0026gt;(T, Properties\u0026lt;T\u0026gt;?, number?) joinTracedToNode\u0026lt;T extends AstNode\u0026gt;(T, Properties\u0026lt;T\u0026gt;?) 我们可以使用这些函数捕获所需的跟踪数据，并重写 generateModuleContent3 如下：\n1 2 3 4 5 6 7 8 function generateModuleContent4(module: Module): Generated { return expandTracedToNode(module)` let ${lastComputableExpressionValueVarName}; ${ joinTracedToNode(module, \u0026#39;statements\u0026#39;)(module.statements, generateStatement, { appendNewLineIfNotEmpty: true }) } return ${lastComputableExpressionValueVarName}; `; } 请注意，这两个函数都会再次返回函数。返回函数的签名与 expandToNode 和 joinToNode 的签名完全一致。因此，expandTracedToNode(module) 的结果是一个将模板字面意义转换为标记模板的标记函数。它在内部委托给 expandToNode，并在组成的 GeneratorNode 中注释了模块是相应源对象的信息。\n同样的原理也适用于 joinTracedToNode(模块, \u0026lsquo;语句\u0026rsquo;)。它返回一个与 joinToNode(\u0026hellip;) 接口相同的函数。第 4 行中对 generateModuleContent4(Module) 的调用是指：对 module.statements 中的每个元素应用 generateStatement(Statement)，为生成的每个 GeneratorNode 注释跟踪信息，说明生成的部分代表父对象模块中名为 statements 的属性（集合）的第 i 个元素，将所有这些生成器节点添加到一个容器 GeneratorNode 中，并为该容器注释信息，说明生成的部分代表源对象模块中 statements 属性的全部内容。\n追踪数据剖析 Langium 会在生成任务（2）中对跟踪数据进行评估和计算。在这种情况下，函数 toStringAndTrace(GeneratorNode) 将取代 Langium 的 toString(unknown)。它返回一个形状为 { text: string, trace：traceRegion }，其中 text 是希望生成的文本，trace 是描述嵌套跟踪区域的复合结构，将生成文本中的区域与源文件中的区域关联起来。数据类型 TraceRegion 的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 interface TraceRegion { sourceRegion?: TextRegion; targetRegion: TextRegion; children?: TraceRegion[]; } interface TextRegion { fileURI?: string; offset: number; end: number; length?: number; range?: Range; } 假定源数据是 Langium 通过解析 DSL 语法表述的文本而创建的有效 AST 元素，AstNode 实例就会被注释为代表相应具体语法节点的对象。后者反过来又提供了其 DSL 文档中的起始和结束位置以及文档的文件 URI。通过这些信息，toStringAndTrace(GeneratorNode) 计算出生成器节点的源区域。在文本渲染过程中，通过记录生成器节点生成文本的开始和结束位置，计算出相应的目标区域。此时，目标 TextRegion 的 fileURI 属性永远不会被设置，因为此时还不知道生成的文本是否会被写入某个文件，如果是，文件的 URI 可能是什么。\n让我们来看看以下输入和相应输出的简化示例：\n1 2 3 4 Module priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; 1 2 3 4 5 let lastComputableExpressionValue; const materialPerUnit = lastComputableExpressionValue = 100; const laborPerUnit = lastComputableExpressionValue = 200; return lastComputableExpressionValue; 下面的截图中展示了所得到的轨迹区域：\n玫瑰色背景所限定的区域代表跟踪所描述的根跟踪区域，该区域来自 generateModuleContent4(module) 所返回的生成器节点。 淡黄色矩形表示的区域来自 generateModuleContent4(Module) 。第 4 行中调用 joinTracedToNode(\u0026hellip;)(\u0026hellip;) 生成器节点生成的区域。源区域等于对象模块属性 \u0026ldquo;语句 \u0026ldquo;中所有元素定义的 \u0026ldquo;边界框\u0026rdquo;，目标区域等于第 4 行中 joinTracedToNode(\u0026hellip;)(\u0026hellip;) 调用 generateStatement(Statement) 的结果所描述的所有文本片段的 \u0026ldquo;边界框\u0026rdquo;，加上 { appendNewLineIfNotEmpty: true } 所要求的插入分隔线。包含这些源文本区域和目标文本区域描述的 TraceRegion 实例可通过根跟踪对象的子属性（即 trace.children[0]）访问。 蓝色背景区域表示跟踪区域，包括对象模块属性 \u0026ldquo;statements \u0026ldquo;条目 0 定义所涉及的源文本区域，以及执行 generateStatement(module.statements[0])后返回的生成器节点所描述的目标区域。跟踪区域描述对象可通过 trace.children[0].children[0] 访问。同样的情况也适用于绿色背景区域，但它们表示 module.statements 的条目 1 的定义和生成文本。该跟踪区域描述可通过 trace.children[0].children[1] 访问。 实际上，这种深度的跟踪数据捕获并不是终点。如果我们继续将 expandTracedToNode(\u0026hellip;) 应用于在 generateStatement(Module) 中要区分的所有特殊情况，我们就会得到完全深度解析和细粒度的跟踪区域，直至每个标识符、运算符和数字字面。\n将跟踪数据转换为 JavaScript 源映射 如今的浏览器和 VS Code 都支持源映射的概念，以便于调试已编译、转译或最小化的代码。源映射可以作为单独文件附加到生产的 JavaScript 代码中，甚至可以内联到生产的代码中（这通常会大大增加要传输的代码）。因此，为了实现能够调试用算术 DSL 编写的脚本这一目标，我们不仅需要捕获跟踪信息，还需要使用它们来合成符合源映射格式的数据。好消息是我们不需要完全靠自己。https://npmjs.com 上发布的 source-map 软件包可以帮我们完成大部分工作。\n在 langium-in-browser-codegen-example GitHub 代码库中，我实现了源地图数据的组合，并将其内联到生成的 JavaScript 代码中。如果内联，源地图数据必须进行 base64 编码\u0026ndash;这意味着我们基本上没有机会审查我们实际生成的内容。不过，sokra 和其他一些好心人建立了一个工具 https://sokra.github.io/source-map-visualization/。它允许我们上传生成的代码，包括源地图数据（或将源地图数据作为单独文件上传）。下面，我添加了一张所提供的可视化截图。原始页面甚至允许通过将鼠标悬停在某个区域上，观察其对应区域的高亮度（如果有的话），以交互方式查看源区域和目标区域。\n","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/code-generation-for-langium-based-dsls/","summary":"DSL 和 DSL 工具的一个重要方面是代码生成。DSL 本身在形式化、指定和交流内容方面具有优势，因为它们具有特定领域的性质。但是，如果能从指定的内容中推导出实现代码，就能大大提高工作效率。\nResources blogs https://www.typefox.io/blog/code-generation-for-langium-based-dsls/ https://www.typefox.io/blog/code-generation-for-langium-based-dsls-2 https://www.typefox.io/blog/code-generation-for-langium-based-dsls-3/ github repo: https://github.com/TypeFox/langium-in-browser-codegen-example/tree/main https://github.com/eclipse-langium/langium/blob/main/examples/arithmetics 运行示例 本帖中的运行示例使用 Langium 的 Arithmetics 示例实现。Arithmetics 的 grammar 见 arithmetics.langium\n代码生成器的输入示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 MODULE priceCalculator DEF materialPerUnit: 100; DEF laborPerUnit: 200; DEF costPerUnit: materialPerUnit + laborPerUnit; DEF expectedNoOfSales: 200; DEF costOfGoodsSold: expectedNoOfSales * costPerUnit; DEF generalExpensesAndSales: 10000; DEF desiredProfitPerUnit: 50; DEF netPrice: (costOfGoodsSold + generalExpensesAndSales) / expectedNoOfSales + desiredProfitPerUnit; DEF vat: 0.","title":"Code generation for Langium-based DSLs"},{"content":"模板引擎 模板引擎（也称为模板处理器或模板解析器）是设计用于将模板与数据模型结合起来以生成结果文档的软件，编写模板所用的语言称为模板语言或模板语言。模板引擎通常作为 Web 模板系统或应用程序框架的一部分，也可以用作预处理器或过滤器。流行的模板引擎包括 Ejs、Jade、Pug、Mustache、HandlebarsJS、Jinja2 和 Blade。\n模板引擎如何工作 上图说明了模板引擎的所有基本元素和处理流程。\n使用模板引擎构建服务器端应用程序时，模板引擎会将模板文件中的变量替换为实际值，并将此值显示给客户端。这样，我们就能更轻松地快速构建应用程序。\n使用 expressJS 和 ejs 模板引擎的示例 对于使用 NodeJS 运行时编写的服务器端应用程序，可以使用模板引擎。\n以下步骤演示了模板引擎如何使用 expressJs 和 ejs 模板引擎工作。下面的示例在网页上渲染用户数据。\n步骤 1：安装 express 和 ejs 模板引擎\n安装 ejs 模板引擎和 express 框架，\n1 npm install express ejs 步骤 2：设置视图引擎\n1 2 3 4 5 6 7 8 const express = require(\u0026#34;express\u0026#34;) const app = express(); // Set the View Engine or Template Engine app.set(\u0026#39;view engine\u0026#39;, \u0026#39;ejs\u0026#39;); app.listen(3000) 在上面的代码中，我们创建了 express 应用程序。该应用程序通过 3000 端口监听。\napp.set('view engine', 'ejs'); 告诉我们的 express 应用程序，我们要使用 EJS 作为模板引擎。\n步骤 3：设置视图文件夹\n创建一个名为 view 的文件夹。视图文件夹应包含我们的模板。其中一个模板是 index.ejs，它将生成我们的首页。第二个模板是 user.ejs，用于从服务器端传递用户数据，并立即在网页上呈现。\n1 2 3 4 index.js \u0026gt;view index.ejs user.ejs 步骤 4：设置 routes\n让我们为主页和用户页面创建routes。\n请注意下面的 res.render() 方法。这就是在 expressJS 中渲染模板的方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 app.get(\u0026#39;/\u0026#39;, function (req, res) { res.render(\u0026#34;index\u0026#34;); }) app.get(\u0026#34;/user\u0026#34;, function(req,res){ const user = { name: \u0026#34;Theodore Kelechukwu O.\u0026#34;, stack: \u0026#34;MERN\u0026#34;, email: \u0026#34;theodoreonyejiaku@gmail.com\u0026#34;, hubby: [\u0026#34;singing\u0026#34;, \u0026#34;playing guitar\u0026#34;, \u0026#34;reading\u0026#34;, \u0026#34;philosoph\u0026#34;] } res.render(\u0026#34;user\u0026#34;, {user}); }) 正如我们所见，访问默认路由\u0026quot;\u0026quot;时，会显示或渲染 index.ejs 页面。同时，\u0026quot;\\user \u0026ldquo;会显示 user.ejs 页面。\n我们将用户对象传递给 render 对象，以便将用户属性传递给网页并进行渲染。\n步骤 5：模板化我们的视图文件\n现在，我们已经从服务器端传递了用户数据，我们需要立即在前端或网页上显示这些数据。\nindex.ejs\n1 2 3 4 5 6 7 8 9 10 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;This is the title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Welcome to Template Engines\u0026lt;/p\u0026gt; \u0026lt;a href=\u0026#34;/user\u0026#34;\u0026gt;View User\u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; user.ejs\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;title\u0026gt;This is the title\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h1\u0026gt;Welcome to User Details\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Name:\u0026lt;/b\u0026gt; \u0026lt;%= user.name %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Email:\u0026lt;/b\u0026gt; \u0026lt;%= user.email %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;p\u0026gt;\u0026lt;b\u0026gt;Stack:\u0026lt;/b\u0026gt; \u0026lt;%= user.stack %\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;u\u0026gt;\u0026lt;b\u0026gt;Hubbies\u0026lt;/b\u0026gt;\u0026lt;/u\u0026gt; \u0026lt;% user.hubby.forEach(hubby =\u0026gt;{ %\u0026gt; \u0026lt;li\u0026gt;\u0026lt;%= hubby %\u0026gt;\u0026lt;/li\u0026gt; \u0026lt;% })%\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 注意显示值的 \u0026lt;%= variable %\u0026gt; 模式。这是在 ejs 中使用的方式。还要注意 user.forEach(); 这是为了显示模板引擎有多么强大。\nResources https://en.wikipedia.org/wiki/Template_processor https://www.educative.io/answers/what-are-template-engines ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/template-engine/","summary":"模板引擎 模板引擎（也称为模板处理器或模板解析器）是设计用于将模板与数据模型结合起来以生成结果文档的软件，编写模板所用的语言称为模板语言或模板语言。模板引擎通常作为 Web 模板系统或应用程序框架的一部分，也可以用作预处理器或过滤器。流行的模板引擎包括 Ejs、Jade、Pug、Mustache、HandlebarsJS、Jinja2 和 Blade。\n模板引擎如何工作 上图说明了模板引擎的所有基本元素和处理流程。\n使用模板引擎构建服务器端应用程序时，模板引擎会将模板文件中的变量替换为实际值，并将此值显示给客户端。这样，我们就能更轻松地快速构建应用程序。\n使用 expressJS 和 ejs 模板引擎的示例 对于使用 NodeJS 运行时编写的服务器端应用程序，可以使用模板引擎。\n以下步骤演示了模板引擎如何使用 expressJs 和 ejs 模板引擎工作。下面的示例在网页上渲染用户数据。\n步骤 1：安装 express 和 ejs 模板引擎\n安装 ejs 模板引擎和 express 框架，\n1 npm install express ejs 步骤 2：设置视图引擎\n1 2 3 4 5 6 7 8 const express = require(\u0026#34;express\u0026#34;) const app = express(); // Set the View Engine or Template Engine app.set(\u0026#39;view engine\u0026#39;, \u0026#39;ejs\u0026#39;); app.listen(3000) 在上面的代码中，我们创建了 express 应用程序。该应用程序通过 3000 端口监听。","title":"Template Engine"},{"content":"今天花了一点时间搭建了自己的GitHub的博客，当然咯，试验阶段总会发生很多乱七八糟的问题，记录下处理问题过程中几个比较 nice 的 blog\nResources 系列文章，用hugo的PaperMod Theme 建站: https://www.sulvblog.cn/posts/blog/ Hugo + GitHub Action，搭建你的博客自动发布系统: https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ PaperMod主题优化： https://kdjlyy.cn/posts/site/hugo-papermod-optimization https://dvel.me/posts/hugo-papermod-config/ ","permalink":"https://WFUing.github.io/posts/tech/architecture/git/how-to-build-github-blog-with-hugo/","summary":"今天花了一点时间搭建了自己的GitHub的博客，当然咯，试验阶段总会发生很多乱七八糟的问题，记录下处理问题过程中几个比较 nice 的 blog\nResources 系列文章，用hugo的PaperMod Theme 建站: https://www.sulvblog.cn/posts/blog/ Hugo + GitHub Action，搭建你的博客自动发布系统: https://www.pseudoyu.com/zh/2022/05/29/deploy_your_blog_using_hugo_and_github_action/ PaperMod主题优化： https://kdjlyy.cn/posts/site/hugo-papermod-optimization https://dvel.me/posts/hugo-papermod-config/ ","title":"How to Build Github Blog With Hugo"},{"content":"为什么要用代码生成 productivity：使用代码生成，只需编写一次 generator ，就可以根据需要多次重复使用。向 generator 提供特定输入并调用它比手动编写代码要快得多，因此代码生成可以节省时间。 Simplification：通过代码生成，你可以从一些抽象的描述中生成代码。需要维护的部分变成了 generator 的输入部分，该部分通常是代码的描述，而不是代码本身，与整个生成的代码相比，该描述通常更容易分析和检查。 Portability：一旦你有了为某种语言或框架生成代码的程序，你就可以简单地更改 generator ，并以不同的语言或框架为目标。您还可以同时针对多个平台。 例如，使用解析器生成器，您可以获得 C#、Java 和 C++ 的 parser。 另一个例子：您可能会编写一个 UML 图表，然后使用代码生成器用 C# 创建一个骨架类，并用 SQL 代码为 MySQL 创建一个数据库。因此，相同的抽象描述可用于生成不同类型的工件。 Consistency：有了代码生成，你总能得到你所期望的代码。生成的代码是根据相同的原则设计的，命名规则等也是一致的。当然，除了生成器中的 bug 之外，代码总是能按照你所期望的方式运行，代码质量始终如一。如果用手工编写代码，不同的开发人员可能会使用不同的风格，即使是最重复的代码也会偶尔出现错误。 为什么不要用代码生成 Maintenance：当您使用代码生成工具时，您的代码就会依赖于它。代码生成工具必须得到维护。如果你创建了它，你就必须不断更新它；如果你只是使用现有的工具，你就必须希望有人继续维护它，或者你必须自己接手。因此，代码生成的优势并不是免费的。如果你没有或找不到合适的能力来维护代码生成器，风险就会更大。 Complexity：自动生成的代码往往比手工编写的代码更复杂。有时，这与将不同部分连接在一起所需的胶水代码有关，或者与生成器支持的用例多于您所需的用例有关。在第二种情况下，生成的代码可以做比你想要的更多的事情，但这并不一定是一种优势。生成代码的优化程度肯定也不如手工编写的代码。有时这种差异很小，并不明显，但如果您的应用程序需要尽可能地提高性能，那么生成的代码对您来说可能并不是最佳选择。 如何使用代码生成? 根据具体情况，代码生成既可以提高工作效率，也可以成为开发过程中的重要组成部分。许多现代集成开发环境就是一个有用的例子：只需点击一个按钮，就能创建一个骨架类来实现接口或类似功能。你完全可以自己编写这样的代码，只不过会浪费一些时间来完成琐碎的任务。\n设计代码生成流水线的方法有很多种。基本上，我们需要定义两个要素：\nInput：用于生成代码的信息来自何处。 Output：如何获得生成的代码。 您也可以在输入和输出之间设置转换步骤。这些步骤可以简化输出层，并使输入和输出更加独立。\nPossible Inputs\nA DSL：例如，我们可以使用 ANTLR 来描述一种语言的语法。由此，我们可以生成一个解析器。 code in other formats：数据库模式。根据数据库模式，我们可以生成 DAO。 wizards：它们允许向用户询问信息。 reverse engineering：可通过处理复杂的代码工件获得信息。 data sources：比如一个DB，一个csv文件或者一个电子表格。 Possible Outputs\ntemplate engine：大多数网络程序员都知道模板引擎，它用于在 HTML UI 中填充数据。 code building APIs：例如，Javaparser 可用于以编程方式创建 Java 文件。 Some Pipelines\n现在让我们来检查一些 pipelines：\nparser generation：本网站的读者一定很熟悉 ANTLR 和其他此类从形式语法自动生成解析器的工具。在这种情况下，输入是一个 DSL，输出则是使用 template engine 生成的。 model driven design：集成开发环境或独立集成开发环境的插件，可以描述应用程序的模型，有时还提供图形界面，并据此生成整个应用程序或仅生成其骨架。 database-related code：这种用法可视为模型驱动设计和模板引擎的产物。通常，程序员会定义一个数据库模式，并据此生成整个 CRUD 应用程序或处理数据库的代码。也有一些工具可以执行相反的过程：根据现有数据库创建数据库模式或处理数据库的代码。 meta-programming languages：这些语言组包括可对程序代码进行近乎完全操作的语言，源代码只是另一种可操作的数据结构。 ad hoc applications：这一类包括所有内容：从为处理一件事情而设计的工具到企业环境中使用的临时系统，这些系统可以根据正式的自定义描述生成整个应用程序。这些应用程序通常是特定工作流程的一部分。例如，客户使用图形界面描述一个应用程序，一个临时系统会生成支持该应用程序的数据库模式，另一个系统会生成 CRUD 界面等。 IDE generated code：许多静态类型语言需要编写大量的模板代码，而集成开发环境通常可以生成其中的一部分：为要实现的方法提供存根的类、标准的等值、hashCode 和 toString 方法、所有现有属性的获取器和设置器。 代码生成工具 模板引擎 模板引擎组 (Template Engine) 可能是最著名和最常用的。模板引擎基本上就是一个能理解简单模板语言的迷你编译器。模板文件包含可由模板引擎解释的特殊符号。它能做的最简单的事情就是用运行时给出的适当数据替换这些特殊符号。大多数模板引擎还支持简单的流程控制命令（如 for 循环、if-else 语句），允许用户描述简单的结构。\n有很多例子，让我们来看两个代表大多数模板引擎行为方式的例子。\nJinja2 Jinja2 是一个广泛使用的 Python 模板引擎。它能做所有模板引擎都能做的事情：根据提供的数据创建独一无二的文档。 它支持模块化模板、控制流、变量等。不过，它也有强大的安全措施：HTML 转义系统和沙箱环境，可以控制对危险属性的访问。\n1 2 3 4 5 6 \u0026lt;title\u0026gt;{% block title %}{% endblock %}\u0026lt;/title\u0026gt; \u0026lt;ul\u0026gt; {% for user in users %} \u0026lt;li\u0026gt;\u0026lt;a href=\u0026#34;{{ user.url }}\u0026#34;\u0026gt;{{ user.username }}\u0026lt;/a\u0026gt;\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; Jinja2 特别支持生成 HTML 页面，这也是最常用的功能。不过，它也可用于创建其他类型的文件。\nPug Pug 是一个深受 Haml 影响的高性能模板引擎，使用 JavaScript 实现，适用于 Node.js 和浏览器。在许多方面，Pug 与许多其他模板引擎一样：它支持模块化模板、控制流等。不同的是，Pug 看起来像 DSL，而且只适用于 HTML。因此，Pug 模板看起来非常简洁。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 doctype html html(lang=\u0026#34;en\u0026#34;) head title= pageTitle script(type=\u0026#39;text/javascript\u0026#39;). if (foo) bar(1 + 5) body h1 Pug - node template engine #container.col if youAreUsingPug p You are amazing else p Get on it! p. Pug is a terse and simple templating language with a strong focus on performance and powerful features. 解析器生成器 解析器生成器 (Parser Generation) 是一种自动快速创建语言解析器的工具。它们非常成功且富有成效，因为人们已经对语言解析问题进行了广泛的研究。因此，有一些解决方案可以保证解析人们需要解析的大多数语言。\nANTLR ANTLR 可能是使用最多的解析器生成器。这意味着有很多示例。然而，庞大社区的真正附加价值在于大量可用的语法。\nANTLR 的输入是语法：对语言的正式描述。解析器的输出是一棵解析树：一种包含源代码的结构，其转换方式便于程序的其他部分使用。ANTLR 还提供了两种走解析树的方法：访问者和监听者。第一种适用于需要对解析树中的元素进行操作或交互的情况，而第二种则适用于只需要在规则匹配时做一些事情的情况。\n1 2 3 4 5 6 7 grammar simple; basic : NAME \u0026#39;:\u0026#39; NAME ; NAME : [a-zA-Z]* ; COMMENT : \u0026#39;/*\u0026#39; .*? \u0026#39;*/\u0026#39; -\u0026gt; skip ; 模型驱动设计 这些通常是集成开发环境的插件或独立的集成开发环境，可以通过图形界面描述应用程序的模型，并由此生成应用程序的骨架。之所以会出现这种情况，是因为模型驱动设计的基础是抽象模型，可以用 UML 图表或 DSL 来定义。一旦程序的主要特征可以根据模型进行描述，那么就有可能自动生成该程序的表示法。这种代码中的模型表示法会自动生成结构，但行为通常必须由开发人员自己直接实现。\nAcceleo Acceleo 3 是一款实现 OMG 模型到文本规范的代码生成器。它为开发人员提供了高质量代码生成集成开发环境所应具备的大部分功能：简单的语法、高效的代码生成、先进的工具以及与 JDT 不相上下的功能。Acceleo 可帮助开发人员处理代码生成器的生命周期。得益于基于原型的方法，您可以从现有原型的源代码中快速、轻松地创建第一个生成器，然后利用 Acceleo 工具的所有功能（如重构工具），您可以轻松地改进生成器，实现完整的代码生成器。\nAcceleo 的工作：实施模型驱动设计原则。但缺少的是对 Acceleo 工作体验的描述。Acceleo 基本上是一个 Eclipse 插件，它为您提供了一个工具，可以根据您指定的模板，从 EMF 模型开始创建 Java 代码。EMF 模型可以通过不同方式定义：UML 图表或自定义 DSL。\nUmple Umple 是一种建模工具和编程语言系列，可实现作者所说的面向模型的编程。它在面向对象编程语言（如 Java、C++、PHP 和 Ruby）中添加了关联、属性和状态机等抽象概念，这些抽象概念源自 UML。Umple 还可用于以文本方式创建 UML 类图和状态图。\nUmple 是一种将 UML 模式与传统编程语言结构化结合的工具。它的诞生是为了简化模型驱动开发的过程，而传统的模型驱动开发需要特定而复杂的工具。它本质上是一种编程语言，支持 UML（类和状态）图定义模型的功能。然后，Umple 代码会被其编译器转换为 Java 或 PHP 等传统语言。\nUmple 可以有多种用法：\n可用于以文本方式描述 UML 图表 可与传统语言结合使用，作为该目标语言的预处理器或扩展程序。Umple 编译器在目标语言中转换 Umple 代码，并保持现有目标语言不变。 由于其对 UML 状态机的大量支持，它可以作为状态机生成器使用。根据 Umple 对状态机的描述，可以生成许多目标语言的实现。 1 2 3 4 5 6 7 8 9 10 class Student {} class CourseSection {} class Registration { String grade; * -- 1 Student; * -- 1 CourseSection; } 下面的 Umple 代码描述的是一个状态机。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class GarageDoor { status { Open { buttonOrObstacle -\u0026gt; Closing; } Closing { buttonOrObstacle -\u0026gt; Opening; reachBottom -\u0026gt; Closed; } Closed { buttonOrObstacle -\u0026gt; Opening; } Opening { buttonOrObstacle -\u0026gt; HalfOpen; reachTop -\u0026gt; Open; } HalfOpen { buttonOrObstacle -\u0026gt; Opening; } } } Telosys Telosys 设计用于生成所有管道和重复代码。它不需要使用 UML，但允许用户从起始数据库或使用 DSL 生成模型。它是一个有趣且易于使用的解决方案，还以 Eclipse 插件的形式提供 IDE 支持。\nurl：https://tomassetti.me/telosys-code-generation-tool/ 数据库相关代码 这一切都围绕着一个数据库模式展开，而代码就是从这个模式中生成的，或者是从一个数据库中生成一个模式。之所以可以使用这些生成器，有两个原因：\n关系数据库支持与之交互的标准语言（SQL） 编程语言中存在与数据库交互的广泛模式和库 这两个原因保证了在编程语言和包含程序所需数据的数据库之间创建标准胶合代码成为可能。在实践中，数据库模式可以作为一个简单的模型，用来生成代码。\n许多框架或集成开发环境都包含从类生成数据库模式的基本工具，反之亦然，生成与数据库表交互的类。在本节中，我们将看到一个可以做更多事情的工具示例。\nCelerio Celerio 是面向数据应用程序的代码生成工具。\nCelerio 是一款 Java 工具，其中包括一个数据库提取器，用于从现有数据库中获取数据库模式。然后，它将生成的模式与配置文件结合起来，然后启动模板引擎，以创建整个应用程序。提取的数据库模式为 XML 格式。\nDomain Specific Language（DSL） DSL 是以正规化方式捕捉业务逻辑的好方法。之后，需要以某种方式执行这些逻辑。虽然有时会使用解释器和编译器来执行 DSL，但代码生成器却经常被使用。通过这种方式，DSL 可以被翻译成已经存在编译器的语言，如 Java 或 C#。\n现在，可以使用语言工作台来构建 DSL，语言工作台是专门为设计和实现 DSL 而设计的集成开发环境。语言工作台之所以有用，是因为它们还能以较低的成本为 DSL 定义编辑器和其他支持工具。这一点非常重要，因为非开发人员也可以使用 DSL，他们需要定制的编辑器来利用语言的功能，或者根本无法使用普通的文本编辑器。除其他功能外，语言工作台通常还集成了代码生成功能。让我们来看几个例子。\nJetBrains MPS\nJetBrains MPS 是基于项目编辑器的语言工作台。您可以用它创建一个或多个 DSL。它还可用于扩展现有语言。例如，mbeddr 就是基于 JetBrains MPS 的 C 语言扩展，用于改进嵌入式编程。\n所谓投影式编辑器，是指 MPS 会保留数据的基本结构，并以易于编辑的形式显示出来。这个概念可能有点难以理解。想想传统的编程：你写出源代码，然后编译器将源代码转换为逻辑表示，即解析树。编译器使用这种表示法来执行一些操作，如优化或将其转换为机器代码来执行。使用项目编辑器，您可以直接处理逻辑表示：解析树。不过，您只能按照编辑器（MPS）允许的方式对其进行修改。\n这样做的主要后果是，当使用 JetBrains MPS 创建 DSL 时，您需要整个集成开发环境及其所有功能和功能。您可以获得语法高亮、代码自动补全、项目管理等功能。\n不过，这种方法的优势在于，您可以创建一个使用任何形式的输入来修改代码的 DSL，因此您可以创建一个图形编辑器、一个表格输入，甚至是普通文本。这一优势使得创建非程序员也能使用的 DSL 特别有用。\nXtext Xtext 是一种语言工作台，构建于 Eclipse 和 Eclipse Modeling Framework 之上。它可用于设计文本 DSL 并为其获取编辑器。 从功能上讲，Xtext 是不同工具（如用于解析的 ANTLR、用于用户界面的 Eclipse 等）的组合，用于生成 DSL。\nJulia 让我们看看 Julia 中宏的示例，Julia 是一种受 Lisp 启发的语言，它的语法更易于理解。\n1 2 3 4 5 6 7 8 9 10 11 12 13 julia\u0026gt; macro twostep(arg) println(\u0026#34;I execute at parse time. The argument is: \u0026#34;, arg) return :(println(\u0026#34;I execute at runtime. The argument is: \u0026#34;, $arg)) end @twostep (macro with 1 method) julia\u0026gt; ex = macroexpand( :(@twostep :(1, 2, 3)) ); julia\u0026gt; ex # the macro itself :((println)(\u0026#34;I execute at runtime. The argument is: \u0026#34;, $(Expr(:copyast, :($(QuoteNode(:((1, 2, 3))))))))) julia\u0026gt; eval(ex) # execution of the macro I execute at runtime. The argument is: (1, 2, 3) 可以看出，执行宏和执行宏返回的表达式是两码事。\n这个非常强大的功能可以用于代码生成：你不需要外部工具来创建模板代码，你可以从内部创建。在下面摘自 Julia 文档的示例中，你可以看到它是如何定义一系列新的三元运算符的。\n1 2 3 for op = (:+, :*, :\u0026amp;, :|, :$) eval(:(($op)(a,b,c) = ($op)(($op)(a,b),c))) end 代码利用已定义的二元运算符定义了这些新的三元运算符：\n在前两个元素之间进行基本的二进制运算 然后在第一个运算结果和第三个元素之间再次进行运算 请注意，Julia 的标准语法与传统语言类似：没有奇怪的括号，表达式正常等。然而，当您使用元编程功能时，您将使用类似 Lisp 的内部语法。\n这只是冰山一角，你可以查阅 Julia 手册，进一步了解元编程的强大功能。\nRacket 如果你想在元编程方面做得更多，可以使用 Racket，这是一种受 Lisp 和 Scheme（另一种受 Lisp 影响的语言）启发的语言。\nRacket 同时是一种语言和一个平台，它被设计成一种可以定义其他语言的语言。因此，它甚至可以使用比宏更强大的元编程功能。Racket 可以定义全新的语言，改变基本语言的语法。它之所以能做到这一点，基本上是因为它允许你改变解析本身。\nRacket 的传统语法类似 Lisp。\n1 2 3 (define (four p) (define two-p (hc-append p p)) (vc-append two-p two-p)) 你可以改变它，例如，你可以创建一种语言来定义文档：Scribble\n1 2 3 4 5 6 #lang scribble/base @title{On the Cookie-Eating Habits of Mice} If you give a mouse a cookie, he\u0026#39;s going to ask for a glass of milk. 该语言允许您创建 HTML、PDF 等文件。您可以在语言中定义结构，然后生成所需的任何输出。\n这是一个与元编程和 DSL 相匹配的全新层次：您可以使用类似 DSL 的易用界面轻松创建自定义生成器。当目标受众是其他开发人员时，可以采用这种方法。这是因为您虽然获得了一种功能强大的语言，但它仅仅是一种语言而已。如果使用语言工作台，您就可以拥有一整套强大的编辑工具，帮助普通用户使用语言。\nAd-Hoc Applications 这一类包括所有内容：从为处理一件事情而设计的工具到在企业环境中使用的临时系统，这些系统可以根据正式的自定义描述生成整个应用程序。这些应用程序通常是特定工作流程的一部分。例如，客户使用图形界面描述一个应用程序，一个临时系统会生成支持该应用程序的数据库模式，另一个系统会生成 CRUD 界面等。\n这不是一个正确定义的类别，而是一个总括类别，包括不属于特定组别的所有内容。这意味着这组程序没有标准结构。这也证明了代码生成的多功能性：如果你能创建一个问题模型或描述，那么你就能用代码生成来解决问题。当然，你还必须了解解决一般问题和创建代码生成工具是否有意义，还是直接解决问题更好。\n在本节中，我们将讨论两种工具：CMake 是一款开发工具，而 Yeoman 则是一款脚手架工具。前者主要是生成配置文件：为其他软件提供支持的软件。第二种工具简化了开发人员的工作，提供了一种创建即用项目的方法，可针对特定软件平台、库或需求进行优化。\nCMake CMake 是一个开源、跨平台的工具系列，用于构建、测试和打包软件。\nCMake 包括三个开发工具，用于帮助开发 C 和 C++。主要工具旨在为不同平台和工具链生成构建文件（即 makefile 和项目文件）。例如，它可以生成 Linux 的 makefile 和 Visual Studio 项目文件。\nCMake 不是编译器。用户以 CMake 格式定义项目结构，然后该工具会生成传统构建过程中使用的普通构建文件。\nCMake 文件看起来像一系列命令/宏，用于为编译器设置选项/标志、链接库、执行自定义命令等。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 cmake_minimum_required(VERSION 2.8) project(\u0026#34;Antlr-cpp-tutorial\u0026#34;) [..] if (NOT WIN32) set(CMAKE_CXX_FLAGS \u0026#34;-Wdeprecated -Wno-attributes\u0026#34; ) endif() [..] if(APPLE) add_custom_command(TARGET antlr4-tutorial POST_BUILD COMMAND ${CMAKE_COMMAND} -E copy_if_different \u0026#34;${PROJECT_SOURCE_DIR}/libs/antlr4-runtime.dylib\u0026#34; $\u0026lt;TARGET_FILE_DIR:antlr4-tutorial\u0026gt;) endif() Yeoman Yeoman 是一个通用的脚手架系统，可以创建任何类型的应用程序。\n如今，要成为一名优秀的程序员，意味着不仅仅要知道如何编码。你需要了解你所使用的每种工具的最佳实践，并记住每次都要执行它们。编写代码本身就已经很困难了，如果还需要正确编写配置文件和使用正确的项目结构，那就更难了。这就是像 Yeoman 这样的工具的用武之地：它是一款脚手架工具，只需一条命令就能生成一个新项目，并立即实施所有最佳实践。\nYeoman 的核心是一个生成器生态系统，开发人员可以在此基础上构建自己的模板。该工具非常受欢迎，已有数千个模板可供使用。\nYeoman 是一款 JavaScript 应用程序，因此编写生成器只需编写 JavaScript 代码并使用提供的 API 即可。工作流程也非常简单：向用户询问项目信息（如名称），收集配置信息，然后生成项目。\n以下代码展示了生成器的部分示例，用于创建 Yeoman 模板。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 function makeGeneratorName(name) { name = _.kebabCase(name); name = name.indexOf(\u0026#39;generator-\u0026#39;) === 0 ? name : \u0026#39;generator-\u0026#39; + name; return name; } module.exports = class extends Generator { initializing() { this.props = {}; } prompting() { return askName( { name: \u0026#39;name\u0026#39;, message: \u0026#39;Your generator name\u0026#39;, default: makeGeneratorName(path.basename(process.cwd())), filter: makeGeneratorName, validate: str =\u0026gt; { return str.length \u0026gt; \u0026#39;generator-\u0026#39;.length; } }, this ).then(props =\u0026gt; { this.props.name = props.name; }); } [..] writing() { const pkg = this.fs.readJSON(this.destinationPath(\u0026#39;package.json\u0026#39;), {}); const generatorGeneratorPkg = require(\u0026#39;../package.json\u0026#39;); [..] this.fs.writeJSON(this.destinationPath(\u0026#39;package.json\u0026#39;), pkg); } conflicts() { this.fs.append(this.destinationPath(\u0026#39;.eslintignore\u0026#39;), \u0026#39;**/templatesn\u0026#39;); } install() { this.installDependencies({ bower: false }); } }; Resources https://tomassetti.me/code-generation/ ","permalink":"https://WFUing.github.io/posts/tech/language/code-generation/a-guide-to-code-generation/","summary":"为什么要用代码生成 productivity：使用代码生成，只需编写一次 generator ，就可以根据需要多次重复使用。向 generator 提供特定输入并调用它比手动编写代码要快得多，因此代码生成可以节省时间。 Simplification：通过代码生成，你可以从一些抽象的描述中生成代码。需要维护的部分变成了 generator 的输入部分，该部分通常是代码的描述，而不是代码本身，与整个生成的代码相比，该描述通常更容易分析和检查。 Portability：一旦你有了为某种语言或框架生成代码的程序，你就可以简单地更改 generator ，并以不同的语言或框架为目标。您还可以同时针对多个平台。 例如，使用解析器生成器，您可以获得 C#、Java 和 C++ 的 parser。 另一个例子：您可能会编写一个 UML 图表，然后使用代码生成器用 C# 创建一个骨架类，并用 SQL 代码为 MySQL 创建一个数据库。因此，相同的抽象描述可用于生成不同类型的工件。 Consistency：有了代码生成，你总能得到你所期望的代码。生成的代码是根据相同的原则设计的，命名规则等也是一致的。当然，除了生成器中的 bug 之外，代码总是能按照你所期望的方式运行，代码质量始终如一。如果用手工编写代码，不同的开发人员可能会使用不同的风格，即使是最重复的代码也会偶尔出现错误。 为什么不要用代码生成 Maintenance：当您使用代码生成工具时，您的代码就会依赖于它。代码生成工具必须得到维护。如果你创建了它，你就必须不断更新它；如果你只是使用现有的工具，你就必须希望有人继续维护它，或者你必须自己接手。因此，代码生成的优势并不是免费的。如果你没有或找不到合适的能力来维护代码生成器，风险就会更大。 Complexity：自动生成的代码往往比手工编写的代码更复杂。有时，这与将不同部分连接在一起所需的胶水代码有关，或者与生成器支持的用例多于您所需的用例有关。在第二种情况下，生成的代码可以做比你想要的更多的事情，但这并不一定是一种优势。生成代码的优化程度肯定也不如手工编写的代码。有时这种差异很小，并不明显，但如果您的应用程序需要尽可能地提高性能，那么生成的代码对您来说可能并不是最佳选择。 如何使用代码生成? 根据具体情况，代码生成既可以提高工作效率，也可以成为开发过程中的重要组成部分。许多现代集成开发环境就是一个有用的例子：只需点击一个按钮，就能创建一个骨架类来实现接口或类似功能。你完全可以自己编写这样的代码，只不过会浪费一些时间来完成琐碎的任务。\n设计代码生成流水线的方法有很多种。基本上，我们需要定义两个要素：\nInput：用于生成代码的信息来自何处。 Output：如何获得生成的代码。 您也可以在输入和输出之间设置转换步骤。这些步骤可以简化输出层，并使输入和输出更加独立。\nPossible Inputs\nA DSL：例如，我们可以使用 ANTLR 来描述一种语言的语法。由此，我们可以生成一个解析器。 code in other formats：数据库模式。根据数据库模式，我们可以生成 DAO。 wizards：它们允许向用户询问信息。 reverse engineering：可通过处理复杂的代码工件获得信息。 data sources：比如一个DB，一个csv文件或者一个电子表格。 Possible Outputs\ntemplate engine：大多数网络程序员都知道模板引擎，它用于在 HTML UI 中填充数据。 code building APIs：例如，Javaparser 可用于以编程方式创建 Java 文件。 Some Pipelines","title":"A Guide to Code Generation"},{"content":"案例驱动 通过几个简单的例子来解释和总结什么是交叉熵（Cross Entropy）以及机器学习分类问题中为什么使用交叉熵。\n第一个例子 假设随机从一个口袋里取硬币，口袋里有一个蓝色的，一个红色的，一个绿色的，一个橘色的。取出一个硬币之后，每次问一个问题，然后做出判断，目标是，问最少的问题，得到正确答案。其中一个最好的设计问题的策略如下：\n每一个硬币有 $\\frac{1}{4}$ 的概率被选中，$\\frac{1}{4}机率 * 2道题目 * 4颗球 = 2$，平均需要问两道题目才能找出不同颜色的球，也就是说期望值为 $2$，就是熵（entropy）。\n第二个例子 例子变了，变成了袋子中 $\\frac{1}{8}$ 的硬币是绿色的，$\\frac{1}{8}$ 的是橘色的，$\\frac{1}{4}$ 是红色的，$\\frac{1}{2}$ 是蓝色的，这时最优的问题的策略如下:\n$\\frac{1}{2}$ 的概率是蓝色，只需要 $1$ 个问题就可以知道是或者不是，$\\frac{1}{4}$ 的概率是红色，需要2个问题，按照这个逻辑，猜中硬币需要的问题的期望是\n$$ \\frac{1}{2}*1+\\frac{1}{4}*2+\\frac{1}{8}*3+\\frac{1}{8}*3=1.75 $$\n第三个例子 假设袋子中全部是蓝色的硬币，那么这时候需要 $0$ 个问题就可以猜到硬币，即 $\\log_{2}{1}=0$。 需要注意的是，只有当知道袋子中全部是蓝色的硬币的时候需要的问题是 $0$ 个。\n总结上面的例子，假设一种硬币出现的概率是 $p$，那么猜中该硬币的所需要的问题数是 $\\log_2{\\frac1{P_i}}$。例如 $p=\\frac{1}{4}，\\log_{2}{4}$ 。\n在这个问题中，问题个数的期望是\n$$ \\sum_i{p_i}*log_2{\\frac{1}{p_i}} $$\n这个式子就是熵的表达式 。简单来说，其意义就是在最优化策略下，猜到颜色所需要的问题的个数。熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。\n现在已经了解了熵是什么，那么，下面解释交叉熵（cross entropy） 的含义.对于第二个例子，如果仍然使用第一个例子中的策略，如下图:\n$\\frac{1}{8}$ 的概率，硬币是橘色，需要两个问题，$\\frac{1}{2}$ 的概率是蓝色，仍然需要两个问题，也就是说，认为小球的分布为 $(\\frac{1}{4},\\frac{1}{4},\\frac{1}{4},\\frac{1}{4})$ ，这个分布就是非真实分布。平均来说，需要的问题数是 $\\frac{1}{8}*2+\\frac{1}{8}*2+\\frac{1}{4}*2+\\frac{1}{2}*2=2$ 。\n因此，在例子二中使用例子一的策略是一个比较差的策略。其中 $2$ 是这个方案中的交叉熵，而最优方案的交叉熵是 $1.75$。\n给定一个策略，交叉熵就是在该策略下猜中颜色所需要的问题的期望值。更普遍的说，交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出成本的大小。交叉的字面意思在于：真实分布与非真实分布的交叉。给定一个方案，越优的策略，最终的交叉熵越低。具有最低的交叉熵的策略就是最优化策略，也就是上面定义的熵。因此，在机器学习中，我们需要最小化交叉熵。\n数学上来讲 其中，$p$ 是真正的概率，例如例子二中，橘色和绿色是 $\\frac{1}{8}$，红色是 $\\frac{1}{4}$，蓝色是 $\\frac{1}{2}$。$\\hat p$ 是错误地假设了的概率，例如，在例子二中我们错误地假设了所有的颜色的概率都是 $\\frac{1}{4}$。$p$ 和 $\\hat p$ 可能有点容易混淆。记住一点，$log$ 是用来计算在你的策略下猜中所需要的问题数，因此，$log$ 中需要的是你的预测概率 $\\hat p$ 。在决策树中，如果建立的树不是最优的，结果就是对于输出的概率分布的假设是错误地，导致的直接结果就是交叉熵很高。交叉熵不仅仅应用在决策树中，在其他的分类问题中也有应用。\n分类问题 在二分类问题中，标签 $y$ 是 $1$ 的似然是对于标签 $y$ 的预测 $\\hat y$ ，同样的，标签是 $0$ 的似然是 $1-\\hat y$ 。我们需要最大化似然函数，而且，由于二分类问题的特殊性，根据伯努力分布 (Bernoulli distribution)，可以把似然函数写成\n当 $y=1$ 的时候，第二项为 $1$，因此，优化的是 $\\hat y$ 当 $y=0$ 的时候，第一项为 $1$，优化的是 $1-\\hat y$ 。 对上面的似然函数取对数，结果是最大化似然函数，就是对上面表达式取负然后最小化。也是交叉熵的表达式。\n交叉熵有时候也被称为对数损失函数。注意与上边例子区别是多了个负号，上边例子是消除不确定性需要付出的成本；而现在这个加了负号的交叉熵，则是最终的目标函数。\n举例来说，假设我有 $3$ 枚硬币，正正反，记为 $(1,1,0)$ 。预测结果是 $(0.8,0.9,0.3)$，那么，交叉熵的均值是:\n$$ \\frac13(1×\\log_20.8+1×log_20.9+(1-0)×log_2(1-0.3)) $$\n假设有一个完美的算法，直接预测出了 $(1,1,0)$，那么交叉熵的结果就是 $0$。\n","permalink":"https://WFUing.github.io/posts/tech/algorithm/ai/cross-entropy/","summary":"案例驱动 通过几个简单的例子来解释和总结什么是交叉熵（Cross Entropy）以及机器学习分类问题中为什么使用交叉熵。\n第一个例子 假设随机从一个口袋里取硬币，口袋里有一个蓝色的，一个红色的，一个绿色的，一个橘色的。取出一个硬币之后，每次问一个问题，然后做出判断，目标是，问最少的问题，得到正确答案。其中一个最好的设计问题的策略如下：\n每一个硬币有 $\\frac{1}{4}$ 的概率被选中，$\\frac{1}{4}机率 * 2道题目 * 4颗球 = 2$，平均需要问两道题目才能找出不同颜色的球，也就是说期望值为 $2$，就是熵（entropy）。\n第二个例子 例子变了，变成了袋子中 $\\frac{1}{8}$ 的硬币是绿色的，$\\frac{1}{8}$ 的是橘色的，$\\frac{1}{4}$ 是红色的，$\\frac{1}{2}$ 是蓝色的，这时最优的问题的策略如下:\n$\\frac{1}{2}$ 的概率是蓝色，只需要 $1$ 个问题就可以知道是或者不是，$\\frac{1}{4}$ 的概率是红色，需要2个问题，按照这个逻辑，猜中硬币需要的问题的期望是\n$$ \\frac{1}{2}*1+\\frac{1}{4}*2+\\frac{1}{8}*3+\\frac{1}{8}*3=1.75 $$\n第三个例子 假设袋子中全部是蓝色的硬币，那么这时候需要 $0$ 个问题就可以猜到硬币，即 $\\log_{2}{1}=0$。 需要注意的是，只有当知道袋子中全部是蓝色的硬币的时候需要的问题是 $0$ 个。\n总结上面的例子，假设一种硬币出现的概率是 $p$，那么猜中该硬币的所需要的问题数是 $\\log_2{\\frac1{P_i}}$。例如 $p=\\frac{1}{4}，\\log_{2}{4}$ 。\n在这个问题中，问题个数的期望是\n$$ \\sum_i{p_i}*log_2{\\frac{1}{p_i}} $$\n这个式子就是熵的表达式 。简单来说，其意义就是在最优化策略下，猜到颜色所需要的问题的个数。熵代表的是随机变量或整个系统的不确定性，熵越大，随机变量或系统的不确定性就越大。\n现在已经了解了熵是什么，那么，下面解释交叉熵（cross entropy） 的含义.对于第二个例子，如果仍然使用第一个例子中的策略，如下图:\n$\\frac{1}{8}$ 的概率，硬币是橘色，需要两个问题，$\\frac{1}{2}$ 的概率是蓝色，仍然需要两个问题，也就是说，认为小球的分布为 $(\\frac{1}{4},\\frac{1}{4},\\frac{1}{4},\\frac{1}{4})$ ，这个分布就是非真实分布。平均来说，需要的问题数是 $\\frac{1}{8}*2+\\frac{1}{8}*2+\\frac{1}{4}*2+\\frac{1}{2}*2=2$ 。\n因此，在例子二中使用例子一的策略是一个比较差的策略。其中 $2$ 是这个方案中的交叉熵，而最优方案的交叉熵是 $1.75$。\n给定一个策略，交叉熵就是在该策略下猜中颜色所需要的问题的期望值。更普遍的说，交叉熵用来衡量在给定的真实分布下，使用非真实分布所指定的策略消除系统的不确定性所需要付出成本的大小。交叉的字面意思在于：真实分布与非真实分布的交叉。给定一个方案，越优的策略，最终的交叉熵越低。具有最低的交叉熵的策略就是最优化策略，也就是上面定义的熵。因此，在机器学习中，我们需要最小化交叉熵。\n数学上来讲 其中，$p$ 是真正的概率，例如例子二中，橘色和绿色是 $\\frac{1}{8}$，红色是 $\\frac{1}{4}$，蓝色是 $\\frac{1}{2}$。$\\hat p$ 是错误地假设了的概率，例如，在例子二中我们错误地假设了所有的颜色的概率都是 $\\frac{1}{4}$。$p$ 和 $\\hat p$ 可能有点容易混淆。记住一点，$log$ 是用来计算在你的策略下猜中所需要的问题数，因此，$log$ 中需要的是你的预测概率 $\\hat p$ 。在决策树中，如果建立的树不是最优的，结果就是对于输出的概率分布的假设是错误地，导致的直接结果就是交叉熵很高。交叉熵不仅仅应用在决策树中，在其他的分类问题中也有应用。","title":"交叉熵"},{"content":" 英文名: WDS 职业: 程序员 运动: 跑步、乒乓球、爬山 ","permalink":"https://WFUing.github.io/about/","summary":" 英文名: WDS 职业: 程序员 运动: 跑步、乒乓球、爬山 ","title":"🙋🏻‍♂️"}]